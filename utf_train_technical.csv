"When controller is working as Device then host part of controller is held in reset andvice versa, so driver has restricted access to registers.Thanks,Cheers,Pawel Laszczak",Technical
,
"Switching role form user space will limited driver only to selected mode.Only for USB_DR_MODE_OTG driver should base on ID pin.That's my intension.Thanks,Cheers,Pawel",Technical
,
"Yes, I know and I agree with you.I have plan to replace this with tracepoints.But I need some time for this. Currently I'm focusing on testing.Probably  I will change It by the end of this month, so it should be inRFC PATCH v3.Thanks,Cheers,Pawell",Technical
,
"User space setting should override ID if it was OTG mode. At least this is howit is for dwc3. That way it is useful for testing role swap.cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
I think you should send it to ASoC maintainer and list for applying.Shawn,Technical
,
"Hi Shawn,It's still quite new for me to submit patch, but if this patch shouldbe sent to ASoC maintainer maybe there is a line missing in theMAINTAINERS file no ?SOUNDM:      Jaroslav Kysela <perex@perex.cz>M:      Takashi Iwai <tiwai@suse.com>L:      alsa-devel@alsa-project.org (moderated for non-subscribers)W:      http://www.alsa-project.org/T:      git git://git.kernel.org/pub/scm/linux/kernel/git/tiwai/sound.gitT:      git git://git.alsa-project.org/alsa-kernel.gitQ:      http://patchwork.kernel.org/project/alsa-devel/list/S:      MaintainedF:      Documentation/sound/+ F:      include/dt-bindings/sound/F:      include/sound/F:      include/uapi/sound/F:      sound/Regards,Clement",Technical
,
"@Mark, comment?Shawn",Technical
,
"Adding a file pattern for this seems sensible, yes.",Technical
,
"Hi Mark,OK,I will send a v2 for the IMX6 Audmux bindings with ASoC List and Maintainers.Thanks,Clement",Technical
,
"Hi Peter,This is v2 patch. I'm sorry that I forgot to add theword ""v2"" to the subject.Yours,Muchun Song",Technical
,
"AFAICS this will break e.g. x86 which can have both ZONE_DMA andZONE_DMA32, and now you would make kmalloc(__GFP_DMA) return objectsfrom ZONE_DMA32 instead of __ZONE_DMA, which can break something.Also I'm probably missing the point of this all. In patch 3 you use__get_dma32_pages() thus __get_free_pages(__GFP_DMA32), which usesalloc_pages, thus the page allocator directly, and there's no slabcaches involved. It makes little sense to involve slab for page tableallocations anyway, as those tend to be aligned to a page size (orhigh-order page size). So what am I missing?",Technical
,
"Oh, I was not aware that both ZONE_DMA and ZONE_DMA32 can be definedat the same time. I guess the test should be inverted, something likethis (can be simplified...):#ifdef CONFIG_ZONE_DMA#define SLAB_CACHE_DMA_GFP GFP_DMA#elif defined(CONFIG_ZONE_DMA32)#define SLAB_CACHE_DMA_GFP GFP_DMA32#else#define SLAB_CACHE_DMA_GFP GFP_DMA // ?#endif__get_dma32_pages fixes level 1 page allocations in the patch 3.This change fixes level 2 page allocations(kmem_cache_zalloc(data->l2_tables, gfp | GFP_DMA)), by transparentlyremapping GFP_DMA to an underlying ZONE_DMA32.The alternative would be to create a new SLAB_CACHE_DMA32 whenCONFIG_ZONE_DMA32 is defined, but then I'm concerned that the callerswould need to choose between the 2 (GFP_DMA or GFP_DMA32...), and alsoneed to use some ifdefs (but maybe that's not a valid concern?).Level 2 tables are ARM_V7S_TABLE_SIZE(2) => 1kb, so we'd waste 3kb ifwe allocated a full page.Thanks,",Technical
,
"Oh, I see.Well, I think indeed the most transparent would be to supportSLAB_CACHE_DMA32. The callers of kmem_cache_zalloc() would then need notadd anything special to gfp, as that's stored internally uponkmem_cache_create(). Of course SLAB_BUG_MASK would no longer have totreat __GFP_DMA32 as unexpected. It would be unexpected when passed tokmalloc() which doesn't have special dma32 caches, but for a cacheexplicitly created to allocate from ZONE_DMA32, I don't see why not. I'msomewhat surprised that there wouldn't be a need for this earlier, somaybe I'm still missing something.",Technical
,
Do you have any numbers for how much difference this change makes withvarious different workloads?,Technical
,
"Ð¿Ð½, 12 Ð½Ð¾ÑÐ±. 2018 Ð³. Ð² 6:58, Matthew Wilcox <willy@infradead.org>:Yep, i got some non KVM numbers,Formulas: Percentage - (pages_sharing - pages_shared)/pages_unshared Memory saved - (pages_sharing - pages_shared)*4/1024 MiB- My working laptop: 5% - ~100 MiB saved ~2GiB used  Many different chrome based apps + KDE- K8s test VM:  40% - ~160 MiB saved ~920MiB used  With some small running docker images- Ceph test VM: 20% - ~60MiB saved ~600MiB used  With ceph mon, osd.Develop cluster servers:- K8s server backend: 72%, ~5800 MiB saved ~35.7 GiB used  (With backend apps: C, java, go & etc server apps)- K8s server processing: 55%, ~2600 MiB saved ~28 GiB used  (90% of load many instance of one CPU intensive application)- Ceph node: 2%, ~190 MiB saved ~11.7 GiB used  (OSD only)So numbers, as always depends on the load.Thanks!- - -P.S.On recent kernels (4.19) i see BUG_ON message, that ksmd scheduledwhile in critical section/atomic context,not sure how to properly fix that.(If i understood correctly, i can use preempt_disable(); but thatlooks more like hack, not a fix).Any feedback are welcome.",Technical
,
"Hi Alan,Isn't it more straight-forward to use ""rcu-rscs^-1"" other than""rcu-rscsi"" in the definition of ""rcu-fence"", is it?The introduction of ""rcu-rscsi"" makes sense in the first patch, but withthis refactoring, I think it's better we just don't use it.Regards,Boqun",Technical
,
It's a matter of personal preference.  I prefer to store the inverserelation in a separate variable rather than recomputing it multipletimes.  (Maybe OCaml is smart enough to recognize when a value hasalready been computed and avoid computing it again; I don't know.)In the end this probably doesn't make much difference.Alan,Technical
,
"On Thu, 22 Nov 2018 17:54:54 +0000Vitor Soares <vitor.soares@synopsys.com> wrote:Isn't it too early to do this change? Can't we wait until we have a SoCthat actually embeds this IP?I'd prefer to have a dw/ subdir where you'd place all dw files.Do we really have to create one module for the core and one per SoC?Can't we have everything in the same .ko?",Technical
,
"Hi Boris,I'm trying to turn it more flexible so the other can reuse the code.Sure. I will change to this:../dwc Â Â  |-core.h Â Â  |-master.c Â Â  |-platdrv.cso the user doesn't need to write dw-i3c.. several times. The foldername is the same as for other subsystem (e.g. PCI).What do you think?This will help the introduction of new modules. The design in my mind isto have:-core.h-common.c-master.c-slave.c...I'm not sure if make sense to change core.h to common.h.Thaks for your feedback.Best regards,Vitor Soares",Technical
,
"On Fri, 23 Nov 2018 12:39:31 +0000vitor <vitor.soares@synopsys.com> wrote:Looking at the separation you've done here, I don't see why you needit. All the resources you request are generic, so why not just adding anew compat in the of_match_table?Just realized the driver is named dw-i3c-master, while the cadencedriver is named i3c-master-cdns.c. I'll send a patch to make thatconsistent and follow the initial naming scheme: i3c-master-<ipname>.c.",Technical
,
"Hi Boris,I understand your point.I'm just following what it's done in others Synopsys drivers and what Iexpect is that in the future we will have the same for the I3C.Some of the current generic functions might be override according withSoC requirements (e.g i2c-designware, pcie-designware).for now what do you prefer?As I shared with you in previous email, the structure that I have inmind is this one:- core.h (or common.h, any though?)- common.c- master.c- slave.cso for me doesn't make sense to have for instance: i3c-master-dw-slave.cBut seeing what is already in the kernel I wasn't coherent and it shouldbe named to i3c-designware-master.corfollow this https://lkml.org/lkml/2017/7/12/430This topic rise another one related with the master folder. I understandthat now the subsystem doesn't have slave support but the name islimited. Isn't better to have something like controller or busses? Whatdo you have in mind for the slave?Best regards,Vitor Soares",Technical
,
"On Mon, 26 Nov 2018 12:06:24 +0000vitor <vitor.soares@synopsys.com> wrote:I prefer that we keep the driver as is until we actually need to splitthings up.If you have several files and they're all placed in a dw/ subdir, thenI agree, prefixing everything with i3c-master- is useless, as you'llhave to define a custom rule to create the i3c-master-dw.ko object.When there's a single source file, and this source file is directlyused to create a .ko, we need this prefix, otherwise we would havedw.ko, and this would basically conflict with any other designwaredriver that does not have a proper prefix.Actually it's i3c-master-designware.c (or i3c-master-dw.c) if we followwhat's been done for the cadence driver.And I agree with Linus on this, except that does not apply to singlesource file drivers.drivers/i3c/slave/... for slave drivers and drivers/i3c/slave.c for theframework, just like we have drivers/i3c/master/ for master controllerdrivers and drivers/i3c/master.c.",Technical
,
"This is already done and will benefit everyone: Â Â Â  - for me is better do it now than the secondary master and slavedevelopment. Â Â Â  - for the others it will easy the SoC integration avoidingduplicated work and doing things from scratch.I was referring to what was made in other modules and should be appliedhere too.I have to disagree here. I don't see any place on the kernel with.../master/ and ../slave/ folders and it is very likely that both ruleswill have some common code.With this structure the user will have the code spread in /master and/slave folders...I would like you consider to change the folder name and the names rulesto something like in i2c.Maybe someone else can give his opinion too.Best regards,Vitor Soares",Technical
,
"On Mon, 26 Nov 2018 18:33:37 +0000vitor <vitor.soares@synopsys.com> wrote:Sorry, I don't get that one.What would be duplicated? You want to support a new SoC, just add a newentry in the of_match_table and you're done. When you need to addSoC/integration specific stuff, create a struct and attach a differentinstance per-compatible so that each SoC can have its own configuration(or even init sequence if needed). That's how we do for pretty much allIPs out there, why should designware ones be different?This is a subsystem decision. I don't mind changing the naming scheme,though I don't see why yours is better than the one I initiallyproposed. In any case, what's important here is to keep driver namesconsistent.I see at least one that uses this model: the USB framework(drivers/usb/gadget/ for device controllers and drivers/usb/host/ forhost controllers). Given that I3C is closer to USB than I2C I initiallydecided to keep this separation. Maybe I'm wrong, but I'd like tounderstand why you think it's not appropriate.Not sure who you call ""user"" here, but yes, master controller and slavecontroller drivers would be placed in different dirs.Why? And more importantly, why is this coming up now? You've beenreviewing the framework since the beginning, and never complained aboutthe subdirs/files organization so far.I'm okay changing it, but I want to understand why the proposedseparation is not good.",Technical
,
"On Mon, 26 Nov 2018 19:56:18 +0100Boris Brezillon <boris.brezillon@bootlin.com> wrote:To be more specific, I'd like a real example that shows why theseparation is needed.",Technical
,
"On Mon, 26 Nov 2018 19:28:02 +0000vitor <vitor.soares@synopsys.com> wrote:I finally understand what this separation is all about: supporting bothPCI and platform devices. I guess I've been distracted by this sentence:""This patch will allow SOC integrators to add their code specific toDesignWare I3C IP.""which for me meant each SoC would have its own platform_driver.In any case, I think this is a bit premature do this separation, unlessyou already know about one integrator planning to expose this IP overPCI.",Technical
,
"I already share my plan with you. See the structure above.You can say there some features from USB in I3C but cannot compare USBvs I3C since they are in different championships.The aim of I3C is to fill the gaps discovery on I2C over the years butstill keeping its simplicity not to go to the complexity of USB.I'm not sure but I think that a controller cannot change between gadgetto host in USB in runtime. Even so, this kind of behavior is more likelyto have in an I3C bus.Sorry for that and don't take me wrong... maybe I should rise thisquestion early but this only came up now when I started splitting andthinking where to put what is for master for slave, what is common andthe thing of putting everything of controller in a folder.Taking the USB as exemple do you prefer a dwc folder on i3c root?I already tell you my use case and as I said maybe someone can advise :)",Technical
,
"On Mon, 26 Nov 2018 20:11:39 +0000vitor <vitor.soares@synopsys.com> wrote:My point is, I don't get the relationship between your patch andsecondary-master/slave-mode support.I maintain that functionally, I3C is closer to USB than I2C. That doesnot mean that it's competing with USB performance-wise, it just meansthat the SW stack is likely to resemble the USB one (probably a bitsimpler, at least at the beginning).Look at the bus discovery mechanism, the notion of DCR (close to theconcept of USB class), or the fact that each dev has a uniquemanufacturer+PID pair (which resemble the product/vendor ID concept)that allows us to easily bind a dev to a driver without requiring astatic description.That's called USB OTG. Okay, to be fair, it's not exactly the same, andthe mastership handover in I3C is probably more complex than what wehave with USB OTG (I'm not a USB expert, so I might be wrong here).Maybe.So you have such a dual-role controller? I mean, Cadence IP has a dummyGPIO mode in its Master IP when is operating in slave mode (secondarymaster, or main master after it's released the bus), but I'm not surethis was designed for anything else but testing.What I call a slave controller would be something that lets you reply toSDR/DDR transactions or fill a generic regmap that would be exposed toother masters on the bus. This way we could implement generic slavedrivers in Linux (the same way we have gadget drivers). Anything elseis likely to be to specific to be exposed as a generic framework.Hm, not sure I like this idea either. So I see 2 options:1/ put all controller drivers (both master and slave ones) in a common   directory (drivers/i3c/controllers) as you suggest, and prefix them   correctly (i3c-master-<ip>.c, i3c-slave-<ip>.c and i3c-dual-<ip>.c)2/ place them in separate directories: drivers/i3c/{master,slave,dual}I'm fine either way.I think I understand your concerns now, but only because you started tomention a few things that were not clearly stated before (at least, Ididn't understand it this way), like the fact that your controller (andprobably others too) supports dual-role, or the fact that you plan toexpose your IP through the PCI bus.",Technical
,
"Hi Boris,Sorry for the delayed response.I think this should be discuss in another thread. Do you agree?Yes, that was what I trying to tell you. For me this might be the bestoption.I would like to avoid having dual role i3c driver in a master folder.I don't disagree, and for those that have more than one file they shouldbe in a folder, right?What prefix do you have in mind for those files inside a folder?No, it's not. But as you can see to slipt the driver in parts thissubject has some relevance.Best regards,Vitor Soares",Technical
,
Ok no problem. We can delay this for PCI and other rules support.,Technical
,
It's quite unusual for a backlight device to have a trivial binding.The driver supports fairly extensive parametrization via structlm3530a_platform_data. It is really the case that none of theseproperties should ever be set via DT?Daniel.,Technical
,
Similar to my reply to the DT bindings: I would have expected thereto be code to handle DT properties here.Daniel.,Technical
,
"Hi Daniel,I initially assumed that we would let user space configure these valuesonce the system has booted, but you are right that these should beavailable in device tree.The driver has two different LED banks that can be configuredindependently. How do you feel about having a single property indevice tree populate the initial values for both banks? I propose thatwe could use the property default-brightness-level for leda_init_brtand ledb_init_brt in struct lm3630a_platform_data. The max-brightnessproperty can populate leda_max_brt and ledb_max_brt.I need to look at other bindings this weekend to see if there are anystandard properties that I can use for leda_ctrl/ledb_ctrl, pwm_ctrl,and pwm_period.Brian",Technical
,
#NAME?,Technical
,
"Hi Rob,I agree and I'm not going to use a trivial binding for v2. See below forsome questions that I have from my last email.",Technical
,
"Rob/BrianThis is a standard 8-bit white LED driver.  It looks like Brian is just adding DTsupport to load the driver.I would expect that the bindings need to be updated to be able to register one string oranother using the led-sources property.  There are a couple of examples in the kernel anda couple of them in patch form.This driver and binding need to be updated to the latest spec, as you pointed out with child nodes.And Jacek has some new proposed bindings for the LED class so we may want to adopt those standards hereas well.  This is what I am waiting on for agreement so I can update my patch set.Dan--------------------Dan Murphy",Technical
,
"This member is only written to, but never used.This function is only used once. Maybe drop the function and put the ifto the caller.This error message looks wrong, several others, too.return PTR_ERR(clk)?sun8i_pwm is shared for all 8 PWMs, right? So if you assign mux-1 herefor the second mux, how does this influence the first PWM?mux-0 might already be enabled, it is then never disabled.This looks wrong. If val is > 1 there shouldn't be a reason to abort?I'd degrade this to dev_dbg.Noting the underlying formula for the calculation and the bitwidth forthe related register fields above would be good.Why ""<< 0""?sun8i_pwm_config writes the registers that are relevant for period andduty_cycle. When do these values take effect? If it's already here,switching the polarity below might introduce a glitch.Please document how the hardware behaves when being disabled. (Does itdrive a 0? Does it drive a 1 when inverted? Or is the output high-z?)This looks strange to me. While syntactically equivalent it is moreusual to write this as	if (val & PWM_ACT_STA)When the PWM should be enabled, you also set the CLK_GATING bit. Shouldthis better be checked for in .get_state, too?.data doesn't need to be specified.This prevents a match by driver-name, right? Other than that match isonly used to assign pwm->data below to NULL.You might want to handle pwm->clk == ERR_PTR(-EPROBE_DEFER) without fallingback to mux-1 and without printing an error.This is equivalent to	if (ret)because &pwm->chip.npwm is only modified if of_property_read_u32returns 0 and the variable holds a 0 before.dev_dbg?If you do this earlier (typically after the allocation succeeded) youcan simplify the last few lines to:	ret = pwmchip_add(&pwm->chip);	if (ret < 0)		dev_err(&pdev->dev, ...);	return ret;This is at least unusual (and maybe broken). Please call pwmchip_removebefore clk_disable_unprepare.I think the space in the alias must be dropped. Giving that the driverdoesn't bind by driver-name I suggest to drop this completely.Best regardsUwe--Pengutronix e.K.                           | Uwe Kleine-Knig            |Industrial Linux Solutions                 | http://www.pengutronix.de/  |",Technical
,
"Hi!That should be a separate patch.(also, your patch series don't seem to have the threading properlyconfigured, you might want to fix that.)sun8i here (and in the rest of the driver) is too vague. There'salready plenty of SoCs part of the sun8i family that are supported bythe other driver. sun8i-r40 would be a better fit (and there's no needto mention all the rebranding that allwinner has done with the R40,just use R40).This is pretty much reimplementing the clock framework. I guess you'dbe better off just modeling this clock as a clock registered in theframework. It will take care by itself of the combination of muxingand rate, and making sure the parent clocks are properly enabled whenneeded.Do you really need that field if you leave it NULL?Thanks!Maxime--Maxime Ripard, BootlinEmbedded Linux and Kernel engineeringhttps://bootlin.com",Technical
,
"Hello,Given that the documentation is publically available, I suggest to add alink to it in a comment here.(http://linux-sunxi.org/File:Allwinner_R40_User_Manual_V1.0.pdf)I think this is the case after taking a look into the reference manual.There are two 16 bit fields in the PWM_PERIOD_REG. One specifies thenumber of clock ticks defining the period (""PWM_ENTIRE_CYCLE"") and theother the duty cycle (""PWM_ACT_CYCLE"").So if you go from duty_cycle=5 + period=10 + POLARITY_NORMAL toduty_cycle=3 + period=10 + POLARITY_INVERTED this might generate: ____      __           ______/    \____/  \_________/      \__/^         ^         ^         ^Also there is a PWM_PERIOD_RDY bit field that probably has to beconsulted before writing to the PWM_PERIOD_REG register.It's not entirely clear to me if the PWM_ACT_STA bit that is used forinversion is shadowed until the next period, too. That's what I assumedabove. If it's not the wave might look as follows: ____      __  _____    ______/    \____/  \/     \__/      \__/^         ^   *     ^         ^Where * marks the point where the inversion starts to take effect.Best regardsUwe--Pengutronix e.K.                           | Uwe Kleine-Knig            |Industrial Linux Solutions                 | http://www.pengutronix.de/  |",Technical
,
"Hello,To clearify my question:after the first pwm is used and enabled (maybe using mux-0) changingsun8i_pwm->clk for the second pwm is broken because then when the firstpwm is disabled the wrong clock is stopped.Best regardsUwe--Pengutronix e.K.                           | Uwe Kleine-Knig            |Industrial Linux Solutions                 | http://www.pengutronix.de/  |",Technical
,
"Hi,No, I meant for your mails, sorry. Each patch should be sent in replyto your cover letter, and they are all sent as separate mails, whichmakes it hard to track.I'm not sure how you're sending your patches, but using git send-emailthis would be using --no-chain-reply-to --thread if I remember well.You don't need to move it anywhere, you can declare a clock in adriver, without being in drivers/clk. We're doing that in the DRM orthe RTC drivers for example.Maxime--Maxime Ripard, BootlinEmbedded Linux and Kernel engineeringhttps://bootlin.com",Technical
,
"You should never try to get resources at this point. You should haverequested them already at ->probe() time. Otherwise, how are you goingto handle failures here?So this isn't really how atomic is supposed to work. The whole point ofthe single callback is to allow the driver to apply the changes in anatomic way, which means that either everything is applied or nothing isapplied.That's not what you do here. In the above you can end up with an enabledclock but the settings not being applied. Similarly sun8i_pwm_config()can abort in a number of places, which would leave you with a half-configured PWM channel.Instead, what you should be doing is precompute everything and checkthat the configuration can be applied before touching any registers orenabling clocks. Once you've validate the new state, you need to writeeverything and there should be no more risk of failure.Thierry",Technical
,
"Thierry Reding <thierry.reding@gmail.com> äºŽ2018å¹´12æœˆ21æ—¥å‘¨äº” ä¸Šåˆ1:57å†™é“ï¼šSomething wrong here, i will fix it, thanks :)Got it, it is useful for me !",Technical
,
"So, now it's enabled to be added via regular ndo.I have similar change in mind, but was going to send it aftermcast/ucast, and - enabling same vlans patch...2 things stopped me to add this:1) Moving it to be enabled via regular call is Ok, but in dual mac modeit causes overlaps, at least while vid deletion. So decided to wait tillsame vlans series is applied.2) Wanted implement somehow similar handling for single port boardsin one patch, not only for dual mac mode. This part was not clear andnot verified completely...So, if it's needed now, maybe better at this moment only removeuntag field? and remove vlan0 later, once other vlan changes applied.Say:cpsw_ale_add_vlan(cpsw->ale, cpsw->data.default_vlan,		  ALE_ALL_PORTS, 0, ALE_ALL_PORTS, 0);instead of:cpsw_ale_add_vlan(cpsw->ale, cpsw->data.default_vlan,		  ALE_ALL_PORTS, ALE_ALL_PORTS, 0, 0);--Regards,Ivan Khoronzhuk",Technical
,
"TI driver documentation mentions this restriction""While adding VLAN id to the eth interfaces,same VLAN id should not be added in both interfaces which will lead to VLANforwarding and act as switch""This patch affects only dual_mac mode and in this mode adding vid0 by default isdefinitely make no sense in any case.[1] http://processors.wiki.ti.com/index.php/Linux_Core_CPSW_User%27s_Guide#Dual_Standalone_EMAC_mode--regards,-grygorii",Technical
,
"It's not accurate now.This sw bug ""acting like a switch"" was fixed indirectly in LKML ).And at least for upstream version, not TISDK, desc should be updated,but better do this when it fixed completely and merged with TISDK.I know about this ""written"" restriction(for tiSDK, and it's not TRM after all ...),it can be avoided and it's partly avoided now ...Also, for notice, while you add any of the vlans to any ofthe ports, vlan0 is added to both of them.....restricted it or not.Thanks to last changes in the driver it's not ""acting like a switch""The patch in question enables this in ndo, not me.#ip link add link eth0 name eth0.400 type vlan id 400[  326.538989] 8021q: 802.1Q VLAN Support v1.8[  326.543217] 8021q: adding VLAN 0 to HW filter on device eth0[  326.554645] 8021q: adding VLAN 0 to HW filter on device eth1[  326.572236] net eth0: Adding vlanid 400 to vlan filterI just propose to extend it later, when it's correct to do.But if no harm (basically no harm, only if someone decidesto add vlan0 to both ports and then delete on one of them), at least you should take this into account.The above proposition is only to your change, only for dual-mac.--Regards,Ivan Khoronzhuk",Technical
,
"Thank you for your review. Seems not everything works as expected with this patch,so ignore it please.regards,-grygorii",Technical
,
"I'd like to clarify point about supporting same VLANs in dual_mac mode,to avoid future misunderstanding, overall: it's *not* supported asadding same VLAN to both netdevices will cause unknown unicast packetsleaking between interfaces and it can't be avoided - hw limitation.Regarding vid0 - current default configuration of CPSW considersvid0/priority tagged packets as - untagged and assigns pvid to anysuch ingress packet inside switch. Hence, P0 (Linux host) egress portnever modifies packet contents - this behavior is not visible to Linux.(EN_VID0_MODE=0, P1_PASS_PRI_TAGGED=0)--regards,-grygorii",Technical
,
"Simple test shows no issues with ucast leaking.But for current buggy ucast vlan implementation it's not possible to verify,not sure but probably leaking in your case cuased by hidden toggling ofinterface to promisc while added ucast to vlans or other reason or so.Anyway I just decided to check specifically ucasts (macst as you know are not normal now).For verification you need to apply ucast fix (including vlans) first:https://git.linaro.org/people/ivan.khoronzhuk/tsn_kernel.git/log/?h=vlan_addr_flt_fixThis is generic fix (not sure it will be approved, need try RFC) but implementthe same as local fix for vlan ucasts:https://git.linaro.org/people/ivan.khoronzhuk/tsn_kernel.git/log/?h=ucast_vlan_fixAny of those are correct. I've used generic one.Applied the following scheme:                     +--------------------------+                     | host 74:DA:EA:47:7D:9C   |                     +--------------------------+                        +---------------------+			|       am572 evm     |                        |    eth0      eth1   |                        +----------+----------+                        | eth0.400 | eth1.400 |                        +----------+----------+                            ^          |                            |          |  +-----------+ +-----------------+        |          |  |     PC    | | BBB eth0.400    |--------+          +->| Wireshark | +-----------------+                      +-----------+1) Configure vlans on am572x evm ip link add link eth0 name eth0.400 type vlan id 400 ip link add link eth1 name eth1.400 type vlan id 4002) On BBB side: # ip link add link eth0 name eth0.400 type vlan id 400Send ucast vlan traffic to the am572 evm, vlan ucast address is unreq on am572. # ./plget -i eth0.400 -t ptpl2 -m tx-lat -n 160 -s 10 -a 74:DA:EA:47:7D:66 # ./plget -i eth0.400 -t ptpl2 -m tx-lat -n 160 -s 10 -a 18:03:73:66:87:423) Observe silence on PC wireshark.Thus, no see issues with this.PS: I'm sure in plget tool, you can use your own.I can't verify everything with vlan0 at this moment (not time), justshared my thoughts adding a notice it has same possible overlap issues(or part of them) after this patch as regular vlans have.--Regards,Ivan Khoronzhuk",Technical
,
"I'm using packeth to generate udp packets (vlan) src=PC dst=unknownif there is record in ALE table which looks like:type: vlan , vid = 100, untag_force = 0x0, reg_mcast = 0x7, unreg_mcast = 0x0, member_list = 0x7then above udp packet will be forwarded to BBB.--regards,-grygorii",Technical
,
"Agree, seems no normal way to avoid ucast leak.--Regards,Ivan Khoronzhuk",Technical
,
"One of the ways could be removing end ports as memembers, leaving only port0:type: vlan , vid = 100, untag_force = 0x0, reg_mcast = 0x7, unreg_mcast = 0x0, member_list = 0x1and allow tagged packets to be received by ports beeing non memebers of a vlan:       cpsw_ale_control_set(cpsw->ale, slave_port,			    ALE_PORT_DROP_UNKNOWN_VLAN, 0);So that only unknown vlans are dropped...--Regards,Ivan Khoronzhuk",Technical
,
"Nice work Rafael. Minor nits below..                                                            minimum                           observation                                            latency                                                                   greaterWhat about a short section for the ladder governor as well ?                                                                  containingMaybe I missed, but I couldn't find any text that says what state 0, 1, ... Nmean. Like which is the deepest idle state and which one is the shallowest.                                                                          opening                                      constraints--viresh",Technical
,
"Thanks for the typo fixes.  The spellchecker I have here evidently doesn't work.[cut]There is a paragraph on that above.But this part is missing, good catch!Thanks,Rafael",Technical
,
I have this in my .vimrc and I am shown these spelling mistakes somewhatforcefully :)set spell spelllang=en_us--viresh,Technical
,
"Interestingly enough, it appears to work when I turn the automaticspellchecking, which I don't do for code as a rule, because itdistracts me.  I will need to do that for docs going forward it seems,though.BTW, I didn't respond to the remark about the ladder governor.  I haveno plans to describe it at this time and that can be done at any timelater easily enough if anyone wants to do it.Thanks,Rafael",Technical
,
"That would have made this doc complete somewhat. But anyway, that's fine withme.--viresh",Technical
,
Same as my previous comments.--paul moorewww.paul-moore.com,Technical
,
"Hi all,After merging the clk tree, today's linux-next build (armmulti_v7_defconfig) failed like this:arm-linux-gnueabi-ld: drivers/clk/imx/clk-frac-pll.o: in function `clk_pll_round_rate':clk-frac-pll.c:(.text+0x50): undefined reference to `__aeabi_uldivmod'Caused by commit  9fd680d0fafd (""clk: imx: add fractional PLL output clock"")I have used the clk tree from next-20181129 for today.--Cheers,Stephen Rothwell",Technical
,
"Hi Abel,Did you mean to lose the doubling of ""rate"" above?--Cheers,Stephen Rothwell",Technical
,
"Adding the current maintainers on CC.							Thanx, Paul",Technical
,
"* Peter Zijlstra <peterz@infradead.org> wrote:Indeed, and it's actually *worse* to read, as 0/1 stands out more and ismore compact than false/true...The only reasonable case where bool is recommended is when functions arereturning it, to make sure there's no mishap returning something else.But for a plain .c variable? Nope.Ack.Thanks,	Ingo",Technical
,
"Personally, I would prefer that assignments involving boolean variablesuse true or false.  It seems more readable.  Potentially better for toolsas well.  But if the community really prefers 0 and 1, then the test canbe deleted.julia",Technical
,
How about it it were suggested only in files that already use true andfalse somewhere?julia,Technical
,
"Now thinking further about this, I actually still need to validate that the L12ÂEPT for this gfn actually contains the apic_access address. To ensure that IÂonly fixup the fault when the L1 hypervisor sets up both VMCS L12 APIC_ACCESSÂand L12 EPT to contain the same address.Will fix and send v2.Amazon Development Center Germany GmbHKrausenstr. 3810117 BerlinGeschaeftsfuehrer: Christian Schlaeger, Ralf HerbrichUst-ID: DE 289 237 879Eingetragen am Amtsgericht Charlottenburg HRB 149173 B",Technical
,
"The ioctl(BC_FREE_BUFFER) frees the buffer memory associated with atransaction that has completed processing in userspace. If the buffercontains an FDA object (file-descriptor array), then it closes all of thefds passed in the transaction using ksys_close(). In the case with theissue, the fd associated with the binder driver has been passed in thearray. Since the fdget() optimization didn't increment the reference, thismakes us vulnerable to the UAF described above since the rules forfdget() are being violated (ksys_close()). This change did prevent thefinal close during the handling of BC_FREE_BUFFER, but as you pointout, may still result in the final close being processed prematurely afterthe new fput() (no observed negative side-effects right now, but agreedthis could be an issue).I'll rework it according to your suggestion. I had hoped to do this in a waythat doesn't require adding calls to non-exported functions since we aretrying to clean up binder (I hear you snickering) to be a better citizen andnot rely on internal functions that drivers shouldn't be using. I presumethere are no plans to export task_work_add()...There are indeed many things about the binder interface we'd do differentlyif we had the chance to start over...-Todd",Technical
,
Thanks for the detailed responses. I'll rework it for v3.,Technical
,
"Er...  Your variant critically depends upon binder being non-modular; if it*was* built as a module, you could	* lose the timeslice just after your fput()	* have another process hit the final fput() *and* close the struct file	* now that module refcount is not pinned by anything, get rmmod removeyour module	* have the process in binder_ioctl() regain the timeslice and find thecode under it gone.That's one of the reasons why such kludges are brittle as hell - normally youare guaranteed that once fdget() has succeeded, the final fput() won't happenuntil fdput().  With everything that guarantees in terms of code/data not goingaway under you.  This patch relies upon the lack of accesses to anythingsensitive after that fput() added into binder_ioctl().  Which is actuallytrue, but only because the driver is not modular...At least this variant (task_work_add()-based) doesn't depend on anythingsubtle - the lack of exports is the only problem there (IOW, it would'veworked in a module if not for that).",Technical
,
"Hi Rafael,That should be s/high/above I suppose.Other than that this seems really useful :-)Thanks,Quentin",Technical
,
"Right, thanks for spotting this. :-)Thanks!",Technical
,
"s/mertics/metricsI am probably pointing out something that has been already debated,apologies if so.exit_latency is the *worst* case exit latency for idle states that involvemultiple CPUs, we can't say for certain it is the latency that wasactually experienced by the idle state exit.It can be microseconds (eg CPU resume) vs milliseconds (eg groups ofcpus resume).I think the current approach (which may only understimate the ""below"" bysubstracting the worst case value) is reasonable but I pointed this outsince I do not know how these stats will be used.Lorenzo",Technical
,
"On Fri, Dec 7, 2018 at 1:57 PM Lorenzo Pieralisi<lorenzo.pieralisi@arm.com> wrote:Right, thanks!Right.This is on purpose.I want to count the cases when the selected state has been off for certain.Thanks,Rafael",Technical
,
"...[snip]...Same here.Same here.My graphs now include the ""above"" and ""below"" metrics.In particular see Idle State 1 ""above"" (was too deep) graphs in the links below.However, performance is up and power about the same, so O.K.I cherry picked a couple of the mmtests that Giovanni was doing:Test kernels:""stock"" kernel 4.20-rc5 + a couple of rjw patches. Specifically:	    2a110ed cpuidle: poll_state: Disregard disable idle states	    8f09875 cpuidle: Add 'above' and 'below' idle state metrics	    d6851a5 Documentation: admin-guide: PM: Add cpuidle document	    2595646 Linux 4.20-rc5""teov6"" above + teov6 patch""teov7"" above + teov7 patch""teov8"" above + teov8 patch1.) mmtests - netperf-unbound test (UDP):                                   4.20-rc5               4.20-rc5               4.20-rc5               4.20-rc5                                      stock                   teo6                   teo7                   teo8Hmean     send-64         129.64 (   0.00%)      132.45 *   2.17%*      130.55 *   0.71%*      132.87 *   2.49%*Hmean     send-128        259.53 (   0.00%)      264.90 *   2.07%*      261.61 *   0.80%*      264.94 *   2.09%*Hmean     send-256        515.24 (   0.00%)      525.41 *   1.97%*      517.41 *   0.42%*      524.88 *   1.87%*Hmean     send-1024      2041.01 (   0.00%)     2079.22 *   1.87%*     2045.03 *   0.20%*     2077.25 *   1.78%*Hmean     send-2048      3980.04 (   0.00%)     4071.09 *   2.29%*     4041.15 *   1.54%*     4057.09 *   1.94%*Hmean     send-3312      6321.90 (   0.00%)     6460.23 *   2.19%*     6395.71 *   1.17%*     6409.09 *   1.38%*Hmean     send-4096      7695.18 (   0.00%)     7882.81 *   2.44%*     7813.72 *   1.54%*     7832.77 *   1.79%*Hmean     send-8192     13920.53 (   0.00%)    14146.47 *   1.62%*    13986.72 *   0.48%*    14079.07 *   1.14%*Hmean     send-16384    24714.99 (   0.00%)    25225.95 *   2.07%*    24896.10 *   0.73%*    25131.52 *   1.69%*Hmean     recv-64         129.64 (   0.00%)      132.45 *   2.17%*      130.55 *   0.71%*      132.87 *   2.49%*Hmean     recv-128        259.53 (   0.00%)      264.90 *   2.07%*      261.61 *   0.80%*      264.94 *   2.09%*Hmean     recv-256        515.24 (   0.00%)      525.41 *   1.97%*      517.41 *   0.42%*      524.88 *   1.87%*Hmean     recv-1024      2041.01 (   0.00%)     2079.22 *   1.87%*     2045.03 *   0.20%*     2077.25 *   1.78%*Hmean     recv-2048      3980.04 (   0.00%)     4071.09 *   2.29%*     4041.15 *   1.54%*     4057.09 *   1.94%*Hmean     recv-3312      6321.88 (   0.00%)     6460.23 *   2.19%*     6395.71 *   1.17%*     6409.09 *   1.38%*Hmean     recv-4096      7695.15 (   0.00%)     7882.81 *   2.44%*     7813.72 *   1.54%*     7832.75 *   1.79%*Hmean     recv-8192     13920.52 (   0.00%)    14146.43 *   1.62%*    13986.72 *   0.48%*    14079.07 *   1.14%*Hmean     recv-16384    24714.99 (   0.00%)    25225.90 *   2.07%*    24896.07 *   0.73%*    25131.49 *   1.69%*Graphs: http://www.smythies.com/~doug/linux/idle/teo8/net-pref-udp-unbound/index.html(note: slow upload speed from my server)2.) mmtests - sockperf-udp-throughput test:                            4.20-rc5               4.20-rc5               4.20-rc5               4.20-rc5                               stock                   teo6                   teo7                   teo8Hmean     14        24.57 (   0.00%)       25.91 *   5.46%*       25.99 *   5.78%*       25.73 *   4.75%*Hmean     100      175.37 (   0.00%)      185.09 *   5.54%*      185.89 *   6.00%*      184.48 *   5.19%*Hmean     300      523.81 (   0.00%)      553.47 *   5.66%*      554.70 *   5.90%*      550.16 *   5.03%*Hmean     500      870.08 (   0.00%)      918.88 *   5.61%*      924.33 *   6.24%*      914.53 *   5.11%*Hmean     850     1449.44 (   0.00%)     1530.84 *   5.62%*     1535.40 *   5.93%*     1522.53 *   5.04%*Graphs: http://www.smythies.com/~doug/linux/idle/teo8/sockperf-udp-throughput/index.html(note: slow upload speed from my server)The above results tables are also here:http://www.smythies.com/~doug/linux/idle/teo8/index.htmlI wanted to also do the tbench on loopback test, but have not been able to get it working on my system yet.I'll supply more test results at a later date.... Doug",Technical
,
"Thanks a lot for the comprehensive results, much appreciated as always!This basically confirms my own observations, so my overall conclusionis that what we have here is as good as it can get without changingthe approach entirely or adding complications that would be difficultto justify in general.And so that's what I'm going to do.Cheers,Rafael",Technical
,
"I like that you're getting rid of the extra tasklet, but the other part of thisis properly refilling your rx ring.  The way you have this coded, you alwaysblindly just receive the incomming frame, even if your refill operation fails.If you get a long enough period in which you are memory constrained, you willwind up with an empty rx ring, which isn't good.  With this patch, if your ringbecomes empty, then you will stop receiving frames (no buffers to put them in),which in turn will prevent further attempts to refill the ring.  The result iseffectively a hang in traffic reception that is only solveable by a NIC reset.Common practice is to, for each skb that you intend to receive:1) Allocate a replacement buffer/skb2a) If allocation succedes, receive the buffer currently on the ring, andreplace it with the buffer from (1)2b) If allocation fails, record a frame drop, mark the existing buffer as clean,and move onThis process ensures that the ring never has any gaps in it, preventing theabove hang condition.Neil",Technical
,
"It should be:	if (!leak) {		kfree(d);		return NULL;	}Note that The check is not strictly needed in this artificialexample because we never read/write any data there. But I agreethat we should add the check to promote the the right programmingpatterns.Best Regards,Petr",Technical
,
"The same comments apply here as for PATCH 1/2.Best Regards,Petr",Technical
,
thanks for catching this !will send a V2.thx!hofrat,Technical
,
"This is unusual and the example below lists a clock phandle (which isthe common thing), so I guess the description is just wrong.What is the unit? I'd drop ""approx"", that the driver might not be ableto exactly hit the specified period is (IMHO) obvious and doesn't needto be mentioned in the property name.Best regardsUwe--Pengutronix e.K.                           | Uwe Kleine-Knig            |Industrial Linux Solutions                 | http://www.pengutronix.de/  |",Technical
,
"If there is a publically available reference manual, please add a linkto it here.@Thierry: You see, this driver is cheating in the same way that Isuggested to implement for imx.You must not use / to divide an u64 (unless you're on a 64 bit arch).Also if real_period is for example 10 ms and the consumer requestsduty=12 ms + period=100 ms, the hardware is configured for duty=1.2 ms +period=10 ms, right?You should also check polarity (and fail if it's !=PWM_POLARITY_INVERSED?).If state->duty_cycle == state->period, we end up with frac = 0xffff.Does that mean the chip cannot output 100%?Is this the expected behaviour of .apply to update *state? (I think it'sa good idea, but I think it misses official blessing.)How does a period start with this PWM hardware. The expected behaviourwould be to start with low level for duty_cycle and then high for therest of the period (given that the polarity is always inversed). Is thiswhat the hardware actually does?If the duty cycle changes, is the currently running period completedbefore the new setting gets active? If yes, .apply is supposed to blockuntil the new setting is active.A single space before the = please.What happens with the output if you don't set the BIT_PWM_EN_ALWAYS bit?I suggest commenting this assignment with something like: ""As scale <=15 the shift operation cannot overflow."" You must use div64_ul fordividing an unsigned long long variable. Can it happen that the resultis too big to be hold by read_period (which is an unsigned int only)?Maybe add a dev_dbg with the new real_period here.Please don't emit an error message if PTR_ERR(pwm->clk) is-EPROBE_DEFER.You're supposed to call clk_get_rate only after you enabled the clk.In probe you setup the clk notifier before calling pwmchip_add. So it'sa good habit to do it the other way round in .remove.You're not using the irq that according to the dt binding is required?!Best regardsUwe--Pengutronix e.K.                           | Uwe Kleine-Knig            |Industrial Linux Solutions                 | http://www.pengutronix.de/  |",Technical
,
This should reference the common doc Paul has written and not re-explainthe versioning scheme again.Needs a unit suffix as defined in property-units.txt,Technical
,
Ok sure.Will be done.Thanks for the comments!,Technical
,
"On Tue, Dec 18, 2018 at 2:46 AM Uwe Kleine-KÃ¶nig<u.kleine-koenig@pengutronix.de> wrote:You are right, I will correct the description.The unit is nanoseconds. Will add the unit suffix to the property name.Thanks for the comments!",Technical
,
"On Tue, Dec 18, 2018 at 3:42 AM Uwe Kleine-KÃ¶nig<u.kleine-koenig@pengutronix.de> wrote:Ok will add the link to the reference manual.Will use div_u64().Right.Will add the check for polarity.No, it does not mean that. The chip can output 100%Ok, will update the *state by calling get_state() from .applyYes, Correct.No, it is not the case.Sure.If BIT_PWM_EN_ALWAYS is set, the PWM counter increments continuously.If not set, PWM counter will be disabled. There won't be PWM output unlessBIT_PWM_EN_ONCE is set. In that case it will generate single PWM cycle and stop.Ok. Will add that comment and also use div64_ul for division.Regarding the result, I don't think so it will be big enough tooverflow read_period.Sure, will add it.Will add an ""if"" check.Will fix this.Will change the sequence.Yes, currently there is no use.Thanks for the comments!",Technical
,
"(adding some more people, please remember to run get_maintainer.plto get the full list in the future)",Technical
,
"Are you talking about the precondition	if (arch_apei_filter_addr)?Because apei_resources_fini() happens under the same condition check andif arch_apei_filter_addr was false, it should not become true, all of asudden. Or?Or does that function ptr get set in the meantime on your machine? I.e., thishackery:#define set_apei_filter() (arch_apei_filter_addr = pci_mmcfg_for_each_region)being called in pci_mmcfg_early_init()...?Hmmm.--Regards/Gruss,    Boris.Good mailing practices for 400: avoid top-posting and trim the reply.",Technical
,
"Hi Borislav,please take a look at the stacktrace. For some reason, and only at thatspecific hardware, the condition is false, there but later the indicatederror exit is taken whose message you can see immediately before thestack trace.So this should documents the one observed case where the NULL deref isactually happening.Of course, it would be possible to develop another solution, but thisone appears the simplest and safest to me (minimum changes to the logic).I have tested the patch on that specifc hardware: I have verified thatthe patch does not trigger the NULL deref anymore.Of course, on any other hardware we have tested, the bug did not triggerat all.If you don't have that specific hardware, you probably cannot easilytrigger / verify the problem.If you need access to the specfic hardware, talk to me in a privateconversation.Cheers,Thomas",Technical
,
"Yes, but if you say ""for some reason"", then we still don't know whatthe root cause is. So before we do any fixing, let's find out what theproblem is first.Can you pls run this debugging hunk ontop of -rc6, on the box and sendme full dmesg? Privately is fine too.Thx.---diff --git a/arch/x86/pci/mmconfig-shared.c b/arch/x86/pci/mmconfig-shared.cindex 7389db538c30..5166639b7280 100644--- a/arch/x86/pci/mmconfig-shared.c+++ b/arch/x86/pci/mmconfig-shared.c@@ -667,6 +667,9 @@ void __init pci_mmcfg_early_init(void) 			acpi_sfi_table_parse(ACPI_SIG_MCFG, pci_parse_mcfg); 		__pci_mmcfg_init(1);+		pr_info(""%s: setting apei filter\n"", __func__);+		dump_stack();+ 		set_apei_filter(); 	} }diff --git a/drivers/acpi/apei/apei-base.c b/drivers/acpi/apei/apei-base.cindex da370e1d31f4..e87b183ca73d 100644--- a/drivers/acpi/apei/apei-base.c+++ b/drivers/acpi/apei/apei-base.c@@ -494,6 +494,9 @@ int apei_resources_request(struct apei_resources *resources, 	if (rc) 		goto nvs_res_fini;+	pr_info(""%s: 1, arch_apei_filter_addr: 0x%px\n"",+		__func__, arch_apei_filter_addr);+ 	if (arch_apei_filter_addr) { 		apei_resources_init(&arch_res); 		rc = apei_get_arch_resources(&arch_res);@@ -552,6 +555,9 @@ int apei_resources_request(struct apei_resources *resources, 		release_mem_region(res->start, res->end - res->start); 	} arch_res_fini:+	pr_info(""%s: arch_res_fini, arch_apei_filter_addr: 0x%px\n"",+		__func__, arch_apei_filter_addr);+ 	if (arch_apei_filter_addr) 		apei_resources_fini(&arch_res); nvs_res_fini:--Regards/Gruss,    Boris.Good mailing practices for 400: avoid top-posting and trim the reply.",Technical
,
"Ah, I overlooked that commit e56c92565dfe2 is already providing adifferent solution to the same problem in newer kernels _only_, as a_side_ effect (not clear to me from the description, but clear fromreading the code).But this patch is not present at the 4.4.166 kernel where I found theproblem and fixed it internally in a different way.The 4.4.166 code looks like this, without the if-statement you arementioning, unconditionally trying to free the unitinialized variableunder certain circumstances:d91525eb8ee6a (Chen, GongÂ Â Â Â  2014-12-10 13:53:26 -0800 553) arch_res_fini:d91525eb8ee6a (Chen, GongÂ Â Â Â  2014-12-10 13:53:26 -0800 554)apei_resources_fini(&arch_res);d91525eb8ee6a (Chen, GongÂ Â Â Â  2014-12-10 13:53:26 -0800 555) nvs_res_fini:4134b8c8811f2 (Huang YingÂ Â Â Â  2011-12-08 11:25:50 +0800 556)apei_resources_fini(&nvs_resources);23f124ca3dda9 (Huang YingÂ Â Â Â  2010-09-29 19:53:54 +0800 557) return rc;So another alternative would be backporting e56c92565dfe2 to the 4.4 LTSseries. Also fine for me.",Technical
,
"Damn, I missed the fact that this is not the upstream kernel:CPU: 0 PID: 1 UID: 0 Comm: swapper/0 Not tainted 4.4.0-ui18344.004-uiabi1-infong-amd64 #1That looks like the right fix.A note for the next time: do not send a fix for a stable kernel which isnot upstream:From Documentation/process/stable-kernel-rules.rst:"" - It or an equivalent fix must already exist in Linus' tree (upstream).""The stable kernels track upstream so if a stable kernel has a problem,the first thing one needs to do is to check whether this has been fixedupstream and if so, to backport it. This is the case most of the time.In the very seldom cases where a separate fix is needed, it needs to behandled by asking Greg what to do. :-)Adding stable@ folks to CC to set me straight if I'm missing something.--Regards/Gruss,    Boris.Good mailing practices for 400: avoid top-posting and trim the reply.",Technical
,
"Nope, you are correct, thanks!greg k-h",Technical
,
"There is no JESD85-B51.  I presume you mean JESD84-B51, but I can't find anyreference to DMA in 6.6.39.  All the host controller relevant material seemsto be in Annex B.  Can you clarify this reference?",Technical
,
"From: Bart Van Assche <bvanassche@acm.org>Date: Mon, 17 Dec 2018 13:40:58 -0800 ...Please just fix the test to use the global object created for this purposeinstead of an unnecessary on-stack instance.Thanks.",Technical
,
"+AD4 From: Bart Van Assche +ADw-bvanassche+AEA-acm.org+AD4+AD4 Date: Mon, 17 Dec 2018 13:40:58 -0800+AD4+AD4 +AD4 The test+AF8-insert+AF8-dup() function from lib/test+AF8-rhashtable.c passes a+AD4 +AD4 pointer to a stack object to rhltable+AF8-init(). Avoid that the following+AD4 +AD4 is reported with object debugging enabled while running the selftest+AD4 +AD4 from lib/test+AF8-rhashtable.c:+AD4  ...+AD4 +AD4 Signed-off-by: Bart Van Assche +ADw-bvanassche+AEA-acm.org+AD4+AD4+AD4 Please just fix the test to use the global object created for this purpose+AD4 instead of an unnecessary on-stack instance.Hi Dave,I will do that. Thanks for the feedback.Bart.",Technical
,
"Hi Anson,Do you mean ATF (ARM Trusted Firmware) instead?",Technical
,
"TF-A is the name of the day for what was formerly known as ATF...However I don't think that it's correct to just don't cache the clocksettings. Normally the secure world firmware should not change anyclock settings at runtime, or it would run into all kinds of conflictswith the clock driver. So there are probably some well known points intime like a suspend or resume event when the firmware might changeclock settings, so we could instead use those to trigger an explicitinvalidate of the clock caches with much lower overhead.Regards,Lucas",Technical
,
"Hi, LucasFrom Anson's iPhone 6There is bus-freq feature on imx8m which is to scale ddr clock, this is done in ARM Trusted Firmware, for some setpoints, the DDR PLL clock rate must be changed directly in TF-A, but its child clock like dram core is unaware in Linux kernel, so the clock rate will mismatch with hardware, since ddr related clocks will NOT used by any module in Linux kernel, so it will NOT introduce any conflict.Regarding about the over head, yes, the change in common composite clock register has too many over head for other clocks, what if I ONLY have dram core clock to pass the CLK_GET_RATE_NOCACHE flag to register the composite clock?Anson.",Technical
,
"Hi Anson,I don't think there is anything implementing the bus frequency scalingin mainline, right?IMHO marking clocks under TF-A control explicitly as nocache would bemuch more acceptable than doing it for every composite clock. Thisseems okay for a short term solution.Still I think that whatever is causing the bus frequency scale tochange should have a way to explicitly invalidate the clock cache forthe affected clocks eventually.Regards,Lucas",Technical
,
"Hi, LucasFrom Anson's iPhone 6Yes, mainline has no bus-freq scaling so far, but internally we use same composite clock driver as mainline, and bus-freq clock rate issue/bug reported during our internal test, that is why I create this patch to easy our next kernel upgrade.It is because the DDR PLL/clocks can only be changed with strict DDR freq change flow, and it is done in TF-A, Linux kernel can NOT touch it in runtime, so we have to mark the child clock of DDR PLL to be uncached, in V2 patch, I will just add the flag for the DDR PLL child clocks to be a shorten solution, should be only very few ones, hope it is acceptable, thanks.Anson.",Technical
,
"[...]I fully understand why you are doing the frequency change in TF-A and Iagree with the reasoning to do so. I also think that using uncached forthe few clocks under TF-A control is fine for now.But if/when the bus frequency scaling is actually implemented forupstream I think the flow should look something like that:1. Bus freq scaling driver determines that a change is necessary2. Scaling driver calls into TF-A to do the change3. TF-A reconfigures clock rates4. Scaling driver calls into clock driver to signal that a clock changemight have happened5. Clock driver invalidates and recalculates cached values for theaffected clocksRegards,Lucas",Technical
,
"Quoting Lucas Stach (2018-12-18 06:02:28)Does any clk consuming driver of the downstream clks that are branchedoff of the bus clk managed by firmware care about the frequency? Or dothey just want the clk to be on. If they don't care then it's possibleto break the parent dependency and just not care to tell them what thebus frequency is anymore.I don't know how you would implement #4 above, besides by having the busfreq scaling driver use clk_set_rate() to tell the bus clk that it wantsa new rate and then having that clk implementation do #2. That way therate propagation works without having to notify clk code somehow.",Technical
,
"Hi, StephenBest Regards!Anson HuangIn our case, the original clock relationship is as below, when DDR freq needs to be scaled, below things are proceeded:Clock tree:IMX8MQ_DRAM_PLL2	IMX8MQ_DRAM_PLL2_DIV		IMX8MQ_DRAM_PLL2_OUT			IMX8MQ_DRAM_PLL_OUT				IMX8MQ_CLK_DRAM_CORE1. Linux kernel do SMC call into TF-A;2. in TF-A, we have to scale the IMX8MQ_DRAM_PLL2 to dedicated frequency along with DDR freq scale flow;3. After TF-A done the DDR freq scale and return back to Linux, all the downstream of IMX8MQ_DRAM_PLL2 clock will  have mismatch clock rate between clock tree and HW settings since they are cached;4. Maybe we can call clk_set_rate in Linux for IMX8MQ_DRAM_PLL2 again (although the HW settings are already expected)  to update the downstream clocks, looks like can fix it, but will the call be skipped by clock framework when clock driver  re-calculate the PLL rate based on HW setting, as HW setting already equal the rate wants to be set, and clk_propagate_rate_change  will be skipped too or it will automatically update all child clocks' rate?Is it correct? if all child clocks' rate can be updated by clk_propagate_rate_change(), then we no need to add any clock flag,just make sure after TF-A finish the DDR freq scale, make sure calling the clk_set_rate() for the IMX8MQ_DRAM_PLL2, then everything should be correct?Anson.",Technical
,
"You may want to check linux/next. As far as I can see, the two patchesare there already.Thanks,	M.--Jazz is not dead. It just smells funny...",Technical
,
Hi MarcWow !!Thank you !!Best regards---Kuninori Morimoto,Technical
,
This makes it impossible to write a wrapper that turns this modeon for unmodified programs.Do you have a real use case where this behavior is a problem?-Andi,Technical
,
"You can always force disable SSB. In that case, all the child processeswill have SSBD on.Yes, we have an enterprise application partner that found that theirapplication slow down up to 10-20% depending on how their applicationwas set up. With the slow setup, the application was spawned by Javaprocesses causing the SSBD bit to stay on when the application was running.Cheers,Longman",Technical
,
"Okay that sounds reasonable, given the below. Thanks.-Andi",Technical
,
"Ping! Any comments of objections?Cheers,Longman",Technical
,
"Lot's of MAY's here. Aside of that this fundamentally changes thebehaviour. I'm not really a fan of doing that.If there are good reasons to have a non-inherited variant, then we ratherintroduce that instead of changing the existing semantics without a way forexisting userspace to notice.Thanks,	tglx",Technical
,
"I understand your point. How about adding a "",noexec"" auxillary optionto the spec_store_bypass_disable command line to activate this newbehavior without changing the default. Will that be acceptable?Cheers,Longman",Technical
,
"I'd rather have an explicit PR_SPEC_DISABLE_NOEXEC argument for the PRCTLso you can decide at the application level what kind of behaviour you want.Thanks,	tglx",Technical
,
"Thanks for the advice. Will work on a v2 to be sent out later this week.Cheers,Longman",Technical
,
"On Wed, 19 Dec 2018 13:07:31 -0800Amir Mahdi Ghorbanian <indigoomega021@gmail.com> wrote:*groans*  Another one where the MODULE_LICENSE is different.Michael, Analog copyright, so if you want to express a view onthe intent that would be great.My feeling would be that the MODULE_LICENSE is the wrong one given it'seasier to get that wrong than to add an 'or later' to the text..On these I generally want an ack from the copyright holder anywayjust to be sure everything is in order.Thanks,Jonathan",Technical
,
"Folks,I'm about to vanish for a truly needed break until Jan 7th. Time to lookback to an interesting year.Almost exactly a year ago, all hell broke loose and quite some people wereforced to cancel their Christmas and New Year vacation and instead ofspending quality time with family and friends they tried to bring the bitsand pieces for the Meltdown and Spectre mitigations into shape.While the Meltdown part (KPTI) was in a halfways good shape - at least inmainline - the Spectre mitigations did not make it into mainline on timeand caused havoc in distros. The broken microcode updates and otherunpleasant issues did not help the situation either. And no, the 6 daysextra if the embargo wouldn't have ended early would not have made anydifference. It's a wonder that it held up until Jan. 3rd at all.The reasons for this disaster have been pretty much covered in variousways, so no point to go back to that again. Though it's worth to mentionthat some of the mitigations took quite some time to materialize and thedevelopment was not at all driven by those who are responsible for theproblem in the first place. Primary examples are KPTI support for 32bit andSTIBP which took more than 9 months to get into the mainline. KPTI for32bit was ignored completely and STIPB only got attention due toperformance regressions, though the response was causing more work thanhelp.The next round of speculation-related issues including the scary L1TFhardware bug was a way more ""pleasant"" experience to work on. While forobvious reasons the mitigation development happened behind closed doors ina smaller group of people, we were at least able to collaborate in a waywhich is somehow close to what we are used to.There were surely a few rough edges with respect to bringing in particulardevelopers and information flow, but both Intel and we as a community havelearned how to deal with that and improved a lot.As a consequence, we are going to have a well documented and formalizedprocess for this in the foreseeable future. There are also efforts on theway to have non-public testing infrastructure available for future eventsof this kind.No need to speculate whether this makes sense. I'm not overly optimisticthat we have seen all of that by now and my gut feeling tells me that weare going to be haunted by that kind of issues for a very long time. Forthe very unlikely case that I'm proven wrong, then I'm surely not going toshed a tear about the time spent on writing the documentation and gettingthings prepared.At this point I want to say BIG THANKS to everybody involved for all thegreat work which was done under not so enjoyable circumstances. Both therequired secrecy and the set in stone timelines are pretty different fromour normal workflow. At the same time I want to take the opportunity andapologize for any outburst I had. I know that I went overboard occasionallyand it's nothing I'm proud of.Looking back, I have to say that all of this certainly had consequencesoutside of that restricted setting. The coordinated release dates forcedquite some people to put a break on other tasks which were piling upnevertheless. The review backlog was from time to time tremendous and I'msure that we dropped stuff on the way and that we still have things tocatch up with on all ends.Though a lot of this pressure and fallout is home-grown and could have beenavoided at least to some extent. The underlying reasons are not specific tothe mitigation development, the circumstances just emphasized them and madethem more observable for everyone - involved or not. 1) Lack of code quality    This is a problem which I observe increasing over many years.    The feature driven duct tape engineering mode is progressing    massively. Proper root cause analysis has become the exception not the    rule.    In our normal kernel development it's just annoying and eats up review    capacity unnecessarily, but in the face of a timeline or real bugs it's    worse. Aside of wasting time for review rounds, at some point other    people have to just drop everything else and get it fixed.    Even if some people don't want to admit it, the increasing complexity    of the hardware technology and as a consequence the increasing    complexity of the kernel code base makes it mandatory to put    correctness and maintainability first and not to fall for the    featuritis and performance chants which are driving this    industry. We've learned painfully what that causes in the last year. 2) Lack of review response    Not addressing review feedback is not a new problem, but again under    time pressure or in the face of real bugs it becomes a real pain and    causes extra work for others and maintainers in particular. 3) Outright refusal    I've seen particularly in this year quite some people who responded to    review feedback with outright and outspoken refusal. The points they    refuse to address are not some esoteric whims of particular    maintainers, no it's refusal to accept that there are documented    process and patch submission rules which apply for everyone.    Again, not a big problem if it's related to features. If it's related    to actual bugs or the timelined mitigation development then it causes    extra burden for others.In other words, if we are exposed to more half-baked patches, sloppyaddressing of review feedback or in the worst case refusal to collaborateand then on top getting complaints about maintainers and reviewers beingbottlenecks, then this will become a real problem in the not so distantfuture.Companies have to understand, that the kernel community cannot provideall-inclusive educational programs for their engineers. It's about time,that the companies catch the obvious wreckage before it leaves the houseand make sure that feedback is addressed properly and in all points.I'm neither expecting perfect patches nor is there a guarantee that evenwell thought out and well written code will go into the tree undisputed.Though reviewing and discussing something which is well done is way lesstime consuming and frustrating than dealing with the above.I know that some people will come forth immediately and educate me oncemore on maintainer models and the need to bring new maintainers in fast.I'm all for more maintainers, but it's hard to find the right people.All good maintainers - and I've brought quite a few of them into that rolemyself - had proven themselves in their contributor role before taking thatup. Rest assured that I constantly look out for these people and try to getthem on board. Picking them out is based on their technical skills but evenmore so on their mindset. Unfortunately quite some of them don't want tostep into that role because they are well aware of the responsibility andthe burden which comes with it. I respect that decision and I definitelycan understand it. I was more than once on the verge of throwing in thetowel during the last year.I'm not opposed to try new things, quite the contrary. But something whichworked out for a particular subsystem cannot be applied blindly toeverything else in the hope that it works out. That needs a lot morethought and I'm not at all buying that tooling is a crucial part of thesolution.Last but not least, I'm not sure whether more maintainers can solve thepain points which bugger me most. I rather think we'd need lots ofnursemaids and teachers to address that.Sorry for the lengthy and maybe unpleasant read, but keeping thefrustration which built up over the year to myself would just cause megastric ulcer and a bad mood over Christmas. So I decided to vent and shareit with all of you even at the risk that I'm barking up the wrong tree.That said, I'm going to vanish into vacation until Jan. 7th and I'm notgoing to read any (LKML) mails until then. As I predict from experiencethat my (filtered) inbox will be a untameable beast by then, don't expectme to actually go through it mail by mail. If your mail will unfortunatelyend up in the 'lkml/done' folder without being read, I'm sure you'll noticeand find a way to resend it.I'm nevertheless looking positively forward to the new challenges of 2019and I wish you all a Merry Christmas, a Happy New Year and a refreshingbreak! I wish especially for those who suffered a year ago, that they canenjoy quality time with their families and friends!Thanks,	Thomas",Technical
,
"Hi Thomas,[trimmed cc list]I totally agree on this point by having been hit by the same problem onanother project (haproxy). It turns out that everyone are interested infeatures, reliability and performance. But these ones cannot come withoutmaintainability, and in practice only these 3 former ones can improve overtime. Maintainability only gets worse and is never ever addressed ""later""by incremental code updates. Now I tend to be a bastard on this point andto demand properly documented patches, properly named functions/variablesand everything that helps other people quickly figure why the code worksor doesn't work, knowing that performance/features/reliability area easilyaddressed afterwards by many other contributors when the code is maintainable.Take your well deserved vacation with your family, ignore e-mails and don'tread the news, it will only make you relax better, and you'll come backfully recharged.Willy",Technical
,
"Ping? Jonathan, can you pick this up?								Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Hi Deepa,Thanks a lot for the follow-up to our earlier discussion here!Are we actually worried about concurrent writers here? I thought theonly problem was a race between writer and reader, which would meanthat we could solve it using only a seqcount_t which is cheaper toupdate than a seqlock_t.       Arnd",Technical
,
"I considered using just the seqcount_t. But, I think we do care aboutconcurrent writers here.A couple of scenarios I can think of:1. When you have 2 concurrent recvmsg() calls on a socket, and theyboth try to update sk_tstamp.2. If a socket has don't have one of the SO_TIMESTAMP/NS options setand you have a first recvmsg and a concurrent ioctl call on thesocket.These are corner cases and if we don't care aout these then we can usejust the sequence counters.I have missed out tstamp update in the sunrcpc code. If everyone is okwith this approach, I will add it in when I post an update-Deepa",Technical
,
"From: Deepa Dinamani <deepa.kernel@gmail.com>Date: Fri, 21 Dec 2018 12:27:33 -0800Since, regardless of whether this is the final approach we willtake, it seems that sunrpc needs to be added to this patch.So I'm definitely waiting for a new version.Thanks.",Technical
,
"Hi DeepaPlease come up with something that has zero added costs for 64bit kernels.Most of us do not really care about 32bit kernels anymore, so we do not want to slowdown 64bits kernels for such things.Look at include/linux/u64_stats_sync.h for initial thoughts.Thanks.",Technical
,
"This is similar to what I did here. But, I can add a few ifdef's tomake this code a noop on 64 bit arches.I will include this in my next update.I'm assuming there is no contention on whether writers need exclusiveaccess and hence requiring a lock here.Let me know otherwise.Thanks,Deepa",Technical
,
"Hi,What makes you think that not matching on this compatible is an error?Have you looked at the rest of the dirver?--Dmitry",Technical
,
"Btrfs have better error message infrastructures (e.g. distinguishdifferent filesystems).Please use btrfs_error() or btrfs_warn() instead.Despite that, I think the patch looks good.Thanks,Qu",Technical
,
"Hi Myungho,Were you able to reproduce?  If so, did you use the syzkaller output orsomething else?Thanks,                Ilya",Technical
,
"Hi Ilya,I reproduced on vm using syzkaller utils and verified the fix by syzbot.Thanks,Myungho",Technical
,
"Hi Myungho,I think this might be a better fix:diff --git a/net/ceph/messenger.c b/net/ceph/messenger.cindex d5718284db57..c5f5313e3537 100644--- a/net/ceph/messenger.c+++ b/net/ceph/messenger.c@@ -3205,10 +3205,11 @@ void ceph_con_keepalive(struct ceph_connection *con) {        dout(""con_keepalive %p\n"", con);        mutex_lock(&con->mutex);+       con_flag_set(con, CON_FLAG_KEEPALIVE_PENDING);        clear_standby(con);        mutex_unlock(&con->mutex);-       if (con_flag_test_and_set(con, CON_FLAG_KEEPALIVE_PENDING) == 0 &&-           con_flag_test_and_set(con, CON_FLAG_WRITE_PENDING) == 0)++       if (con_flag_test_and_set(con, CON_FLAG_WRITE_PENDING) == 0)                queue_con(con); } EXPORT_SYMBOL(ceph_con_keepalive);WRITE_PENDING can be set without con->mutex held from socket callbacks.This is the reason we use atomic bit ops here, so testing WRITE_PENDINGunder the lock didn't make sense to me.At the same time, KEEPALIVE_PENDING could have been a non-atomic flag.I spent some time trying to make sense of conditioning queue_con() callon the previous value of KEEPALIVE_PENDING and couldn't see any, so I'msetting it with con_flag_set(), making ceph_con_keepalive() symmetricwith ceph_con_send().Thanks,                Ilya",Technical
,
"Hi Ilya,Yes, it looks clear and makes sense to have an atomic operation in if statementbut it still triggers warning. KEEPALIVE_PENDING should be set afterclear_standby() because con_fault() can be called right before acquiring thelock here which sets the flag in standby state. I tesed the change with syzbotand confirmed there was no warning.Thanks,Myungho",Technical
,
"Right, it still triggers one of the warnings.  I was too focused onWRITE_PENDING and missed that in plain sight.  I'll update the patch.Thanks for testing!                Ilya",Technical
,
"Really?  Why not?  What keeps you from ""knowing"" this?  Can't thedeveloper of the chip tell you?Shouldn't ""Unknown"" really be the same thing as ""Vulnerable""?  A usershould treat it the same way, ""Unknown"" makes it feel like ""maybe I canjust ignore this and hope I really am safe"", which is not a good idea atall.thanks,greg k-h",Technical
,
"Do some of the ""Unknown"" cases arise from the vulnerability detectioncode being compiled out of the kernel?I wonder whether at least the detection support should be mandatory.sysfs is not very useful as a standard vulnerability reporting interfaceunless we make best efforts to always populate it with real information.Also, does ""Unknown"" convey anything beyond what is indicated by thesysfs entry being omitted altogether?Cheers---Dave",Technical
,
"There tends to be a few cases, possibly incomplete white/black lists,firmware that isn't responding correctly, or the user didn't build inthe code to check the mitigation (possibly because its an embeddedsystem and they know its not vulnerable?).I would hope that it is an exceptional case.I tend to agree its not clear what to do with ""unknown"".OTOH, I think there is a hesitation to declare something vulnerable whenit isn't. Meltdown for example, is fairly rare given that it currentlyonly affects a few arm parts, so declaring someone vulnerable when theylikely aren't is going to be just as difficult to explain.",Technical
,
"Hi,Yes,I'm not sure about this one. I tend to think the ""unknown"" caseencourages users that really want an answer to dig deeper and call theirhardware/os/whoever to get an answer. I would tend to think that if theentry is missing it would tend to encourage the behavior that Greg KHmentions where the user assumes ""hey the system doesn't have a sysfsentry for $VUNLERABILITY, that probably means that its not possible onthe architecture"".",Technical
,
"Then fix the lists :)If the firmware doesn't respond, that would imply it is vulnerable :)And if the code isn't built in, again, it's vulnerable.Then have the default be vulnerable, don't give people false hope.If you know it is rare, then you know how to properly detect it so""unknown"" is not needed, correct?Again, ""unknown"" is not going to help anyone out here, please don't doit.thanks,greg k-h",Technical
,
"Hi Jeremy,i applied your patch series on linux-next-20190103. On my Raspberry Pi 3B+ (defconfig) i'm getting this from sysfs:l1tf:Not affectedmeltdown:Not affectedspec_store_bypass:Unknownspectre_v1:Mitigation: __user pointer sanitizationspectre_v2:UnknownAFAIK it has 4 Cortex-A53 cores (no PSCI firmware), so shouldn't be affected.How can this be fixed?ThanksStefan",Technical
,
"Hi,So, for spec_store_bypass, as you noted your getting hit by the lack ofpsci/smccc to report the ssb state, and this patch is just reflecting that.In the case of spectrev2 it may be correct to blame this patch setbecause its displaying ""unknown"" since your core isn't in the blacklist, and your core isn't new enough to have the csv2 bit indicating itsnot vulnerable. In this case if we do away with the unknown state, weshould probably depend entirely on the black list and simply display""Not affected"" if the core isn't listed. (meaning we may report coresnot affected when they are missing from the blacklist).For ssb, the correct answer is probably fix the firmware, but given thesituation, its likely this kind of machine is going to force anadditional MIDR list to report the state correctly. Maybe Will orsomeone can chime in here?For spectrev2, wait for another version of this patch.",Technical
,
"Marc Z is already working on this iirc, since we need it to fix the messageprinted to dmesg about the mitigation status anyway.Will",Technical
,
"Thinking about it, ""unknown"" is actually the common case.Kernels that predate the sysfs vulnerabilities interface effectivelyreport this for all vulnerabilities by omitting the sysfs entriesentirely.Current kernels also don't know anything about future vulnerabilitiesthat may be added in sysfs later on (but which may nevertheless bediscovered subsequently to affect current hardware).So, can we simply omit the sysfs entries for which we can't provide agood answer?IMHO the kernel should make best efforts to provide answers for everyvulnerability that it knows about, so the checks should not be Kconfig-dependent without a good reason.There will be cases where whitelists/blacklists are the only source ofanswers, and we are ultimately reliant on vendors to provide thatinformation.  Upstream Linux is likely to lag, there's not much we cando about that.Cheers---Dave",Technical
,
"As you say, we already do this for older systems.But don't add new logic to explicitly not create the files just becausewe ""can not figure it out"".  For those systems, I would default to""vulnerable"" as I think that's what we do today, right?thanks,greg k-h",Technical
,
"Nope: currently the vulnerabilities directory doesn't even exist for arm64because we don't select GENERIC_CPU_VULNERABILITIES.There are also a few other things to consider here:  1. The action to take as an end-user is slightly different in the case     that you know for sure that your system is vulnerable, as opposed to     the case that you don't know whether your system is vulnerable or not.     The former needs a firmware update; the second needs a statement about     the CPU, which could result in a simple whitelist update in Linux.  2. There's an unfortunate political angle to this. Whilst the Arm website     [1] provides information for all of the Arm-designed CPUs (i.e.     Cortex-A*), it doesn't comment on partner implementations. I'm not at     all keen to be seen as branding them all as vulnerable in the Linux     kernel, as this is likely to cause more problems than it solves.     If we had complete whitelist information available in public, that     would be ideal, but it's not the case.  3. The architecture has added some ID registers to determine if a CPU     is affected by Spectre and Meltdown, so a whitelist only needs to     cover existing CPUs.So I agree with Dave that continuing to omit the files when we don't knowwhether or not the system is affected is the right thing to do.Will[1] https://developer.arm.com/support/arm-security-updates/speculative-processor-vulnerability",Technical
,
Already send a new versionMy reference is SCSI Block Commands â€“ 3 (SBC-3) Revision 25.Section 5.32 WRITE (10) and 5.34 WRITE (16),Technical
,
"That is the GROUP NUMBER field. Also found in READ(16) at the samelocation within its cdb. The proposed code deserves at least anexplanatory comment.Since it is relatively recent, perhaps the above should only be done iff:    - the REPORT SUPPORTED OPERATION CODES (RSOC) command is supported, and    - in the RSOC entry for WRITE(16), the CDB USAGE DATA field (a bit mask)      indicates the GROUP NUMBER field is supportedThat check can be done once, at disk attachment time where there is alreadycode to fetch RSOC.Is there a bi_read_hint ? If not then the bi_write_hint should also be appliedto READ(16). Makes that variable naming look pretty silly though.Doug Gilbert",Technical
,
"SBC-5 says that support for the grouping function is indicated by theGROUP_SUP bit in the Extended Inquiry VPD page (86h).  I'm not sure howmany devices actually support that page though.  Probably most don't.What devices actually DO support the grouping and do something with it?We'd probably need a blacklist flag to turn this off and/or some code inthe error path to discontinue setting the field if the device returnsINVALID FIELD IN CDB or something, like we do for disabling discardcommands if they don't actually work in sd_done().-Ewan",Technical
,
"Ewan,Several devices support it, albeit for various different purposes. It'sone of these wonderful features whose interpretation was left outsidethe scope of the spec for a long time.So even though we absolutely and positively need to make setting GROUPNUMBER conditional on GROUP_SUP being reported, we also need additionalinformation from the storage about how the field should be interpreted.The official way to report hinting is for the device to implement the IOAdvice Hints Grouping mode page. I wrote some code to support that butno vendors that I know of ended up actually shipping an implementation.A few implemented my older I/O class proposal but didn't ship thateither despite really convincing performance results.If Randall has access to a device which implements hinting, I'd love toknow more.--Martin K. Petersen	Oracle Linux Engineering",Technical
,
I am working on Android phone.The idea is to enable write hint for Turbo write UFS feature.Turbo write feature in UFS 3.x is under discussion in JEDEC JC-64.This patch is the under-lying framework for supporting this feature.,Technical
,
"Hi Randall,OK, but we can't blindly go setting GROUP NUMBER to a non-zero value.That'll break a massive amount of devices which will fail READ/WRITEcommands with INVALID FIELD IN CDB.So aside from requiring the device to report GROUP_SUP=1, we'll needsome sort of indication that this device supports the UFS Turbo Writefeature. If you are engaged with JEDEC on this, please tell them we'llneed a VPD page, a mode page, or something similar to use as trigger toentertain enabling this feature.--Martin K. Petersen	Oracle Linux Engineering",Technical
,
"Hi Randall,As far as I know, there are more than one Turbo Write featureproposals in JEDEC, which are currently under discussion.For now, not all proposals are using CDB bytes for enablingTurboWrite.So, maybe making this change in SCSI is still too early.",Technical
,
"Given that keycodes are linux-specific, I think the property should belinux,keycodes. Also, I am not sure we need separaterotary-encoder,relative-keys property as we can infer that we want togenerate keys from presence of linux,keycodes property.Rob, any comments?Thanks.--Dmitry",Technical
,
"Yes, I had similar thoughts.",Technical
,
"Hello,i used this rotary-encoder patch in my embedded project and found twoerrors:First, in drivers/input/misc/rotary_encoder.c,at @@ -237,6 +244,16 @@:instead of+Â Â Â Â Â Â Â  if (err)+Â Â Â Â Â Â Â Â Â Â Â  dev_err(dev, ""unable to get keycodes: %d\n"", err);+Â Â Â Â Â Â Â  return err;it must be+Â Â Â Â Â Â Â  if (err) {+Â Â Â Â Â Â Â Â Â Â Â  dev_err(dev, ""unable to get keycodes: %d\n"", err);+Â Â Â Â Â Â Â Â Â Â Â  return err;+Â Â Â Â Â Â Â  }otherwise successful creation of device is not possible.Second, a typo inDocumentation/devicetree/bindings/input/rotary-encoder.txt,at @@ -48,3 +52,11 @@:instead of+Â Â Â Â Â Â Â Â Â Â Â  rotary-encoder,relative-keycode = <103>, <108>;it should be+Â Â Â Â Â Â Â Â Â Â Â  rotary-encoder,relative-keycodes = <103>, <108>;otherwise keycodes are not found.I am sorry, I know that E-Mail style is not good.I have no time right now, but I'll be back in two weeks.Someone, maybe Mr. Han, could submit a new version of the patch.If not, I'll try to do it on my return. (it could take some time, sinceI am new to patchwork)Best Regards and thanksAlexey Slepov",Technical
,
"[ resending to Rob... ]Given that keycodes are linux-specific, I think the property should belinux,keycodes. Also, I am not sure we need separaterotary-encoder,relative-keys property as we can infer that we want togenerate keys from presence of linux,keycodes property.Rob, any comments?Thanks.--Dmitry",Technical
,
"From: ""Gustavo A. R. Silva"" <gustavo@embeddedor.com>Date: Tue, 8 Jan 2019 10:13:56 -0600Applied.",Technical
,
"Hi Dave,I wonder if you can take this.Thanks--Gustavo",Technical
,
Any comment on this patch ?,Technical
,
"Hi Robin,please take a look at this series, which implements a completely genericset of dma_map_ops for IOMMU drivers.  This is done by taking theexisting arm64 code, moving it to drivers/iommu and then massaging itso that it can also work for architectures with DMA remapping.  Thisshould help future ports to support IOMMUs more easily, and also allowto remove various custom IOMMU dma_map_ops implementations, like Tomwas planning to for the AMD one.A git tree is also available at:    git://git.infradead.org/users/hch/misc.git dma-iommu-opsGitweb:    http://git.infradead.org/users/hch/misc.git/shortlog/refs/heads/dma-iommu-ops",Technical
,
Any chance to get a review on this one?---end quoted text---,Technical
,
"I've been pondering this for a while now, and I still can't really comeup with a case where arch_dma_prep_coherent() would need to behavedifferently from arch_sync_dma_for_device(..., DMA_BIDIRECTIONAL). Iwonder if we could just save ourselves this little bit of complexity byusing that instead...Robin.",Technical
,
"I think the __KERNEL__ and asm/errno.h slip-ups are things Icargo-culted from the arch code as a fresh-faced noob yet to learn thefiner details, so ack for those parts. The forward-declarations, though,were a deliberate effort to minimise header dependencies and compilationbloat for includers who absolutely wouldn't care, and specifically totry to avoid setting transitive include expectations since they alwaysseem to end up breaking someone's config somewhere down the line.Admittedly this little backwater is hardly comparable to the likes ofthe sched.h business, but I'm still somewhat on the fence about thatchange :/Robin.",Technical
,
"It also defeats the whole purpose of __iommu_dma_alloc_pages(), so I'mnot really buying the simplification angle - you've *seen* that code,right? ;)If you want simple, get rid of the pages array entirely. However, asI've touched on previously, it's all there for a reason, because makingthe individual iommu_map() calls as large as possible gives significantperformance/power benefits in many cases which I'm not too keen toregress. In fact I still have the spark of an idea to sort the filledpages array for optimal physical layout, I've just never had the freetime to play with it. FWIW, since iommu_map_sg() was new and promisingat the time, using sg_alloc_table_from_pages() actually *was* thesimplification over copying arch/arm's __iommu_create_mapping() logic.Robin.",Technical
,
Agreed - I'd definitely ack a version of this change which didn't dependon patch #3 ;)Robin.,Technical
,
"A lot of architectures do really weird stuff in the dma sync routines.So my plan would be to consolidate a lot more logic in there first,and then maybe as a next step we could look into usingarch_sync_dma_for_device eventually.",Technical
,
As far as I can tell almost all users of linux/dma-iommu.h requireCONFIG_DMA_IOMMU to be enabled anyway..,Technical
,
How does it defeat the purpose of __iommu_dma_alloc_pages?,Technical
,
"If there's an actual bugfix here, can we make that before all of theother code movement? If it's at all related to other reports of weirdmmap behaviour it might warrant backporting, and either way I'm findingit needlessly tough to follow what's going on in this patch :(Robin.",Technical
,
"Yes there is, namely assembling large buffers without the need formassive CMA areas and compaction overhead under memory fragmentation.That has always been a distinct concern from the DMA_DIRECT_REMAP cases;they've just been able to share a fair few code paths.As far as I'm concerned that splits things the wrong way. Logically,iommu_dma_alloc() should always have done its own vmap() instead of justreturning the bare pages array, but that was tricky to resolve with thedesign of having the caller handle everything to do with coherency(forcing the caller to unpick that mapping just to remap it yet again inthe noncoherent case didn't seem sensible).Robin.",Technical
,
Acked-by: Robin Murphy <robin.murphy@arm.com>,Technical
,
Acked-by: Robin Murphy <robin.murphy@arm.com>,Technical
,
"Other than dma-iommu.c itself, none of them *require* it - onlyarch/arm64 selects it (the one from MTK_IOMMU is just bogus), and a lotof the drivers also build for at least one other architecture (and/orarm64 with !IOMMU_API).Either way, I have no vehement objection to the change, I just don't seeany positive value in it.Robin.",Technical
,
"Because if iommu_map() only gets called at PAGE_SIZE granularity, thenthe IOMMU PTEs will be created at PAGE_SIZE (or smaller) granularity, soany effort to get higher-order allocations matching larger IOMMU blocksizes is wasted, and we may as well have just done this:	for (i = 0; i < count; i++) {		struct page *page = alloc_page(gfp);		...		iommu_map(..., page_to_phys(page), PAGE_SIZE, ...);	}Really, it's a shame we have to split huge pages for the CPU remap,since in the common case the CPU MMU will have a matching block size,but IIRC there was something in vmap() or thereabouts that explicitlychokes on them.Robin.",Technical
,
I've moved the idef back down below the includes.,Technical
,
"True.  I've dropped this patch.That just needs a volunteer to fix the implementation, as there is nofundamental reason not to remap large pages.",Technical
,
The bug fix is to handle non-vmalloc pages.  I'll see if I can doa smaller and more bandaid-y fix first.,Technical
,
"Well, I guess I need to reword this - there is no _requirement_ toremap.  And x86 has been happy to not remap so far and I see absolutelyno reason to force anyone to remap.I don't parse this.  In the old code base before this seriesiommu_dma_alloc is a relatively low-level helper allocating and mappingpages.  And that one should have done the remapping, and in fact doesso since (""dma-iommu: refactor page array remap helpers"").  It justhappens that the function is now called iommu_dma_alloc_remap.The new iommu_dma_alloc is the high level entry point that handlesevery possible case of different allocations, including those wherewe do not have a virtual mapping.",Technical
,
"Should the timeout be set depending on the max transfer size? 10s seemsan age if the max transfer size is 4KB. In other words, we should thisonly be applied for T194+?Furthermore, in tegra_i2c_xfer_msg() we know the len of the message andso maybe it would be better to dynamically set the timeout depending onlength?CheersJon--nvpublic",Technical
,
"Yes, thatâ€™s the ideal way to compute timeout based on msg len and bus rate.To do this I had to update TEGRA_I2C_TIMEOUT macro to take arg and there are 3 different patches for tegra i2c under review and all of those will effect as the patch changes use TEGRA_I2C_TIMEOUT.So, Should I hold on to this change for now till those patches are merged?ThanksSowjanya",Technical
,
"If you have a number of patches with interdependencies, it's best tosend them out as a whole series. So you'd typically apply them in orderto a single branch, then use:	$ git format-patch first^..lastwhere first is the SHA1 of the first commit you want to send, and lastis the the SHA1 of the last patch. The carret (^) means the parentcommit of the specified one and is needed because git format-patchdoesn't include the start of the sequence.If the commits are at the top of your branch you can use something likethis:	$ git format-patch -3which will generate a series for the last three patches in the branch(more specifically starting from HEAD).If you send them as a series, it's immediately obvious in what orderthey should be applied and generally makes it easier for people toreview and test.I think in this case you can probably just have the other two patchesfirst in the series, then apply the timeout patch on top. That way youcan resolve the conflicts between patches 1 and 2, and patch 3 beforesending out.Thierry",Technical
,
"This has the effect to ensure that if USER_ACCESS is a module then sois cxgb4, otherwise USER_ACCESS can be enabled or disabledJason",Technical
,
"Steve? It seems weird to have NOFAIL and then have an error unwindpath, what is the deal here?",Technical
,
"The other queue allocations in qp.c don't use __GFP_NOFAIL.  So eitherleave it and remove the error check as per this patch, or remove theNOFAIL and leave the check.I suggest you remove the __GFP_NOFAIL.Steve.",Technical
,
"The other queue allocations in qp.c don't use __GFP_NOFAIL.  So eitherleave it and remove the error check as per this patch, or remove theNOFAIL and leave the check.I suggest you remove the __GFP_NOFAIL, since I have a recollection thatusing it was frowned upon.  In this case, if there is no memoryavailable it is reasonable to return that error to the user creating thesrq...Steve.",Technical
,
As per steve's remarkes I revised this to the below and applied it tofor-next,Technical
,
Thanks Jason!,Technical
,
thanks for taking care of this - I simply did not have enoughcontext to decide if there would be some special reasonfor this allocation to need __GFP_NOFAIL - keeping its useto a minimum though is the best solution.thx!hofrat,Technical
,
"Just to clarify to the new Cc'ed list, I'm waiting on one of theChromium guys to review before I put my mucky paws over it.--Lee Jones [æŽç¼æ–¯]Linaro Services Technical LeadLinaro.org â”‚ Open source software for ARM SoCsFollow Linaro: Facebook | Twitter | Blog",Technical
,
"Hi Enric,On Wed, Jan 30, 2019 at 11:06 PM Enric Balletbo Serra<eballetbo@gmail.com> wrote:I don't think we need this to be merged ASAP.I feel that most of the todos are done though, so I'll drop the RFCtag and resend a v4 (which also contains some bug fixes found whentesting).",Technical
,
"Boqun had previously pointed this out; you need to WRITE_ONCE() node->head too.Thanks,Davidlohr",Technical
,
"The patch looks good to me. You can add:Reviewed-by: Jan Kara <jack@suse.cz>								Honza--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"Hum, do we have any users for this API? And wouldn't they also need tocontrol how many lists are allocated then?								Honza--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"This patch is supposed to be used by the epoll patch from Davidlohr. Ashe has retracted the patch, I can drop this patch also. The number oflists scale with the number of CPU cores in the system whether it isused one way or the others.Cheers,Longman",Technical
,
"Right, I will get that into the next version of the patch.Cheers,Longman",Technical
,
"I vote for doing this in the original version. How about the following?----------8<-----------------------------------------------From: Davidlohr Bueso <dave@stgolabs.net>Subject: [PATCH] lib/dlock-list: Scale dlock_lists_empty()Instead of the current O(N) implementation; at the costof adding an atomic counter. We also need to add a headspointer to the node structure such that we can unaccounta thread doing list_del().Signed-off-by: Davidlohr Bueso <dbueso@suse.de>--- include/linux/dlock-list.h |  2 ++ lib/dlock-list.c           | 40 ++++++++++++++++++++++++++++------------ 2 files changed, 30 insertions(+), 12 deletions(-)diff --git a/include/linux/dlock-list.h b/include/linux/dlock-list.hindex c00c7f92ada4..dd73d5787885 100644--- a/include/linux/dlock-list.h+++ b/include/linux/dlock-list.h@@ -36,6 +36,7 @@ struct dlock_list_head { struct dlock_list_heads { 	struct dlock_list_head *heads;+	atomic_t waiters; }; /*@@ -44,6 +45,7 @@ struct dlock_list_heads { struct dlock_list_node { 	struct list_head list; 	struct dlock_list_head *head;+	struct dlock_list_heads *heads; }; /*diff --git a/lib/dlock-list.c b/lib/dlock-list.cindex a4ddecc01b12..bd11fc0da254 100644--- a/lib/dlock-list.c+++ b/lib/dlock-list.c@@ -124,6 +124,8 @@ int __alloc_dlock_list_heads(struct dlock_list_heads *dlist, 		head->lock = __SPIN_LOCK_UNLOCKED(&head->lock); 		lockdep_set_class(&head->lock, key); 	}++	atomic_set(&dlist->waiters, 0); 	return 0; } EXPORT_SYMBOL(__alloc_dlock_list_heads);@@ -139,29 +141,23 @@ void free_dlock_list_heads(struct dlock_list_heads *dlist) { 	kfree(dlist->heads); 	dlist->heads = NULL;+	atomic_set(&dlist->waiters, 0); } EXPORT_SYMBOL(free_dlock_list_heads); /**  * dlock_lists_empty - Check if all the dlock lists are empty  * @dlist: Pointer to the dlock_list_heads structure- * Return: true if list is empty, false otherwise.  *- * This can be a pretty expensive function call. If this function is required- * in a performance critical path, we may have to maintain a global count- * of the list entries in the global dlock_list_heads structure instead.+ * Return: true if all dlock lists are empty, false otherwise.  */ bool dlock_lists_empty(struct dlock_list_heads *dlist) {-	int idx;- 	/* Shouldn't be called before nr_dlock_lists is initialized */ 	WARN_ON_ONCE(!nr_dlock_lists);-	for (idx = 0; idx < nr_dlock_lists; idx++)-		if (!list_empty(&dlist->heads[idx].list))-			return false;-	return true;+	smp_mb__before_atomic();+	return !atomic_read(&dlist->waiters); } EXPORT_SYMBOL(dlock_lists_empty);@@ -179,10 +175,30 @@ void dlock_lists_add(struct dlock_list_node *node, 	struct dlock_list_head *head = &dlist->heads[this_cpu_read(cpu2idx)]; 	/*+	 * Serialize dlist->waiters such that a 0->1 transition is not missed,+	 * by another thread checking if any of the dlock lists are used.+	 *+	 * CPU0				    CPU1+	 * dlock_list_add()                 dlock_lists_empty()+	 *   [S] atomic_inc(waiters);+	 *	 smp_mb__after_atomic();+	 *				      smp_mb__before_atomic();+	 *				      [L] atomic_read(waiters)+	 *       list_add()+	 *+	 * Bump the waiters counter _before_ taking the head->lock such that we+	 * don't miss a thread adding itself to a list while spinning for the+	 * lock.+	 */+	atomic_inc(&dlist->waiters);+	smp_mb__after_atomic();++	/* 	 * There is no need to disable preemption 	 */ 	spin_lock(&head->lock); 	node->head = head;+	node->heads = dlist; 	list_add(&node->list, &head->list); 	spin_unlock(&head->lock); }@@ -199,8 +215,7 @@ EXPORT_SYMBOL(dlock_lists_add);  * a bug.  */ void dlock_lists_del(struct dlock_list_node *node)-{-	struct dlock_list_head *head;+{	struct dlock_list_head *head; 	bool retry; 	do {@@ -214,6 +229,7 @@ void dlock_lists_del(struct dlock_list_node *node) 			list_del_init(&node->list); 			node->head = NULL; 			retry = false;+			atomic_dec(&node->heads->waiters); 		} else { 			/* 			 * The lock has somehow changed. Retry again if it is--2.13.6",Technical
,
"The counter will then become the single contention point for allconcurrent updates to the dlock-list. So it will have a big impact onperformance. On the other hand, instead of being a counter of # ofitems, we can make that a counter of # of non-empty lists. So its valuewill only be changed when a list go from empty to non-empty and viceversa. That will greatly reduce the number of updates to that counter.I don't want to add a new data item into dlock_list_node as there can bethousands or even of them in the system. Instead, I prefer increasing thesize of dlock_list_head which only have a limited number of them andthey have unused space because they are cacheline aligned.Cheers,Longman",Technical
,
"Both are good points. Thanks.----8<--------------------------------------------------------Subject: [PATCH] [PATCH v2] lib/dlock-list: Scale dlock_lists_empty()Instead of the current O(N) implementation, at the costof adding an atomic counter, we can convert the call toan atomic_read(). The counter only serves for accountingempty to non-empty transitions, and vice versa; thereforeonly modified twice for each of the lists, during thelifetime of the dlock -- thus 2*nr_dlock_lists.In addition, to be able to unaccount a list_del(), weadd a dlist pointer to each head, thus minimizing theoverall memory footprint.Signed-off-by: Davidlohr Bueso <dbueso@suse.de>--- include/linux/dlock-list.h |  2 ++ lib/dlock-list.c           | 56 +++++++++++++++++++++++++++++++++++----------- 2 files changed, 45 insertions(+), 13 deletions(-)diff --git a/include/linux/dlock-list.h b/include/linux/dlock-list.hindex c00c7f92ada4..d176a2d00cd1 100644--- a/include/linux/dlock-list.h+++ b/include/linux/dlock-list.h@@ -32,10 +32,12 @@ struct dlock_list_head { 	struct list_head list; 	spinlock_t lock;+	struct dlock_list_heads *dlist; } ____cacheline_aligned_in_smp; struct dlock_list_heads { 	struct dlock_list_head *heads;+	atomic_t waiters; }; /*diff --git a/lib/dlock-list.c b/lib/dlock-list.cindex a4ddecc01b12..a84f42e800d5 100644--- a/lib/dlock-list.c+++ b/lib/dlock-list.c@@ -122,8 +122,11 @@ int __alloc_dlock_list_heads(struct dlock_list_heads *dlist, 		INIT_LIST_HEAD(&head->list); 		head->lock = __SPIN_LOCK_UNLOCKED(&head->lock);+		head->dlist = dlist; 		lockdep_set_class(&head->lock, key); 	}++	atomic_set(&dlist->waiters, 0); 	return 0; } EXPORT_SYMBOL(__alloc_dlock_list_heads);@@ -138,30 +141,36 @@ EXPORT_SYMBOL(__alloc_dlock_list_heads); void free_dlock_list_heads(struct dlock_list_heads *dlist) { 	kfree(dlist->heads);-	dlist->heads = NULL;+	atomic_set(&dlist->waiters, 0); } EXPORT_SYMBOL(free_dlock_list_heads); /**  * dlock_lists_empty - Check if all the dlock lists are empty  * @dlist: Pointer to the dlock_list_heads structure- * Return: true if list is empty, false otherwise.  *- * This can be a pretty expensive function call. If this function is required- * in a performance critical path, we may have to maintain a global count- * of the list entries in the global dlock_list_heads structure instead.+ * Return: true if all dlock lists are empty, false otherwise.  */ bool dlock_lists_empty(struct dlock_list_heads *dlist) {-	int idx;- 	/* Shouldn't be called before nr_dlock_lists is initialized */ 	WARN_ON_ONCE(!nr_dlock_lists);-	for (idx = 0; idx < nr_dlock_lists; idx++)-		if (!list_empty(&dlist->heads[idx].list))-			return false;-	return true;+	/*+	 * Serialize dlist->waiters such that a 0->1 transition is not missed+	 * by another thread checking if any of the dlock lists are used.+	 *+	 * CPU0				    CPU1+	 * dlock_list_add()                 dlock_lists_empty()+	 *   [S] atomic_inc(waiters);+	 *       smp_mb__after_atomic();+	 *					  smp_mb__before_atomic();+	 *				      [L] atomic_read(waiters)+	 *       list_add()+	 *+	 */+	smp_mb__before_atomic();+	return !atomic_read(&dlist->waiters); } EXPORT_SYMBOL(dlock_lists_empty);@@ -179,6 +188,16 @@ void dlock_lists_add(struct dlock_list_node *node, 	struct dlock_list_head *head = &dlist->heads[this_cpu_read(cpu2idx)]; 	/*+	 * Bump the waiters counter _before_ taking the head->lock+	 * such that we don't miss a thread adding itself to a list+	 * while spinning for the lock.+	 */+	if (list_empty_careful(&head->list)) {+		atomic_inc(&dlist->waiters);+		smp_mb__after_atomic();+	}++	/* 	 * There is no need to disable preemption 	 */ 	spin_lock(&head->lock);@@ -199,8 +218,7 @@ EXPORT_SYMBOL(dlock_lists_add);  * a bug.  */ void dlock_lists_del(struct dlock_list_node *node)-{-	struct dlock_list_head *head;+{	struct dlock_list_head *head; 	bool retry; 	do {@@ -212,6 +230,18 @@ void dlock_lists_del(struct dlock_list_node *node) 		spin_lock(&head->lock); 		if (likely(head == node->head)) { 			list_del_init(&node->list);+			/*+			 * We still hold the head->lock, a normal list_empty()+			 * check will do.+			 */+			if (list_empty(&head->list)) {+				struct dlock_list_heads *dlist;+				dlist = node->head->dlist;++				atomic_dec(&dlist->waiters);+				smp_mb__after_atomic();+			}+ 			node->head = NULL; 			retry = false; 		} else {--2.13.6",Technical
,
"We are tracking number of non-empty lists here. So I think we need abetter name and maybe some documentation of what it is.That is racy. You will need to remember that you have opportunisticallyincremented the count. After acquiring the spinlock, the code will haveto decrement it if the list is no longer empty. You will also have toincrement it after lock if the list is empty now, but not previously.Do you need that while the code will do a spin_unlock soon?Cheers,Longman",Technical
,
This patch looks good to me.Acked-by: Waiman Long <longman@redhat.com>,Technical
,
"Looks good to me. You can add:Reviewed-by: Jan Kara <jack@suse.cz>								Honza Kara--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"Just a general kernel programming question here - I thought the whole pointof atomics is that they are, well, atomic across all CPUs so there is noneed for a memory barrier?  If there is a need for a memory barrier foreach atomic access (assuming it isn't accessed under another lock, which wouldmake the use of atomic types pointless, IMHO) then I'd think there is a lotof code in the kernel that isn't doing this properly.What am I missing here?I don't see how this helps if the operations are executed like:	 * CPU0				    CPU1	 * dlock_list_add()                 dlock_lists_empty()	 *   [S] atomic_inc(used_lists);	 *					  smp_mb__before_atomic();	 *       smp_mb__after_atomic();	 *				      [L] atomic_read(used_lists)or alternately like:	 * CPU0				    CPU1	 * dlock_list_add()                 dlock_lists_empty()	 *					  smp_mb__before_atomic();	 *   [S] atomic_inc(used_lists);	 *       smp_mb__after_atomic();	 *				      [L] atomic_read(used_lists)then the same problem would exist, unless those functions/macros are somehowbound to the atomic operations themselves?  In that case, what makes the useof atomic_{inc,dec,read}() in other parts of the code safe without them?Cheers, Andreas",Technical
,
"Atomic update and memory barrier are 2 different things. Atomic updatemeans other CPUs see either the value before or after the update. Theywon't see anything in between. For a counter, it means we won't miss anycounts. However, not all atomic operations give an ordering guarantee.The atomic_read() and atomic_inc() are examples that do not providememory ordering guarantee. See Documentation/memory-barriers.txt formore information about it.A CPU can perform atomic operations 1 & 2 in program order, but otherCPUs may see operation 2 first before operation 1. Here memory barriercan be used to guarantee that other CPUs see the memory updates incertain order.Hope this help.Longman",Technical
,
"There's an omission here which I think Andreas may have been referringto: Â atomic_inc/dec operations *are* strongly ordered with respect toeach other, so if two CPUs are simultaneously executing atomic_inc, theorder in which they execute isn't guaranteed, but it is guaranteed thatthe losing atomic_inc will not begin until the winning one iscompleted, so after both are done the value will have +2. Â So althoughatomic_read and atomic_inc have no ordering guarantee at all (the pointof the barrier above), if you're looking at the return values ofatomic_inc/dec you don't need a barrier because regardless of whichorder the CPUs go in, they'll see distinct values (we use this forreference counting).James",Technical
,
"Or worse: 	 * CPU0				    CPU1 	 * dlock_list_add()                 dlock_lists_empty() 	 *					  smp_mb__before_atomic(); 	 *				      [L] atomic_read(used_lists) 	 *   [S] atomic_inc(used_lists); 	 *       smp_mb__after_atomic();, in which case dlock_lists_empty() misses a increment of used_lists.That said, this may be fine for the usage of dlock_list. But I think thecomments are confusing or wrong. The reason is you can not use barriersto order two memory ops on different CPUs, and usually we add commentslike:	[S] ...			[S] ...	<barrier>		<barrier>	[L] ...			[L] ...Davidlohr, could you try to improve the comments by finding both memoryops preceding and following the barriers? Maybe you will find thosebarriers are not necessary in the end.Regards,Boqun",Technical
,
"So I think that case is OK as CPU1 legitimately reads a 0, the problemwould be if we miss the inc it because we are doing spin_lock().That is true.Ok so for the dlock_list_add() the first barrier is so that the atomic_inc()is not done inside the critical region, after the head->lock is taken.The other barriers that follow I put such that the respective atomic opis done before the list_add(), however thinking about it I don't thinkthey are really needed.Regarding dlock_list_empty(), the smp_mb__before_atomic() is mainly forpairing reasons; but at this point I don't see a respective counterpartfor the above diagram so I'm unclear.Thanks,Davidlohr",Technical
,
Note that this is broken; smp_mb__before_atomic() is not valid onatomic_read().,Technical
,
"Are you planning on sending a v9 with the discussed changes? afaict:- Drop last two patches- Fix tearing (WRITE/READ_ONCE())- Reduce barrier usage for dlock_lists_empty() -- which I'll be sending  you shortly.Thanks,Davidlohr",Technical
,
Reviewed-by: Davidlohr Bueso <dbueso@suse.de>,Technical
,
"Yes, I am planning to do so when I have some free time as I am workingon a high-priority task at the moment.Regards,Longman",Technical
,
"Hi Waiman,What's happened to this patchset? Any plans to repost a more recentversion?FYI, I just ran a workload that hit 60% CPU usage on sb inode listlock contention - a multithreaded bulkstat scan of an XFS filesystemwith millions of inodes on SSDs. last time I ran this (about 18months ago now!) I saw rates of about 600,000 inodes/s being scannedfrom userspace. The run I did earlier today made 300,000 inodes/s onthe same 16p machine and was completely CPU bound....Cheers,Dave.--Dave Chinnerdavid@fromorbit.com",Technical
,
"I was planning to repost the patchset with the latest change lastNovember and then Meltdown/Spectre happened. I was drafted intobackporting fixes to RHEL6. Hopefully, I can finish up the work in earlyMarch and work on my upstream patches again.Cheers,Longman",Technical
,
"Le mardi 22 janvier 2019 Ã  12:53 +0200, Stanimir Varbanov a Ã©crit :ixes -> fixesNote sure, maybe you didn't mean to add 'one' here ? Why not just saythat that firmware expect values in Q16 ?Looking toward testing it, but I had the bad luck of using an USBstorage rootfs, and apparently USB no longer works on 5.0rc+, if youhave a baseline tree to suggest, I'll take it. Thanks for this patch.",Technical
,
"Hi Nicolas,yes, thanks for the suggestion.try qcomlt-4.14 release branch at [1].--regards,Stan[1]https://git.linaro.org/landing-teams/working/qualcomm/kernel.git/log/?h=release/qcomlt-4.14",Technical
,
"Noise, I am wrong...",Technical
,
"This name does not match up with the ""From:"" line :(Please fix up and resend.thanksgreg k-h",Technical
,
Geliang Tang <geliangtang@gmail.com> wrote:Do you have an oops report or test case for this?David,Technical
,
"Here is the test module code. Insmod it, we can get the oops.#include <linux/init.h>#include <linux/module.h>#include <linux/key.h>#include <linux/key-type.h>#include <linux/cred.h>#include <linux/seq_file.h>static int test_instantiate(struct key *key, struct key_preparsed_payload *prep){	return 0;}static void test_describe(const struct key *key, struct seq_file *m){	seq_puts(m, key->description);}struct key_type test_key_type = {        .name           = ""test"",	//.instantiate	= test_instantiate,        .describe       = test_describe,};static int __init test_init(void){	const struct cred *cred = current_cred();	struct key *key;	int ret;	register_key_type(&test_key_type);	key = key_alloc(&test_key_type, ""test"",			GLOBAL_ROOT_UID, GLOBAL_ROOT_GID, cred,			KEY_POS_SEARCH, KEY_ALLOC_NOT_IN_QUOTA, NULL);	if (IS_ERR(key))		return -1;	pr_info(""keyring allocated successfully.\n"");	ret = key_instantiate_and_link(key,				       NULL,				       sizeof(int),				       current->cred->user->session_keyring,				       NULL);	if (ret < 0) {		key_revoke(key);		key_put(key);		return ret;	}	return 0;}static void __exit test_exit(void){	unregister_key_type(&test_key_type);}module_init(test_init);module_exit(test_exit);MODULE_LICENSE(""GPL"");",Technical
,
"Here is the test module code. Insmod it, we can get the oops.#include <linux/init.h>#include <linux/module.h>#include <linux/key.h>#include <linux/key-type.h>#include <linux/cred.h>#include <linux/seq_file.h>static int test_instantiate(struct key *key, struct key_preparsed_payload *prep){	return 0;}static void test_describe(const struct key *key, struct seq_file *m){	seq_puts(m, key->description);}struct key_type test_key_type = {        .name           = ""test"",	//.instantiate	= test_instantiate,        .describe       = test_describe,};static int __init test_init(void){	const struct cred *cred = current_cred();	struct key *key;	int ret;	register_key_type(&test_key_type);	key = key_alloc(&test_key_type, ""test"",			GLOBAL_ROOT_UID, GLOBAL_ROOT_GID, cred,			KEY_POS_SEARCH, KEY_ALLOC_NOT_IN_QUOTA, NULL);	if (IS_ERR(key))		return -1;	pr_info(""keyring allocated successfully.\n"");	ret = key_instantiate_and_link(key,				       NULL,				       sizeof(int),				       current->cred->user->session_keyring,				       NULL);	if (ret < 0) {		key_revoke(key);		key_put(key);		return ret;	}	return 0;}static void __exit test_exit(void){	unregister_key_type(&test_key_type);}module_init(test_init);module_exit(test_exit);MODULE_LICENSE(""GPL"");",Technical
,
"You do not need explicitly unregister input device if it is managed(allocated with devm).This is however is wrong, as you can't shutdown hardware beforedisapling/freeing IRQ, etc. Given that there are no users ofgp2a_platform_data in kernel I'd recommend creating a preparatory patchremoving platform data support from the driver.Thanks.--Dmitry",Technical
,
"No, light sensor is not an input device, keep it in IIO please.--Dmitry",Technical
,
Do you know what it is for?--Dmitry,Technical
,
"Hi Dmitry,Thanks for your review of the patches.Considering that the light sensor part should be in IIO, should the entire driver be rewritten as an IIO driver?  There's already the driver for gp2ap020a00f there which is presumably the gp2ap002a00f's successor and does the same functions.It's the control of the main power supply to the chip.Thanks,Jonathan",Technical
,
"I'd be fine with that.In this case it should be a power supply (regulator), not gpio.Thanks.--Dmitry",Technical
,
"Hi Martin,On Mon, 28 Jan 2019 11:20:22 +0100Martin Kepplinger <martink@posteo.de> wrote:Not sure why it never made it. I created it for use with a wl1271 whichwan't properly reset in case of a fault. Also combined with imx28.Regards,Robin van der Gracht",Technical
,
Isn't there a GPIO that needs to be toggled and separate clk for theWiFi chip that needs to be enabled as well?You don't need this here as this is already part of the generic structmmc_host (via the struct mmc_supply).Ditto.You should use mmc_regulator_set_ocr() instead.Ditto.This isn't needed. The state is already controlled by the mmc core.You should use mmc_regulator_get_supply() instead.Kind regardsUffe,Technical
,
Coding style is off here. But really I don't think these inlines areneeded here. Put them in qemu or something.,Technical
,
"I also wonder why do we want to put this code in the legacy sectionand use the legacy virtio_net_hdr as opposed to the new virtio_net_hdr_v1.coding style says:	Descendants are always substantially shorter than the parent and	are placed substantially to the right.placing a line to the left of ( doesn't count as substantially to theright :)Maybe start a new line at virtio_net_rsc_ext_num_dupacks.Lack of documentation is also a problem.Okay but this assumes specific usage. E.g. someone might wantan offset and not a pointer. Or have a struct instance on stack.Given all above issues (and also header version issuesdescribed above) I'm inclined to say macros are better:#define virtio_net_rsc_ext_num_packets csum_start#define virtio_net_rsc_ext_num_dupacks csum_offsetBut please in any case also add documentation same as we have forfields.",Technical
,
"[ ... ]...Nit: does not seem to be required--Sincerely yours,Mike.",Technical
,
"Good catch. Notch one more line saved in the incremental diffstat fromv8. I'll wait for Michal's thumbs up on the rest before re-spinning,or perhaps Andrew can drop this line on applying?",Technical
,
"The last part is not true with this version anymore, right?I find mm_shuffle_ctl a bit confusing because the mode of operation iseither AUTO (enabled when the HW is present) or FORCE_ENABLE whenexplicitly enabled by the command line. Nothing earth shattering though.Other than that, I haven't spotted any fundamental issues. The featureis a hack but I do agree that it might be useful for the specific HW itis going to be used for. I still think that shuffling only top ordershas close to zero security benefits because it is not that hard tocontrol the memory fragmentation.With thatAcked-by: Michal Hocko <mhocko@suse.com>--Michal HockoSUSE Labs",Technical
,
I have asked in v7 but didn't get any response. Do we really ned perfree_area random pool? Why a global one is not sufficient?--Michal HockoSUSE Labs,Technical
,
"Ah, yes, sorry, overlooked that feedback. A global one is sufficient.Will rework.",Technical
,
"True, and given that page_alloc_init_late() is waiting for it completethe impact is no different from v8 to v9. I'll drop that sentence fromthe changelog.Yeah, it's named from the perspective of the kernel internal usagewhich is flipped from the user facing interaction. ENABLE is calledfrom the command line handler and in a follow-on patch the parser ofthe platform-firmware table indicating the presence of a cache.FORCE_DISABLE is only called from the command line handler. I'll add acomment to this effect.Much appreciated.",Technical
,
"This is unfortunate from a testing and coverage point of view.  Atleast initially it is desirable that all testers run this feature.Also, it's unfortunate that enableing the feature requires a reboot.What happens if we do away with the boot-time (and maybe hotplug-time)randomization and permit the feature to be switched on/off at runtime?Can we get a Documentation update for the new kernel parameter?Does shuffle.h need to be available to the whole kernel or can we putit in mm/?Can this be __meminit?Reflowing the comment to use all 80 cols would save a line :)Second sentence is hard to parse.Reflow the comment...Reflow.",Technical
,
A static inline would be nicer.Well that's nice and simple.,Technical
,
"[..]Currently there's the 'shuffle' at memory online time and a randomfront-back freeing of max_order pages to the free lists at runtime.The random front-back freeing behavior would be trivial to toggle atruntime, however testing showed that the entropy it injects is onlyenough to preserve the randomization of the initial 'shuffle', but notenough entropy to improve cache utilization on its own.The shuffling could be done dynamically at runtime, but it onlyshuffles free memory, the effectiveness is diminished if the workloadhas already taken pages off the free list. It's also diminished if thefree lists are polluted with sub MAX_ORDER pages.The number of caveats that need to be documented makes me skepticalthat runtime triggered shuffling would be reliable.That said, I see your point about experimentation and validation. Whatabout allowing it to be settable as a sysfs parameter formemory-blocks that are being hot-added? That way we know the shufflewill be effective and the administrator can validate shuffling with ahot-unplug/replug?Yes.The wider kernel just needs page_alloc_shuffle() so thatplatform-firmware parsing code that detects a memory-side-cache canenable the shuffle. The rest can be constrained to an mm/ localheader.Yes.WIll do.Earlier versions only arranged to shuffle over non-hole ranges, butthe SHUFFLE_RETRY works around that now. I'll update the comment.yup.ok.",Technical
,
"Hello,Gentle reminder for this new driver reviewBest Regards,Fabrice",Technical
,
"Nvmem provider driver itself looks fine for me, but I am unable to takethis as 5.1 material, as I normally take nvmem patches which arereviewed and ready before rc5.dt bindings patch needs an ack from DT maintainers.Thanks,srini",Technical
,
"Hi Srini,Thanks for the feedback.I hope Rob cant take a look at it.Best Regards,Fabrice",Technical
,
"Several distinct types here. Does s/w need to know the differencerather than just one generic-ish compatible? Access size restrictionsmaybe? Ability to unlock and program?If not, then why even make this stm32 specific?",Technical
,
"Hi Rob,The reading part is represented here as ""st,stm32-romem"" compatible, tosimply handle read only access. I agree this could be a generic-ish.BUT the specifics are regarding the ability to unlock/lock and program.Access size can vary from one part to another (e.g. on stm32f4,reference manual sates: OTP area is divided into 16 OTP data blocks of32 bytes. on stm32f7, OTP area is divided into 16 OTP data blocks of 64bytes.)In STM32MP15, both the read & write access through the BSEC arespecific, represented by dedicated compatible.Do you wish I update the compatible to something like:""st,stm32f4-otp""""st,stm32mp15-bsec""?Thanks for reviewing,Best regards,Fabrice",Technical
,
"Yes, I think given the above that makes sense. We can always mapspecific bindings to generic drivers, but not the reverse.Rob",Technical
,
"Hello Rob, DT Maintainers,Gentlemen reminder for new DT bindings review.Best Regards,Fabrice",Technical
,
Thanks but I submitted a different patch:https://lore.kernel.org/lkml/8b02899853247a2c67669561761f354dd3bd110e.camel@perches.com/,Technical
,
"I tried your patch, but when running checkpatch.pl onhttps://patchwork.kernel.org/patch/10790203/, I still get:WARNING: 'SPDX-License-Identifier: GPL-2.0 */' is not supported in LICENSES/...#75: FILE: drivers/remoteproc/mtk_common.h:1:+/* SPDX-License-Identifier: GPL-2.0 */Feels that these two patches fix different issues.",Technical
,
"Hello everyone,If it's cleared with ptep_clear_flush_notify, change_pte still won'twork. The above text needs updating with""ptep_clear_flush"". set_pte_at_notify is all about havingptep_clear_flush only before it or it's the same as having a rangeinvalidate preceding it.With regard to the code, wp_page_copy() needss/ptep_clear_flush_notify/ptep_clear_flush/ before set_pte_at_notify.change_pte relies on the ptep_clear_flush preceding theset_pte_at_notify that will make sure if the secondary MMU mappingrandomly disappears between ptep_clear_flush and set_pte_at_notify,gup_fast will wait and block on the PT lock until afterset_pte_at_notify is completed before trying to re-establish asecondary MMU mapping.So then we've only to worry about what happens because we left thesecondary MMU mapping potentially intact despite we flushed theprimary MMU mapping with ptep_clear_flush (as opposed toptep_clear_flush_notify which would teardown the secondary MMU mappingtoo).In you wording above at least the ""with a different pfn"" issuperflous. I think it's ok if the protection changes from read-onlyto read-write and the pfn remains the same. Like when we takeover apage because it's not shared anymore (fork child quit).It's also ok to change pfn if the mapping is read-only and remainsread-only, this is what KSM does in replace_page.The read-write to read-only case must not change pfn to avoid losingcoherency from the secondary MMU point of view. This isn't so muchabout change_pte itself, but the fact that the page-copy generallyhappens well before the pte mangling starts. This case never presentsitself in the code because KSM is first write protecting the page andonly later merging it, regardless of change_pte or not.The important thing is that the secondary MMU must be updated first(unlike the invalidates) to be sure the secondary MMU already pointsto the new page when the pfn changes and the protection changes fromread-only to read-write (COW fault). The primary MMU cannot read/writeto the page anyway while we update the secondary MMU because we didptep_clear_flush() before calling set_pte_at_notify(). So thisordering of ""ptep_clear_flush; change_pte; set_pte_at"" ensureswhenever the CPU can access the memory, the access is synchronouswith the secondary MMUs because they've all been updated already.If (in set_pte_at_notify) we were to call change_pte() afterset_pte_at() what would happen is that the CPU could write to the pagethrough a TLB fill without page fault while the secondary MMUs stillread the old memory in the old readonly page.Thanks,Andrea",Technical
,
"Oops, the above two statements were incorrect becauseptep_clear_flush_notify doesn't interfere with change_pte and willonly invalidate secondary MMU mappings on those secondary MMUs thatshares the same pagetables with the primary MMU and that in turn won'tever implement a change_pte method.",Technical
,
"This seems racy by design in the way it copies the page, if the vmamapping isn't readonly to begin with (in which case it'd be ok tochange the pfn with change_pte too, it'd be a from read-only toread-only change which is ok).If the code copies a writable page there's no much issue if coherencyis lost by other means too.Said that this isn't a worthwhile optimization for uprobes so becauseof the lack of explicit read-only enforcement, I agree it's simpler toskip change_pte above.It's orthogonal, but in this function themmu_notifier_invalidate_range_end(&range); can be optimized tommu_notifier_invalidate_range_only_end(&range); otherwise there's nopoint to retain the _notify in ptep_clear_flush_notify.",Technical
,
"This is only allocated in the stack, so saving RAM by mixing bitfieldswith enum in the same 4 bytes to save 4 bytes isn't of maximumpriority.A possibly cleaner way to save those 4 bytes without mixing enum withbitfields by hand, is to add a ""unsigned short flags"" which will make""event/flags/blockable"" fit in the same 8 bytes (bool only needs 1byte) as before the patch (the first bitfield can start from 0 then).Yet another way is to drop blockable and convert it to a flag in""unsigned int flags"".",Technical
,
"So all the above is moot since as you pointed out in the other emailptep_clear_flush_notify does not invalidate kvm secondary mmu hence.Yes i thought this was obvious i will reword and probably just do alist of every case that is fine.Yeah, between do you have any good workload for me to test this ? Iwas thinking of running few same VM and having KSM work on them. Isthere some way to trigger KVM to fork ? As the other case is breakingCOW after fork.Cheers,Jrme",Technical
,
"Background we are discussing __replace_page() in:    kernel/events/uprobes.cand wether this can be call on page that can be written too throughits virtual address mapping.I am not sure the race exist but i am not familiar with the uprobecode so maybe the page is already write protected and thus the copyis fine and in fact that is likely the case but there is not checkfor that. Maybe there should be a check ?Maybe someone familiar with this code can chime in.We need to keep the _notify for IOMMU otherwise it would break IOMMU.IOMMU can walk the page table at any time and thus we need to firstclear the table then notify the IOMMU to flush TLB on all the devicesthat might have a TLB entry. Only then can we set the new pte.But yes the mmu_notifier_invalidate_range_end can be optimized toonly end. I will do a separate patch for this. As it is orthogonal asyou pointed out :)Cheers,Jrme",Technical
,
"KVM can fork on guest pci-hotplug events or network init to run hostscripts and re-init the signals before doing the exec, but it won'tmove the needle because all guest memory registered in the MMUnotifier is set as MADV_DONTFORK... so fork() is a noop unless qemu isalso modified not to call MADV_DONTFORK.Calling if (!fork()) exit(0) from a timer at regular intervals duringqemu runtime after turning off MADV_DONTFORK in qemu would allow toexercise fork against the KVM MMU Notifier methods.The optimized change_pte code in copy-on-write code is the samepost-fork or post-KSM merge and fork() itself doesn't use change_ptewhile KSM does, so with regard to change_pte it should already providea good test coverage to test with only KSM without fork(). It'll coverthe read-write -> readonly transition with same PFN(write_protect_page), the read-only to read-only changing PFN(replace_page) as well as the readonly -> read-write transitionchanging PFN (wp_page_copy) all three optimized with change_pte. Forkwould not leverage change_pte for the first two cases.",Technical
,
"So i run 2 exact same VMs side by side (copy of same COW image) andbuilt the same kernel tree inside each (that is the only importantworkload that exist ;)) but the change_pte did not have any impact:before  mean  {real: 1358.250977, user: 16650.880859, sys: 839.199524, npages: 76855.390625}before  stdev {real:    6.744010, user:   108.863762, sys:   6.840437, npages:  1868.071899}after   mean  {real: 1357.833740, user: 16685.849609, sys: 839.646973, npages: 76210.601562}after   stdev {real:    5.124797, user:    78.469360, sys:   7.009164, npages:  2468.017578}without mean  {real: 1358.501343, user: 16674.478516, sys: 837.791992, npages: 76225.203125}without stdev {real:    5.541104, user:    97.998367, sys:   6.715869, npages:  1682.392578}Above is time taken by make inside each VM for all yes config. npagesis the number of page shared reported on the host at the end of thebuild.There is no change before and after the patchset to restore changepte. I tried removing the change_pte callback alltogether to see ifthat did have any effect (without above) and it did not have anyeffect either.Should we still restore change_pte() ? It does not hurt, but it doesnot seems to help in anyway. Maybe you have a better benchmark i couldrun ?Cheers,Jrme",Technical
,
"Did you set /sys/kernel/mm/ksm/sleep_millisecs to 0?It would also help to remove the checksum check from mm/ksm.c:-	if (rmap_item->oldchecksum != checksum) {-		rmap_item->oldchecksum = checksum;-		return;-	}One way or another, /sys/kernel/mm/ksm/pages_shared and/orpages_sharing need to change significantly to be sure we're exercisingthe COW/merging code that uses change_pte. KSM is smart enough tomerge only not frequently changing pages, and with the default KSMcode this probably works too well for a kernel build.We could also try a microbenchmark based onltp/testcases/kernel/mem/ksm/ksm02.c that already should trigger amerge flood and a COW flood during its internal processing.Thanks,Andrea",Technical
,
"No but i have increase the pages_to_scan to 10000 and during the kernelbuild i see the number of page that are shared increase steadily so itis definitly merging thing.Will try with that.Will try that.Cheers,Jrme",Technical
,
"Would it also make sense to track how many pages are really affectedby change_pte (say, in kvm_set_pte_rmapp, count avaliable SPTEs thatare correctly rebuilt)?  I'm thinking even if many pages are merged byKSM it's still possible that these pages are not actively shadowed byKVM MMU, meanwhile change_pte should only affect actively shadowedSPTEs.  In other words, IMHO we might not be able to observe obviousperformance differeneces if the pages we are accessing are not mergedby KSM.  In our case (building the kernel), IIUC the mostly possibleshared pages are system image pages, however when building the kernelI'm thinking whether these pages will be frequently accesses, andwhether this could lead to similar performance numbers.Thanks,--Peter Xu",Technical
,
"I checked that, if no KVM is running KSM never merge anything (afterbumping KSM page to scan to 10000 and sleep to 0). It starts mergingonce i start KVM. Then i wait a bit for KSM to stabilize (ie to mergethe stock KVM pages). It is only once KSM count is somewhat stablethat i run the test and check that KSM count goes up significantlywhile test is running.KSM will definitly go through the change_pte path for KVM so i amdefinitly testing the change_pte path.I have been running the micro benchmark and on that i do see a perfimprovement i will report shortly once i am done gathering enoughdata.Cheers,Jrme",Technical
,
"So using that and the checksum test removed there is an improvement,roughly 7%~8% on time spends in the kernel:before  mean  {real: 675.460632, user: 857.771423, sys: 215.929657, npages: 4773.066895}before  stdev {real:  37.035435, user:   4.395942, sys:   3.976172, npages:  675.352783}after   mean  {real: 672.515503, user: 855.817322, sys: 200.902710, npages: 4899.000000}after   stdev {real:  37.340954, user:   4.051633, sys:   3.894153, npages:  742.413452}I am guessing for kernel build this get lost in the noise and thatKSM changes do not have that much of an impact. So i will repostingthe mmu notifier changes shortly in hope to get them in 5.1 and iwill post the KVM part separatly shortly there after.If there is any more testing you wish me to do let me know.Cheers,Jrme",Technical
,
"What determines when you want to use polling mode? I'm not sure DTis the best way to control this unless it's really a property ofthe h/w. Driver behavior is really outside the scope of the DT. u-bootwould use polling even if an interrupt is specified, for example.Rob",Technical
,
What's the data type and size? What are valid values?,Technical
,
"Hi Rob,It's tied to the particular revision of the I2C controller, i.e., theiProc NIC i2c controller does not have interrupt line wired. In thiscase, the behavior is determined by the DT compatible string of theiProc I2C device. I thought that it makes sense to now move the'interrupts' property to be under ""Optional"" than ""Required"" which isbasically what this change is.",Technical
,
It's an unsigned u32 mask value. An example of a valid value is forexample 0x03400000. Do you want any of these added to the paragraph above?,Technical
,
Yes. Bindings should define constraints.Rob,Technical
,
"Okay, please put this detail into the commit msg.Rob",Technical
,
Okay will do! Thanks.,Technical
,
Will do! Thanks.,Technical
,
"OK, cool.Prefer slash for TPM specific commits.I can merge this after those extra logs are removed./Jarkko",Technical
,
"Hi,I guess we don't need to initialize it anymore with the check you add?Maxime--Maxime Ripard, BootlinEmbedded Linux and Kernel engineeringhttps://bootlin.com",Technical
,
"From: Yizhuo <yzhai003@ucr.edu>Date: Tue,  5 Feb 2019 14:15:59 -0800I agree with the other reviewer that since you check 'ret' the initialization of'val' is no longer needed.",Technical
,
"Hi Kishon,Could you please help to review and provide your comments to thispatch series when you have time?Regards,Srinath.On Wed, Feb 6, 2019 at 11:03 PM Srinath Mannam<srinath.mannam@broadcom.com> wrote:",Technical
,
"SoC specific compatibles are preferred. Version numbers can be used butshould follow some documented scheme and be meaningful. What we don'twant is just Linux developers making up numbering.Unless there's DT resources for each child node, you don't need these.Just make #phy-cells 1 in the parent.Rob",Technical
,
"Hi Rob,Thanks for review, please see my comments below inline.Both versions are different phy controllers and also have separateregister offsets.I will provide more meaningful compatible IDs and their documentationin next patchset.With the use of phy-cell, PHY argument is available with xlatefunction, But controller specific assignments requiredto be done while probe. So I will take your first option given inprevious comment.Regards,Srinath.",Technical
,
"Not sure if we support backwards compatibility like this?My issue with this change is that by doing this, application will haveno clue if the new bits were ignored or not and it may think that anevent is enabled while it is not.A workaround would be to do a getsockopt and check the size that wasreturned. But then, it might as well use the right struct here in thefirst place.I'm seeing current implementation as an implicitly versioned argument:it will always accept setsockopt calls with an old struct (v4.11 orv4.12), but if the user tries to use v3 on a v1-only system, it willbe rejected. Pretty much like using a newer setsockopt on an oldsystem.",Technical
,
"With the current implementation, given sources that say are supposed torun on a 4.9 kernel (no use of any newer field added in 4.11 or 4.12),we can't rebuild the exact same sources on a 4.19 kernel and still runthem on 4.9 without messing with structures re-definition.I understand your point, but this still looks like a sort of uapibreakage to me.I also had another way to work-around this in mind, by copying optlenbytes and checking that any additional field (not included in the""current"" kernel structure definition) is not set, returning EINVAL insuch case to keep a similar to current behavior.The issue with this is that I didn't find a suitable (ie not totallyarbitrary such as ""twice the existing structure size"") upper limit tooptlen.",Technical
,
"I'm not sure I like this.  If you have a userspace application built againstmore recent uapi headers than the kernel you are actually running on, then bydefintion you won't have this check in place, and you'll get EINVAL returnsanyway.  If you just backport this patch to an older kernel, you'll not get theEINVAL return, but you will get silent failures on event subscriptions that yourapplication thinks exists, but the kernel doesn't recognize.This would make sense if you had a way to communicate back to user space theunrecognized options, but since we don't (currently) have that, I would rathersee the EINVAL returned than just have things not work.Neil",Technical
,
Reviewed-by: Juergen Gross <jgross@suse.com>Juergen,Technical
,
Am 20.12.2017 um 15:05 schrieb Boris Ostrovsky:Acked-by: Christian KÃ¶nig <christian.koenig@amd.com>,Technical
,
"What do you mean by 1st and 2nd level?Pretty much. (3) is true in the sense that memory is first allocatedfrom hostmem_resource (which is non-dom0 RAM).Not anymore, as far as that particular commit is concerned, but that'sbecause of 03a551734 (""x86/PCI: Move and shrink AMD 64-bit window toavoid conflict"") which was introduced after balloon patch. IIRC therewere some issues with fa564ad96366unrelated to balloon.The concern is that in principle nothing prevents someone else to doexact same thing fa564ad96366 did, which is grab something from rightabove end of RAM as the kernel sees it. And that can be done at any point.-boris",Technical
,
"Ah, OK. Doesn'tadditional_memory_resource()->insert_resource(iomem_resource) place theRAM at 1st level? And if not, can we make it so?Since this seems to have broken existing feature this would be anoption. But before going that route I'd like to see if we can fix the patch.I have been unable to reproduce your problem. Can you describe what you did?I am not sure I agree that this is plainly wrong. If not for BIOS issuesthat 03a551734cf mentions I think what the original implementation offa564ad963 did was perfectly reasonable. Which is why I would prefer tokeep keep the hostmem resource *if possible*.-boris",Technical
,
"That'd mean splitting ""Unusable memory"" resource. Since it's allocatedfrom bootmem it has proven to be quite difficult but there are seem tobe special functions available particularly for memory resourcemanagement operations that I've not yet experimented with. So the answeris probably - maybe yes but not straightforward.It doesn't happen on all configurations as sometimes the memory issuccessfully hotplugged to a hole depending on the size of Dom0 memory.But we reproduced it quite reliably with small Dom0 sizes like 752MB.XenServer is using this feature to hotplug additional memory for granttable operations so we started a VM and observed a stable hang.Exactly, those *are* BIOS issues and are not supposed to be workaroundedby the OS. And as the next commit showed even the workaround didn'tquite helped with it.I agree that having hotmem as a precaution is fine but only if there isa non-cringy way to keep things working with it which I'm not sure doesexist.Igor",Technical
,
"We have most of the interfaces in the resource framework to do what wewant. I put together a semi-working prototype but the tricky part isresource locking --- we need to remove a chunk from hostmem (which willcause hostmem to be resized and possibly split), and insert this chunkto iomem's top level as System RAM, all while holding resource_lock.I haven't been able to come up with an acceptable interface for that.Given that we are actually broken I guess I am OK with reverting thepatch, but please make sure this works on AMD boxes (I think family 15his what needs to be tested).-boris",Technical
,
"After their last commit I don't see how this can be broken:1) They only claim addresses starting from 0xbd00000000*unconditionally* which means if there is some memory behind this rangeon the host (regardless if it's Dom0 or native Linux) they'll breaktheir own systems.2) So, theoretically, to trigger the original issue we'd need to have asystem with RAM higher than 0xbd00000000 and that shouldn't be assignedto Dom0 but that contradicts (1).Igor",Technical
,
"This commit breaks Xen balloon memory hotplug for us in Dom0 with""hoplug_unpopulated"" set to 1. The issue is that the common kernelmemory onlining procedures require ""System RAM"" resource to be 1-stlevel. That means by inserting it under ""Unusable memory"" as the commitabove does (intentionally or not) we make it 2-nd level and break memoryonlining.There are multiple ways to fix it depending on what was the intention oforiginal commit and what exactly it tried to workaround. It seems itdoes several things at once:1) Marks non-Dom0 host memory ""Unusable memory"" in resource tree.2) Keeps track of all the areas safe for hotplug in Dom03) Changes allocation algorithms itself in balloon driver to use those areasAre all the things above necessary to cover the issue in fa564ad96366(""x86/PCI: Enable a 64bit BAR on AMD Family 15h (Models 00-1f, 30-3f,60-7f)"")?Can we remove ""Unusable memory"" resources as soon as we finishedbooting? Is removing on-demand is preferable over ""shoot them all"" inthat case?Does it even make sense to remove the 1-st level only restriction inkernel/resource.c ?Igor",Technical
,
"Forget it 0-day bot, and assorted crickets :)With stock knob settings, that's too late to switch from llc -> l2affinity for sync wakeups, and completely demolished tbench top end onhuge socket NUMA box with lots of bandwidth. Lovely for desktop,somewhere below gawd-awful for big box performance.	-Mike",Technical
,
crap.google helpfully disabled this account while I was posting this set.I'll repost can call it v3,Technical
,
"Please change it to read the hardware directly and not use__clk_is_enabled() or clk_hw_is_prepared().--Qualcomm Innovation Center, Inc. is a member of Code Aurora Forum,a Linux Foundation Collaborative Project",Technical
,
"Hi Stephen,Thanks for the review the change.Here intention is to know the software status of the RCG instead ofHW status and we have intentionally not defined the 'is_enabled'ops for clk_rcg2_shared_ops. This clk_rcg2_shared_ops are onlyapplicable for the RCGs with shared branches across differentsubsystems. Reason for using the same is mentioned below.When RCG gets enabled by other subsystem (outside the Applicationprocessor subsystem):   In this case when RCG gets enabled by branch clock managed by   other subsystem (outside the Application processor subsystem)   and if we check HW status of RCG in clk_rcg2_shared_set_rate()   instead of checking its software status then it will give the   status as ENABLED without overlying software knowing its status   and during source switch, update configuration will get fail as   new parent will be in disabled state.   In above scenario, clock framework will not enable the new   parent before configuration update as enable and prepare counts   are zero for RCG clock and clk_set_rate() will follow below path.   clk_rcg2_shared_set_rate()   __clk_set_parent_before()-->New parent will be disabled as preparecount = 0   clk_change_rate()   clk_set_rate()So solution of this problem is as follows and same is explained in thecommit text of https://patchwork.kernel.org/patch/10139985/1. If software status of the RCG is disabled(enable/prepare counts are0)    then just cache or store the rate in current_freq variable and if    software status is enabled then follow the normal update procedure.2. Set the rate and switch to new source only inclk_rcg2_shared_enable()    i.e. during RCG enable sequence. This will make sure that required    parents are already in enable state before configuration update and    RCG switch will happen successfully every time.In past, We have encountered similar RCG update configuration failureissuesfor some display RCGs, where there are two branch clocks, one iscontrolled byapplication processor subsystem and another one controlled by othersubsystem.So to handle such cases, we need clk_rcg2_shared_ops.",Technical
,
"Hello,Ideally you would mention the commit description since the id is not yetusptream.  I found it here (its 1 in this series):  https://github.com/andestech/linux/commit/d25ea659  asm-generic/io.h: move ioremap_nocache/ioremap_uc/ioremap_wc/ioremap_...Ideally we could move <asm-generic/io.h> include down to the bottom of the fileand not have to do the defines like like this, it seems clumsy to me.  In'cris', 'nios2' and other architectures I can see they have the generic includeat the bottom of the file and not need for #define's.I tried that but I get a lot of errors.  Does your patch to asm-generic/io.hcause build issues for those architectures as well?-Stafford",Technical
,
"Hi, Stafford:2018-01-03 22:38 GMT+08:00 Stafford Horne <shorne@gmail.com>:I got this email from kbuild test robot. I personally tried arm64/x86before I sent the generic asm io.h patch.I tried openrisc/sparc before I sent these v5 patches.BUILD REGRESSIONtree/branch: https://github.com/0day-ci/linuxGreentime-Hu/Andes-nds32-Linux-Kernel/20171220-155937branch HEAD: 9353e22157b9b69be3a3beea3553b5a105a45516  dt-bindings:timer: Add andestech atcpit100 timer binding docRegressions in current branch:arch/cris/mm/ioremap.c:79:15: note: in expansion of macro 'ioremap_nocache'arch/openrisc/include/asm/io.h:38:29: error: conflicting types for 'ioremap'arch/openrisc/include/asm/io.h:44:29: note: in expansion of macro'ioremap_nocache'arch/sparc/include/asm/io_32.h:129:15: error: conflicting types for 'ioremap'arch/sparc/include/asm/io_32.h:130:0: warning: ""ioremap_nocache"" redefinedarch/sparc/include/asm/io_32.h:131:0: warning: ""ioremap_wc"" redefinedarch/sparc/include/asm/io_32.h:132:0: warning: ""ioremap_wt"" redefinedarch/sparc/kernel/ioport.c:124:15: error: conflicting types for 'ioremap'arch/sparc/kernel/ioport.c:131:1: note: in expansion of macro 'EXPORT_SYMBOL'drivers/net/ethernet/faraday/ftmac100.c:205:32: sparse: restricted__le32 degrades to integerdrivers/net/ethernet/faraday/ftmac100.c:221:23: sparse: incorrect typein assignment (different base types)drivers/net/ethernet/faraday/ftmac100.c:251:16: sparse: cast torestricted __le32drivers/net/ethernet/faraday/ftmac100.c:262:23: sparse: invalid assignment: &=drivers/net/ethernet/faraday/ftmac100.c:274:23: sparse: incorrect typein assignment (different base types)drivers/net/ethernet/faraday/ftmac100.c:288:18: warning: cast frompointer to integer of different size [-Wpointer-to-int-cast]drivers/net/ethernet/faraday/ftmac100.c:293:9: warning: cast topointer from integer of different size [-Wint-to-pointer-cast]drivers/net/ethernet/faraday/ftmac100.c:534:23: sparse: incorrect typein assignment (different base types)include/asm-generic/io.h:864:15: error: conflicting types for 'ioremap'include/asm-generic/io.h:865:25: error: conflicting types for 'ioremap_nocache'include/asm-generic/io.h:866:29: note: in expansion of macro 'ioremap_nocache'Error ids grouped by kconfigs:recent_errorsâ”œâ”€â”€ cris-etrax-100lx_v2_defconfigâ”‚   â””â”€â”€ arch-cris-mm-ioremap.c:note:in-expansion-of-macro-ioremap_nocacheâ”œâ”€â”€ openrisc-or1ksim_defconfigâ”‚   â”œâ”€â”€ arch-openrisc-include-asm-io.h:error:conflicting-types-for-ioremapâ”‚   â””â”€â”€ arch-openrisc-include-asm-io.h:note:in-expansion-of-macro-ioremap_nocacheâ”œâ”€â”€ sparc64-allyesconfigâ”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:warning:cast-from-pointer-to-integer-of-different-sizeâ”‚   â””â”€â”€ drivers-net-ethernet-faraday-ftmac100.c:warning:cast-to-pointer-from-integer-of-different-sizeâ”œâ”€â”€ sparc-defconfigâ”‚   â”œâ”€â”€ arch-sparc-include-asm-io_32.h:error:conflicting-types-for-ioremapâ”‚   â”œâ”€â”€ arch-sparc-include-asm-io_32.h:warning:ioremap_nocache-redefinedâ”‚   â”œâ”€â”€ arch-sparc-include-asm-io_32.h:warning:ioremap_wc-redefinedâ”‚   â”œâ”€â”€ arch-sparc-include-asm-io_32.h:warning:ioremap_wt-redefinedâ”‚   â”œâ”€â”€ arch-sparc-kernel-ioport.c:error:conflicting-types-for-ioremapâ”‚   â””â”€â”€ arch-sparc-kernel-ioport.c:note:in-expansion-of-macro-EXPORT_SYMBOLâ”œâ”€â”€ x86_64-allmodconfigâ”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:sparse:cast-to-restricted-__le32â”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:sparse:incorrect-type-in-assignment-(different-base-types)-expected-unsigned-int-unsigned-rxdes0-got-restrunsigned-int-unsigned-rxdes0â”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:sparse:incorrect-type-in-assignment-(different-base-types)-expected-unsigned-int-unsigned-rxdes2-got-restrunsigned-int-unsigned-rxdes2â”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:sparse:incorrect-type-in-assignment-(different-base-types)-expected-unsigned-int-unsigned-txdes2-got-restrunsigned-int-unsigned-txdes2â”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:sparse:invalid-assignment:â”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:sparse:restricted-__le32-degrades-to-integerâ”‚   â”œâ”€â”€ drivers-net-ethernet-faraday-ftmac100.c:warning:cast-from-pointer-to-integer-of-different-sizeâ”‚   â””â”€â”€ drivers-net-ethernet-faraday-ftmac100.c:warning:cast-to-pointer-from-integer-of-different-sizeâ””â”€â”€ xtensa-allmodconfig    â”œâ”€â”€ include-asm-generic-io.h:error:conflicting-types-for-ioremap    â”œâ”€â”€ include-asm-generic-io.h:error:conflicting-types-for-ioremap_nocache    â””â”€â”€ include-asm-generic-io.h:note:in-expansion-of-macro-ioremap_nocacheelapsed time: 359mconfigs tested: 128i386                               tinyconfigi386                   randconfig-x016-201751i386                   randconfig-x011-201751i386                   randconfig-x014-201751i386                   randconfig-x017-201751i386                   randconfig-x019-201751i386                   randconfig-x018-201751i386                   randconfig-x010-201751i386                   randconfig-x013-201751i386                   randconfig-x015-201751i386                   randconfig-x012-201751i386                     randconfig-n0-201751x86_64                 randconfig-x003-201751x86_64                 randconfig-x002-201751x86_64                 randconfig-x006-201751x86_64                 randconfig-x007-201751x86_64                 randconfig-x000-201751x86_64                 randconfig-x005-201751x86_64                 randconfig-x004-201751x86_64                 randconfig-x009-201751x86_64                 randconfig-x008-201751x86_64                 randconfig-x001-201751ia64                              allnoconfigia64                                defconfigia64                             alldefconfigi386                   randconfig-i0-12180843i386                   randconfig-i1-12180843x86_64                 randconfig-x012-201751x86_64                 randconfig-x010-201751x86_64                 randconfig-x011-201751x86_64                 randconfig-x015-201751x86_64                 randconfig-x019-201751x86_64                 randconfig-x014-201751x86_64                 randconfig-x013-201751x86_64                 randconfig-x016-201751x86_64                 randconfig-x017-201751x86_64                 randconfig-x018-201751i386                     randconfig-a0-201751i386                     randconfig-a1-201751c6x                        evmc6678_defconfigxtensa                       common_defconfigm32r                       m32104ut_defconfigscore                      spct6600_defconfigxtensa                          iss_defconfigm32r                         opsput_defconfigm32r                           usrv_defconfigm32r                     mappi3.smp_defconfignios2                         10m50_defconfigh8300                    h8300h-sim_defconfigcris                 etrax-100lx_v2_defconfigblackfin                  TCM-BF537_defconfigblackfin            BF561-EZKIT-SMP_defconfigblackfin                BF533-EZKIT_defconfigblackfin                BF526-EZBRD_defconfigi386                              allnoconfigi386                                defconfigi386                             alldefconfigi386                     randconfig-s1-201751i386                     randconfig-s0-201751mn10300                     asb2364_defconfigopenrisc                    or1ksim_defconfigum                           x86_64_defconfigum                             i386_defconfigfrv                                 defconfigtile                         tilegx_defconfigi386                             allmodconfigmicroblaze                      mmu_defconfigmicroblaze                    nommu_defconfigsh                            titan_defconfigsh                          rsk7269_defconfigsh                  sh7785lcr_32bit_defconfigsh                                allnoconfigi386                   randconfig-x007-201751i386                   randconfig-x008-201751i386                   randconfig-x009-201751i386                   randconfig-x004-201751i386                   randconfig-x002-201751i386                   randconfig-x005-201751i386                   randconfig-x001-201751i386                   randconfig-x006-201751i386                   randconfig-x003-201751i386                   randconfig-x000-201751m68k                           sun3_defconfigm68k                          multi_defconfigm68k                       m5475evb_defconfigmips                                   jz4740mips                      malta_kvm_defconfigmips                         64r6el_defconfigmips                           32r2_defconfigmips                              allnoconfigmips                      fuloong2e_defconfigmips                                     txx9sparc                               defconfigsparc64                           allnoconfigsparc64                             defconfigx86_64                           allmodconfigparisc                        c3000_defconfigparisc                         b180_defconfigparisc                              defconfigalpha                               defconfigparisc                            allnoconfigs390                        default_defconfigarm                         at91_dt_defconfigarm                               allnoconfigarm                           efm32_defconfigarm64                               defconfigarm                        multi_v5_defconfigarm                           sunxi_defconfigarm64                             allnoconfigarm                          exynos_defconfigarm                        shmobile_defconfigarm                        multi_v7_defconfigi386                   randconfig-x072-201751i386                   randconfig-x078-201751i386                   randconfig-x071-201751i386                   randconfig-x077-201751i386                   randconfig-x070-201751i386                   randconfig-x074-201751i386                   randconfig-x073-201751i386                   randconfig-x079-201751i386                   randconfig-x076-201751i386                   randconfig-x075-201751x86_64                             acpi-redefx86_64                           allyesdebianx86_64                                nfsrootx86_64                                  kexecx86_64                                   rhelx86_64                               rhel-7.2",Technical
,
"unit address without reg is not valid. Drop the ""@0"".All the memory mapped peripherals should be under at least one simple-bus node.ethernet@...",Technical
,
"cache-controller@...With that,Reviewed-by: Rob Herring <robh@kernel.org>",Technical
,
"2018-01-04 3:14 GMT+08:00 Rob Herring <robh+dt@kernel.org>:Hi, Rob:I'd like to modify it like this in the next version patch.         clock: clk {                 #clock-cells = <0>;                 compatible = ""fixed-clock"";                 clock-frequency = <30000000>;         };         apb {                 compatible = ""simple-bus"";                 #address-cells = <1>;                 #size-cells = <1>;                 ranges;                 serial0: serial@f0300000 {                         compatible = ""andestech,uart16550"", ""ns16550a"";                         reg = <0xf0300000 0x1000>;                         interrupts = <8>;                         clock-frequency = <14745600>;                         reg-shift = <2>;                         reg-offset = <32>;                         no-loopback-test = <1>;                 };                 timer0: timer@f0400000 {                         compatible = ""andestech,atcpit100"";                         reg = <0xf0400000 0x1000>;                         interrupts = <2>;                         clocks = <&clock>;                         clock-names = ""PCLK"";                 };         };         ahb {                 compatible = ""simple-bus"";                 #address-cells = <1>;                 #size-cells = <1>;                 ranges;                 L2: cache-controller@e0500000 {                         compatible = ""andestech,atl2c"";                         reg = <0xe0500000 0x1000>;                         cache-unified;                         cache-level = <2>;                 };                 mac0: ethernet@e0100000 {                         compatible = ""andestech,atmac100"";                         reg = <0xe0100000 0x1000>;                         interrupts = <18>;                };        };",Technical
,
"Hi,If necessary to handle these, symlink might help here i believe.Upon trying to understand memory-barriers.txt, i felt that it might bebetter to have it in PDF/HTML format, thus attempted to convert it torst. And i see it not being welcomed, hence shelving the conversion.afzal",Technical
,
"Yes, I understand that some of us have a (reasonable) doubt aboutthe reST markup.  It is not perfect in any matter, e.g. I don't likethe ``monospace`` markup.  But this is my home opinion.    My hope is, that those of us who have a doubt give reST    a chance ... it is a compromise, not as bad as you might    think first ... your cooperation and your criticism is    needed and welcome. Please let me invite you / read on:There are other plain-text markups e.g. AsciiDoc or Markdown. ThereST markup and the Sphinx-builder is a compromise from a evaluationin 2016 (see linux-doc ML subject ""muddying the waters"" [1]).Jani wrote an article about the evaluation and it results [2]. Andthere are other articles documenting all the various aspects.- A report from the documentation maintainer [3]- Kernel documentation with Sphinx, part 2: how it works [4]- Kernel documentation update [5]To summarize it with my words:The old DocBook-based toolchain was hard to maintain and of coursewho want's to write XML? A consistent plain-text markup forarticles in /Documentation/* and source-code comments (kernel-doc)was needed.The markup: IMO reST wins that race, because it has a extendablemarkup specification while others plain-text markups like Markdownhave various (HTML) builders with various markup dialects[7] (whichis more a mess than a definition).The builder: IMO Sphinx-Doc wins that race, since it is (well)maintained, widely used and has a interface for extensions.I.e. the one extension we wrote: 'kernel-doc' to parse kernel-doccomments from source code and include them in the articles.Perspective: Sphinx-Doc also offers solutions we might use in thefuture (e.g. building man-pages). Not to end in a mess, extensionsshould be implemented cautiously and deliberately (be patient).But that should not fool you; yes we have known problems with ourtoolchain and it is not yet ;) perfect in any matter (e.g. thehighlighting in kernel-doc comments or the PDF generation or thesphinx-doc versions shipped with various distributions or ..)Anyway, today we have more than before: The reST learning curve is(compared to DocBook) not hard for newbees and our toolchain isflexible for all the requirements wich might come up in the future.IMO the actual challenge is the content and the organizationof the doc-tree and for this[1] https://www.mail-archive.com/search?q=muddying+the+waters&l=linux-doc%40vger.kernel.org[2] https://lwn.net/Articles/692704/[3] https://lwn.net/Articles/704613/[4] https://lwn.net/Articles/692705/[5] https://lwn.net/Articles/705224/[6] http://docutils.sourceforge.net/docs/ref/rst/restructuredtext.html[7] http://pandoc.org/MANUAL.html#markdown-variantsThats exactly what I mean: give reST a chance :)-- Markus --",Technical
,
"Hi,Okay, the outcome is exactly as was feared.Abondoning the patch, let this be > /dev/nullafzal",Technical
,
"Hello,I don't think we want to fully guarantee the current behavior.  On thescheduler side, I don't think it's likely to change but blkio side*might* change.  Can you please collect the root behavior in a separtesection and clearly note that the behaviors are subject to change?Thanks.--tejun",Technical
,
"Hello,Will do.Maciej",Technical
,
Seems like kallsyms would be one to absolutely scan... it shouldn'tcause hangs either.-Kees--Kees CookPixel Security,Technical
,
"Haven't we fixed kallsyms now? Do you mean that we should be checking tosee if the scanned kernel has been patched to include the kallsysmsfixes in 4.14? If so perhaps we should add functionality to just checkthe first line for an address and warn if one is found. No real reasonto include ever address in kallsyms in the output.Script doesn't hang but it times out with the default timer (10 seconds).thanks,Tobin.",Technical
,
"Hi Dongjiu Geng,(versions of patches 1,2 and 4 have been queued by Catalin)(Nit 'ACPI / APEI:' is the normal subject prefix for ghes.c, this helps themaintainers know which patches they need to pay attention to when you aretouching multiple trees)This reads as if this patch is handling SError RAS notifications generated by aCPU with the RAS extensions. These are about CPU->Software notifications. APEIand GHES are a firmware first mechanism which is Software->Software.Reading the v8.2 documents won't help anyone with the APEI/GHES code.Please describe this from the ACPI view, ""ACPI 6.x adds support for NOTIFY_SEIas a GHES notification mechanism... "",  its up to the arch code to spot a v8.2RAS Error based on the cpu caps.There are problems with doing this:Oct. 18, 2017, 10:26 a.m. James Morse wrote:| How do SEA and SEI interact?|| As far as I can see they can both interrupt each other, which isn't something| the single in_nmi() path in APEI can handle. I thinks we should fix this| first.[..]| SEA gets away with a lot of things because its synchronous. SEI isn't. Xie| XiuQi pointed to the memory_failure_queue() code. We can use this directly| from SEA, but not SEI. (what happens if an SError arrives while we are| queueing memory_failure work from an IRQ).|| The one that scares me is the trace-point reporting stuff. What happens if an| SError arrives while we are enabling a trace point? (these are static-keys| right?)||  I don't think we can just plumb SEI in like this and be done with it.|  (I'm looking at teasing out the estatus cache code from being x86:NMI only.|  This way we solve the same 'cant do this from NMI context' with the same|  code'.)I will post what I've got for this estatus-cache thing as an RFC, its not readyto be considered yet.external modules? You mean called by the arch code when it gets this NOTIFY_SEI?Thanks,James",Technical
,
"Hi James,If your patch can be consider that, this patch can based on your patchset. thanks.yes, called by kernel ARCH code, such as below, I remember I have discussed with you. asmlinkage void do_serror(struct pt_regs *regs, unsigned int esr) { 	nmi_enter();	if (!ghes_notify_sei())		return; 	/* non-RAS errors are not containable */ 	if (!arm64_is_ras_serror(esr) || arm64_is_fatal_ras_serror(regs, esr)) 		arm64_serror_panic(regs, esr);	nmi_exit();}",Technical
,
"sorry fix a typo.Yes, I know you are dong that. Your serial's patch will consider all above things, right?If your patch can be consider that, this patch can based on your patchset. thanks.",Technical
,
"Hi Dongjiu Geng,After this patch user-space can trigger an SError in the guest. If it wants tomigrate the guest, how does the pending SError get migrated?I think we need to fix migration first. Andrew Jones suggested usingKVM_GET/SET_VCPU_EVENTS:https://www.spinics.net/lists/arm-kernel/msg616846.htmlGiven KVM uses kvm_inject_vabt() on v8.0 hardware too, we should cover systemswithout the v8.2 RAS Extensions with the same API. I think this means a bit toread/write whether SError is pending, and another to indicate the ESR should beset/read.CPUs without the v8.2 RAS Extensions can reject pending-SError that had an ESR.user-space can then use the 'for migration' calls to make a 'new' SError pending.Now that the cpufeature bits are queued, I think this can be split up into twoseparate series for v4.16-rc1, one to tackle NOTIFY_SEI and the associatedplumbing. The second for the KVM 'make SError pending' API.Does nothing in the patch that adds the support? This is a bit odd.(oh, its hiding in patch 6...)Thanks,James",Technical
,
"Hi James,   Thanks a lot for your review and comments.For the CPUs without the v8.2 RAS Extensions, its ESR is always 0, we only can inject a SError with ESR 0 to guest, cannot set its ESR.About how about to use the KVM_GET/SET_VCPU_EVENTS, I will check the code, and consider your suggestion at the same time.The IOCTL KVM_GET/SET_VCPU_EVENTS has been used by X86.Ok, thanks for your suggestion, will split it.To make this patch simple and small, I add it in patch 6.",Technical
,
"Hi James,  thanks for the review.yeah, I have seen that.I pick your modification of setting an impdef ESR for Virtual-SError, so add your name,I change it to 'CC'will follow that.Ok, I will adjust that.thanks, I will directly call pend_guest_serror() in this function.thanks, I will call pend_guest_serror() in the kvm_arm_set_sei_esr().",Technical
,
"Hi gengdongjiu,0? It's always implementation-defined. On Juno it seems to be always-0, butother systems may behave differently. (Juno may generate another ESR value whenI'm not watching it...)Just because we can't control the ESR doesn't mean injecting an SError isn'tsomething user-space may want to do.If we tackle migration of pending-SError first, I think that will give us theAPI to create a new pending SError with/without an ESR as appropriate.(Not my suggestion, It was Andrew Jones idea.)We would be re-using the struct to have values with slightly different meanings.But for migration the upshot is the same, call KVM_GET_VCPU_EVENTS on onesystem, and pass the struct to KVM_SET_VCPU_EVENTS on the new system. If we'relucky Qemu may be able to do this in shared x86/arm64 code.But that made the functionality of this patch: A new API to return -EINVAL fromthe kernel.Swapping the patches round would have avoided this.Regardless, I think this will fold out in a rebase.Thanks,James",Technical
,
"Hi gengdongjiu,Assuming I got it right, yes. It currently makes the race Xie XiuQi spottedworse, which I want to fix too. (details on the cover letter)I'd like to pick these patches onto the end of that series, but first I want toknow what NOTIFY_SEI means for any OS. The ACPI spec doesn't say, and becauseits asynchronous, route-able and mask-able, there are many more corners thanNOTFIY_SEA.This thing is a notification using an emulated SError exception. (emulatedbecause physical-SError must be routed to EL3 for firmware-first, andvirtual-SError belongs to EL2).Does your firmware emulate SError exactly as the TakeException() pseudo code inthe Arm-Arm?Is the emulated SError routed following the routing rules for HCR_EL2.{AMO, TGE}?What does your firmware do when it wants to emulate SError but its masked?(e.g.1: The physical-SError interrupted EL2 and the SPSR shows EL2 had PSTATE.A set. e.g.2: The physical-SError interrupted EL2 but HCR_EL2 indicates the emulated SError should go to EL1. This effectively masks SError.)Answers to these let us determine whether a bug is in the firmware or thekernel. If firmware is expecting the OS to do something special, I'd like toknow about it from the beginning!Sure. The phrase 'external modules' usually means the '.ko' files that live in/lib/modules, nothing outside the kernel tree should be doing this stuff.Thanks,James",Technical
,
"James,   Thank you for your time to reply me.For the armv8.0 cpu without RAS Extensions, it does not have vsesr_el2, so when guest take a virtual SError,its ESR is 0, can not control the virtual SError's syndrom value, it does not have such registers to control that.Does Juno not have RAS Extension? if yes, I think we can only inject an SError, but can not change its ESR value, because it does not have vsesr_el2.yes, we may need to support user-space injects an SError even through CPU does not have RAS Extension.sure, we should. Last week, I checked the KVM_GET/SET_VCPU_EVENTS IOCTL, it should meet our migration requirementsGot it.Thanks for the reminder, I know your meaning.In the x86, the kvm_vcpu_events includes exception/interrupt/nmi/smi. For the RAS, weonly involves the exception, so Qemu handling logic is different. Anyway, I will try toshare code for the two platform in Qemu./* for KVM_GET/SET_VCPU_EVENTS */struct kvm_vcpu_events {	struct {		__u8 injected;		__u8 nr;		__u8 has_error_code;		__u8 pad;		__u32 error_code;	} exception;	struct {		__u8 injected;		__u8 nr;		__u8 soft;		__u8 shadow;	} interrupt;	struct {		__u8 injected;		__u8 pending;		__u8 masked;		__u8 pad;	} nmi;	__u32 sipi_vector;	__u32 flags;	struct {		__u8 smm;		__u8 pending;		__u8 smm_inside_nmi;		__u8 latched_init;	} smi;	__u32 reserved[9];};yes, I will, thanks for your kind suggestion.",Technical
,
"Ok.Yes, it is.Yes, it is.Currently we does not consider much about the mask status(SPSR).I remember that you ever suggested firmware should reboot if the mask status is set(SPSR), right?I ever suggest our firmware team to evaluate that, but there is no response.I CC ""liu jun"" <liujun88@hisilicon.com> who is our UEFI firmware Architect, if you have firmware requirements, you canraise again.I know your meaning, thanks for raising it again.I will rename 'external modules' to other name. Thanks.",Technical
,
"Hi gengdongjiu,My point was its more nuanced than this: the ARM-ARM'sTakeVirtualSErrorException() pseudo-code lets virtual-SError have animplementation defined syndrome. I've never seen Juno generate anything otherthan '0', but it might do something different on a thursday.The point? We can't know what a CPU without the RAS extensions puts in there.Why Does this matter? When migrating a pending SError we have to know thedifference between 'use this 64bit value', and 'the CPU will generate it'.If I make an SError pending with ESR=0 on a CPU with VSESR, I can't migrated toa system that generates an impdef SError-ESR, because I can't know it will be 0.It's two types of v8.0 CPU, no RAS extensions.I agree, this means we need to be able to tell the difference between 'pending'and 'pending with this ESR'.Great!Thanks,James",Technical
,
"Hi James, Thanks for the mail.[...]I checked the ""aarch64/exceptions/asynch/AArch64.TakeVirtualSErrorException"",you are right, the virtual SError's syndrome value can be 0 or implementation defined value, not always 0,which is decided by the ""exception.syndrome<24>"".thanks for the clarification.Yes,But it will have a issue,For the target system, before taking the SError, no one can know whether its syndrome valueis IMPLEMENTATION DEFINED or architecturally defined.when the virtual SError is taken, the ESR_ELx.IDS will be updated, then we can knowwhether the ESR value is impdef or architecturally defined.It seems migration is only allowed only when target system and source system all support RAS extension, because we do not knowwhether its syndrome is IMPLEMENTATION DEFINED or architecturally defined.",Technical
,
"Hi gengdongjiu,For a virtual-SError, the hypervisor knows what it generated. (do I haveVSESR_EL2? What did I put in there?).True, the guest can't know anything about a pending virtual SError until ittakes it. Why is this a problem?I don't think Qemu allows migration between hosts with differing guest-IDregisters. But we shouldn't depend on this, and we may want to hide the v8.2 RASfeatures from the guest's ID register, but still use them from the host.The way I imagined it working was we would pack the following information intothat events struct:{	bool serror_pending;	bool serror_has_esr;	u64  serror_esr;}The problem I was trying to describe is because there is no value of serror_esrwe can use to mean 'Ignore this, I'm a v8.0 CPU'. VSESR_EL2 is a 64bit register,any bits we abuse may get a meaning we want to use in the future.When it comes to migration, v8.{0,1} systems can only GET/SET events whereserror_has_esr == false, they can't use the serror_esr. On v8.2 systems weshould require serror_has_esr to be true.If we need to support migration from v8.{0,1} to v8.2, we can make up an impdefserror_esr.We will need to decide what KVM does when SET is called but an SError wasalready pending. 2.5.3 ""Multiple SError interrupts"" of [0] has something to say.Happy new year,James[0]https://static.docs.arm.com/ddi0587/a/RAS%20Extension-release%20candidate_march_29.pdf",Technical
,
"Hi James,   sorry for my late response due to chines new year.2018-02-16 1:55 GMT+08:00 James Morse <james.morse@arm.com>:I have used your suggestion structyes, I agreed.For the Qemu migration, I need to check more the QEMU code.Hi Andrew,      I use KVM_GET/SET_VCPU_EVENTS IOCTL to migrate the Serrorexception status of VM,The even struct is shown below:{      bool serror_pending;      bool serror_has_esr;     u64  serror_esr;}Only when the target machine is armv8.2, it needs to set theserror_esr(SError Exception Syndrome Register).for the armv8.0,  software can not set the serror_esr(SError ExceptionSyndrome Register).so when migration from v8.{0,1} to v8.2, QEMU should make up an impdefserror_esr for the v8.2 target.can you give me some suggestion how to set that register in the QEMU?I do not familar with the QEMU migration.Thanks very much.how about KVM set again to the same VCPU?thanks!",Technical
,
"Hi gengdongjiu, liu jun... and yet ..... this is a problem.If you ignore SPSR_EL3 you may deliver an SError to EL1 when the exceptioninterrupted EL2. Even if you setup the EL1 register correctly, EL1 can't eret toEL2. This should never happen, SError is effectively masked if you are runningat an EL higher than the one its routed to.More obviously: if the exception came from the EL that SError should be routedto, but PSTATE.A was set, you can't deliver SError. Masking SError is the onlyway the OS has to indicate it can't take an exception right now. VBAR_EL1 may be'wrong' if we're doing some power-management, the FAR/ELR/ESR/SPSR registers maycontain live values that the OS would lose if you deliver another exception overthe top.If you deliver an emulated-SError as the OS eret's, your new ELR will point atthe eret instruction and the CPU will spin on this instruction forever.You have to honour the masking and routing rules for SError, otherwise no OS canrun safely with this firmware.Yes, this is my suggestion of what to do if you can't deliver an SError: storethe RAS error in the BERT and 'reboot'.(UEFI? I didn't think there was any of that at EL3, but I'm not familiar withall the 'PI' bits).The requirement is your emulated-SError from EL3 looks exactly like aphysical-SError as if EL3 wasn't implemented.Your CPU has to handle cases where it can't deliver an SError, your emulationhas to do the same.This is not something any OS can work around.Happy new year,James",Technical
,
"Hi gengdongjiu,Happy new year,Ah! This is where it came from. Sorry, this was just to illustrate theinformation/sizes we wanted to transfer.... I didn't mean it literally.I should have said ""64 bits of ESR, so that we can transfer anything that isadded to VSESR_EL2 in the future, a flag somewhere to indicate an serror ispending, and another flag to indicate the ESR has a value we should use"".Thanks/Sorry!James",Technical
,
"Dear James,        Thanks for this mail and sorry for my late response.2018-02-16 1:55 GMT+08:00 James Morse <james.morse@arm.com>:[....]James, I  summarized the masking and routing rules for SError toconfirm with you for the firmware first solution,1. If the HCR_EL2.{AMO,TGE} is set, which means the SError should route to EL2,When system happens SError and trap to EL3,   If EL3 findHCR_EL2.{AMO,TGE} and SPSR_EL3.A are both set,and find this SError come from EL2, it will not deliver an SError:store the RAS error in the BERT and 'reboot'; but ifit find that this SError come from EL1 or EL0, it also need to deliveran SError, right?2. If the HCR_EL2.{AMO,TGE} is not set, which means the SError shouldroute to EL1,When system happens SError and trap to EL3, If EL3 findHCR_EL2.{AMO,TGE} and SPSR_EL3.A are both not set,and find this SError come from EL1, it will not deliver an SError:store the RAS error in the BERT and 'reboot'; but ifit find that this SError come from EL0, it also need to deliver anSError, right?",Technical
,
"Hi gengdongjiu,You also said ""Currently we does not consider much about the mask status(SPSR).""If one or the other of these bits is set: (AMO==1 || TGE==1)Yes.If neither of these bits is set: (AMO==0 && TGE == 0)(I'm reading this as all three of these bits are clear)No, (AMO==0 && TGE == 0) means SError is routed to EL1, this exceptioninterrupted EL1 and the A bit was clear, so EL1 can take an SError.The two cases here are:AMO==0,TGE==0 means SError should be routed to EL1. If SPSR_EL3 says theexception interrupted EL1 and the A bit was set, you need to do the BERT trick.If SPSR_EL3 says the exception interrupted EL2, you need to do the BERT trickregardless of the A bit, as SError is implicitly masked by running at a higherexception level than it was routed to.(this is re-iterating the two-cases above:)'not be routed to' is one of two things: Route-to-EL2+interruted-EL1, orRoute-to-EL1+interrupted-EL2.Route-to-EL2+interrupted-EL1 is fine, regardless of SPSR_EL3.A the emulatedSError can be delivered to EL2, as EL2 can't mask SError when executing at alower EL.Route-to-EL1+interrupted-EL2 is the problem. SError is implicitly masked byrunning at a higher EL. Regardless of SPSR_EL3.A, the emulated SError can not bedelivered.KVM does this on the way out of a guest, if an SError occurs during this timethe CPU will wait until execution returns to EL1 before delivering the SError.Your firmware has to do the same.Table D1-15 in ""D1.14.2 Asynchronous exception masking"" has a table with all thecombinations. The ARM-ARM is what we need to match with this behaviour.I thought interrupted-EL0 could always be delivered: but re-reading theARM-ARM's ""D1.14.2 Asynchronous exception masking"", if asynchronous exceptionsare routed to EL1 then EL0&EL1 are treated the same.So if SError is routed to EL1, the exception interrupted EL0, and SPSR_EL3.A wasset, you still can't deliver the emulated-SError you have to do the BERT-trick.Linux doesn't do this today, but another OS might (e.g. UEFI), and we might dothis in the future.This is really tricky for firmware to get right. Another alternative would be toput the CPER records in a Polled buffer, unless something needs doing right now,in which case a BERT-reboot is probably best.Thanks,James",Technical
,
"James,   Thanks for this mail.Yes, we currently do not consider much it. After clarification with you, we want to modify the EL3 firmware to follow this rule.sorry, it is a typo issue.it should be HCR_EL2.AMO and HCR_EL2.TGE are both clear, but SPSR_EL3.A is set.Agree.""BERT trick"" is storing the RAS error in the BERT and 'reboot, right?Agree.""can not be delivered"" means storing the RAS error in the BERT and 'reboot, right?In the Table D1-15 in ""D1.14.2 Asynchronous exception masking"", for the case, it is ""C""""C""means SError is not taken regardless of the value of the Process state interrupt mask.for this case, whether it will be unsafe if  BIOS directly reboot?For this case, whether it will be unsafe if  BIOS directly reboot?For example, for some test purpose, EL0 set PSTATE.A, just right happen SError, then BIOS will reboot system.I am afraid that system will become unsafe because BIOS will reboot system.In summary:[1]:Route-to-EL1 + interrupted-EL1, if SPSR_EL3.A is set, EL3 firmware can't deliver the emulated-SError, store the RAS error in the BERT and 'reboot.Route-to-EL2 + interrupted-EL2, if SPSR_EL3.A is set, EL3 firmware can't deliver the emulated-SError, store the RAS error in the BERT and 'reboot.I agree above two cases, but maybe we need to ensure that only in EL2 SError handler and EL1 SError exception handler the PSTATE.A is set, for other places, the PSTATE.A is not set.then BIOS can know this is nested-SError when find the SPSR_EL3.A is set, can we ensure that in the Linux kernel code and KVM code?[2]:Route-to-EL2 + interrupted-EL1, regardless of SPSR_EL3.A the emulated SError can be delivered to EL2.Route-to-EL2 + interrupted-EL0, regardless of SPSR_EL3.A the emulated SError can be delivered to EL2.I agree above two cases.[3]:Route-to-EL1+interrupted-EL0, if SPSR_EL3.A is set, EL3 firmware can't deliver the emulated-SError, store the RAS error in the BERT and 'rebootRoute-to-EL1+interrupted-EL2, EL3 firmware store the RAS error in the BERT and 'reboot regardless of SPSR_EL3.A.For above two cases, I am worried system will become unsafe because BIOS will reboot system.",Technical
,
The patch should be split into two: one is for dt-bindings part and theother is for driver part. Where dt-binding part should requireadditionally to send to Rob and Cc. devicetree@vger.kernel.org.should include 2018 ?how about use devm_request_irq to simplify error path?,Technical
,
"Thanks Sean for review,Sure. Will do it in next version.Will fix in next versionWill change in next versionThanks,Jolly Shah",Technical
,
"Ok, makes sense.[...]Still one minor thing left:When CONFIG_BPF_JIT_ALWAYS_ON is disabled, this will throw the followingwarning:[...]  CC      kernel/bpf/core.okernel/bpf/core.c:1360:21: warning: â€˜__bpf_prog_ret0â€™ defined but not used [-Wunused-function] static unsigned int __bpf_prog_ret0(const void *ctx,                     ^~~~~~~~~~~~~~~Probably just best to wrap it under ifdef CONFIG_BPF_JIT_ALWAYS_ON.",Technical
,
Thanks for adding the comment.Reviewed-by: Andrew Lunn <andrew@lunn.ch>    Andrew,Technical
,
"Sorry, also...I think you'll find you don't need to set MII_SPEED here, sinceMII_SPEED selects between 10 and 100, GMII_SPEED always takesprecidence selecting 1000, and 2500 is done by the comphyincreasing the clocks by 2.5x.--RMK's Patch system: http://www.armlinux.org.uk/developer/patches/FTTC broadband for 0.8mile line in suburbia: sync at 8.8Mbps down 630kbps upAccording to speedtest.net: 8.21Mbps down 510kbps up",Technical
,
"Hi Russell,The mvpp2 driver uses phy_ethtool_get_link_ksettings() to report thelink speed to Ethtool. So it's reporting the speed set by the PHYdriver.So it'll be something to ensure when adding PHYs supporting the mode.We'll have the opportunity to see this when adding the last mcbininterface.Thanks!Antoine--Antoine Tnart, Free ElectronsEmbedded Linux and Kernel engineeringhttp://free-electrons.com",Technical
,
"Hi Russell,Comments always welcomed :)I just had a look at the datasheet, and as you say it seems GMII_SPEEDtakes over MII_SPEED. I'll see if there is a corner case here or ifselecting MII_SPEED doesn't make sense, and update accordingly.Thanks!Antoine--Antoine Tnart, Free ElectronsEmbedded Linux and Kernel engineeringhttp://free-electrons.com",Technical
,
"Hi Russell,I just checked, this can be removed for this mode. I'll update thepatch.Thanks!Antoine--Antoine Tnart, Free ElectronsEmbedded Linux and Kernel engineeringhttp://free-electrons.com",Technical
,
Hi PeterCould you please have a look of thisthanks2018-01-11 11:09 GMT+08:00  <linxiulei@gmail.com>:,Technical
,
"That was an extensive changlog, thanks for the details and for working on this!Acked-by: Ulf Hansson <ulf.hansson@linaro.org>Kind regardsUffe",Technical
,
"Hi Rafael,I've tested this on two very similar systems: Salvator-XS with R-Car H3 ES2.0,and Salvator-X with R-Car M3-W ES1.0.On the M3-based system, everything seems to work fine.On the H3-based system, the serial console (the /dev/ttySC0 device, not kernelserial output) is dead after resume from s2ram, with and withoutno_console_suspend.With no_console_suspend, I see:    ttySC ttySC0: 1 input overrun(s)after typing on the serial console, so it looks like an interrupt problem.This issue seems to be caused by patch [1/2]. But I have no idea what'sreally happening, and why the two systems behave differently.Oh well, have a nice weekend!Gretje,eetings,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
"Good.Well, that's not dramatic.Let's make a deal that we'll fix this on top of [1/2].Which driver is this BTW?  sh-sci?  That one doesn't even support runtimePM, confusingly enough.Thanks, you too!",Technical
,
"What do you mean by ""managed by runtime PM""?I will do that, no worries.OK, I'll send a patch on top of this series.Thanks,Rafael",Technical
,
"Hi Rafael,Could be a firmware issue, too.While the kernel images are identical, the ARM trusted firmware configs aren't(same version, though).I'll do some more investigation...;-)Yes, sh-sci. It does make pm_runtime_*() calls.And of course there's uart_ops.pm, which is driven from serial_core...Gr{oetje,eeting}s,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
"On Sun, Jan 14, 2018 at 10:48 AM, Geert Uytterhoeven<geert@linux-m68k.org> wrote:OK, thanks!It also would be good to know the topology of the device hierarchy andhow that maps to the domains on the failing system (and which UARTclocks are operated by genpd).Hmm.  I overlooked that part.This is sort of unusual, because the driver doesn't provide anyruntime PM callbacks, but still it does provided system suspend ones.It looks like the idea is to never put it into runtime suspend if anyports are enabled and always put it into runtime suspend otherwise.Which one is the case in your testing?  Is the port disabled orenabled during system-wide suspend?What does this point to for that particular device?",Technical
,
"Hi Rafael,The topology is the same on both systems.The UART's module clock is operated by genpd, on both systems.It's enabled on both systems, as a getty is running.sci_pm(), on both systems.See, there's no difference in topology on both systems, so I'll have to looka bit deeper first...Gretje,eetings,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
"Hi Rafael,On Mon, Jan 15, 2018 at 9:16 AM, Geert Uytterhoeven<geert@linux-m68k.org> wrote:I did miss a small difference in topology: in pm/linux-next, H3 has DMAenabled for SCIF2, while M3 hasn't (yet).With DMA enabled on M3, it fails in the same way.As genpd_resume_noirq() no longer calls pm_runtime_force_resume(),rcar_dmac_runtime_resume() is no longer called, and the DMAC's registersare no longer reinitialized after system resume, breaking the serial port.Gretje,eetings,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
"In drivers/dma/sh/rcar-dmac.c, I would try to replace the below line:SET_SYSTEM_SLEEP_PM_OPS(rcar_dmac_sleep_suspend, rcar_dmac_sleep_resume)with:SET_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend, pm_runtime_force_resume)in case that may be too early to suspend the dma device (which israther common for dma devices) then try;SET_LATE_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend, pm_runtime_force_resume)Kind regardsUffe",Technical
,
"[cut]Yes, that probably is the least intrusive thing that can be done toaddress the issue.Good suggestion, and I would go straight for it anyway.Geert, can you try if this works, please?Thanks,Rafael",Technical
,
"Hi Rafael,Works. Both using SET_SYSTEM_SLEEP_PM_OPS() andSET_LATE_SYSTEM_SLEEP_PM_OPS(). But given this is a DMA enginedriver, I'd settle for the latter.And I did verify doing so doesn't break the system without the patchin $subject.Thanks!Will send a patch...Gr{oetje,eeting}s,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
Thank you!,Technical
,
"Thanks.I just sent a v3 that changes the VERMAGIC only, based on Greg'searlier feedback.It has the drawbacks that it:- refuses loading instead of warns- doesn't stop refusing when the feature is runtime disabledBut it's much simpler, just a few lines of ifdef.We can either go with the v3, or rework this one into a v4?-Andi",Technical
,
I think simple is good at this point,Technical
,
"V3 is fine. Not loading is the right thing to do :)Thanks,	tglx",Technical
,
tested v3...Tested-by: Caleb Crome <caleb@crome.org>,Technical
,
"You are setting ssi->synchronous in the AC'97 mode here, the old codedidn't do that (see the next patch hunk below).Since in the previous patch you have replaced cpu_dai_drv.symmetric_rateswith ssi->synchronous this will likely break asymmetric rate support inthe AC'97 mode, since the driver will use STCCR for programming of bothplayback and capture.The next patch in this series (17) also looks affected by this change.You can see it here that the old code didn't set ssi->synchronous in theAC'97 mode.Maciej",Technical
,
Will modify this part. Thanks,Technical
,
I neglected the comments in the middle. Sorry. Will add it back then.,Technical
,
"On Mon, 15 Jan 2018 19:41:12 +0800changbin.du@intel.com wrote:The above totally does not parse (no pun intended).Are you trying to say:""User space can pass in a C nul character '\0' along with its input.The function trace_get_user() will try to process it as a normalcharacter, and that will fail to parse.The above should be something like:""Have the parser stop on '\0' and cease any further parsing. Onlyprocess the characters up to the nul '\0' character and do not processit.""-- Steve",Technical
,
"Hi Rostedt,Thanks for your polish, let me update commit msg with your words.--Thanks,Changbin Du",Technical
,
"RESEND: fix typo in email address.Hi,A few weeks ago, I have sent an RFC about adding bias support for GPIOs [1].It was motivated by the fact that I wanted to enable the pinmuxing strict modefor my pin controller which can muxed a pin as a peripheral or as a GPIO.Enabling the strict mode prevents several devices to be probed becauserequesting a GPIO fails. The pin request function complains about theownership of the GPIO which is different from the mux ownership. I have toremove my pinctrl node to avoid this conflict but I need it to configure mypins and to set a pull-up bias for my GPIOs.My first idea was to add new flags in addition to GPIO_ACTIVE_HIGH and others.Obviously, it was not the way to go since many new flags may be added:strength, debounce, etc.Then I proposed a very ""quick and dirty"" patch to give the picture of what Ihave in mind but I had no feedback. It was probably too dirty. The idea wasto add a cell to the gpios property with a phandle on a pinctrl node whichcontains only the pinconf, no pinmux. The configuration is applied later whenrequesting the GPIO. The main issue is that enabling the strict mode willbreak old DTBs. I was going to submit patches for this but, after using thesysfs which still show me a bad ownership, I decided that it should be fixed.So I did these patches. Unfortunately, there are several ways to lead togpiod_request(). It does the trick only for the gpiod_get family. The issue isstill present with legacy gpio_request and fwnode_get_named_gpiod. It seemsthat more and more drivers are converted to use GPIO descriptors so there issome hope. The advantage of this solution is to not break old DTBs. As I amnot aware of all usage of the gpiolib, I tried to implement it in the safestway.RegardsLudovic[1] https://www.spinics.net/lists/arm-kernel/msg623149.htmlLudovic Desroches (2):  pinctrl: add consumer variant for gpio request  gpio: provide a consumer when requesting a gpio drivers/gpio/gpiolib.c           | 40 +++++++++++++++++++++++++++++++++------- drivers/pinctrl/core.c           | 13 ++++++++++--- drivers/pinctrl/pinmux.c         | 16 ++++++++++++++-- drivers/pinctrl/pinmux.h         | 10 ++++++++++ include/linux/gpio/driver.h      |  5 +++++ include/linux/pinctrl/consumer.h |  6 ++++++ 6 files changed, 78 insertions(+), 12 deletions(-)--2.12.2",Technical
,
"Hi Ludovic, thanks for your patches!On Mon, Jan 15, 2018 at 5:24 PM, Ludovic Desroches<ludovic.desroches@microchip.com> wrote:I was confused I think, because the issue of ownership and addingbias support were conflated.I think I discussed properly the ideas I have for pin control propertiesvs the GPIOlib API/ABI in my response to patch 1.So that is a different thing from bias support.Okay I think the right solution is to fix the ownership issue, and setup bias using pin control/config but use the line through gpiolib for now.Yeah we need to work around that.Yep :)fwnode_get_named_gpiod() must really be fixed too. You probablywant to have things like LEDs and GPIO keys working even ifyour pin controller is strict.I don't care so much about the old functions, I guess you just haveto make sure that the drivers for *your* pin controller all use descriptorsso that you can enable strict mode on *your* pin controller, right?Restrict your task to this, I'd say.Yeah I'm doing this when I have time. There is plenty of work...Help appreciated.Yours,Linus Walleij",Technical
,
"On Mon, Jan 15, 2018 at 5:24 PM, Ludovic Desroches<ludovic.desroches@microchip.com> wrote:I think we need to think over what is a good way to share ownershipof a pin.Russell pointed me to a similar problem incidentally and I briefly lookedinto it: there are cases when several devices may need to hold thesame pin.Can't we just look up the associated gpio_chip from the GPIO range,and in case the pin is connected between the pin controller andthe GPIO chip, then we allow the gpiochip to also take areference?I.e. in that case you just allow gpio_owner to proceed and take thepin just like with a non-strict controller.Yours,Linus Walleij",Technical
,
"It's the probably the way to go, it was Maxime's proposal and Andy seemsto agree this solution.RegardsLudovic",Technical
,
"On Thu, Jan 18, 2018 at 4:12 PM, Ludovic Desroches<ludovic.desroches@microchip.com> wrote:I'm looking into SPI and regulators for the next kernel cycle, sothose will hopefully get fixed.Yours,Linus Walleij",Technical
,
"If pin_request() is called with gpio_range not NULL, it means that therequests comes from a GPIO chip and the pin controller handles this pin.In this case, I would say the pin is connected between the pincontroller and the GPIO chip. Is my assumption right?I am not sure it will fit all the cases:- case 1: device A requests the pin (pinctrl-default state) and mux it  as a GPIO. Later,it requests the pin as a GPIO (gpiolib). This 'weird'  situation happens because some strict pin controllers were not declared  as strict and/or pinconf is needed.- case 2: device A requests the pin (pinctrl-default state). Device B  requests the pin as a GPIO (gpiolib).In case 1, pin_request must not return an error. In case 2, pin_requestmust return an error even if the pin is connected between the pincontroller and the GPIO chip.RegardsLudovic",Technical
,
"On Wed, Jan 24, 2018 at 3:07 PM, Ludovic Desroches<ludovic.desroches@microchip.com> wrote:How do you find my proposal about introducing ownership level (notrequested yet; exclusive; shared)?Confirm with caveat that this is a fix for subset of cases.I think it doesn't cover cases when you have UART + UART + GPIO (Iposted early a use case example).But at least it doesn't move things in a wrong direction.For these cases looks OK to me.--With Best Regards,Andy Shevchenko",Technical
,
"Yes but I don't see how I can fix my issue with these levels. In mycase, I need an exclusive ownership at device level not at pin level. Inreality, it is at pin level but I am in this situation because my pincontroler was introduced as non strict and also because I need to setthe configuration of the pin which is going to be used as a GPIO.If the ownership is exclusive, pinmuxing coming from pinctrl-defaultwill be accepted but the GPIO request will fail even if it comes from thesame device.If the ownership is shared then, pinmuxing coming from pinctrl-defaultwill be accepted but a GPIO request from another device will be acceptedtoo.Both situations are incorrect in my case.Let me know if I have not well understood your proposal. My concern isto get out of this situation without breaking current DTs.RegardsLudovic",Technical
,
"On Fri, Jan 26, 2018 at 9:32 AM, Ludovic Desroches<ludovic.desroches@microchip.com> wrote:The problem here is to declare a right consumer of the resource.My understanding that consumer at the end is device or device(s):none: resource is free to acquireexclusive: certain device has access to the resource (pin)shared: several devices may access to the resourceIn both cases couple of caveats:- power management has a special access level to the resource onbehalf of the owner(s)- it can have some flags, like 'locked', which means no more ownerscan be changed / added, but still possible to free resource by allowners to go to state 'none'Yes, since the ownership design is based on subsystem rather consumer device.See above, hope it clarifies a bit.--With Best Regards,Andy Shevchenko",Technical
,
"Yes I get it but I still don't see how I can use your approach to solvemy issue. We have a situation for several pin controllers. If I can'tknow who is requesting the GPIO, I have no idea about how to solve thisissue. Bypassing the strict mode, as suggested, if the pin controller is alsoa gpio controller may lead, IMO, to wrong behaviors.Do I have to try to find a way to fix this situation? Maybe, it will beeasier to progress on the muxing and configuration topic and tointroduce a DT property to enable the strict mode or wathever modes youwant once everything is ready and DTs fixed.I'd prefer to fix the current situation then to improve muxing andconfiguration stuff because it will take time.RegardsLudovic",Technical
,
"2018-01-16 1:30 GMT+08:00 Vitaly Kuznetsov <vkuznets@redhat.com>:Maybe you can apply a similar idea to kvm nested on kvm.Regards,Wanpeng Li",Technical
,
"Wanpeng Li <kernellwp@gmail.com> writes:Yes we can. Basically, that would mean directly accessing 'structvmcs12' from L1 hypervisor.--  Vitaly",Technical
,
"Haven't looked into the details, but we have to watch out for otherVCPUs trying to modify that vmcs12.Basically because other VCPUs could try to modify values in vmcs12 whilewe are currently building vmcs02. Nasty races could result in us copyingstuff (probably unchecked) into vmcs02 and therefore running somethingthat was not intended.If this is not possible with the current design, perfect :)--Thanks,David / dhildenb",Technical
,
"Yes, the vmcs12 would have to be copied from memory to internalhypervisor data before prepare_vmcs02.I'm curious how well the ""clean"" flags overlap with the choice of fieldsfor which we allow shadow VMCS vmread/vmwrite.Paolo",Technical
,
"David Hildenbrand <david@redhat.com> writes:I don't think we share VMCS among vCPUs, do we?--  Vitaly",Technical
,
"VMCS is just memory, so who knows what a malicious L1 guest will do.But for vmread/vmwrite we can go through hypervisor memory, forenlightened VMCS we cannot.Paolo",Technical
,
"Paolo Bonzini <pbonzini@redhat.com> writes:True; not sure if Hyper-V actually copies the data to some internalstorage, probably it does. TLFS explicitly forbids making the sameenlightened VMCS active on several vCPUs simultaneously but again, thisis just memory...--  Vitaly",Technical
,
"FWIF, on nested s390x we pin the guest provided SIE control block (""SCB""- s390x VMCS12). As this is just guest memory, another VCPU can write tothat memory.When building our shadow SCB (""VMCS02""), we directly access the pinnedblock, but we basically only copy values and mask them for the criticalparts (execution controls).However, as I realize, the compiler might fetch values several times, sowe better add READ_ONCE() to these places. Will look into that.--Thanks,David / dhildenb",Technical
,
"You don't even need to make them active, you can just scribble on itsimultaneously with a VMRESUME.Paolo",Technical
,
"2018-01-15 18:30+0100, Vitaly Kuznetsov:Nice!IIUC, eVMCS replaces VMCS when enabled, hence doing it for all VMs wouldbe simplest -- we wouldn't need to setup VMCS nor reconfigure Hyper-V onthe fly.  (I'm thinking we could have a union in loaded_vmcs foractually used type of VMCS.)Static keys seem like a good choice.I'd go for a separate mapping from Intel VMCS into its MS eVMCS anddirty bit, something like vmcs_field_to_offset_table.Thanks.",Technical
,
Reviewed-by: Thomas Gleixner <tglx@linutronix.de>,Technical
,
"This wants to be split into x86 and core changes. Ideally you make the corechanges before the previous patch and add the empty inline intolinux/processor.h....Thanks,	tglx",Technical
,
"Good point, will fix.I agree with you that this behavior fits better a ""global"" definitionthan a ""shared"" one, especially given that it does not target a specificshared memory mapping. The main issue I have is due to the pre-existingMEMBARRIER_CMD_SHARED introduced in Linux 4.3. That one should also havebeen called ""MEMBARRIER_CMD_GLOBAL"" based on the current line of thoughts.Do you envision a way to transition forward to a new ""MEMBARRIER_CMD_GLOBAL"" forthe currently existing MEMBARRIER_CMD_SHARED ?Perhaps with a duplicated enum entry ?enum membarrier_cmd {        MEMBARRIER_CMD_QUERY                                    = 0,        MEMBARRIER_CMD_SHARED                                   = (1 << 0), /* use MEMBARRIER_CMD_GLOBAL instead */        MEMBARRIER_CMD_GLOBAL                                   = (1 << 0),[...]};Thanks,Mathieu--Mathieu DesnoyersEfficiOS Inc.http://www.efficios.com",Technical
,
"That should work. Though I doubt that you ever can get rid of CMD_SHARED,but at least the code is clearer that way.Thanks,	tglx",Technical
,
"Good point, done. The first commit introducing the new command now alsointroduces the generic stuff moved from the x86 patches.Thanks,Mathieu--Mathieu DesnoyersEfficiOS Inc.http://www.efficios.com",Technical
,
"Scratch this: it's cleaner if I add a separate generic patch to introducejust the empty inline into linux/processor.h and theARCH_HAS_SYNC_CORE_BEFORE_USERMODE in init/Kconfig.Thanks,Mathieu--Mathieu DesnoyersEfficiOS Inc.http://www.efficios.com",Technical
,
"FWIW, SLCG stands for ""second level clock gating"".Cheers,Mikko",Technical
,
"'boutside proctetion'?In general I'd rather have the tracepoints when actually submitting therequest; with this tracepoint we might be getting a trace which doesn'treally indicate if the command was submitted at all.Cheers,Hannes--Dr. Hannes Reinecke		   Teamlead Storage & Networkinghare@suse.de			               +49 911 74053 688SUSE LINUX GmbH, Maxfeldstr. 5, 90409 NÃ¼rnbergGF: F. ImendÃ¶rffer, J. Smithard, J. Guild, D. Upmanyu, G. NortonHRB 21284 (AG NÃ¼rnberg)",Technical
,
Pleas keep the trace header under drivers/nvme/host/,Technical
,
"yes but if we really want to be 100% certain we need to take the tracepointsin either in blk_mq_dispatch_rq_list() and trace the return value of the respective->queue_rq() or in the PCI/FC/RDMA drivers.--Johannes Thumshirn                                          Storagejthumshirn@suse.de                                +49 911 74053 689SUSE LINUX GmbH, Maxfeldstr. 5, 90409 NrnbergGF: Felix Imendrffer, Jane Smithard, Graham NortonHRB 21284 (AG Nrnberg)Key fingerprint = EC38 9CAB C2C4 F25D 8600 D0D0 0393 969D 2D76 0850",Technical
,
"The timer is supposed to be triggered by carrier detect interrupt. After remove the line noise, the carrier detect interrupt is never triggered again, because the carrier is always ok and it only trigger the timer once, Since the protocol was terminated and no new interrupts happen, the link will never be back. So the case here is that the line noise is good and just good to make the carrier detect still goodÂ  but the protocol fail, the timer will be never triggered again.Of course, if you increase the noise and make even the carrier detect fail, then remove the noise, the link will be up, Because the carrier down and up again and then trigger the timer to restart.Denis DuFrom: Denis Du <dudenis2000@yahoo.ca>Date: Tue, 16 Jan 2018 16:58:25 +0000 (UTC)The timer is supposed to restart the protocol again, that's how thiswhole thing is designed to work.I think you are making changes to the symptom rather than the truecause of the problems you are seeing.Sorry, I will not apply this until the exact issue is betterunderstood.Thank you.",Technical
,
"Ok, I submit itÂ  again.In drivers/net/wan/hdlc_ppp.c, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiationThis patch is against the kernel version Linux 4.15-rc8From: Denis Du <dudenis2000@yahoo.ca>Date: Tue, 6 Feb 2018 15:15:28 +0000 (UTC)Please resubmit it and I'll think about it again, thank you.",Technical
,
"HowÂ  is your thinking about this patch?From: Denis Du <dudenis2000@yahoo.ca>Date: Mon, 15 Jan 2018 17:26:06 -0500Subject: [PATCH] netdev: carrier detect ok, don't turn off negotiationSometimes when physical lines have a just good noise to make the protocolhandshaking fail, but the carrier detect still good. Then after remove ofthe noise, nobody will trigger this protocol to be start again to causethe link to never come back. The fix is when the carrier is still on, notterminate the protocol handshaking.Signed-off-by: Denis Du <dudenis2000@yahoo.ca>---drivers/net/wan/hdlc_ppp.c | 5 ++++-1 file changed, 4 insertions(+), 1 deletion(-)diff --git a/drivers/net/wan/hdlc_ppp.c b/drivers/net/wan/hdlc_ppp.cindex afeca6b..ab8b3cb 100644--- a/drivers/net/wan/hdlc_ppp.c+++ b/drivers/net/wan/hdlc_ppp.c@@ -574,7 +574,10 @@ static void ppp_timer(struct timer_list *t)Â Â Â Â Â Â Â Â Â Â Â Â ppp_cp_event(proto->dev, proto->pid, TO_GOOD, 0, 0,Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  0, NULL);Â Â Â Â Â Â Â Â Â Â Â Â proto->restart_counter--;-Â Â Â Â Â Â Â Â } else+Â Â Â Â Â Â Â Â } else if (netif_carrier_ok(proto->dev))+Â Â Â Â Â Â Â Â Â Â Â Â ppp_cp_event(proto->dev, proto->pid, TO_GOOD, 0, 0,+Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  0, NULL);+Â Â Â Â Â Â Â Â elseÂ Â Â Â Â Â Â Â Â Â Â Â ppp_cp_event(proto->dev, proto->pid, TO_BAD, 0, 0,Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  0, NULL);Â Â Â Â Â Â Â Â break;--2.1.4Ok, I submit itÂ  again.In drivers/net/wan/hdlc_ppp.c, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiationThis patch is against the kernel version Linux 4.15-rc8From: Denis Du <dudenis2000@yahoo.ca>Date: Tue, 6 Feb 2018 15:15:28 +0000 (UTC)Please resubmit it and I'll think about it again, thank you.",Technical
,
"From: Denis Du <dudenis2000@yahoo.ca>Date: Tue, 6 Feb 2018 15:15:28 +0000 (UTC)Please resubmit it and I'll think about it again, thank you.",Technical
,
Well this introduces significant overhead for large sized allocation. Doesthis not matter because the areas are small?Would it not be better to use compound page allocations here?page_head(whatever) gets you the head page where you can store all sortsof information about the chunk of memory.,Technical
,
"IIUC, he means PageHead(), which is also hard to grep for, since it isa constructed name, via Page##uname in include/linux/page-flags.h:__PAGEFLAG(Head, head, PF_ANY) CLEARPAGEFLAG(Head, head, PF_ANY)-Kees--Kees CookPixel Security",Technical
,
"Hi Igor,Thank you for the patch! Yet something to improve:[auto build test ERROR on linus/master][also build test ERROR on v4.15][cannot apply to next-20180201][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Igor-Stoppa/mm-security-ro-protection-for-dynamic-data/20180202-123437config: i386-tinyconfig (attached as .config)compiler: gcc-7 (Debian 7.2.0-12) 7.2.1 20171025reproduce:        # save the attached .config to linux build tree        make ARCH=i386All errors (new ones prefixed by >>):   mm/pmalloc.o: In function `pmalloc_pool_show_chunks':   mm/pmalloc.o: In function `pmalloc_pool_show_size':   mm/pmalloc.o: In function `pmalloc_pool_show_avail':   mm/pmalloc.o: In function `pmalloc_chunk_free':   mm/pmalloc.o: In function `pmalloc_create_pool':   mm/pmalloc.o: In function `pmalloc_prealloc':   mm/pmalloc.o: In function `pmalloc':   pmalloc.c:(.text+0x3f1): undefined reference to `gen_pool_add_virt'   pmalloc.c:(.text+0x401): undefined reference to `gen_pool_alloc'   mm/pmalloc.o: In function `pmalloc_destroy_pool':   pmalloc.c:(.text+0x4a1): undefined reference to `gen_pool_for_each_chunk'   pmalloc.c:(.text+0x4a8): undefined reference to `gen_pool_destroy'---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
"Hi Igor,Thank you for the patch! Perhaps something to improve:[auto build test WARNING on linus/master][also build test WARNING on v4.15][cannot apply to next-20180201][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Igor-Stoppa/mm-security-ro-protection-for-dynamic-data/20180202-123437config: i386-randconfig-x071-201804 (attached as .config)compiler: gcc-7 (Debian 7.2.0-12) 7.2.1 20171025reproduce:        # save the attached .config to linux build tree        make ARCH=i386All warnings (new ones prefixed by >>):   mm/pmalloc.c: In function 'pmalloc_pool_show_avail':     return sprintf(buf, ""%lu\n"", gen_pool_avail(data->pool));                          ~~^     ~~~~~~~~~~~~~~~~~~~~~~~~~~                          %u   mm/pmalloc.c: In function 'pmalloc_pool_show_size':   mm/pmalloc.c:81:25: warning: format '%lu' expects argument of type 'long unsigned int', but argument 3 has type 'size_t {aka unsigned int}' [-Wformat=]     return sprintf(buf, ""%lu\n"", gen_pool_size(data->pool));                          ~~^     ~~~~~~~~~~~~~~~~~~~~~~~~~                          %uvim +71 mm/pmalloc.c    63    64	static ssize_t pmalloc_pool_show_avail(struct kobject *dev,    65					       struct kobj_attribute *attr,    66					       char *buf)    67	{    68		struct pmalloc_data *data;    69    70		data = container_of(attr, struct pmalloc_data, attr_avail);  > 71		return sprintf(buf, ""%lu\n"", gen_pool_avail(data->pool));    72	}    73---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
"Hi Igor,Thank you for the patch! Yet something to improve:[auto build test ERROR on linus/master][also build test ERROR on v4.15][cannot apply to next-20180201][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Igor-Stoppa/mm-security-ro-protection-for-dynamic-data/20180202-123437config: xtensa-allyesconfig (attached as .config)compiler: xtensa-linux-gcc (GCC) 7.2.0reproduce:        wget https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross        chmod +x ~/bin/make.cross        # save the attached .config to linux build tree        make.cross ARCH=xtensaAll error/warnings (new ones prefixed by >>):   mm/pmalloc-selftest.c: In function 'pmalloc_selftest':     var_vmall = vmalloc(SIZE_2);                 ^~~~~~~                 kvmalloc     var_vmall = vmalloc(SIZE_2);               ^     vfree(var_vmall);     ^~~~~     kvfree   cc1: some warnings being treated as errorsvim +43 mm/pmalloc-selftest.c    19    20	#define validate_alloc(expected, variable, size)	\    21		pr_notice(""must be "" expected "": %s"",		\    22			  is_pmalloc_object(variable, size) > 0 ? ""ok"" : ""no"")    23    24	#define is_alloc_ok(variable, size)	\    25		validate_alloc(""ok"", variable, size)    26    27	#define is_alloc_no(variable, size)	\    28		validate_alloc(""no"", variable, size)    29    30	void pmalloc_selftest(void)    31	{    32		struct gen_pool *pool_unprot;    33		struct gen_pool *pool_prot;    34		void *var_prot, *var_unprot, *var_vmall;    35    36		pr_notice(""pmalloc self-test"");    37		pool_unprot = pmalloc_create_pool(""unprotected"", 0);    38		pool_prot = pmalloc_create_pool(""protected"", 0);    39		BUG_ON(!(pool_unprot && pool_prot));    40    41		var_unprot = pmalloc(pool_unprot,  SIZE_1 - 1, GFP_KERNEL);    42		var_prot = pmalloc(pool_prot,  SIZE_1, GFP_KERNEL);  > 43		var_vmall = vmalloc(SIZE_2);    44		is_alloc_ok(var_unprot, 10);    45		is_alloc_ok(var_unprot, SIZE_1);    46		is_alloc_ok(var_unprot, PAGE_SIZE);    47		is_alloc_no(var_unprot, SIZE_1 + 1);    48		is_alloc_no(var_vmall, 10);    49    50    51		pfree(pool_unprot, var_unprot);  > 52		vfree(var_vmall);---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
"Thank you, I'll try to provide a meaningful reply soon, but I'll be AFKduring most of next 2 weeks, so it might be delayed :-(--igor",Technical
,
Ok its compound_head(). See also the use in the SLAB and SLUB allocator.If you save the size in the head page struct then you could do that prettyfast.compund pages are higher order pages that are handled as a single page bythe VM. See https://lwn.net/Articles/619514/,Technical
,
"[...]Ok, now I get what you mean.But it doesn't seem to fit the intended use case, for other reasons(maybe the same, from 2 different POV):- compound pages are aggregates of regular pages, in numbers that arepowers of 2, while the amount of pages to allocate is not known upfront.One *could* give a hint to pmalloc about how many pages to allocateevery time there is a need to grow the pool.Iow it would be the size of a chunk. But I'm afraid the granularitywould still be pretty low, so maybe it would be 2-4 times less.- the property of the compound page will affect the property of all thepages in the compound, so when one is write protected, it can generate alot of wasted memory, if there is too much slack (because of the order)With vmalloc, I can allocate any number of pages, minimizing the waste.Finally, there was a discussion about optimization:http://www.openwall.com/lists/kernel-hardening/2017/08/07/2The patch I sent does indeed take advantage of the new information, notjust for pmalloc use.I have not measured if/where/what there is gain, but it does look likethe extra info can be exploited also elsewhere.--igor",Technical
,
I thought the intend here is to create a pool where the whole pool becomesRO?,Technical
,
"LOCAL variable names should be short, and to the point.  If you havesome random integer loop counter, it should probably be called ``i``.Calling it ``loop_counter`` is non-productive, if there is no chance of itbeing mis-understood.  Similarly, ``tmp`` can be just about any type ofvariable that is used to hold a temporary value.(Documentation/process/coding-style.rst)",Technical
,
"Yes, but why would I force the number of pages in the pool to be a powerof 2, when it can be any number?If a need, say, 17 pages, I would have to allocate 32.But it can be worse than that.Since the size of the overall allocated memory is not known upfront, Iwold have a problem to decide how many pages to allocate, every timethere is need to grow the pool.Or push the problem to the user of the API, who might be equally unaware.Notice that there is already a function (prealloc) available to the userof the API, if the size is known upfront.So I do not really see how using compound pages would make memoryutilization better or even not worse.--igor",Technical
,
"[...][...]ok, will do, thanks for the pointer!--igor",Technical
,
I've done this as the first line of my new documentation files:.. SPDX-License-Identifier: CC-BY-SA-4.0I think this is the CC license that's closest in spirit to the GPL withoutthe unintended consequences of the GPL when used on documentation.  TheGFDL seems to be out of favour these days.,Technical
,
"On Fri, 9 Feb 2018 19:37:14 -0800Matthew Wilcox <willy@infradead.org> wrote:I think that's a great license.  I still fear that it is not suitable forkernel documentation, though, especially when we produce documents thatinclude significant text from the (GPL-licensed) kernel source.  Theresult is almost certainly not distributable, and I don't think that's agood thing.  The GPL is not perfect for documentation, but I don't thinkthat we have a better alternative for in-kernel docs.jon",Technical
,
"That's a reasonable concern.  I've read other reasonable concerns aboutthe unintended effects of using the GPL to produce a printed book (egcan you print it in a proprietary font, do you have to provide anelectronic version of the text, and so on).  I fear these wise wordsstill ring true:  But the real problem is that we as a community lack a copyleft license  that works well for both code and text. About the only thing that even  comes close to working is putting the documentation under the GPL as  well, but the GPL is a poor fit for text. Nonetheless, it may be the  best we have in cases where GPL-licensed code is to be incorporated  into documentation.I dare suggest another possibility: that we create a further exception tothe license that the kernel is distributed under.  Something along theselines:Documentation [1] extracted from files marked as GPL [2] may bedistributed under the terms of the CC-BY-SA-4.0 license.[1] This includes text explicitly marked for extraction using the kernel-doctool.  It may include short example code sequences.  It does not includecode that would normally be expected to be compiled.[2] GPL-2.0, GPL-2.0+, GPL-1.0+, LGPL-2.0, LGPL-2.0+, LGPL-2.1, LGPL-2.1+We'd want to run it by a lawyer, of course, to have them check forunintended consequences.",Technical
,
"May be you can merge above with the previous entry which already has/sys/devices/system/cpu/cpuidle/current_driver/sys/devices/system/cpu/cpuidle/current_governer_roOtherwise looks good.--Regards,Sudeep",Technical
,
"Thu, Jan 18, 2018 at 02:17:28PM CET, arnd@arndb.de wrote:I already sent a fix for this:http://patchwork.ozlabs.org/patch/862787/",Technical
,
"Thu, Jan 18, 2018 at 03:19:14PM CET, arnd@arndb.de wrote:Okay. Will add comment.",Technical
,
"I am removing checks from core. Export and import were optional in beginnigof crypto framework, but as time goes on they become mandatory.--Best regards,Kamil KoniecznySamsung R&D Institute Poland",Technical
,
"Seems like if the driver doesn't implement those, the core can easilydetect that and perform the necessary action. Moving the checks out ofcore seems like the wrong thing to do, rather you should enhance thechecks in core if they're insufficient in my opinion.--Best regards,Marek Vasut",Technical
,
"I removed all checks. No checks in driver and no checks in crypto framework.If you would like any check, I think the place to add them is in ahash algregistraction, in function ahash_prepare_alg add something like:	if ((alg->init == NULL) ||	    (alg->digest == NULL) ||	    (alg->final == NULL) ||	    (alg->update == NULL) ||	    (alg->export == NULL) ||	    (alg->import == NULL))		return -EINVAL;The only downsize is this will be usefull in backport (to prevent NULL dereference),as any new driver will have all those pointers sets.--Best regards,Kamil KoniecznySamsung R&D Institute Poland",Technical
,
All applied.  Thanks.--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt,Technical
,
"The bug can only be in driver which will not implement those two functions,but we already had all drivers with those due to patches 1..4All other drivers do have them.Additionally, with crypto we want minimize code and run as fast as possible.Moving checks out of core will impose on driver author need for implementthose functions, or declare them empty, but in case of empty onescrypto will not work properly with such driver.--Best regards,Kamil KoniecznySamsung R&D Institute Poland",Technical
,
"Page tables are protected by their locks.  VMAs may change whilemigration is active on them, but does that need locking against?I have not been keeping up with Michal's recent migration changes,but migrate_pages() never used to need mmap_sem held (despite beingcalled with an mmap_sem held from some of its callsites), and itwould be a backward step to require that now.There is not even an mm argument to migrate_pages(), so whichmm->mmap_sem do you think would be required for it?  There may beparticular cases in which it is required (when the new_page functioninvolves the old_page's vma - is that so below?), but in general not.Hugh",Technical
,
"This doesn't make much sense to me, to be honest. We are holdingmmap_sem for _read_ so we allow parallel updates like page faultsor unmaps. Therefore we are isolating pages prior to the migration.The sole purpose of the mmap_sem in add_page_for_migration is to protectfrom vma going away _while_ need it to get the proper page.Moving the lock up is just wrong because it allows caller to hold thelock for way too long if a lot of pages is migrated. Not only that,it is even incorrect because we are doing get_user() (aka page fault)and while read lock recursion is OK, we might block and deadlock whenthere is a writer pending. I haven't checked the current implementationof semaphores but I believe we do not allow recursive locking.--Michal HockoSUSE Labs",Technical
,
"Hugh Dickins wrote:mmap_sem is held during migrate_pages() in current implementation.http://elixir.free-electrons.com/linux/latest/source/mm/migrate.c#L1576--Best Regards,Yan Zi",Technical
,
You mean in the original code? I strongly suspect this was to not takeit for each page.--Michal HockoSUSE Labs,Technical
,
"Right. The original code gathers 169 pages, whose information (struct page_to_node, 24bytes)fits into a 4KB page, then migrates them at a time. So mmap_sem is not held for longin the original code, because of this design.I think the question is whether we need to hold mmap_sem for migrate_pages(). Hughalso agrees it is not necessary on a separate email. But it is held in the original code.--Best RegardsYan Zi",Technical
,
"[...]I would be really surprised if we really needed the lock. If we do,however, then we really need a very good explanation why. The code usedto do so is not a valid reason.--Michal HockoSUSE Labs",Technical
,
"Compiled and booted on my test system. No dmesg regressions.thanks,-- Shuah",Technical
,
"There are 13 patches in this series, all will be posted as a response<br>to this one.Â  If anyone has any issues with these being applied, please<br>let me know.<br><br>Responses should be made by Wed Feb 28 20:15:12 UTC 2018.<br>Anything received after that time might be too late.<br><br>The whole patch series can be found in one patch at:<br>Â  Â  Â  Â  <a href=""https://www.kernel.org/pub/linux/kernel/v3.x/stable-review/patch-3.18.97-rc1.gz"" rel=""noreferrer"" target=""_blank"">https://www.kernel.org/pub/linux/kernel/v3.x/stable-review/patch-3.18.97-rc1.gz</a><br>or in the git tree and branch at:<br>Â  Â  Â  Â  git://<a href=""http://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable-rc.git"" rel=""noreferrer"" target=""_blank"">git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable-rc.git</a> linux-3.18.y<br>and the diffstat can be found below.<br></blockquote></div><div><br></div><div>No regressions noticed on the OnePlus 3T. CAF&#39;s msm-3.18 tree requires reverting commitÂ <a href=""https://source.codeaurora.org/quic/la/kernel/msm-3.18/commit?id=1278f001ef9bf1329bc2aa123f6038ad9f8a65ee"">https://source.codeaurora.org/quic/la/kernel/msm-3.18/commit?id=1278f001ef9bf1329bc2aa123f6038ad9f8a65ee</a> to avoid conflicting with the patch titled &quot;usb: gadget: f_fs: Process all descriptors during bind&quot;, kernel-common has no merge problems. Thanks for the update.</div><div><br></div><div>Harsh Shandilya</div><div><br></div><div class=""gmail_quote""><blockquote class=""gmail_quote"" style=""margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex""></blockquote></div>",Technical
,
"stable-rc/linux-3.18.y boot: 62 boots: 0 failed, 58 passed with 2 offline, 2 untried/unknown (v3.18.96-14-g9fdaa6623e85)Full Boot Summary: https://kernelci.org/boot/all/job/stable-rc/branch/linux-3.18.y/kernel/v3.18.96-14-g9fdaa6623e85/Full Build Summary: https://kernelci.org/build/stable-rc/branch/linux-3.18.y/kernel/v3.18.96-14-g9fdaa6623e85/Tree: stable-rcBranch: linux-3.18.yGit Describe: v3.18.96-14-g9fdaa6623e85Git Commit: 9fdaa6623e85034df1bae98e3a543606a0098861Git URL: http://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable-rc.gitTested: 30 unique boards, 13 SoC families, 14 builds out of 171Offline Platforms:arm:    multi_v7_defconfig:        exynos5410-odroidxu: 1 offline lab    exynos_defconfig:        exynos5410-odroidxu: 1 offline lab---For more info write to <info@kernelci.org>",Technical
,
"Build results:	total: 136 pass: 135 fail: 1Failed builds:	xtensa:allmodconfigQemu test results:	total: 112 pass: 108 fail: 4Failed tests:	xtensa:dc232b:lx60:generic_kc705_defconfig	xtensa:dc232b:kc705:generic_kc705_defconfig	xtensa:dc233c:ml605:generic_kc705_defconfig	xtensa:dc233c:kc705:generic_kc705_defconfigPresumably the xtensa patch does not apply to this kernel.Details are available at http://kerneltests.org/builders.Guenter",Technical
,
"xtensa patch is now dropped, thanks.greg k-h",Technical
,
"I wanted, I got. This is upstream already (66f793099a63) so this commitmessage possibly wants tweaking slightly.Acked-by: David Woodhouse <dwmw@amazon.co.uk>",Technical
,
"Right you are, I should have re-read these Changelogs before posting ;-)",Technical
,
"I couldn't make it work there, but it could be my makefile foo isn'tstrong enough. The ordering of arch/*/Makefile vs scripts/Makefile.buildis forever confusing me.",Technical
,
Can't you do that with the existing check in arch/x86/Makefile?Âcf.Â http://git.infradead.org/users/dwmw2/linux-retpoline.git/commitdiff/eb12299edwhich is going nowhere until https://bugs.llvm.org/show_bug.cgi?id=36329gets fixed but still I'd like to have the check in *one* place.,Technical
,
"Ted, any objection to this patch?thanks,greg k-h",Technical
,
"No objections with my ext4 hat on.It should be noted though that this is a partial backport because itonly fixes ext4, while Al's original upstream fix addressed a muchlarger set of file systems.  In the Android kernel the f2fs fix hadbeen backported separately.  But for the upstream kernel, it *might*be the case that we should try backporting the original commit so thatin case there is some other general purpose distribution decides (a)to base their system on 4.4, and (b) support a 32-bit kernel, they getthe more general bug fixes which applies for btrfs, isofs, ocfs2, nfs,etc.I haevn't been paying attention to what LTS kernels general purposedistro's are using, so I don't know how important this would be.  Andif there are companies like Cloudflare which are using upstream LTSkernel, it seems unlikely they would want to use a 32-bit kernel,so.... shrug.  Greg, I'll let you decide if you want to backport thefull commit or not.(We had a similar discussion on the AOSP kernel, and came to theconclusion that we only needed to make the patch support ext4.  No onewas going to test the other file systems besides ext4 and f2fs,anyway.  But the calculus might be different might be different forthe general upstream LTS kernel.)				- Ted",Technical
,
"Well, the main point of backporting this change is to fix symlink decryption on32-bit systems.  So, it would be needed on both ext4 and f2fs.  Jin, it might bea good idea to fix f2fs in this patch at well, since unlike the AOSP kernels,the LTS kernels do not have the latest f2fs backported to them.I don't think backporting this change for other filesystems is particularlyimportant, since if I understand correctly, the reasons that Al made the changeoriginally were:- to allow following symlinks in RCU mode, but that's not implemented in old  kernels- to prevent a process from using up all kmaps and deadlocking the system, which  I'm not sure is a real problem (someone would need to try to put together a  reproducer), but if so it would probably just be a local device of service.Also if we actually backported the full commit there are follow-on fixes such ase8ecde25f5e that would be needed as well but might be missed.Thanks,- Eric",Technical
,
"Sure, uploaded https://lkml.org/lkml/2018/2/6/856. PTAL.jin",Technical
,
"Yup... and *that's* only a problem on 32-bit systems.  And aside fromAndroid, it's unclear to me how much we need to support 32-bit systemson upstream LTS kernels.  I suppose there might be Rasperry PI's whichare 32-bits and which might want to use btrfs.  Personally I'm notsure we should care all that much, but others who care more about LTSkernels and 32-bit systems might have a different opinion.Good point.					- Ted",Technical
,
"Hi,You have on extra line hereThe leading 0 will generate a DT warningSince you have that extra line above, you can just drop this new linehere.Thanks!Maxime--Maxime Ripard, Bootlin (formerly Free Electrons)Embedded Linux and Kernel engineeringhttp://bootlin.com",Technical
,
"This should be the whole size of the memory region.Maxime--Maxime Ripard, Bootlin (formerly Free Electrons)Embedded Linux and Kernel engineeringhttp://bootlin.com",Technical
,
OK. (Although on the datasheet digital part and analogpart is listed as one region.),Technical
,
"Queued, thanks.Paolo",Technical
,
"I am not arguing about the kvm change but do we actaully want to warnfor 0 sized allocations? This just doesn't make much sense to me.In other words don't we want this?diff --git a/mm/vmalloc.c b/mm/vmalloc.cindex 673942094328..c5d832510c54 100644--- a/mm/vmalloc.c+++ b/mm/vmalloc.c@@ -1748,7 +1748,9 @@ void *__vmalloc_node_range(unsigned long size, unsigned long align, 	unsigned long real_size = size; 	size = PAGE_ALIGN(size);-	if (!size || (size >> PAGE_SHIFT) > totalram_pages)+	if (!size)+		return NULL;+	if ((size >> PAGE_SHIFT) > totalram_pages) 		goto fail; 	area = __get_vm_area_node(size, align, VM_ALLOC | VM_UNINITIALIZED |--Michal HockoSUSE Labs",Technical
,
"There have been quite a few reports of this from syzkaller and generallywe've fixed them.  It does seem like a recipe for NULL-pointerdereferences when the size is user-controlled (as in this case).But here I'm actually not sure that the ""allocation failure: 0 bytes""can happen, since we have a check above for ""if (routing.nr)"", and thereis a check also so that the maximum allocation here is a meager 128 KiB. So I'm wondering if this patch is obsolete actually after commitf8c1b85b2523.  David?Thanks,PaoloPaolo",Technical
,
[...]                                                                       ^^^^^      ^^^^^Are you sure that you got the right vmalloc?,Technical
,
"Nice catch!  But well, it's the only one in the whole file. :)That seems very much like an old patch then.  I'm unqueuing it.Paolo",Technical
,
We do return NULL for that case regardless the above. The patch justdoesn't warn. Or do you think it is helpful to warn?--Michal HockoSUSE Labs,Technical
,
"It certainly helps bringing potential issues in the spotlight (throughfuzzing, mostly).Paolo",Technical
,
[...]Fair enough.--Michal HockoSUSE Labs,Technical
,
"It's not a catch at all, the fact that I saw this warning with an olderkernel for KVM_SET_GSI_ROUTING doesn't mean that I can't patch it with anupstream kernel.  Would you prefer I remove the stack trace completely?",Technical
,
"FWIW, your stack trace did not complain about a too big allocation, itcomplained about 0 allocation:----- snip ------vmalloc: allocation failure: 0 bytes, mode:0x24000c2(GFP_KERNEL|__GFP_HIGHMEM)----- snip ------After commit f8c1b85b2523 (""KVM: x86: avoid vmalloc(0) in the KVM_SET_CPUID)""this case should be prevented. The only question is does your patch makes sensenevertheless as we gracefully handle the ENOMEM case? So a reproducer ona newer kernel would be good. Maybe use the ""vmalloc"" kernel parameter to forcethis.",Technical
,
"The upstream kernel doesn't warn.  It checks ""if (routing.nr)"" beforecalling vmalloc.Paolo",Technical
,
It will warn of the vmalloc space is really exhausted. But then I really askmyself if we really want to suppress this warning. This should be a bigALERT to the host admin.,Technical
,
Especially since the biggest allocation KVM_SET_GSI_ROUTING can do is128 KiB...Paolo,Technical
,
"Shouldn't this be the other way around?  Everyone is used to 7 now, soyou're changing the default back to 6.  I would think that it should be7 by default, and platforms like Brahma-B53 should force it to 6.--Qualcomm Datacenter Technologies, Inc. as an affiliate of QualcommTechnologies, Inc.  Qualcomm Technologies, Inc. is a member of theCode Aurora Forum, a Linux Foundation Collaborative Project.",Technical
,
"That is debatable, is there a good publicly available table of what thetypical L1 cache line size is on ARMv8 platforms?--Florian",Technical
,
"I don't have that, but I was under the impression that we moved from 6to 7 because more and more ARMv8 platforms have 128-byte caches, so thatis the ""new normal"".--Qualcomm Datacenter Technologies, Inc. as an affiliate of QualcommTechnologies, Inc.  Qualcomm Technologies, Inc. is a member of theCode Aurora Forum, a Linux Foundation Collaborative Project.",Technical
,
"That does not seem to be the data that I am collecting from ARM'swebsite and some quick googling:The following cores appear to have a 64bytes L1D cache line size: A55,A73 (fixed), A35, A32, A53, A57 (fixed), A72 (fixed) even the Falkorseems to be that way according to [1].APM Mustang also seems to be 64b L1D according to [2].[1]: https://en.wikichip.org/wiki/qualcomm/microarchitectures/falkor[2]: http://www.7-cpu.com/cpu/X-Gene.htmlAnd then we seem to covering what the ARM64 mainline kernel knows aboutnon-ARM implementations: ThunderX and ThunderX2 (formerly BroadcomVulcan). There is possibly the Qualcomm Kryo is different, but wikipediaseems to suggest it is a derivative of existing Cortex-A CPUs which havea 64b cache line size.Let's see what Catalin and Will think about what the default should be.Thanks!--Florian",Technical
,
This approach has been raised before ([1] as an example but you canprobably find other threads) and NAK'ed. I really don't want this macroto be configurable as we aim for a single kernel Image.My proposal was to move L1_CACHE_SHIFT back to 6 and ARCH_DMA_MIN_ALIGNto 128 as this is the largest known CWG. The networking code is wrong inassuming SKB_DATA_ALIGN only needs SMP_CACHE_BYTES for DMA alignment butwe can add some safety checks (i.e. WARN_ON) in the arch dma ops code ifthe device is non-coherent.I'll send a patch to the list (hopefully later today).Catalin[1] https://patchwork.kernel.org/patch/8634481/,Technical
,
"With a server hat on...There are many ARMv8 server platforms that do 64b today, but futuredesigns are likely to head toward 128b (for a variety of reasons). Manyof the earlier designs were 64b because that's what certain other archeswere using in their server cores. I doubt Vulcan will remain a uniqueand special case for very long. On the CCIX side of things, I've beentrying to push people to go with 128b lines in future designs too.Jon.",Technical
,
"Hi Mathieu,[...]Mmm, I'm afraid we can't do this. __sched_setscheduler might be calledfrom interrupt contex by normalize_rt_tasks().Best,- Juri",Technical
,
Maybe conditionally grabbing it if pi is true could do? I guess we don'tcare much about domains when sysrq.,Technical
,
"Ops.. just got this. :/--->8---[    0.020203] ======================================================[    0.020946] WARNING: possible circular locking dependency detected[    0.021000] 4.16.0-rc1+ #64 Not tainted[    0.021000] ------------------------------------------------------[    0.021000] swapper/0/1 is trying to acquire lock:[    0.021000]  (cpu_hotplug_lock.rw_sem){.+.+}, at: [<000000007164d41d>] smpboot_register_percpu_thread_cpumask+0x2d/0x100[    0.021000][    0.021000] but task is already holding lock:[    0.021000]  (cpuset_mutex){+.+.}, at: [<000000008529a52c>] __sched_setscheduler+0xb5/0x8b0[    0.021000][    0.021000] which lock already depends on the new lock.[    0.021000][    0.021000][    0.021000] the existing dependency chain (in reverse order) is:[    0.021000][    0.021000] -> #2 (cpuset_mutex){+.+.}:[    0.021000]        __sched_setscheduler+0xb5/0x8b0[    0.021000]        _sched_setscheduler+0x6c/0x80[    0.021000]        __kthread_create_on_node+0x10e/0x170[    0.021000]        kthread_create_on_node+0x37/0x40[    0.021000]        kthread_create_on_cpu+0x27/0x90[    0.021000]        __smpboot_create_thread.part.3+0x64/0xe0[    0.021000]        smpboot_register_percpu_thread_cpumask+0x91/0x100[    0.021000]        spawn_ksoftirqd+0x37/0x40[    0.021000]        do_one_initcall+0x3b/0x160[    0.021000]        kernel_init_freeable+0x118/0x258[    0.021000]        kernel_init+0xa/0x100[    0.021000]        ret_from_fork+0x3a/0x50[    0.021000][    0.021000] -> #1 (smpboot_threads_lock){+.+.}:[    0.021000]        smpboot_register_percpu_thread_cpumask+0x3b/0x100[    0.021000]        spawn_ksoftirqd+0x37/0x40[    0.021000]        do_one_initcall+0x3b/0x160[    0.021000]        kernel_init_freeable+0x118/0x258[    0.021000]        kernel_init+0xa/0x100[    0.021000]        ret_from_fork+0x3a/0x50[    0.021000][    0.021000] -> #0 (cpu_hotplug_lock.rw_sem){.+.+}:[    0.021000]        cpus_read_lock+0x3e/0x80[    0.021000]        smpboot_register_percpu_thread_cpumask+0x2d/0x100[    0.021000]        lockup_detector_init+0x3e/0x74[    0.021000]        kernel_init_freeable+0x146/0x258[    0.021000]        kernel_init+0xa/0x100[    0.021000]        ret_from_fork+0x3a/0x50[    0.021000][    0.021000] other info that might help us debug this:[    0.021000][    0.021000] Chain exists of:[    0.021000]   cpu_hotplug_lock.rw_sem --> smpboot_threads_lock --> cpuset_mutex[    0.021000][    0.021000]  Possible unsafe locking scenario:[    0.021000][    0.021000]        CPU0                    CPU1[    0.021000]        ----                    ----[    0.021000]   lock(cpuset_mutex);[    0.021000]                                lock(smpboot_threads_lock);[    0.021000]                                lock(cpuset_mutex);[    0.021000]   lock(cpu_hotplug_lock.rw_sem);[    0.021000][    0.021000]  *** DEADLOCK ***[    0.021000][    0.021000] 1 lock held by swapper/0/1:[    0.021000]  #0:  (cpuset_mutex){+.+.}, at: [<000000008529a52c>] __sched_setscheduler+0xb5/0x8b0[    0.021000][    0.021000] stack backtrace:[    0.021000] CPU: 0 PID: 1 Comm: swapper/0 Not tainted 4.16.0-rc1+ #64[    0.021000] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-2.fc27 04/01/2014[    0.021000] Call Trace:[    0.021000]  dump_stack+0x85/0xc5[    0.021000]  print_circular_bug.isra.38+0x1ce/0x1db[    0.021000]  __lock_acquire+0x1278/0x1320[    0.021000]  ? sched_clock_local+0x12/0x80[    0.021000]  ? lock_acquire+0x9f/0x1f0[    0.021000]  lock_acquire+0x9f/0x1f0[    0.021000]  ? smpboot_register_percpu_thread_cpumask+0x2d/0x100[    0.021000]  cpus_read_lock+0x3e/0x80[    0.021000]  ? smpboot_register_percpu_thread_cpumask+0x2d/0x100[    0.021000]  smpboot_register_percpu_thread_cpumask+0x2d/0x100[    0.021000]  ? set_debug_rodata+0x11/0x11[    0.021000]  lockup_detector_init+0x3e/0x74[    0.021000]  kernel_init_freeable+0x146/0x258[    0.021000]  ? rest_init+0xd0/0xd0[    0.021000]  kernel_init+0xa/0x100[    0.021000]  ret_from_fork+0x3a/0x50",Technical
,
Arrghhh... Back to the drawing board.,Technical
,
"Eh.. even though the warning simply happens because unlocking ofcpuset lock is missing--->8---@@ -4312,6 +4312,7 @@ static int __sched_setscheduler(struct task_struct *p,        /* Avoid rq from going away on us: */        preempt_disable();        task_rq_unlock(rq, p, &rf);+       cpuset_unlock();        if (pi)                rt_mutex_adjust_pi(p);--->8---Still grabbing it is a no-go, as do_sched_setscheduler callssched_setscheduler from inside an RCU read-side critical section.So, back to the drawing board indeed. :/Thanks,- Juri",Technical
,
"[...]I was then actually thinking that trylocking might do.. not sure howeverif failing with -EBUSY in the contended case is feasible (and about thegeneral uglyness of the solution :/).--->8--- include/linux/cpuset.h | 4 ++-- kernel/cgroup/cpuset.c | 6 +++--- kernel/sched/core.c    | 4 +++- 3 files changed, 8 insertions(+), 6 deletions(-)diff --git a/include/linux/cpuset.h b/include/linux/cpuset.hindex 4bbb3f5a3020..53c3f4e13cb0 100644--- a/include/linux/cpuset.h+++ b/include/linux/cpuset.h@@ -55,7 +55,7 @@ extern void cpuset_init_smp(void); extern void cpuset_force_rebuild(void); extern void cpuset_update_active_cpus(void); extern void cpuset_wait_for_hotplug(void);-extern void cpuset_lock(void);+extern int cpuset_trylock(void); extern void cpuset_unlock(void); extern void cpuset_cpus_allowed(struct task_struct *p, struct cpumask *mask); extern void cpuset_cpus_allowed_fallback(struct task_struct *p);@@ -178,7 +178,7 @@ static inline void cpuset_update_active_cpus(void) static inline void cpuset_wait_for_hotplug(void) { }-static inline void cpuset_lock(void) { }+static inline int cpuset_trylock(void) { return 1; } static inline void cpuset_unlock(void) { }diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.cindex 41f8391640e6..995aac5b032d 100644--- a/kernel/cgroup/cpuset.c+++ b/kernel/cgroup/cpuset.c@@ -2410,11 +2410,11 @@ void __init cpuset_init_smp(void) } /**- * cpuset_lock - Grab the cpuset_mutex from another subsysytem+ * cpuset_trylock - Try to grab the cpuset_mutex atomically from another subsytem  */-void cpuset_lock(void)+int cpuset_trylock(void) {-	mutex_lock(&cpuset_mutex);+	return mutex_trylock(&cpuset_mutex); } /**diff --git a/kernel/sched/core.c b/kernel/sched/core.cindex 0d8badcf1f0f..b491b406a835 100644--- a/kernel/sched/core.c+++ b/kernel/sched/core.c@@ -4180,7 +4180,8 @@ static int __sched_setscheduler(struct task_struct *p, 	 * domains can be rebuilt or modified while operations like DL 	 * admission checks are carried out. 	 */-	cpuset_lock();+	if (!cpuset_trylock())+		return -EBUSY; 	/* 	 * Make sure no PI-waiters arrive (or leave) while we are@@ -4312,6 +4313,7 @@ static int __sched_setscheduler(struct task_struct *p, 	/* Avoid rq from going away on us: */ 	preempt_disable(); 	task_rq_unlock(rq, p, &rf);+	cpuset_unlock(); 	if (pi) 		rt_mutex_adjust_pi(p);",Technical
,
"Or, as suggested by Peter in IRC, the following (which still wouldrequire conditional locking for the sysrq case).--->8--- kernel/sched/core.c | 21 +++++++++++++++++---- 1 file changed, 17 insertions(+), 4 deletions(-)diff --git a/kernel/sched/core.c b/kernel/sched/core.cindex 0d8badcf1f0f..4e9405d50cbd 100644--- a/kernel/sched/core.c+++ b/kernel/sched/core.c@@ -4312,6 +4312,7 @@ static int __sched_setscheduler(struct task_struct *p, 	/* Avoid rq from going away on us: */ 	preempt_disable(); 	task_rq_unlock(rq, p, &rf);+	cpuset_unlock(); 	if (pi) 		rt_mutex_adjust_pi(p);@@ -4409,10 +4410,16 @@ do_sched_setscheduler(pid_t pid, int policy, struct sched_param __user *param) 	rcu_read_lock(); 	retval = -ESRCH; 	p = find_process_by_pid(pid);-	if (p != NULL)-		retval = sched_setscheduler(p, policy, &lparam);+	if (!p) {+		rcu_read_unlock();+		goto exit;+	}+	get_task_struct(p); 	rcu_read_unlock();+	retval = sched_setscheduler(p, policy, &lparam);+	put_task_struct(p);+exit: 	return retval; }@@ -4540,10 +4547,16 @@ SYSCALL_DEFINE3(sched_setattr, pid_t, pid, struct sched_attr __user *, uattr, 	rcu_read_lock(); 	retval = -ESRCH; 	p = find_process_by_pid(pid);-	if (p != NULL)-		retval = sched_setattr(p, &attr);+	if (!p) {+		rcu_read_unlock();+		goto exit;+	}+	get_task_struct(p); 	rcu_read_unlock();+	retval = sched_setattr(p, &attr);+	put_task_struct(p);+exit: 	return retval; }",Technical
,
"Just for the record, while this may work for media, it won't work for allsubsystems.  One will quickly get a complaint that the big patch needs togo into multiple trees.julia",Technical
,
"For the record: this only applies to drivers/media. We discussed what do to with serieslike this during our media summit last Friday and this was the conclusion of that.Obviously I can't talk about other subsystems.Regards,	Hans",Technical
,
"I have got an other impression.I continued with the presentation of suggestions from my selectionof change possibilities.It seems that there are very different expectations for thepreferred patch granularity.Can it happen again that you are going to use a development toollike â€œquiltâ€ (as a maintainer) for the desired recombinationof possible update steps?Regards,Markus",Technical
,
"I find it safer in this way  while I was browsing through the landscape of Linuxsoftware components.It is just the case that there are so many remaining open issues.Thanks for a bit of change acceptance.Will any chances evolve to integrate 146 patches in any other combination?Can we achieve an agreement on the shown change patterns?Is a consensus possible for involved update candidates?I find that I did this already.I got an other software development opinion.Do we need to try any additional communication tools out?I hope that various change possibilities (from my selection) will become usefulfor more Linux users.How will the clarification evolve further?Regards,Markus",Technical
,
"Do both I2C and OF have stubs so that a driver will build when they areboth disabled?  I.e., only COMPILE_TEST is enabled?thanks,--~Randy",Technical
,
"Please no.16 temperature channels ...Excessive [and inconsistent] ( )Please make this	if (ret)		return ret;	...	return 0;return followed by break doesn't make sense.	&buf -> bufUnnecessary ( )... but this array only has 8+1 elements. This seems inconsistent.How about using some defines for array sizes ?Also, why initialize those arrays ? You are overwriting them below.You could just use a static size array instead.I assume it is guaranteed that there is only exactly one instanceof this device in the system. Have you tried what happens if youdeclare two instances anyway ? The result must be interesting,with all those static variables.The matching gsc_fan_ch has only 5 entries.You declare local 'dev' variables all over the place, except here,where it would actually be used multiple times.Please either declare one here as well, or drop all the others.It must be interesting to see what happens if no 'label' propertyis provided. Have you tried ? Also, no validation of 'reg' and 'type' ?Are you sure ?This leaves the string unterminated if it is too long. Have you testedwhat happens in this situation ? Consider using strlcpy instead.Also please use sizeof() instead of '32'.I would suggest to abort with EINVAL if this happens. Otherwise the last entryis overwritten, which doesn't make much sense. Also, this accepts up to ARRAY_SIZE()entries, leaving no termination.So a reg value of 0xXXyy is auto-converted to 0xYY ?It is going to be interesting to see what happens if there are more than5 such entries.All other types are silently ignored ?I would suggest to move above code into a separate function.The error would be ENOMEM. Is it necessary to report that again ?",Technical
,
"Hi Tim,""To compile this driver as a module...""Let's keep the same // comment block fir the copyright notice as well.An one-line describing what this driver is would be appreciated too.Please no.Why is this needed? To clear irq? What happens if several events happenat the same time? Do we lose one of them?Could we provide the mapping in DTS instead of hard-coding them?		input_sync();Why not use threaded interrupt?Not needed - it is set by devm_input_allocate_device().I'd say mapping should be done by MFD piece. You can add interrupts asresources and fetch them here.Thanks.--Dmitry",Technical
,
"Hi TimMaybe it is in these patches, and i missed it....How do these emulated devices work? Does the controller respond todifferent addresses for these different emulated devices? Or is it anI2c bus mux?    Andrew",Technical
,
"Andrew,You didn't miss it - I probably need to explain it better.The 'emulated devices' do respond on different slave addresses (whichmatch one of or the only the slave addresses those parts support). Forexample the device-tree for the GW54xx has the following which are allfrom the GSC which is the only thing on i2c1:&i2c1 {        clock-frequency = <100000>;        pinctrl-names = ""default"";        pinctrl-0 = <&pinctrl_i2c1>;        status = ""okay"";        gsc: gsc@20 {                compatible = ""gw,gsc_v2"";                reg = <0x20>;                interrupt-parent = <&gpio1>;                interrupts = <4 GPIO_ACTIVE_LOW>;                interrupt-controller;                #interrupt-cells = <1>;                gsc_input {                        compatible = ""gw,gsc-input"";                };                gsc_hwmon {                        compatible = ""gw,gsc-hwmon"";                        #address-cells = <1>;                        #size-cells = <0>;                        hwmon@0 { /* A0: Board Temperature */                                type = <0>;                                reg = <0x00>;                                label = ""temp"";                                /* lookup table */                        };                        hwmon@1 { /* A1: Input Voltage */                                type = <1>;                                reg = <0x02>;                                label = ""Vin"";                                gw,voltage-divider = <22100 1000>;                                gw,offset = <800>;                        };                        hwmon@2 { /* A2: 5P0 */                                type = <1>;                                reg = <0x0b>;                                label = ""5P0"";                                gw,voltage-divider = <22100 1000>;                        };                        hwmon@4 { /* A4: 0-5V input */                                type = <1>;                                reg = <0x14>;                                label = ""ANL0"";                                gw,voltage-divider = <10000 10000>;                        };                        hwmon@5 { /* A5: 2P5 PCIe/GigE */                                type = <1>;                                reg = <0x23>;                                label = ""2P5"";                                gw,voltage-divider = <10000 10000>;                        };                        hwmon@6 { /* A6: 1P8 Aud/Vid */                                type = <1>;                                reg = <0x1d>;                                label = ""1P8"";                        };                        hwmon@7 { /* A7: GPS */                                type = <1>;                                reg = <0x26>;                                label = ""GPS"";                                gw,voltage-divider = <4990 10000>;                        };                        hwmon@12 { /* A12: VDD_CORE */                                type = <1>;                                reg = <0x3>;                                label = ""VDD_CORE"";                        };                        hwmon@13 { /* A13: VDD_SOC */                                type = <1>;                                reg = <0x11>;                                label = ""VDD_SOC"";                        };                        hwmon@14 { /* A14: 1P0 PCIe SW */                                type = <1>;                                reg = <0x20>;                                label = ""1P0"";                        };                        hwmon@15 { /* fan0 */                                type = <2>;                                reg = <0x2c>;                                label = ""fan_50p"";                        };                        hwmon@16 { /* fan1 */                                type = <2>;                                reg = <0x2e>;                                label = ""fan_60p"";                        };                        hwmon@17 { /* fan2 */                                type = <2>;                                reg = <0x30>;                                label = ""fan_70p"";                        };                        hwmon@18 { /* fan3 */                                type = <2>;                                reg = <0x32>;                                label = ""fan_80p"";                        };                        hwmon@19 { /* fan4 */                                type = <2>;                                reg = <0x34>;                                label = ""fan_90p"";                        };                        hwmon@20 { /* fan5 */                                type = <2>;                                reg = <0x36>;                                label = ""fan_100p"";                        };                };        };        gsc_gpio: pca9555@23 {                compatible = ""nxp,pca9555"";                reg = <0x23>;                gpio-controller;                #gpio-cells = <2>;                interrupt-parent = <&gsc>;                interrupts = <4>;        };        eeprom1: eeprom@50 {                compatible = ""atmel,24c02"";                reg = <0x50>;                pagesize = <16>;        };        eeprom2: eeprom@51 {                compatible = ""atmel,24c02"";                reg = <0x51>;                pagesize = <16>;        };        eeprom3: eeprom@52 {                compatible = ""atmel,24c02"";                reg = <0x52>;                pagesize = <16>;        };        eeprom4: eeprom@53 {                compatible = ""atmel,24c02"";                reg = <0x53>;                pagesize = <16>;        };        rtc: ds1672@68 {                compatible = ""dallas,ds1672"";                reg = <0x68>;        };};One issue I'm trying to figure out the best way to deal with is thefact that the GSC can 'NAK' transactions occasionally which is why Ioverride the regmap read/write functions and provide retries. Thisresolves the issue for the mfd core driver and sub-module drivers butdoesn't resolve the issue with these 'emulated devices' which havetheir own stand-alone drivers. I'm not sure how to best deal with thatyet. I tried to add retires to the i2c adapter but that wasn'taccepted upstream because it was too generic and I was told I need towork around it in device-drivers. I'm guessing I need to write my ownsub-module drivers that will largely duplicate whats in thestand-alone drivers (ds1672, at24, pca9553x).Regards,Tim",Technical
,
Hi TimThere appears to be a few spaces vs tabs issues in this file.      Andrew,Technical
,
Thanks. I'll run through checkpatch prior to v2.Tim,Technical
,
"That was just to point out that you use smaller arrays later on.That is what you do, isn't it ? So reg=0xffff and reg=0xfeff will bothmap to 0xff. Or, in other word, the code happily accepts invalid valuesand converts them into something else.Much preferred.Thanks,Guenter",Technical
,
"Please note that there is nothing wrong in the generated code, justthat it confuses objtool.Clang has simply omitted the statement where NULL is returned sincethe pointer was always dereferenced post inlining.Note that GCC will also remove the NULL pointers if it knows that thepointer is dereferenced.Here is an example.void null_check(int *P) {  int deref = *P;  if (P == 0) // GCC won't check the condition.    return;  *P = 4;}Compiling with gcc -O2 gives:        movl    $4, (%rdi)        retThanks,ManojOn Tue, Mar 27, 2018 at 11:16 PM, Greg Kroah-Hartman<gregkh@linuxfoundation.org> wrote:",Technical
,
... but returning NULL would be far more sane than falling through tothe next function.This is why we use -fno-delete-null-pointer-checks.--Josh,Technical
,
"Or, as the case may be, oopsing at the point of failure.--Josh",Technical
,
"El Wed, Mar 28, 2018 at 08:05:56PM +0200 Greg Kroah-Hartman ha dit:Thanks all for your input, we'll try to get-fno-delete-null-pointer-checks or a similar flag to be added toclang.",Technical
,
"El Wed, Mar 28, 2018 at 08:19:36PM +0200 Greg Kroah-Hartman ha dit:Nope, clang doesn't currently have such a flag.IIRC this patch was needed to work around the lack of the flag:commit beaec533fc2701a28a4d667f67c9f59c6e4e0d13Author: Alexander Potapenko <glider@google.com>Date:   Wed Jul 19 20:27:30 2017 +0200    llist: clang: introduce member_address_is_nonnull()    Currently llist_for_each_entry() and llist_for_each_entry_safe() iterate    until &pos->member != NULL.  But when building the kernel with Clang,    the compiler assumes &pos->member cannot be NULL if the member's offset    is greater than 0 (which would be equivalent to the object being    non-contiguous in memory).  Therefore the loop condition is always true,    and the loops become infinite.    To work around this, introduce the member_address_is_nonnull() macro,    which casts object pointer to uintptr_t, thus letting the member pointer    to be NULL.    Signed-off-by: Alexander Potapenko <glider@google.com>    Tested-by: Sodagudi Prasad <psodagud@codeaurora.org>    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>Other than that I am not aware of any known issues.",Technical
,
I think you have gotten lucky :)greg k-h,Technical
,
"Looks good.  Thanks!regards,dan carpenter_______________________________________________devel mailing listdevel@linuxdriverproject.orghttp://driverdev.linuxdriverproject.org/mailman/listinfo/driverdev-devel",Technical
,
"Looks good.  Thanks!Greg just hasn't gotten to it yet.regards,dan carpenter_______________________________________________devel mailing listdevel@linuxdriverproject.orghttp://driverdev.linuxdriverproject.org/mailman/listinfo/driverdev-devel",Technical
,
"Are there any opinions? I'd like to know how this patch is going.Best regards,Ji-Hun",Technical
,
Greg does not take drivers/staging/media/* patches :)_______________________________________________devel mailing listdevel@linuxdriverproject.orghttp://driverdev.linuxdriverproject.org/mailman/listinfo/driverdev-devel,Technical
,
"I don't know the state in 3.16, but in 3.12, I had to fix the 32bitentry on 64bit in arch/x86/ia32/ia32entry.S (ia32_sysenter_target &others) too.thanks,--jssuse labs",Technical
,
"Build results:	total: 136 pass: 136 fail:0Qemu test results:	total: 115 pass: 112 fail:3Failed tests:	mipsel:24Kf:malta_defconfig:smp:rootfs	mipsel64:malta_defconfig:nosmp:rootfs	mipsel64:malta_defconfig:smp:rootfsThe failures are due to newly added tests; the init process crashes.v3.16 passes those tests, so the problem was introduced later.I'll run a bisect later to see if I can find the culprit. If not,I'll drop the new tests from this kernel version.Guenter",Technical
,
"Turns out I did the bisect kalready. Attached. It does suggest that theremay be a real problem.Guenter---# bad: [3e50cd97ed730bb0abfcdbc8c1a18871c2750c33] Linux 3.16.55# good: [19583ca584d6f574384e17fe7613dfaeadcdc4a6] Linux 3.16git bisect start 'HEAD' 'v3.16'# good: [d1afef76e102be87955151c93bd51fd04c1c0c01] arm64: mm: ensure that the zero page is visible to the page table walkergit bisect good d1afef76e102be87955151c93bd51fd04c1c0c01# good: [b6927bd60d353de044584ab9400aaccd8694fe1e] can: Fix kernel panic at security_sock_rcv_skbgit bisect good b6927bd60d353de044584ab9400aaccd8694fe1e# good: [aa9a2ec0e82b64db1851d96ab1e9c83f8ea17a39] ARM: kexec: Make .text R/W in machine_kexecgit bisect good aa9a2ec0e82b64db1851d96ab1e9c83f8ea17a39# good: [bf5ac638a0ffa923ed03ba8cdb8241b812f5fe4f] can: gs_usb: fix busy loop if no more TX context is availablegit bisect good bf5ac638a0ffa923ed03ba8cdb8241b812f5fe4f# good: [957a3d249cb16292a199f73b7138d23ee44ca433] Revert ""x86: kvmclock: Disable use from vDSO if KPTI is enabled""git bisect good 957a3d249cb16292a199f73b7138d23ee44ca433# bad: [66fe40226beb16fb7809d275aec362f479388935] USB: serial: option: adding support for YUGA CLM920-NC5git bisect bad 66fe40226beb16fb7809d275aec362f479388935# good: [0b6433856a149885470f2ab3a138e99347c323a4] arm64: fpsimd: Prevent registers leaking from dead tasksgit bisect good 0b6433856a149885470f2ab3a138e99347c323a4# good: [d6e7dd39a7f036eb3e48032d68d9e70f2e9781cf] MIPS: Clear [MSA]FPE CSR.Cause after notify_die()git bisect good d6e7dd39a7f036eb3e48032d68d9e70f2e9781cf# bad: [d97c5dd698a37a6f4fcce8132853620f7390f797] MIPS: Fix an FCSR access API regression with NT_PRFPREG and MSAgit bisect bad d97c5dd698a37a6f4fcce8132853620f7390f797# bad: [b18b5d55c0e8b2bccda919f5f227ec3ba1056f2a] MIPS: Fix a preemption issue with thread's FPU defaultsgit bisect bad b18b5d55c0e8b2bccda919f5f227ec3ba1056f2a# good: [0efd2f915bbc608f66065c36b291d37efe0a0b0f] MIPS: Always clear FCSR cause bits after emulationgit bisect good 0efd2f915bbc608f66065c36b291d37efe0a0b0f# bad: [3127c502272aca5f46b04c0b11afb464ad4fcbaf] MIPS: math-emu: Define IEEE 754-2008 feature control bitsgit bisect bad 3127c502272aca5f46b04c0b11afb464ad4fcbaf# bad: [8605aa2fea28c0485aeb60c114a9d52df1455915] MIPS: Set `si_code' for SIGFPE signals sent from emulation toogit bisect bad 8605aa2fea28c0485aeb60c114a9d52df1455915# first bad commit: [8605aa2fea28c0485aeb60c114a9d52df1455915] MIPS: Set `si_code' for SIGFPE signals sent from emulation too",Technical
,
"Thank you, yes I need to fix them in 3.16 too.  I also failed to useretpolines there.Ben.--Ben HutchingsThe first rule of tautology club is the first rule of tautology club.",Technical
,
"Maciej W. Rozycki worked out that it depends on commit 27e28e8ec47a(""MIPS: Normalise code flow in the CpU exception handler"") which Imistakenly omitted.  I'll include that in the next update (3.16.57).Ben.--Ben HutchingsTime is nature's way of making sure thateverything doesn't happen at once.",Technical
,
"As I watched this email send, I noticed the ""3/3"" in the Subject. ;) Isee the amdcz support now. :Phttps://patchwork.kernel.org/project/LKML/list/?submitter=18441This question still stands, though.-Kees--Kees CookPixel Security",Technical
,
"wrote: From the same patch: https://patchwork.kernel.org/patch/10283641/if (CONFIG_ACPI_SPCR_TABLE && !CONFIG_SERIAL_8250)in other words, if serial ports are disabled, but we still want to parsethe APCI_SPCR_TABLE, which ""defaults y if X86"".Perhaps that logic should be changed (no need to parse ACPI SPCR table ifwe are going to disable serial anyway)?",Technical
,
"But won't this break? ""static const bool ..."" but the code tries toset a value but I'd expect the compiler to still yet about it?I think you could drop the .h #ifdef and use:if (IS_ENABLED(CONFIG_SERIAL_825) && amdcz_present(...)) {-Kees--Kees CookPixel Security",Technical
,
"wrote:wrote:mentionb/include/linux/serial_8250.hCONFIG_SERIAL_8250ifer... yeah.oooohhh... nice.  I like it, will change.",Technical
,
"Hi Daniel,Thank you for the patch! Yet something to improve:[auto build test ERROR on v4.16-rc4][also build test ERROR on next-20180316][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Daniel-Kurtz/Add-earlycon-support-for-AMD-Carrizo-Stoneyridge/20180318-025754config: x86_64-allmodconfig (attached as .config)compiler: gcc-7 (Debian 7.3.0-1) 7.3.0reproduce:        # save the attached .config to linux build tree        make ARCH=x86_64All errors (new ones prefixed by >>):   drivers//acpi/spcr.c: In function 'acpi_parse_spcr':      serial8250_skip_old_ports = true;                                ^--    bool serial8250_skip_old_ports;         ^~~~~~~~~~~~~~~~~~~~~~~~~   In file included from drivers//tty/serial/8250/8250_core.c:29:0:   include/linux/serial_8250.h:142:19: note: previous declaration of 'serial8250_skip_old_ports' was here    static const bool serial8250_skip_old_ports;                      ^~~~~~~~~~~~~~~~~~~~~~~~~sparse warnings: (new ones prefixed by >>)   drivers/acpi/spcr.c: In function 'acpi_parse_spcr':   drivers/acpi/spcr.c:212:29: error: assignment of read-only variable 'serial8250_skip_old_ports'      serial8250_skip_old_ports = true;                                ^vim +/serial8250_skip_old_ports +212 drivers//acpi/spcr.c    94    95	/**    96	 * acpi_parse_spcr() - parse ACPI SPCR table and add preferred console    97	 *    98	 * @enable_earlycon: set up earlycon for the console specified by the table    99	 * @enable_console: setup the console specified by the table.   100	 *   101	 * For the architectures with support for ACPI, CONFIG_ACPI_SPCR_TABLE may be   102	 * defined to parse ACPI SPCR table.  As a result of the parsing preferred   103	 * console is registered and if @enable_earlycon is true, earlycon is set up.   104	 * If @enable_console is true the system console is also configured.   105	 *   106	 * When CONFIG_ACPI_SPCR_TABLE is defined, this function should be called   107	 * from arch initialization code as soon as the DT/ACPI decision is made.   108	 *   109	 */   110	int __init acpi_parse_spcr(bool enable_earlycon, bool enable_console)   111	{   112		static char opts[64];   113		struct acpi_table_spcr *table;   114		acpi_status status;   115		char *uart;   116		char *iotype;   117		int baud_rate;   118		int err;   119   120		if (acpi_disabled)   121			return -ENODEV;   122   123		status = acpi_get_table(ACPI_SIG_SPCR, 0,   124					(struct acpi_table_header **)&table);   125   126		if (ACPI_FAILURE(status))   127			return -ENOENT;   128   129		if (table->header.revision < 2)   130			pr_info(""SPCR table version %d\n"", table->header.revision);   131   132		if (table->serial_port.space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY) {   133			switch (ACPI_ACCESS_BIT_WIDTH((   134				table->serial_port.access_width))) {   135			default:   136				pr_err(""Unexpected SPCR Access Width.  Defaulting to byte size\n"");   137				/* fall through */   138			case 8:   139				iotype = ""mmio"";   140				break;   141			case 16:   142				iotype = ""mmio16"";   143				break;   144			case 32:   145				iotype = ""mmio32"";   146				break;   147			}   148		} else   149			iotype = ""io"";   150   151		switch (table->interface_type) {   152		case ACPI_DBG2_ARM_SBSA_32BIT:   153			iotype = ""mmio32"";   154			/* fall through */   155		case ACPI_DBG2_ARM_PL011:   156		case ACPI_DBG2_ARM_SBSA_GENERIC:   157		case ACPI_DBG2_BCM2835:   158			uart = ""pl011"";   159			break;   160		case ACPI_DBG2_16550_COMPATIBLE:   161		case ACPI_DBG2_16550_SUBSET:   162			uart = ""uart"";   163			break;   164		default:   165			err = -ENOENT;   166			goto done;   167		}   168   169		switch (table->baud_rate) {   170		case 3:   171			baud_rate = 9600;   172			break;   173		case 4:   174			baud_rate = 19200;   175			break;   176		case 6:   177			baud_rate = 57600;   178			break;   179		case 7:   180			baud_rate = 115200;   181			break;   182		default:   183			err = -ENOENT;   184			goto done;   185		}   186   187		/*   188		 * If the E44 erratum is required, then we need to tell the pl011   189		 * driver to implement the work-around.   190		 *   191		 * The global variable is used by the probe function when it   192		 * creates the UARTs, whether or not they're used as a console.   193		 *   194		 * If the user specifies ""traditional"" earlycon, the qdf2400_e44   195		 * console name matches the EARLYCON_DECLARE() statement, and   196		 * SPCR is not used.  Parameter ""earlycon"" is false.   197		 *   198		 * If the user specifies ""SPCR"" earlycon, then we need to update   199		 * the console name so that it also says ""qdf2400_e44"".  Parameter   200		 * ""earlycon"" is true.   201		 *   202		 * For consistency, if we change the console name, then we do it   203		 * for everyone, not just earlycon.   204		 */   205		if (qdf2400_erratum_44_present(&table->header)) {   206			qdf2400_e44_present = true;   207			if (enable_earlycon)   208				uart = ""qdf2400_e44"";   209		}   210   211		if (amdcz_present(table)) { > 212			serial8250_skip_old_ports = true;---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
Please take a look at drivers/staging/ipx/TODO_______________________________________________devel mailing listdevel@linuxdriverproject.orghttp://driverdev.linuxdriverproject.org/mailman/listinfo/driverdev-devel,Technical
,
"Hi Andy,On Thu, Mar 1, 2018 at 1:32 PM, Andy Shevchenko<andy.shevchenko@gmail.com> wrote:Zorro II address space is always mapped, and address conversion donethrough ZTWO_VADDR()/ZTWO_PADDR().Indeed. This should print the physical addresses, using pdata->base insteadof base.Gretje,eetings,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
"Does this use driver model? I cannot see it.Regards,Simon",Technical
,
Hi YannickI would replace debug by dev_err() here.DittoDittoDittoDittoDittoDitto,Technical
,
"Hi YannickAs you get access to the struct udevice, prefer dev_err() here.dittodittodittodev_info()dev_err()dittodittodittodev_info()dev_err()dittodittodev_info()ThanksPatrice",Technical
,
Hi Yannickdev_err()Is it useful to print this each time the backligth is enabled ?dittodev_err()dittodebug() ?,Technical
,
Hi yannickdev_err()dev_err()dev_warn() or dev_err() ?is it useful to print this each time ? or is it for debug purpose ? inthis case use debug()dev_err()dittodittodittodittodittodittoditto,Technical
,
Hi yannickpr_err()dittodebug() ?debug() ?dev_info()dittodebug() ?dev_err(),Technical
,
Alexey Dobriyan <adobriyan@gmail.com> wrote:Acked-by: Florian Westphal <fw@strlen.de>I'll send a patch for xtables too to reject bogus namescoming from userspace (syzbot reports WARN() ).,Technical
,
"Hmm, patch is probably good idea, but now it means that userspace cantrigger WARN()s, and can hide objects from root by naming them '.' and'..'... which is not good.If you know where this happens, it would be nice to fix them inaddition to this patch.--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Patch rejects creation of such entries.And they should be harmless as VFS lookup won't find them, only readdirwould. It not clear how they could be useful.",Technical
,
"Yeah, as I said, that's half of problem.If I can name my object ""."" and it will be hidden from root, thatsounds like a security hole to be prevented.So if you know _which_ subsystem allow creating files and directoriesin /proc with names directly controlled by userspace, please let usknow, we want to fix that.								Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"--- a/fs/proc/generic.c~proc-reject-and-as-filenames-fix+++ a/fs/proc/generic.c@@ -387,10 +387,8 @@ static struct proc_dir_entry *__proc_cre 		WARN(1, ""name len %u\n"", qstr.len); 		return NULL; 	}-	if (qstr.len == 1 && fn[0] == '.') {-		WARN(1, ""name '.'\n"");+	if (WARN(qstr.len == 1 && fn[0] == '.', ""name '.'\n"")) 		return NULL;-	} 	if (qstr.len == 2 && fn[0] == '.' && fn[1] == '.') { 		WARN(1, ""name '..'\n""); 		return NULL;is neater, but the whole function should be thus converted and I'll letyou decide on that.",Technical
,
"Oh, I hate this style of WARN.For one thing it overlaps with comma operator.",Technical
,
"On 13 March 2018 at 13:53, Alexander Sverdlin<alexander.sverdlin@nokia.com> wrote:...This is slightly dodgy. You are assuming that sizeof(plt->lit) >=sizeof(fixed_plts), which may change depending on configuration orfuture changes.Could you add a BUILD_BUG_ON() here to ensure that this remains the case?Where is plt_ent ever used?Please move the if () check into prealloc_fixed(), and only keep the loop belowPlease use a normal for loop here and iterate upward starting at 0",Technical
,
"Hello Ard,                                                           ^^^^^^^^^^^ (*)Above is exactly the place it's used.I need to cache it because after the module load is finished the ELF header is freed,pltsec->plt pointer (*) is not valid any more.With the above modification it's possible to call the function during the whole lifetime of the module.I'll prepare v5 based on your other comments.--Best regards,Alexander Sverdlin.",Technical
,
"On 13 March 2018 at 17:13, Alexander Sverdlin<alexander.sverdlin@nokia.com> wrote:Right, ok. That's a problem.This means that you are relying on get_module_plt() being called atleast once at module load time, which is not guaranteed.Instead, you should set this member (and perhaps the entire preallocroutine) in a module_finalize() implementation.",Technical
,
"On 13 March 2018 at 17:32, Alexander Sverdlin<alexander.sverdlin@nokia.com> wrote:I think it would be much better to use the module_finalize() hook forthis, given that it is only called once already, and all the data youneed is still available.Note that ARM already has such a function, so you'll need to add acall there, i.e.,if (IS_ENABLED(CONFIG_ARM_MODULE_PLTS))    module_plt_alloc_fixed();or something like that. The CONFIG_FTRACE dependency can be kept localto module-plts.c",Technical
,
"Do you consider this a legal C code if without module-plts.o the function would not exist at all?That's too much relying on optimizer I think...--Best regards,Alexander Sverdlin.",Technical
,
"On 13 March 2018 at 17:49, Alexander Sverdlin<alexander.sverdlin@nokia.com> wrote:Yes, we rely on that in many different places in the kernel.",Technical
,
"Hi!https://www.kernel.org/doc/Documentation/process/coding-style.rst:""However, this approach still allows the C compiler to see the codeinside the block, and check it for correctness (syntax, types, symbolreferences, etc).  Thus, you still have to use an #ifdef if the code inside theblock references symbols that will not exist if the condition is not met.""But we can of course ignore it.--Best regards,Alexander Sverdlin.",Technical
,
"Hi!^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^(*)No problem, but some kind of (*) block would still be required, becauseget_module_plt() has to work after module_finalize() as well as *before* it.So before module_finalize() we would have to dereference pltsec->plt->sh_addr conditionally.--Best regards,Alexander Sverdlin.",Technical
,
"On 13 March 2018 at 18:24, Alexander Sverdlin<alexander.sverdlin@nokia.com> wrote:""will not exist"" is ambiguous here. It is rather common to declaresymbols, but only define them conditionally, and use IS_ENABLED() torefer to them. As the documentation says, this gets rid of #ifdefs,making the code always visible to the compiler which is a good thing.",Technical
,
"Hello Ard,now when I have a new implementation via module_finalize(), I must admit it's not possible todo it sanely this way.module_finalize() can only add entries at the end of PLT, which means, they will be differentfrom the entries module loader/relocator has created before, which means, FTRACE will notbe able to replace these entries with NOPs.As I don't want to do O(N) search on every dynamic ftrace operation, seems this is not anoption.Either v4 has to be accepted, or I cannot propose a solution for upstream FTRACE+MODULES_PLTcombination.--Best regards,Alexander Sverdlin.",Technical
,
"I'm trying to parse this but I'm not really sure.All I know is:	unsigned int size = ibuf[2];and that is really a 4-byte unsigned quantity so anything less is anarbitrary limitation.--Regards/Gruss,    Boris.Good mailing practices for 400: avoid top-posting and trim the reply.",Technical
,
"There is no limit on CPU equivalence table length in this patch serieslike it was in the previous version.The maximum possible value returned by install_equiv_cpu_table() ofUINT_MAX + CONTAINER_HDR_SZ comes from the maximum value of this 'size'variable (that is UINT_MAX) plus the header length of CONTAINER_HDR_SZ.This won't fit in 'int' type, hence this patch.That's because this functions tells its caller how much bytes to skipfrom the beginning of a microcode container file to the first patchsection contained in it.Maciej",Technical
,
"OK, will do then.Maciej",Technical
,
"Sure, it leaves the function to deal with the equiv table length onlyand the caller then adds the header length. Which is actually cleaner.--Regards/Gruss,    Boris.Good mailing practices for 400: avoid top-posting and trim the reply.",Technical
,
"This can be done if this function is modified to return only the CPUequivalence table length (without the container header length), leavingits single caller the job of adding the container header length to skipto the fist patch section.Otherwise we introduce a equivalence table length limit ofUINT_MAX - CONTAINER_HDR_SZ, as anything more will overflow anunsigned int variable on a 64-bit kernel (on 32-bit this will be caughtby the equivalence table truncation check).Maciej",Technical
,
So this one missed writel calls in:i40e:  i40e_program_fdir_filter  i40e_clean_rx_irq  i40e_tx_mapi40evf:  i40e_clean_rx_irq  i40e_tx_map,Technical
,
"thank you very much, I will resend my patch.BR.Ning.",Technical
,
Quoting Peter Zijlstra (2018-03-15 12:19:04)Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>-Chris,Technical
,
Acked-by: David Sterba <dsterba@suse.com>,Technical
,
"Hi Peter,Is this commit ready to hit tip/sched/core? I'm looking for animmutable branch that I can use as a basis for the ""dax vs dma vstruncate"" fix series.Thanks in advance.",Technical
,
"will do. thanks for the feedback.--Sinan KayaQualcomm Datacenter Technologies, Inc. as an affiliate of Qualcomm Technologies, Inc.Qualcomm Technologies, Inc. is a member of the Code Aurora Forum, a Linux Foundation Collaborative Project.",Technical
,
You can update the writel call in fm10k_tx_map as well.Of the drivers updated in drivers/net/ethernet/intel/* it looks likethis is the only one that still requires any additional changes.Thanks.- Alex,Technical
,
"Hi Arushi,On Wed, 21 Mar 2018 11:07:09 +0530, Arushi Singhal<arushisinghal19971997@gmail.com> wrote:I don't think this bring anything. However, if you want to fixsomething you should jump below on error to disable the clock insteadof returning 'ret' directly.Thanks,MiquÃ¨l--Miquel Raynal, Bootlin (formerly Free Electrons)Embedded Linux and Kernel engineeringhttps://bootlin.com",Technical
,
"I'm still not sure I understand the full extent of theoriginally-reported error (it's still likely a SPI transport issue?),but I believe this patch is good anyway:Reviewed-by: Brian Norris <briannorris@chromium.org>I wonder if we should tone down the BUG_ON()'s in drivers/mfd/cros_ec*and drivers/platform/chrome/* too. That's basically a no-no these days,as all of these type of things should be able to gracefully propagateerrors, no matter how ""unlikely"" it should be to see a crazy protocolversion number or a bad message length.",Technical
,
"Jon tracked down the root cause of the originally-reported error, butwe should still land this patch, as it fixes error signaling that waspreviously broken.",Technical
,
"Hi Shawn,Acked-by: Benson Leung <bleung@chromium.org>--Benson LeungStaff Software EngineerChrome OS KernelGoogle Inc.bleung@google.comChromium OS Projectbleung@chromium.org",Technical
,
"Hi Lee,Can you also queue this one as a fix for v4.15?CheersJon--nvpublic",Technical
,
"Applied, thanks.--Lee JonesLinaro STMicroelectronics Landing Team LeadLinaro.org â”‚ Open source software for ARM SoCsFollow Linaro: Facebook | Twitter | Blog",Technical
,
"Dear all,Cc'ing some more chromium folks.2017-11-29 13:11 GMT+01:00 Lee Jones <lee.jones@linaro.org>:This patch is a bit old and is already applied but I would like todiscuss an issue that Tomeu found playing with kernelci and a VeyronJaq attached to our lab.Seems that after this patch, the veyron jaq spits out lots of spitranfer error messages. See full log here [1] cros-ec-spi spi0.0: spi transfer failed: -121 cros-ec-spi spi0.0: Command xfer error (err:-121) cros-ec-i2c-tunnel ff110000.spi:ec@0:i2c-tunnel: Error transferringEC i2c message -121The issue is random, not always happens, but when happens makescros-ec unusable. Reproduce the issue is easier if CONFIG_SMP is notset.What happens is that the master starts the transmission and thecros-ec returns an spi error event (EC_SPI_RX_BAD_DATA  - data is0xfb). The difference between after and before the patch is that nowthe cros-ec does not recover, whereas without this patch after sometries it succeeds (note that before the patch the affected codereturned -EAGAIN whereas now returns -EREMOTEIO)I think that reverting this patch is NOT the solution, but I don'thave enough knowledge yet to understand why the cros-ec fails. I needto look at the cros-ec firmware to understand better what ishappening, but meanwhile, thoughts? clues?An important note is that I did not reproduce the issue on a VeyronMinnie, even with CONFIG_SMP disabled.[1] https://lava.collabora.co.uk/scheduler/job/1085493#L905Best regards,  Enric",Technical
,
"Hello EnricOn Mon, Mar 26, 2018 at 9:48 AM, Enric Balletbo Serra<eballetbo@gmail.com> wrote:Would it be possible for you to run ""ectool version"" on both yourmachines? Based on the code the EC is running we might have some hintson what the differences are.You can find both ectool and the code the ec runs onhttps://chromium.googlesource.com/chromiumos/platform/ec/+/firmware-veyron-6588.B.Though I would use ectool from the master branch.One thing I suspect is different is that veyron_minnie regularly pollsan accelerometer, depending on the userspace you're running it'spossible it unwedged itself with a few accelerometer requests.",Technical
,
"Hi Alexandru2018-03-26 19:26 GMT+02:00 Alexandru M Stan <amstan@chromium.org>:I think that accessing to the ec console should give the same result, right?In such case here is:Veyron Minnie ( ASUS Chromebook Flip C100PA )-------------------------------------------------------------------Chip:    stm stm32f07xBoard:   0RO:      minnie_v1.1.2697-faafaa5RW:      minnie_v1.1.2712-242f6bdBuild: minnie_v1.1.2712-242f6bd 2016-11-03 00:34:41 @build196-m2Veyron Jaq (  Haier Mighty MP )--------------------------------------------------------------------Chip:    stm stm32f07xBoard:   0RO:      mighty_v1.1.2680-6727e1dRW:      mighty_v1.1.2712-242f6bdBuild: mighty_v1.1.2680-6727e1d 2015-03-24 01:12:48 @build290-m2We're running the RW firmware and I just discovered that our jaq is amighty (but I guess it's the same?)Thanks,  Enric",Technical
,
"On Tue, Mar 27, 2018 at 3:49 AM, Enric Balletbo Serra<eballetbo@gmail.com> wrote:Yep, even better.Looks like your mighty is running the RO firmware, whereas your minnieruns RW. Is it possible you have the 0x200 bit in the gbb flags set onmighty? That would prevent the RO->RW transition, and give you anolder firmware.6727e1d..242f6bd is quite the change. I see some spi changes too,though i believe it's mostly at power state transitions(suspend/resume). Other changes include battery settings (yeah.. youshould really avoid running that RO if you can avoid it) and a ton ofaccelerometer stuff for minnie.If it's not the gbb flags, and we can't figure it out why you're stuckin RO, you can also use ""sysjump RW"" to force the RW copy on mighty.See if there's any behavior changes in what you care about.They're essentially the same, but they're running slightly differentfirmware. In practice the only difference is that mighty's firmwarereads an extra gpio for the battery presence.Feel free to diff the board/{jaq,mighty} ec folders for yourself formore details/assurances.All in all I'm not sure that the version differences are enough toexplain the spi errors you see in the kernel.My bet is back to the accelerometer stuff:Are you running chromeos ui on this device (is there a chromeos-chromeprocess constantly polling the accelerometer, so asking the cros-ecdriver for transfers)?Another thing to make sure accelerometer is disabled is to run""accelrate 0 0"" on the minnie EC.If none of that accelerometer stuff is enabled, minnie shouldessentially act like a mighty/jaq.",Technical
,
"Reviewed-by: Gilad Ben-Yossef <gilad@benyossef.com>--Gilad Ben-YossefChief Coffee Drinker""If you take a class in large-scale robotics, can you end up in asituation where the homework eats your dog?"" -- Jean-Baptiste Queru",Technical
,
"Reviewed-by: Gilad Ben-Yossef <gilad@benyossef.com>--Gilad Ben-YossefChief Coffee Drinker""If you take a class in large-scale robotics, can you end up in asituation where the homework eats your dog?"" -- Jean-Baptiste Queru",Technical
,
"On Sun, Mar 25 2018 at  2:41pm -0400,Yael Chemla <yael.chemla@foss.arm.com> wrote:This one had various issues.  I've fixed most of what I saw and stagedin linux-next (purely for build test coverage purposes).  I may dropthis patch if others disagree with it (or my sg deallocation in theerror path question isn't answered).I've staged the changes here (and in linux-next via 'for-next'):https://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm.git/log/?h=dm-4.17I switched all the new GFP_KERNEL uses to GFP_NOIO.  The fact thatyou're doing allocations at all (per IO) is bad enough.  UsingGFP_KERNEL is a serious liability (risk of deadlock if dm-verity were tobe used for something like.. swap.. weird setup but possible).But the gfp flags aside, the need for additional memory and theexpectation of scalable async parallel IO is potentially at odds withchanges like this (that I just staged, and had to rebase your 2 patchesontop of):https://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm.git/commit/?h=dm-4.17&id=a89f6a2cfec86fba7a115642ff082cb4e9450ea6So I'm particulalry interested to hear from google folks to understandif they are OK with your proposed verity async crypto API use.Mike",Technical
,
"Out of my curiosity, since I thought whether or not this should useGFP_NOIO during my reviewbut than answered to myself ""Nah, dm-verity is read only, can't swapto that"" - how does oneuse a read only DM-Verity to host swap partition/file? :-)If by ""scalable async parallel IO"" you mean crypto HW than for whatit's worth, my experience is that makers of devices with is lesspowerful CPUsare the ones that tend to add them, so they stands to benefit  themost of this change.Gilad--Gilad Ben-YossefChief Coffee Drinker""If you take a class in large-scale robotics, can you end up in asituation where the homework eats your dog?"" -- Jean-Baptiste Queru",Technical
,
"[+Cc linux-crypto]Hi Yael,Okay, I definitely would like to see dm-verity better support hardware cryptoaccelerators, but these patches were painful to read.There are lots of smaller bugs, but the high-level problem which you need toaddress first is that on every bio you are always allocating all the extramemory to hold a hash request and scatterlist for every data block.  This willnot only hurt performance when the hashing is done in software (I'm skepticalthat your performance numbers are representative of that case), but it will alsofall apart under memory pressure.  We are trying to get low-end Android devicesto start using dm-verity, and such devices often have only 1 GB or even only 512MB of RAM, so memory allocations are at increased risk of failing.  In fact I'mpretty sure you didn't do any proper stress testing of these patches, since thefirst thing they do for every bio is try to allocate a physically contiguousarray that is nearly as long as the full bio data itself (n_blocks *sizeof(struct dm_verity_req_data) = n_blocks * 3264, at least on a 64-bitplatform, mostly due to the 'struct dm_verity_fec_io'), so potentially up toabout 1 MB; that's going to fail a lot even on systems with gigabytes of RAM...(You also need to verify that your new code is compatible with the forward errorcorrection feature, with the ""ignore_zero_blocks"" option, and with the new""check_at_most_once"" option.  From my reading of the code, all of those seemedbroken; the dm_verity_fec_io structures, for example, weren't even beinginitialized...)I think you need to take a close look at how dm-crypt handles async cryptoimplementations, since it seems to do it properly without hurting the commoncase where the crypto happens synchronously.  What it does, is it reserves spacein the per-bio data for a single cipher request.  Then, *only* if the cipherimplementation actually processes the request asynchronously (as indicated by-EINPROGRESS being returned) is a new cipher request allocated dynamically,using a mempool (not kmalloc, which is prone to fail).  Note that unlike yourpatches it also properly handles the case where the hardware crypto queue isfull, as indicated by the cipher implementation returning -EBUSY; in that case,dm-crypt waits to start another request until there is space in the queue.I think it would be possible to adapt dm-crypt's solution to dm-verity.Thanks,Eric",Technical
,
"Mike and others,did anyone even try to run veritysetup tests?We have verity-compat-test in our testsuite, is has even basic FEC tests included.We just added userspace verification of FEC RS codes to compare if kernel behaves the same.I tried to apply three last dm-verity patches from your tree to Linus mainline.It does even pass the *first* line of the test script and blocks the kernel forever...(Running on 32bit Intel VM.)*NACK* to the last two dm-verity patches.(The ""validate hashes once"" is ok, despite I really do not like this approach...)And comments from Eric are very valid as well, I think all this need to be fixedbefore it can go to mainline.Thanks,Milan",Technical
,
"Hi Eric,Thanks for the detailed feedback, I'll have a look at how  dm-crypt avoid dynamic allocation per-bio, and also do forward error correction tests.Yael-----Original Message-----From: Eric Biggers <ebiggers3@gmail.com>Sent: Tuesday, 27 March 2018 9:55To: Yael Chemla <yael.chemla@foss.arm.com>Cc: Alasdair Kergon <agk@redhat.com>; Mike Snitzer <snitzer@redhat.com>; dm-devel@redhat.com; linux-kernel@vger.kernel.org; ofir.drang@gmail.com; Yael Chemla <yael.chemla@arm.com>; linux-crypto@vger.kernel.org; gilad@benyossef.comSubject: Re: [dm-devel] [PATCH 2/2] md: dm-verity: allow parallel processing of bio blocks[+Cc linux-crypto]Hi Yael,Okay, I definitely would like to see dm-verity better support hardware crypto accelerators, but these patches were painful to read.There are lots of smaller bugs, but the high-level problem which you need to address first is that on every bio you are always allocating all the extra memory to hold a hash request and scatterlist for every data block.  This will not only hurt performance when the hashing is done in software (I'm skeptical that your performance numbers are representative of that case), but it will also fall apart under memory pressure.  We are trying to get low-end Android devices to start using dm-verity, and such devices often have only 1 GB or even only 512 MB of RAM, so memory allocations are at increased risk of failing.  In fact I'm pretty sure you didn't do any proper stress testing of these patches, since the first thing they do for every bio is try to allocate a physically contiguous array that is nearly as long as the full bio data itself (n_blocks * sizeof(struct dm_verity_req_data) = n_blocks * 3264, at least on a 64-bit platform, mostly due to the 'struct dm_verity_fec_io'), so potentially up to about 1 MB; that's going to fail a lot even on systems with gigabytes of RAM...(You also need to verify that your new code is compatible with the forward error correction feature, with the ""ignore_zero_blocks"" option, and with the new ""check_at_most_once"" option.  From my reading of the code, all of those seemed broken; the dm_verity_fec_io structures, for example, weren't even beinginitialized...)I think you need to take a close look at how dm-crypt handles async crypto implementations, since it seems to do it properly without hurting the common case where the crypto happens synchronously.  What it does, is it reserves space in the per-bio data for a single cipher request.  Then, *only* if the cipher implementation actually processes the request asynchronously (as indicated by -EINPROGRESS being returned) is a new cipher request allocated dynamically, using a mempool (not kmalloc, which is prone to fail).  Note that unlike your patches it also properly handles the case where the hardware crypto queue is full, as indicated by the cipher implementation returning -EBUSY; in that case, dm-crypt waits to start another request until there is space in the queue.I think it would be possible to adapt dm-crypt's solution to dm-verity.Thanks,Eric",Technical
,
"Hi MikeI need to rewrite these patches according to issues you and Eric Biggers mentioned.please drop this v1 patch.Thank you,Yael-----Original Message-----From: Mike Snitzer <snitzer@redhat.com>Sent: Tuesday, 27 March 2018 4:07To: Yael Chemla <yael.chemla@foss.arm.com>Cc: Alasdair Kergon <agk@redhat.com>; dm-devel@redhat.com; linux-kernel@vger.kernel.org; ofir.drang@gmail.com; Yael Chemla <yael.chemla@arm.com>Subject: Re: [PATCH 2/2] md: dm-verity: allow parallel processing of bio blocksOn Sun, Mar 25 2018 at  2:41pm -0400,Yael Chemla <yael.chemla@foss.arm.com> wrote:This one had various issues.  I've fixed most of what I saw and staged in linux-next (purely for build test coverage purposes).  I may drop this patch if others disagree with it (or my sg deallocation in the error path question isn't answered).I've staged the changes here (and in linux-next via 'for-next'):https://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm.git/log/?h=dm-4.17I switched all the new GFP_KERNEL uses to GFP_NOIO.  The fact that you're doing allocations at all (per IO) is bad enough.  Using GFP_KERNEL is a serious liability (risk of deadlock if dm-verity were to be used for something like.. swap.. weird setup but possible).But the gfp flags aside, the need for additional memory and the expectation of scalable async parallel IO is potentially at odds with changes like this (that I just staged, and had to rebase your 2 patches ontop of):https://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm.git/commit/?h=dm-4.17&id=a89f6a2cfec86fba7a115642ff082cb4e9450ea6So I'm particulalry interested to hear from google folks to understand if they are OK with your proposed verity async crypto API use.Mike",Technical
,
"Hi Milan,I will run veritysetup test on next version of these patches and contact you about verity-compat-test testsuits.Thank you,Yael-----Original Message-----From: Milan Broz <gmazyland@gmail.com>Sent: Tuesday, 27 March 2018 11:05To: Eric Biggers <ebiggers3@gmail.com>; Yael Chemla <yael.chemla@foss.arm.com>; Mike Snitzer <snitzer@redhat.com>Cc: Alasdair Kergon <agk@redhat.com>; dm-devel@redhat.com; linux-kernel@vger.kernel.org; ofir.drang@gmail.com; Yael Chemla <yael.chemla@arm.com>; linux-crypto@vger.kernel.org; gilad@benyossef.comSubject: Re: [dm-devel] [PATCH 2/2] md: dm-verity: allow parallel processing of bio blocksMike and others,did anyone even try to run veritysetup tests?We have verity-compat-test in our testsuite, is has even basic FEC tests included.We just added userspace verification of FEC RS codes to compare if kernel behaves the same.I tried to apply three last dm-verity patches from your tree to Linus mainline.It does even pass the *first* line of the test script and blocks the kernel forever...(Running on 32bit Intel VM.)*NACK* to the last two dm-verity patches.(The ""validate hashes once"" is ok, despite I really do not like this approach...)And comments from Eric are very valid as well, I think all this need to be fixed before it can go to mainline.Thanks,Milan",Technical
,
"I have a question regarding scatterlist memory:I noticed that all blocks in dmverity end up using two buffers: one for data and other for salt.I'm using function similar to verity_for_io_block to iterate and find the number of buffers,in my case data_dev_block_bits =12, todo=4096, thus the do while will iterate only once.I assume that since it's there there are cases it'll iterate more.I'm trying to figure out which cases will require more than one buffer of data per block?In dm_crypt there is limitation of static 4 scatterlist elements per in/out (see struct dm_crypt_request).Is there an upper bound regarding number of buffers per block in dm-verity?I need this for the implementation of  mempool per scatterlist buffers.Thanks ,Yael",Technical
,
"Peter Z points out that this isn't sufficient...  Let me try again.regards,dan carpenter",Technical
,
"Hi Jae,That's a hefty cc list. I can't see Rob Herring though, and he'susually the person who you need to convince to get your bindingsaccepted.I recommend using ./scripts/get_maintainers.pl to build your CC list,and then add others you think are relevant.I'm not sure what the guidelines are for generic bindings, so I'lldefer to Rob for this patch.Cheers,Joel",Technical
,
"We try to capitalise ASPEED.Are you sure that this is driven by clkin? Most peripherals on theAspeed are attached to the apb, so should reference that clock.Can you explain why you need both the parent clock and this frequencyto be specified?Perhaps msg-timing-period? Or just msg-timing?",Technical
,
"The patches to the device trees get merged by the ASPEED maintainer(me). Once you have the bindings reviewed you can send the patches tome and the linux-aspeed list (I've got a pending patch to maintainersthat will ensure get_maintainers.pl does the right thing as far asemail addresses go).I'd suggest dropping it from your series and re-sending once thebindings and driver are reviewed.Cheers,Joel",Technical
,
"Hi Guenter,Thanks a lot for sharing your time. Please see my inline answers.No it isn't. Will drop the line.Okay. I'll use bool instead of int.The two above functions are slightly different but uses the same PECIcommand which provides both Tthrottle and Tcontrol values in pkg_configarray so it updates the values to reduce duplicate PECI transactions.Probably, combining these two functions into get_ttrottle_and_tcontrol()would look better. I'll rewrite it.Are you pointing out this code?/**  * Processors return a value of the core DTS reading in 10.6 format  * (10 bits signed decimal, 6 bits fractional).  * Error codes:  *   0x8000: General sensor error  *   0x8001: Reserved  *   0x8002: Underflow on reading value  *   0x8003-0x81ff: Reserved  */if (core_dts_margin >= 0x8000 && core_dts_margin <= 0x81ff)	return -EIO;Then I'll rewrite it as a function. If not, please point out theduplication.Core temperature group will be registered only when it detects at leastone core checked by check_resolved_cores(), so find_core_index() can becalled only when priv->core_mask has a non-zero value. The 'nothing isfound' case will not happen.cputemp_read_string() is mapped to read_string member of hwmon_opsstruct, so hwmon susbsystem passes the channel parameter based on theregistered channel order. Should I modify hwmon subsystem code?As explained above, find_core index() returns a correct index always.This is an attribute of DTS margin temperature which reflects thermalmargin to Tcontrol of the CPU package. If it shows '0' means it reachedto Tcontrol, the first level of thermal warning. If the CPU keepsgetting hot then this DTS margin shows a negative value until it reachesto Tjmax. When the temperature reaches to Tjmax at last then it showsthe lower critcal value which lcrit indicates as the second level ofthermal warning.Both Tjmax and Tcontrol have positive values and Tjmax is greater thanTcontrol always. As explained above, lcrit of DTS margin should show anegative value means the margin goes down across '0'. On the other hand,crit_hyst of Die temperature should show absolute hyterisis valuebetween Tcontrol and Tjmax.This driver provides multiple channels and each channel has its ownsupplement attributes. As you mentioned, Die temperature channel andCore temperature channel have their individual crit attributes and theyreflect the same value, Tjmax. It is not reporting several times butreporting the same value.Each function is called from cputemp_read() which is mapped to readfunction pointer of hwmon_ops struct. Since each channel has differentset of attributes so the cputemp_read() calls an individual channelhandler after checking the channel type. Of course, we can handle allattributes of all channels in a single function but the way also needschannel type checking code on each attribute.Sure, will use defines instead.For proper operation of this driver, PECI_CMD_GET_TEMP andPECI_CMD_RD_PKG_CFG have to be supported by a client CPU.PECI_CMD_GET_TEMP is provided as a default command butPECI_CMD_RD_PKG_CFG depends on PECI minor revision of a CPU package sothis checking is needed.Got it. I'll remove the error message and will add a proper handlingcode into PECI core.This driver can't support core temperature monitoring if a CPU doesn'tsupport PECI_CMD_RD_PCI_CFG_LOCAL command. In that case, it skips coretemperature group creation and supports only basic temperaturemonitoring of Die, DTS margin and etc. I'll add this description as acomment.Should I split out hwmon documents and dt bindings too?No. Will drop the line.It is temperature monitoring specific function and it touches modulespecific variables. Do you really think that this non-generic functionshould be moved to PECI core?find_dimm_number()? I'm sure it isn't.Sure, I'll rewrite it.Okay. In case of check_cpu_id(), it could be used as a generic PECIfunction. I'll move it into PECI core.'&' has a precedence over '!=' but '|' doesn't. I'll rewrite it to:	if (client->adapter->cmd_mask &	    (BIT(PECI_CMD_GET_TEMP) | BIT(PECI_CMD_RD_PKG_CFG)) !=	    (BIT(PECI_CMD_GET_TEMP) | BIT(PECI_CMD_RD_PKG_CFG)))Should I use -EPERM? Any suggestion?Client address range validation will be done inpeci_check_addr_validity() in PECI core before probing a device driver.I'll remove the error message and will add a proper handling code intoPECI core on each error type.Yes, it would be safer. Will fix it.",Technical
,
"There is lots of other duplication.That doesn't guarantee a match. If what you are saying is correct there should always bea well defined match of channel -> idx, and the search should be unnecessary.Huh ? Changing	f(x) { y = x - const; }...	f(x);to	f(y) { }...	f(x - const);requires a hwmon core change ? Really ?The hwmon ABI reports chip values, not constants. Even though some drivers doit, reporting a constant is always wrong.The hwmon ABI requires reporting of absolute temperatures in milli-degrees C.Your statements make it very clear that this driver does not reportabsolute temperatures. This is not acceptable.Then maybe fold the functions accordingly ?I do not question the check. I question the error message and error return value.Why is it an _error_ if the CPU does not support the functionality, and why doesit have to be reported in the kernel log ?The message says ""Failed to ..."". It does not say ""This CPU does not support ..."".Why does this message display the device name twice ?Actually, that is wrong. You refer to address-of. Bit operations do have lowerprecedence that comparisons. I stand corrected.Is it an _error_ if the CPU does not support this functionality ?",Technical
,
"Hello Joel,Thanks for sharing your time. Please see my answers inline.Yes, it took a hidden review process between v2 and v3. I know it's anunusual process but it was requested. Hopefully, change logs in coverletter could roughly provide the details. Thanks for your comments.Agreed. I'll change the description.Okay then, better change it now than later. Will change all defines.It doesn't use all but better keep for bug fix or improvement use, I think.Yes, that would be better. I'll rewrite it.Yes, it could be simplified like you pointed out. Will change it.Got it. I'll replace it with print_hex_dump_debug() after removing thedefine.Intention was that make it run just amount up to the rx_len but it's notefficient. I'll rewrite it like you suggested.No specific reason. regmap makes some overhead as you mentioned but italso provides some advantages on access simplification, endiannesshandling and register dump at run time. I'd not insist using of regmapif you prefer using of raw readl and writel. Do you?You are right. I'll keep this checking only in _probe() function andremove all redundant error checking codes on memory mapped IO.This code makes changes on the status_ack variable to write back ack biton each interrupt.Unlike other HW module, PECI uses the 24MHz external clock as its clocksource. Should it use clk-aspeed.c in this case?Agreed. I'll make it print out the message only when ret == 0 andmsg_timing_nego > PECI_MSG_TIMING_NEGO_MAX.I'll test it again and will remove it if it is not necessary.You are right. I'll remove the flag.",Technical
,
"Hi Joel,Got it. Will capitalize all Aspeed words.According to the datasheet, PECI controller module is attached to apbbut its clock source is the 24MHz external clock.Based on this setting, driver code makes clock divisor value to setoperation clock of PECI controller which is adjustable.Will use msg-timing instead.",Technical
,
"Do you mean that bindings and driver of ASPEED peci adapter driverincluding documents?Thanks,-Jae",Technical
,
"Sorry but can you point out the duplication?There could be some disabled cores in the resolved core mask bitsequence also it should remove indexing gap in channel numbering so itis the reason why this search function is needed. Well defined match ofchannel -> idx would not be always satisfied.Sorry for my misunderstanding. You are right. I'll change the parameterpassing of find_core_index() from 'channel' to 'channel -DEFAULT_CHANNEL_NUMS'.Okay. I'll remove the 'DTS margin' temperature. All others are reportingabsolute temperatures.I'll use a single function for 'Die temperature' and 'Core temperature'that have the same attributes set. It would simplify this code a bit.Got it. I'll change that to dev_dbg.Got it. Will correct the message.For an example, dev_name(hwmon_dev) shows 'hwmon5' and priv->name shows'peci-cputemp0'.Actually, it returns from this probe() function without making any hwmoninfo creation so I intended to handle this case as an error. Am I wrong?",Technical
,
"write a python script to do a semantic comparison.Are you saying that each call to the function, with the same parameters,can return a different result ?And dev_dbg() shows another device name. So you'll have something likepeci-cputemp0: hwmon5: sensor 'peci-cputemp0'If the functionality or HW supported by the driver isn't available, it is customaryto return -ENODEV and no error message. Otherwise the kernel log would drown in""not supported"" error messages. I don't see where it would add any value to handlethis driver differently.EINVAL	Invalid argumentEPERM	Operation not permittedYou'll have to work hard to convince me that any of those makes sense, and thatENODEV	No such devicedoesn't. More specifically, if EINVAL makes sense, the caller did something wrong,meaning there is a problem in the infrastructure which should get fixed.The same is true for EPERM.",Technical
,
"Okay. I'll try to simplify this code again.No, the result will be consistent. After reading the priv->core_maskonce in check_resolved_cores(), the value will not be changed. I'msaying about this case, for example if core number 2 is unresolved intotal 4 cores, then the idx order will be '0, 1, 3' but channel orderwill be '5, 6, 7' without making any indexing gap.Practically it shows likepeci-cputemp 0-30:00: hwmon10: sensor 'peci_cputemp.cpu0'where 0-30:00 is assigned by peci core.Now I fully understood what you pointed out. Thanks for the detailedexplanation. I'll change the error return value to -ENODEV and will usedev_dbg for the message printing. Thanks!",Technical
,
"[ ... ]And you yet you claim that this is not well defined ? Or are you concernedabout the amount of memory consumed by providing an array for the mapping ?Note that an indexing gap is acceptable and, in many cases, preferred.[ ... ]And what message would you see for cpu1 ?",Technical
,
"""dt-bindings: ..."" for the subject prefix please.This should be all one document.No need for these 2 here.Some details on the addressing for PECI would be good.This part of the example is not relevant. Just start with the adapternode.I don't understand what this has to do with PECI? ""simple-bus"" alreadyhas a defined meaning.Bindings are for h/w, not client drivers.How are PECI devices defined?8 devices should be enough for anyone...Where is PECI_OFFSET_MAX defined?Not a valid node name. ""function@30"" is what it probably should be. Fora new bus you can define unit-address format you like, but it must bebased on the contents of reg. However, it doesn't look like you shouldcreate anything special here.",Technical
,
"This is the frequency of the bus or used to derive it? It would bebetter to specify the bus frequency instead and have the drivercalculate its internal freq. And then use ""bus-frequency"" instead.s/_/-/All these either need vendor prefixes or should be standard propertiesfor PECI adapters. I think probably the latter case. If so, the first2 should probably be in units of clocks (not 4 clocks). And they shouldthen be documented in the common PECI binding doc.No need to show this part in examples.",Technical
,
"""dt-bindings: hwmon: ..."" for the subject.Again, where is PECI_OFFSET_MAX defined? It can't depend on something inthe kernel.unit-address is wrong.It is a different bus from cputemp? Otherwise, you have conflictingaddresses. If that's the case, probably should make it clear by showingdifferent host adapters for each example.",Technical
,
"Hi Rob,Thanks for sharing your time. Please see my answers inline.Sure, I'll change the subject.Okay. I'll combine them into one document.Will drop these 2.It is for the PECI client address. Will add details.Will remove that part. Thanks!Maybe I'm wrong but I intended to show this node is an umbrella node ofa PECI bus subsystem. What should I use then?Got it. I'll correct the description. PECI client device is Intel CPUwhich is connected through a PECI bus.PECI_OFFSET_MAX is defined in include/linux/peci.h based on the maximumCPU numbers of the current IA generation. I'll remove the unnecessarydetails. A setting out of range would be handled accordingly in kernel.Got it. I'll fix these node name like function@30 and function@31.Thanks a lot for your comments!-Jae",Technical
,
"I agree with you. Actually, it is being used for operation frequencysetting of PECI controller module in SoC so it's different from themeaning of ""bus-frequency"". I'll change it to ""operation-frequency"".Will fix it.So far I've checked that these are ASPEED PECI controller specificproperties so it should be listed in here.Got it. Will drop the part.",Technical
,
"I'll change the subject.I'll remove the unnecessary description.Will fix it using the reg value.It could be the same bus with cputemp. Also, client address sharing ispossible by PECI core if the functionality is different. I mean, cputempand dimmtemp targeting the same client is possible case like this.peci-cputemp@30peci-dimmtemp@30",Technical
,
"Oh, I got your point. Probably, I should change these separate settingsinto one likepeci-client@30 {     compatible = ""intel,peci-client"";     reg = <0x30>;};Then cputemp and dimmtemp drivers could refer the same compatiblestring. Will rewrite it.",Technical
,
"On Mon, Apr 16, 2018 at 6:12 PM, Jae Hyun Yoo<jae.hyun.yoo@linux.intel.com> wrote:[...]No, now you've gone from a standard property name to something custom.Why do you need to set the frequency in DT if it is not related to theinterface frequency?Rob",Technical
,
"Just a drive-by nit:[...]FWIW, <linux/bitfield.h> already provides functionality like this, so itmight be worth taking a look at FIELD_{GET,PREP}() to save all theselocal definitions.Robin.",Technical
,
"Actually, the interface frequency is affected by the operation frequencybut there is no description of its relationship in datasheet. I'll checkagain about the detail to ASPEED chip vendor and will use'bus-frequency' if available.Thanks,Jae",Technical
,
"Hi Robin,Yes, that looks better. Thanks a lot for your pointing it out.Jae",Technical
,
"[...]I've checked it again and realized that it should use function basednode name like:peci-cputemp@30peci-dimmtemp@30If it use the same string like 'peci-client@30', the drivers cannot beselectively enabled. The client address sharing way is well handled inPECI core and this way would be better for the future implementations ofother PECI functional drivers such as crash dump driver and so on. SoI'm going change the unit-address only.Thanks,Jae",Technical
,
"I investigated it more deeply. Basically, by the spec, PECI bus speedcannot be set as a fixed speed. A PECI bus can have a wide speed rangefrom 2Kbps to 2Mbps which is dynamically set by a handshaking sequencebetween an originator and clients called 'timing negotiation' in spec.This timing negotiation behavior happens on every single transaction sothe bus speed also can vary on every transactions. So I'm thinking acustom property name for it, 'peci-clk-frequency' if it is acceptable.Thanks,Jae",Technical
,
"On Tue, Apr 17, 2018 at 5:06 PM, Jae Hyun Yoo<jae.hyun.yoo@linux.intel.com> wrote:Okay, seems bus-frequency is not appropriate here. So use'clock-frequency' (note the '-' not '_' as that is the standardproperty).Rob",Technical
,
"On Tue, Apr 17, 2018 at 3:40 PM, Jae Hyun Yoo<jae.hyun.yoo@linux.intel.com> wrote:2 nodes at the same address is wrong (and soon dtc will warn you onthis). You have 2 potential options. The first is you need additionaladdress information in the DT if these are in fact 2 independentdevices. This could be something like a function number to usesomething from PCI addressing. From what I found on PECI, it doesn'tseem to have anything like that. The 2nd option is you have a singleDT node which registers multiple hwmon devices. DT nodes and driversdon't have to be 1-1. Don't design your DT nodes from how you want topartition drivers in some OS.Rob",Technical
,
Thanks! I'll use 'clock-frequency' for it.Jae,Technical
,
"Please correct me if I'm wrong but I'm still thinking that it ispossible. Also, I did compile it but dtc doesn't make a warning. Let meshow an another use case which is similar to this case:In arch/arm/boot/dts/aspeed-g5.dtsi[...]lpc_host: lpc-host@80 {         compatible = ""aspeed,ast2500-lpc-host"", ""simple-mfd"", ""syscon"";         reg = <0x80 0x1e0>;         reg-io-width = <4>;         #address-cells = <1>;         #size-cells = <1>;         ranges = <0x0 0x80 0x1e0>;         lpc_ctrl: lpc-ctrl@0 {                 compatible = ""aspeed,ast2500-lpc-ctrl"";                 reg = <0x0 0x80>;                 clocks = <&syscon ASPEED_CLK_GATE_LCLK>;                 status = ""disabled"";         };         lpc_snoop: lpc-snoop@0 {                 compatible = ""aspeed,ast2500-lpc-snoop"";                 reg = <0x0 0x80>;                 interrupts = <8>;                 status = ""disabled"";         };}[...]This is device tree setting for LPC interface and its child nodes.LPC interface can be used as a multi-functional interface such assnoop 80, KCS, SIO and so on. In this use case, lpc-ctrl@0 andlpc-snoop@0 are sharing their address range from their individualdriver modules and they can be registered quite well through bothstatic dt or dynamic dtoverlay. PECI is also a multi-functionalinterface which is similar to the above case, I think.Thanks,Jae",Technical
,
"On Wed, Apr 18, 2018 at 3:28 PM, Jae Hyun Yoo<jae.hyun.yoo@linux.intel.com> wrote:I did say *soon*. It's in dtc repo, but not the kernel copy yet.This case too is poor design and should be fixed as well. Simply put,you can have 2 devices on a bus at the same address without some sortof mux or arbitration device in the middle. If you have a device/blockwith multiple functions provided to the OS, then it is the OS'sproblem to arbitrate access. It is not a DT problem because OS's canvary in how they handle that both from OS to OS and over time.Rob",Technical
,
"If I change it to a single DT node which registers 2 hwmon devices usingthe 2nd option above, then I still have 2 devices on a bus at the sameaddress. Does it also make a problem to the OS then?Jae",Technical
,
"Hi Jae,Thank you for the patch! Yet something to improve:[auto build test ERROR on linus/master][also build test ERROR on v4.17-rc1 next-20180419][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Jae-Hyun-Yoo/PECI-device-driver-introduction/20180411-180018config: x86_64-randconfig-s0-04192349 (attached as .config)compiler: gcc-6 (Debian 6.4.0-9) 6.4.0 20171026reproduce:        # save the attached .config to linux build tree        make ARCH=x86_64All errors (new ones prefixed by >>):   drivers//peci/peci-core.c: In function 'peci_device_match':     if (peci_of_match_device(drv->of_match_table, client))         ^~~~~~~~~~~~~~~~~~~~   At top level:   drivers//peci/peci-core.c:840:28: warning: 'peci_new_device' defined but not used [-Wunused-function]    static struct peci_client *peci_new_device(struct peci_adapter *adapter,                               ^~~~~~~~~~~~~~~   drivers//peci/peci-core.c:135:29: warning: 'peci_verify_adapter' defined but not used [-Wunused-function]    static struct peci_adapter *peci_verify_adapter(struct device *dev)                                ^~~~~~~~~~~~~~~~~~~   cc1: some warnings being treated as errorsvim +/peci_of_match_device +739 drivers//peci/peci-core.c   732   733	static int peci_device_match(struct device *dev, struct device_driver *drv)   734	{   735		struct peci_client *client = peci_verify_client(dev);   736		struct peci_driver *driver;   737   738		/* Attempt an OF style match */ > 739		if (peci_of_match_device(drv->of_match_table, client))   740			return 1;   741   742		driver = to_peci_driver(drv);   743   744		if (peci_match_id(driver->id_table, client))   745			return 1;   746   747		return 0;   748	}   749---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
"Additionally, I need to explain that there is one and only bus host(adapter) and multiple clients on a PECI bus, and PECI spec doesn'tallow multiple originators so only the host device can originatemessage. In this implementation, all message transactions on a bus fromclient driver modules and user space will be serialized well in the PECIcore bus driver so bus occupation and traffic arbitration will bemanaged well in the PECI core bus driver even in case of a bus has 2client drivers at the same address. I'm sure that this implementationdoesn't make that kind of problem to OS.Jae",Technical
,
"Hi Greg,Thanks a lot for your review.I think, it should contain actual device resource release code which isbeing done by peci_del_adapter(), or a coupling logic should be addedbetween peci_adapter_dev_release() and peci_del_adapter().As you suggested, I'll check it again after reading documentation andunderstanding core.c code more deeply.Jae",Technical
,
"Does it make sense one driver per patch?Are we talking about x86 CPU IDs here?If so, why x86 corresponding headers, including intel-family.h are notused?--Andy Shevchenko <andriy.shevchenko@linux.intel.com>Intel Finland Oy",Technical
,
"All comments you got for patch 6 are applicable here.And perhaps in the rest of the series.The rule of thumb: when you get even single comment in a certain place,re-check _entire_ series for the same / similar patterns!--Andy Shevchenko <andriy.shevchenko@linux.intel.com>Intel Finland Oy",Technical
,
"Hi Andy,Thanks a lot for your review. Please check my inline answers.Yes, I'll separate it into two patches.Yes, that would make more sense. I'll include the intel-family.h andwill use these defines instead:INTEL_FAM6_HASWELL_XINTEL_FAM6_BROADWELL_XINTEL_FAM6_SKYLAKE_XThanks,Jae",Technical
,
Thanks for your advice. I'll keep that in mind.Jae,Technical
,
"Hi Joel,Thanks a lot for letting me know that. I'll do as you suggested.-Jae",Technical
,
"If the indexing gap is acceptable, the index search function isn'tneeded anymore. I'll fix all relating code to make that use directmapping of channel -> idx then. Thanks!It shows likepeci-cputemp 0-31:00: hwmon10: sensor 'peci_cputemp.cpu1'",Technical
,
"Hello,so I finally got to this :)I know some people (Matthew Wilcox?) wanted to do something like KSM forfile pages - not all virtualization schemes use overlayfs and e.g. if youuse reflinks (essentially shared on-disk extents among files) for yourcontainer setup, you could save significant amounts of memory with theability to share pages in page cache among files that are reflinked.It is interesting that you can get rid of page->mapping uses in mostplaces. For page reclaim (vmscan) you'll still need a way to get from apage to an address_space so that you can reclaim the page so you can hardlyget rid of page->mapping completely but you're right that with such limiteduse that transition could be more complex / expensive.What I wonder though is what is the cost of this (in the terms of code sizeand speed) - propagating the mapping down the stack costs something... Alsoin terms of maintainability, code readability suffers a bit.This could be helped though. In some cases it seems we just use the mappingbecause it was easily available but could get away without it. In othercase (e.g. lot of fs/buffer.c) we could make bh -> mapping transition easyby storing the mapping in the struct buffer_head - possibly it couldreplace b_bdev pointer as we could get to that from the mapping with a bitof magic and pointer chasing and accessing b_bdev is not very performancecritical. OTOH such optimizations make a rather complex patches from mostlymechanical replacement so I can see why you didn't go that route.Overall I think you'd need to make a good benchmarking comparison showinghow much this helps some real workloads (your motivation) and also howother loads on lower end machines are affected.So I'm interested in this write protection mechanism but I didn't find muchabout it in the series. How does it work? I can see KSM writeprotects pagesin page tables so that works for userspace mappings but what aboutin-kernel users modifying pages - e.g. pages in page cache carryingfilesystem metadata do get modified a lot like this.AFAIK you're right.Auch, the fact that we could share a page as data storage for severalinode+offset combinations that are not sharing underlying storage justlooks viciously twisted ;) But is it really that useful to warrantcomplications? In particular I'm afraid that filesystems expect consistencybetween their internal state (attached to page->private) and page state(e.g. page->flags) and when there are multiple internal states attached tothe same page this could go easily wrong...								Honza--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"[...]Yes i believe they are still use case where KSM with file back page makesenses, i am just not familiar enough with those workload to know how bigof a deal this is.Idea for vmscan is that you either have regular mapping pointer store inpage->mapping or you have a pointer to special struct which has a functionpointer to a reclaim/walker function (rmap_walk_ksm)I haven't checked that, i will, i was not so concern because in the vastmajority of places there is already struct address_space on the stackframe (ie local variable in function being call) so moving it to functionargument shouldn't impact that. However as i expect this will be mergeover multiple kernel release cycle and the intermediary step will see anincrease in stack size. The code size should only grow marginaly i expect.I will provide numbers with my next posting after LSF/MM.I am willing to do the buffer_head change, i remember considering it buti don't remember why not doing it (i failed to take note of that).Do you have any specific benchmark you would like to see ? My list was:  https://github.com/01org/lkp-tests  https://github.com/gormanm/mmtests  https://github.com/akopytov/sysbench/  http://git.infradead.org/users/dhowells/unionmount-testsuite.gitFor workload i care this will be CUDA workload. We are still working onthe OpenCL open source stack but i don't expect we will have sometingthat can shows the same performance improvement with OpenCL as soon aswith CUDA.So i only care about page which are mmaped into a process address space.At first i only want to intercept CPU write access through mmap of filebut i also intend to extend write syscall to also ""fault"" on the writeprotection ie it will call a callback to unprotect the page allowing thewrite protector to take proper action while write syscall is happening.I am affraid truely generic write protection for metadata pages is bitout of scope of what i am doing. However the mechanism i am proposingcan be extended for that too. Issue is that all place that want to writeto those page need to be converted to something where write happensbetween write_begin and write_end section (mmap and CPU pte does givethis implicitly through page fault, so does write syscall). Basiclythere is a need to make sure that write and write protection can beordered against one another without complex locking.So at first i want to limit to write protect (not KSM) thus page->flagswill stay consistent (ie page is only ever associated with a singlemapping). For KSM yes the page->flags can be problematic, however herewe can assume that page is clean (and uptodate) and not under writeback. So problematic flags for KSM:  - private (page_has_buffers() or PagePrivate (nfs, metadata, ...))  - private_2 (FsCache)  - mappedtodisk  - swapcache  - errorIdea again would be to PageFlagsWithMapping(page, mapping) so that fornon KSM write protected page you test the usual page->flags and forwrite protected page you find the flag value using mapping as lookupindex. Usualy those flag are seldomly changed/accessed. Again theoverhead (ignoring code size) would only be for page which are KSM.So maybe KSM will not make sense because perf overhead it has withpage->flags access (i don't think so but i haven't tested this).Thank you for taking time to read over all this.Cheers,Jrme",Technical
,
"Imagine container farms where they deploy the base os image via cp --reflink.This would be a huge win for btrfs/xfs but we've all been too terrifiedof the memory manager to try it. :)For those following at home, we had a track at LSFMM2017 (and hallwaybofs about this in previous years):https://lwn.net/Articles/717950//me starts to look at this big series, having sent his own yesterday. :)--D",Technical
,
"So e.g. mmtests have a *lot* of different tests so it's probably notrealistic for you to run them all. I'd look at bonnie++ (file & dir tests),dbench, reaim - these are crappy IO benchmarks because they mostly fit intopage cache but for your purposes this is exactly what you want to seedifferences in CPU overhead :).I understand metadata pages are not interesting for your use case. Howeverfrom mm point of view these are page cache pages as any other. So maybe myquestion should have been: How do we make sure this mechanism will not beused for pages for which it cannot work?Yeah, sure, page->flags could be dealt with in a similar way but at thispoint I don't think it's worth it. And without page->flags I don't thinkabstracting page->private makes much sense - or am I missing something whyyou need page->private depend on the mapping? So what I wanted to suggestis that we leave page->private as is currently and just concentrate onpage->mapping hacks...								Honza--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"[...]Oh that one is easy, the API take vma + addr or rather mm struct + addr(ie like KSM today kind of). I will change wording in v1 to almostgeneric write protection :) or process' page write protection (but thiswould not work for special pfn/vma so not generic their either).Well i wanted to go up to KSM or at least as close as possible to KSMfor file back page. But i can focus on page->mapping first, do writeprotection with that and also do the per page wait queue for page lock.Which i believe are both nice features. This will also make the patchsetsmaller and easier to review (less scary).KSM can be done on top of that latter and i will be happy to help. Ihave a bunch of coccinelle patches for page->private, page->index andi can do some for page->flags.Cheers,Jrme",Technical
,
"Your approach seems useful if there are lots of locked pages sharingthe same wait queue.That said, in the original workload from our customer with the long wait queueproblem, there was a single super hot page getting migrated, and itis being accessed by all threads which caused the big log jam while they wait forthe migration to get completed.With your approach, we will still likely end up with a long queuein that workload even if we have per page wait queue.Thanks.Tim",Technical
,
"Ok so i re-read the thread, i was writting this cover letter from memoryand i had bad recollection of your issue, so sorry.First, do you have a way to reproduce the issue ? Something easy wouldbe nice :)So what i am proposing for per page wait queue would only marginaly helpyou (it might not even be mesurable in your workload). It would certainlymake the code smaller and easier to understand i believe.Now that i have look back at your issue i think there is 2 things weshould do. First keep migration page map read only, this would at leastavoid CPU read fault. In trace you captured i wasn't able to ascertainif this were read or write fault.Second idea i have is about NUMA, everytime we NUMA migrate a page wecould attach a temporary struct to the page (using page->mapping). Soif we scan that page again we can inspect information about previousmigration and see if we are not over migrating that page (ie bouncingit all over). If so we can mark the page (maybe with a page flag if wecan find one) to protect it from further migration. That temporarystruct would be remove after a while, ie autonuma would preallocate abunch of those and keep an LRU of them and recycle the oldest when itneeds a new one to migrate another page.LSF/MM slots:Michal can i get 2 slots to talk about this ? MM only discussion, oneto talk about doing migration with page map read only but writeprotected while migration is happening. The other one to talk aboutattaching auto NUMA tracking struct to page.Cheers,Jrme",Technical
,
"Unfortunately it is a customer workload that they guard closely and wouldn't let uslook at the source code.  We have to profile and backtrace its behavior.Mel made a quick attempt to reproduce the behavior with a hot page migration,but he wasn't quite able to duplicate the pathologic behavior.In certain cases if we have lots of pages sharing a page wait queue,your solution would help, and we wouldn't be wasting time checkingwaiters not waiting on the page that's being unlocked.  Though Idon't have a specific workload that has such behavior.The goal to migrate a hot page with care, or avoid bouncing it aroundfrequently makes sense.  If it is a hot page shared by many threadsrunning on different NUMA nodes, and moving it will only mildly improve NUMAlocality, we should avoid the migration.Tim",Technical
,
"Sorry about that, I actually had three people review my code internally,then I managed to send out an old version. 100% guilty of submittingcode when I needed sleep. As for the change, that was in responseto a request from Andrew to make the update function less racy.Should I resend a correct v2 now that the thread exists?â€”Buddy",Technical
,
"Let's just discuss open questions for now. Specifics of the code are theleast interesting at this stage.If you want some help with the code review, you can put it somewhere inthe git tree and send a reference for those who are interested.--Michal HockoSUSE Labs",Technical
,
"Ok, I will go back through the thread and make sure all questions andconcerns have been addressed.",Technical
,
"Thanks, MatthewOn 4/5/2018 7:23 PM, Matthew Wilcox Wrote:okHow about include/asm-generic/early_pfn.h ?And could I use CONFIG_HAVE_ARCH_PFN_VALID and CONFIG_HAVE_MEMBLOCKinthis case?Currently, arm/arm64 have memblock enable by default. When other archesimplementtheir HAVE_MEMBLOCK and HAVE_ARCH_PFN_VALID, they can include this file?--Cheers,Jia",Technical
,
"On 4/5/2018 7:34 PM, Matthew Wilcox Wrote:Thanks, thus the binary search in next step can be discarded?--Cheers,Jia",Technical
,
I don't know all the circumstances in which this is called.  Maybe a linearsearch with memo is more appropriate than a binary search.,Technical
,
"That's been brought up before, and the reasoning appears to besomething along the lines of...Academics and published wisdom is that on cached architectures, binarysearches are bad because it doesn't operate efficiently due to theoverhead from having to load cache lines.  Consequently, there seemsto be a knee-jerk reaction that ""all binary searches are bad, we musteliminate them.""What is failed to be grasped here, though, is that it is typical thatthe number of entries in this array tend to be small, so the entirearray takes up one or two cache lines, maybe a maximum of four linesdepending on your cache line length and number of entries.This means that the binary search expense is reduced, and is lowerthan a linear search for the majority of cases.What is key here as far as performance is concerned is whether thegeneral usage of pfn_valid() by the kernel is optimal.  We shouldnot optimise only for the boot case, which means evaluating theeffect of these changes with _real_ workloads, not just ""does mymachine boot a milliseconds faster"".--RMK's Patch system: http://www.armlinux.org.uk/developer/patches/FTTC broadband for 0.8mile line in suburbia: sync at 8.8Mbps down 630kbps upAccording to speedtest.net: 8.21Mbps down 510kbps up",Technical
,
"On Fri, Apr 6, 2018 at 11:09 AM, Russell King - ARM Linux<linux@armlinux.org.uk> wrote:This is actually a good point.a) This does not make sense. At least in general case.b) It is not the case here. Here it's really mostly called withsequentially incremented pfns, AFAICT.In this case it hits mostly the last result or eventually thesequentially next one.IIUC, this is only used during early boot (and memory hotplug) and itdoes not influence regular runtime. Whether the general usage ofpfn_valid() by the kernel is optimal is another good question, butthat's totally unrelated to this series, IMHO.On the other hand I also wonder if this all really is worth thenegligible boot time speedup.--nX",Technical
,
"Thanks for your comments, RussellOn 4/6/2018 5:09 PM, Russell King - ARM Linux Wrote:IIUC, are you opposed to entirely removing the binary search instead of myprevious patch set?hmm.. But pfn is linearly increased during the booting time. This assumptionis not correct in real workload for pfn_valid out of booting time. So in mypatchset, I defined another pfn_valid_region for booting time only.I didn't have many arm/arm64 boxes to verifed. What I can do is guaranteeingthe improvemnet in my armv8a (qualcom centriq 2400). Sorry about it.  --Cheers,Jia",Technical
,
"'arm96_common'?!  No.  Just no.The right way to share common code is to create a header file (or usean existing one), either in asm-generic or linux, with a #ifdef CONFIG_fooblock and then 'select foo' in the arm Kconfig files.  That allows thiscommon code to be shared, maybe with powerpc or x86 or ... in the future.",Technical
,
"Sure, but I bet if we are >end_pfn, we're almost certainly going to thestart_pfn of the next block, so why not test that as well?		early_region_idx++;		start_pfn = PFN_DOWN(regions[early_region_idx].base);		if (pfn >= end_pfn && pfn <= start_pfn)			return start_pfn;",Technical
,
"Hi, Linus,Please pull fromÂ  git://git.kernel.org/pub/scm/linux/kernel/git/rzhang/linux.git nextto receive the latest Thermal Management updates for v4.17-rc1 withtop-most commit f8837aac36cdc7430422cd65f4466071b42654bb:Â  Merge branches 'thermal-core' and 'thermal-soc' into next (2018-04-0221:49:31 +0800)on top of commit 0c8efd610b58cb23cefdfa12015799079aef94ae:Â  Linux 4.16-rc5 (2018-03-11 17:25:09 -0700)Specifics:- Fix race condition in imx_thermal_probe(). (Mikhail Lappo)- Add cooling device's statistics in sysfs. (Viresh Kumar)- add support for i.MX7 thermal sensor in imx_thermal driver. (AnsonHuang)- add support for MT7622 SoC in mtk_thermal driver. (Sean Wang)- Remove unused min/max cpu cooling DT property. (Viresh Kumar).- A series of fixes on exynos driver. (Bartlomiej Zolnierkiewicz,Maciej Purski, Marek Szyprowski)thanks,rui----------------------------------------------------------------Anson Huang (1):Â Â Â Â Â Â thermal: imx: add i.MX7 thermal sensor supportBartlomiej Zolnierkiewicz (10):Â Â Â Â Â Â thermal: exynos: remove unused ""type"" field from structexynos_tmu_platform_dataÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung,tmu_default_temp_offset propertyÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung, tmu_[first,second]_point_trim propertiesÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung, tmu_noise_cancel_modepropertyÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung, tmu[_min,_max]_efuse_value propertiesÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung, tmu_reference_voltagepropertyÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung,tmu_gain propertyÂ Â Â Â Â Â thermal: exynos: remove parsing of samsung, tmu_cal_type propertyÂ Â Â Â Â Â thermal: exynos: remove separate exynos_tmu.h header fileÂ Â Â Â Â Â dt-bindings: thermal: remove no longer needed samsung thermalpropertiesMaciej Purski (1):Â Â Â Â Â Â thermal: exynos: Read soc_type from match dataMarek Szyprowski (2):Â Â Â Â Â Â thermal: exynos: Reading temperature makes sense only when TMU isturned onÂ Â Â Â Â Â thermal: exynos: Propagate error value from tmu_read()Mikhail Lappo (1):Â Â Â Â Â Â thermal: imx: Fix race condition in imx_thermal_probe()Sean Wang (2):Â Â Â Â Â Â dt-bindings: thermal: add binding for MT7622 SoCÂ Â Â Â Â Â thermal: mediatek: add support for MT7622 SoCViresh Kumar (2):Â Â Â Â Â Â dt-bindings: thermal: Remove ""cooling-{min|max}-level"" propertiesÂ Â Â Â Â Â thermal: Add cooling device's statistics in sysfsZhang Rui (2):Â Â Â Â Â Â Merge branch 'linus' of git://git.kernel.org/.../evalenti/linux-soc-thermal into thermal-socÂ Â Â Â Â Â Merge branches 'thermal-core' and 'thermal-soc' into nextÂ .../devicetree/bindings/thermal/exynos-thermal.txt |Â Â 23 +-Â .../devicetree/bindings/thermal/imx-thermal.txtÂ Â Â Â |Â Â Â 9 +-Â .../bindings/thermal/mediatek-thermal.txtÂ Â Â Â Â Â Â Â Â Â |Â Â Â 1 +Â .../devicetree/bindings/thermal/thermal.txtÂ Â Â Â Â Â Â Â |Â Â 16 +-Â Documentation/thermal/sysfs-api.txtÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â 31 +++Â drivers/thermal/KconfigÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â Â 7 +Â drivers/thermal/imx_thermal.cÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â | 301++++++++++++++++-----Â drivers/thermal/mtk_thermal.cÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â 35 +++Â drivers/thermal/samsung/exynos_tmu.cÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â | 268 +++++++++---------Â drivers/thermal/samsung/exynos_tmu.hÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â 75 -----Â drivers/thermal/thermal_core.cÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â Â 3 +-Â drivers/thermal/thermal_core.hÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â 10 +Â drivers/thermal/thermal_helpers.cÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â Â 5 +-Â drivers/thermal/thermal_sysfs.cÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â | 225+++++++++++++++Â include/linux/thermal.hÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â |Â Â Â 1 +Â 15 files changed, 706 insertions(+), 304 deletions(-)Â delete mode 100644 drivers/thermal/samsung/exynos_tmu.h",Technical
,
"Just ""make allmodconfig"" and the warning is about a uninitialized variable.Line 304 in drivers/thermal/samsung/exynos_tmu.c if my shell historyis to be believed.                Linus",Technical
,
"These couple of warnings were introduced by:commit 480b5bfc16e17ef51ca1c55bfcebf55db8673ebfAuthor: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>Date:   Tue Mar 6 15:43:45 2018 +0100    thermal: exynos: remove parsing of samsung, tmu_default_temp_offsetproperty    Trimming (one point based or two points based) is always used for    the temperature calibration and the default non-trimming code should    never be reached.    Modify temp_to_code() and code_to_temp() accordingly (WARN_ON(1)    in the default cases) and then remove no longer needed parsing of    samsung,tmu_default_temp_offset property.    There should be no functional changes caused by this patch.    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>    Signed-off-by: Eduardo Valentin <edubezval@gmail.com>After digging into, there is no obvious fix. It returns effectively anuninitialized value and the callers are assuming the value is alwayscorrect, so it is also not possible to simply return an error.-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Technical
,
"Hello,Yeah, this has also passed my local compilation error. Somehow my gcc4.9is not catching it. Using an older gcc (gcc4.6) does catch it.Anyways, given that the conversion functions are written to coverfor unexpected cal_type, the right way of fixing this is to rewritethe conversion functions to allow for returning error codes andadjusting the callers as expected.Rui, bzolnier, please consider the following fix:From: Eduardo Valentin <edubezval@gmail.com>Date: Thu, 12 Apr 2018 21:00:48 -0700Subject: [PATCH 1/1] thermal: exynos: fix compilation warning around conversion functionsIn order to fix the warns:drivers/thermal/samsung/exynos_tmu.c:931:37: warning: 'temp' may be used uninitialized in this function [-Wmaybe-uninitialized]drivers/thermal/samsung/exynos_tmu.c:304:9: warning: 'temp_code' may be used uninitialized in this function [-Wmaybe-uninitialized]the conversion functions should allow return error codesand the not mix the converted value with error code.This patch change the conversion functions to returnerror code or success and adjusts the callers accordingly.Signed-off-by: Eduardo Valentin <edubezval@gmail.com>--- drivers/thermal/samsung/exynos_tmu.c | 120 ++++++++++++++++++++++++----------- 1 file changed, 84 insertions(+), 36 deletions(-)diff --git a/drivers/thermal/samsung/exynos_tmu.c b/drivers/thermal/samsung/exynos_tmu.cindex 2ec8548..b3f0704 100644--- a/drivers/thermal/samsung/exynos_tmu.c+++ b/drivers/thermal/samsung/exynos_tmu.c@@ -282,52 +282,54 @@ static void exynos_report_trigger(struct exynos_tmu_data *p)  * TMU treats temperature as a mapped temperature code.  * The temperature is converted differently depending on the calibration type.  */-static int temp_to_code(struct exynos_tmu_data *data, u8 temp)+static int temp_to_code(struct exynos_tmu_data *data, u8 temp, int *temp_code) {-	int temp_code;+	int ret = 0; 	switch (data->cal_type) { 	case TYPE_TWO_POINT_TRIMMING:-		temp_code = (temp - EXYNOS_FIRST_POINT_TRIM) *+		*temp_code = (temp - EXYNOS_FIRST_POINT_TRIM) * 			(data->temp_error2 - data->temp_error1) / 			(EXYNOS_SECOND_POINT_TRIM - EXYNOS_FIRST_POINT_TRIM) + 			data->temp_error1; 		break; 	case TYPE_ONE_POINT_TRIMMING:-		temp_code = temp + data->temp_error1 - EXYNOS_FIRST_POINT_TRIM;+		*temp_code = temp + data->temp_error1 - EXYNOS_FIRST_POINT_TRIM; 		break; 	default: 		WARN_ON(1);+		ret = -EINVAL; 		break; 	}-	return temp_code;+	return ret; } /*  * Calculate a temperature value from a temperature code.  * The unit of the temperature is degree Celsius.  */-static int code_to_temp(struct exynos_tmu_data *data, u16 temp_code)+static int code_to_temp(struct exynos_tmu_data *data, u16 temp_code, int *temp) {-	int temp;+	int ret = 0; 	switch (data->cal_type) { 	case TYPE_TWO_POINT_TRIMMING:-		temp = (temp_code - data->temp_error1) *+		*temp = (temp_code - data->temp_error1) * 			(EXYNOS_SECOND_POINT_TRIM - EXYNOS_FIRST_POINT_TRIM) / 			(data->temp_error2 - data->temp_error1) + 			EXYNOS_FIRST_POINT_TRIM; 		break; 	case TYPE_ONE_POINT_TRIMMING:-		temp = temp_code - data->temp_error1 + EXYNOS_FIRST_POINT_TRIM;+		*temp = temp_code - data->temp_error1 + EXYNOS_FIRST_POINT_TRIM; 		break; 	default: 		WARN_ON(1);+		ret = -EINVAL; 		break; 	}-	return temp;+	return ret; } static void sanitize_temp_error(struct exynos_tmu_data *data, u32 trim_info)@@ -352,7 +354,7 @@ static u32 get_th_reg(struct exynos_tmu_data *data, u32 threshold, bool falling) 	struct thermal_zone_device *tz = data->tzd; 	const struct thermal_trip * const trips = 		of_thermal_get_trip_points(tz);-	unsigned long temp;+	int temp; 	int i; 	if (!trips) {@@ -362,6 +364,8 @@ static u32 get_th_reg(struct exynos_tmu_data *data, u32 threshold, bool falling) 	} 	for (i = 0; i < of_thermal_get_ntrips(tz); i++) {+		int val, ret;+ 		if (trips[i].type == THERMAL_TRIP_CRITICAL) 			continue;@@ -371,7 +375,14 @@ static u32 get_th_reg(struct exynos_tmu_data *data, u32 threshold, bool falling) 		else 			threshold &= ~(0xff << 8 * i);-		threshold |= temp_to_code(data, temp) << 8 * i;+		ret = temp_to_code(data, temp, &val);+		if (ret) {+			pr_err(""%s: Convertion error from temp (%d) to code: %d!\n"",+				__func__, temp, ret);+			return 0;+		}++		threshold |= val << 8 * i; 	} 	return threshold;@@ -460,11 +471,10 @@ static int exynos4210_tmu_initialize(struct platform_device *pdev) 	/* Write temperature code for threshold */ 	reference = trips[0].temperature / MCELSIUS;-	threshold_code = temp_to_code(data, reference);-	if (threshold_code < 0) {-		ret = threshold_code;+	ret = temp_to_code(data, reference, &threshold_code);+	if (ret < 0 || threshold_code < 0) 		goto out;-	}+ 	writeb(threshold_code, data->base + EXYNOS4210_TMU_REG_THRESHOLD_TEMP); 	for (i = 0; i < of_thermal_get_ntrips(tz); i++) {@@ -537,7 +547,10 @@ static int exynos4412_tmu_initialize(struct platform_device *pdev) 		goto out; 	}-	threshold_code = temp_to_code(data, crit_temp / MCELSIUS);+	ret = temp_to_code(data, crit_temp / MCELSIUS, &threshold_code);+	if (ret)+		goto out;+ 	/* 1-4 level to be assigned in th0 reg */ 	rising_threshold &= ~(0xff << 8 * i); 	rising_threshold |= threshold_code << 8 * i;@@ -620,7 +633,9 @@ static int exynos5433_tmu_initialize(struct platform_device *pdev) 		/* Write temperature code for rising threshold */ 		tz->ops->get_trip_temp(tz, i, &temp); 		temp /= MCELSIUS;-		threshold_code = temp_to_code(data, temp);+		ret = temp_to_code(data, temp, &threshold_code);+		if (ret)+			goto out; 		rising_threshold = readl(data->base + rising_reg_offset); 		rising_threshold |= (threshold_code << j * 8);@@ -629,7 +644,9 @@ static int exynos5433_tmu_initialize(struct platform_device *pdev) 		/* Write temperature code for falling threshold */ 		tz->ops->get_trip_hyst(tz, i, &temp_hist); 		temp_hist = temp - (temp_hist / MCELSIUS);-		threshold_code = temp_to_code(data, temp_hist);+		ret = temp_to_code(data, temp_hist, &threshold_code);+		if (ret)+			goto out; 		falling_threshold = readl(data->base + falling_reg_offset); 		falling_threshold &= ~(0xff << j * 8);@@ -677,7 +694,12 @@ static int exynos5440_tmu_initialize(struct platform_device *pdev) 	/* if last threshold limit is also present */ 	if (!data->tzd->ops->get_crit_temp(data->tzd, &crit_temp)) {-		threshold_code = temp_to_code(data, crit_temp / MCELSIUS);+		int ret;++		ret = temp_to_code(data, crit_temp / MCELSIUS, &threshold_code);+		if (ret)+			return ret;+ 		/* 5th level to be assigned in th2 reg */ 		rising_threshold = 			threshold_code << EXYNOS5440_TMU_TH_RISE4_SHIFT;@@ -749,7 +771,10 @@ static int exynos7_tmu_initialize(struct platform_device *pdev) 		temp_hist = temp - (temp_hist / MCELSIUS); 		/* Set 9-bit temperature code for rising threshold levels */-		threshold_code = temp_to_code(data, temp);+		ret = temp_to_code(data, temp, &threshold_code);+		if (ret)+			goto out;+ 		rising_threshold = readl(data->base + 			EXYNOS7_THD_TEMP_RISE7_6 + reg_off); 		rising_threshold &= ~(EXYNOS7_TMU_TEMP_MASK << (16 * bit_off));@@ -758,7 +783,9 @@ static int exynos7_tmu_initialize(struct platform_device *pdev) 		       data->base + EXYNOS7_THD_TEMP_RISE7_6 + reg_off); 		/* Set 9-bit temperature code for falling threshold levels */-		threshold_code = temp_to_code(data, temp_hist);+		ret = temp_to_code(data, temp_hist, &threshold_code);+		if (ret)+			goto out; 		falling_threshold &= ~(EXYNOS7_TMU_TEMP_MASK << (16 * bit_off)); 		falling_threshold |= threshold_code << (16 * bit_off); 		writel(falling_threshold,@@ -925,11 +952,18 @@ static int exynos_get_temp(void *p, int *temp) 	clk_enable(data->clk); 	value = data->tmu_read(data);-	if (value < 0)+	if (value < 0) { 		ret = value;-	else-		*temp = code_to_temp(data, value) * MCELSIUS;+		goto out;+	}++	ret = code_to_temp(data, value, temp);+	if (ret)+		goto out;+	*temp *= MCELSIUS;++out: 	clk_disable(data->clk); 	mutex_unlock(&data->lock);@@ -937,9 +971,11 @@ static int exynos_get_temp(void *p, int *temp) } #ifdef CONFIG_THERMAL_EMULATION-static u32 get_emul_con_reg(struct exynos_tmu_data *data, unsigned int val,-			    int temp)+static int get_emul_con_reg(struct exynos_tmu_data *data, unsigned int val,+			    int temp, u32 *con_reg) {+	int code, ret = 0;+ 	if (temp) { 		temp /= MCELSIUS;@@ -950,27 +986,36 @@ static u32 get_emul_con_reg(struct exynos_tmu_data *data, unsigned int val, 		if (data->soc == SOC_ARCH_EXYNOS7) { 			val &= ~(EXYNOS7_EMUL_DATA_MASK << 				EXYNOS7_EMUL_DATA_SHIFT);-			val |= (temp_to_code(data, temp) <<-				EXYNOS7_EMUL_DATA_SHIFT) |+			ret = temp_to_code(data, temp, &code);+			if (ret)+				goto out;++			val |= (code << EXYNOS7_EMUL_DATA_SHIFT) | 				EXYNOS_EMUL_ENABLE; 		} else { 			val &= ~(EXYNOS_EMUL_DATA_MASK << 				EXYNOS_EMUL_DATA_SHIFT);-			val |= (temp_to_code(data, temp) <<-				EXYNOS_EMUL_DATA_SHIFT) |+			ret = temp_to_code(data, temp, &code);+			if (ret)+				goto out;++			val |= (code << EXYNOS_EMUL_DATA_SHIFT) | 				EXYNOS_EMUL_ENABLE; 		} 	} else { 		val &= ~EXYNOS_EMUL_ENABLE; 	}-	return val;+	*con_reg = val;+out:+	return ret; } static void exynos4412_tmu_set_emulation(struct exynos_tmu_data *data, 					 int temp) { 	unsigned int val;+	int ret; 	u32 emul_con; 	if (data->soc == SOC_ARCH_EXYNOS5260)@@ -983,18 +1028,21 @@ static void exynos4412_tmu_set_emulation(struct exynos_tmu_data *data, 		emul_con = EXYNOS_EMUL_CON; 	val = readl(data->base + emul_con);-	val = get_emul_con_reg(data, val, temp);-	writel(val, data->base + emul_con);+	ret = get_emul_con_reg(data, val, temp, &val);+	if (!ret)+		writel(val, data->base + emul_con); } static void exynos5440_tmu_set_emulation(struct exynos_tmu_data *data, 					 int temp) { 	unsigned int val;+	int ret; 	val = readl(data->base + EXYNOS5440_TMU_S0_7_DEBUG);-	val = get_emul_con_reg(data, val, temp);-	writel(val, data->base + EXYNOS5440_TMU_S0_7_DEBUG);+	ret = get_emul_con_reg(data, val, temp, &val);+	if (!ret)+		writel(val, data->base + EXYNOS5440_TMU_S0_7_DEBUG); } static int exynos_tmu_set_emulation(void *drv_data, int temp)--2.1.4",Technical
,
"I think there are two problems here1. Actually, this error has been raised by 0-day earlier.https://marc.info/?l=linux-pm&m=152107340117077&w=2Don't know why it still goes into thermal-soc tree.2. After pulled the thermal-soc changes, I also asked 0-day to runbuild test, but I didn't get any warning report (email attached), CCPhilip and Shun to look at this issue.thanks,rui",Technical
,
"Hi, Eduardo,as it is late in this merge window, I'd prefer to1. drop all the thermal-soc material in the first pull request which Iwill send out soon.2. you can prepare another pull request containing the thermal-socmaterials except the exynos fixes3. exynos fixes with the problem solved can be queued for -rc2 orlater.thanks,rui",Technical
,
"Hi,Since this condition cannot happen (the driver makes sure of this duringprobe) I would prefer much simpler fix from Arnd:https://patchwork.kernel.org/patch/10313313/(I've already ACKed it two weeks ago).dittoBest regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
"I'm not sure these are correct fixes.The change 480b5bfc16e1 tells:""There should be no functional changes caused by this patch.""but the fix above returns 0 as a default value instead of '50' or '25'for the 5440 and that impacts the threshold etc ...IMO, the correct fix would be to define a default value '50', overrideit at init time to '25' if it is a 5440. And then the variable 'temp'and 'temp_code' get this value in the default case.-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Technical
,
"It is okay to return 0 because this code-path (the default one) will benever hit by the driver (probe makes sure of it) - the default case ishere is just to silence compilation errors..Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
Agreed,Technical
,
"Sent you thishttps://marc.info/?l=linux-pm&m=152361492711499&w=2I see there is still some discussion around the topic of how to fixthis. So, once we get to a point of agreement, I will send the remainingwith exynos fixes.",Technical
,
"What should I do now to help resolve the issue?[ There has been no action from you on Arnd's fix for over two weeks and  also you have not commented on it now.. ]Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
"[ ... ]Actually the switch statement was fine until the cleanup.Regarding the latest comment, this can be fixed properly by 'return' (orwhatever you want which does not get around of gcc warnings).-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Technical
,
"I don't see how it was fine before as the driver has never used the defaultcase (always used TYPE_ONE_POINT_TRIMMING or TYPE_TWO_POINT_TRIMMING).Could you please explain this more?Do you mean that you want the patch with switch statement removal?Is incremental fix OK or do you want something else?Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
"Thanks Daniel, this is much better fix.Acked-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
"+++ b/drivers/thermal/samsung/exynos_tmu.c@@ -260,7 +260,7 @@ static int temp_to_code(struct exynos_tmu_data*data, u8 temp)                temp_code = temp + data->temp_error1 -pdata->first_point_trim;                break;        default:-               temp_code = temp + pdata->default_temp_offset;+               WARN_ON(1);                break;        }@@ -287,7 +287,7 @@ static int code_to_temp(struct exynos_tmu_data*data, u16 temp_code)                temp = temp_code - data->temp_error1 +pdata->first_point_trim;                break;        default:-               temp = temp_code - pdata->default_temp_offset;+               WARN_ON(1);                break;        }I'm not saying the code path was fine but from the compiler point ofview, it was. By removing the defaulting temp value there is a code pathgcc sees the temp variable as not initialized.Your cleanups are relevant.-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Technical
,
"Danial has already posted it, I hope the fix is fine with you.Also sorry for the delay with handling issue - I was on holiday last twodays and for some reason I was under (wrong) impression that the previousfix has been in thermal tree (so I was quite surprised today reading thismail thread).Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
"should have been:Eduardo: Daniel has already posted it, I hope the fix is fine with you.(& sorry for the typo)Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Technical
,
"Please resend your series with the patches without the warnings..Thanks,Eduardo",Technical
,
"Hello, James.Thanks for your reply :)I agree that usleep_range() here will not much affect the real executionof this driver.But I think usleep_range() can more opportunity for other threads to usethe CPU core to schedule during waiting.That is why I detect mdelay() that can be replaced with msleep() orusleep_range().Best wishes,Jia-Ju Bai",Technical
,
"James is right, You have added all usleep_range() during system boot-uptime.During boot-up system will run as single threaded. Where this change willnot make much sense. System first priority is match the exact timing oneach and every boot-up.~arvind",Technical
,
"What an understatement :-)Can't we instead improve the error message and turn this into apr_debug2? Isn't it a reasonable scenario that the user expects thistopology information to be present and then ends up without it?Perhaps something like:	pr_debug2(""%s: could't read %s, does this arch have topology information?\n"", __func__, path);- Arnaldo",Technical
,
"Fine with me, I will provide a version 2....--Thomas Richter, Dept 3303, IBM LTC Boeblingen Germany--Vorsitzende des Aufsichtsrats: Martina KoederitzGeschÃ¤ftsfÃ¼hrung: Dirk WittkoppSitz der Gesellschaft: BÃ¶blingen / Registergericht: Amtsgericht Stuttgart, HRB 243294",Technical
,
"Will do in my next email.Appologies. This must be Thunderbird, I've been trying to coax intodoing otherwise. Will send the corrected patch shortly.",Technical
,
"Best is to set up and use git send-email. Anyway, you can see the resultof the corruption at https://patchwork.kernel.org/patch/10343535/;it appears that patchwork doesn't understand your patch either.Guenter",Technical
,
"Hi Xiaotong,[snip]I'm not sure how the input_ff is freed for managed devices.Either you don't have to destroy it here, or you also need to destroy itin a release() function.No need to unregister managed input devices.Cheers,Marcus Folkesson",Technical
,
"Hi Marcus,I checked again, we do not need to destroy it manually. Will remove innext version.You are correct. Will remove these in next version. Thanks for your comments.--Baolin.wangBest Regards",Technical
,
"Hi Ulf,So are you saying that multi-slot support is a no go in general or it is onlyapplicable to DW MMC (I really doubt that's a case)?BTW there're other controllers that seem to support multi-slot like Atmel etc.-Alexey",Technical
,
"In general.Yeah, none of those are working - it just bad attempts to try to make*something* work.Kind regardsUffe",Technical
,
"Hi Ulf,Previous multi slot implementation was removed as nobody used it andnobody tested it. There are lots of mistakes in previous implementationwhich are not related to request serializationlike lack of slot switch / lack of adding slot id to CIU commands / ets...So obviously it was never tested and never used at real multi slot hardware.In current implementation data transfers and commands to differenthosts (slots) are serialized internally in the dw_mmc driver. We haverequest queue and when .request() is called we add new request to thequeue. We take new request from the queue only if the previous onehas already finished.So although hosts (slots) have separate locks (mmc_claim|release_host())the requests to different slots are serialized by driver.Isn't that enough?I'm not very familiar with SD/SDIO/(e)MMC specs so my assumptions might be wrongin that case please correct me.Nevertheless we had to deal somehow with existing hardware whichhas multislot dw mmc controller and both slots are used...This patch at least shouldn't break anything for current users (which useit in single slot mode)Moreover we tested this dual-slot implementation and don't catch any problems(probably yet) except bus performance decrease in dual-slot mode (which isquite expected).-- Eugeniy Paltsev",Technical
,
"That isn't sufficient. The core expects all calls to *any* of the hostops to be serialized for one host. It does so to conform to the specs.For example it may call: ->set_ios()->request()->set_ios()->request()->request()Sorry, but no.Well, that kind of explains your simplistic approach.I would suggest you to study the specs and the behavior of the mmccore a bit more carefully, that should give you a better understandingof the problems.Honestly, I don't think efforts of implementing this is worth it!Even if we would be able to solve the problem from an mmc subsystempoint of view, we would still have the I/O scheduling problem toaddress. To solve that, we would need to be able to configure upperblock layer code to run one scheduling instance over multiple blockdevices...Kind regardsUffe",Technical
,
A bit remark for better understanding:All card settings change are serialized too. These settings are appliedafter slot switch before execution of new request for this slot.So situations like calling any host_0 ops while another host (host_1) is activeare handled by current code.This is example of simultaneous ops calls for both slots:host (slot) 0    | host (slot) 1-----------------------------------h0->set_ios()    |    h1->set_ios()h0->request()    |    h1->request()h0->set_ios()    |    h1->set_ios()h0->request()    |    h1->request()h0->request()    |h0->request()    |h0->request()    |How it will be serialized in the mmc driver:h0->set_ios()   // h0 settings saveh1->set_ios()   // h1 settings saveh0->request()   // apply settings for h0 and do request------ slot switch to h1 ------h1->request()   // apply settings for h1 and do requesth0->set_ios()   // h0 settings saveh1->set_ios()   // h1 settings save------ slot switch to h0 ------h0->request()   // apply settings for h0 and do request------ slot switch to h1 ------h1->request()   // apply settings for h1 and do request------ slot switch to h0 ------h0->request()   // do request (no new settings to apply)h0->request()   // do request (no new settings to apply)h0->request()   // do request (no new settings to apply)-- Eugeniy Paltsev,Technical
,
This doesn't work as it would mean violation of the specs in somescenarios. Particular during the card initialization and card poweroff.Ditto. Etc...Kind regardsUffe,Technical
,
"Hi,Sorry for late. :(Well, I will read the other comments..and reply soon.Best Regards,Jaehoon Chung",Technical
,
"On Mon, 23 Apr 2018 14:30:36 +0200,Paul Menzel wrote:Usually perf would help, but even a simple printk() should suffice tosee what's going on there :)We know that there are some cases where the codec / controllercommunication stalls on the recent Coffee Lake or such platforms.But quite not sure how it happens.Moving the stuff into async just moves something ugly, and it's nofix, per se, if such a long delay itself is unexpected.thanks,Takashi",Technical
"On Tue, 24 Apr 2018 13:59:58 +0200,Paul Menzel wrote:Indeed.  But even from this result, you can have a rough idea.As you can see, the most of time was spent before ""1"" point, which isthe very beginning of azx_probe().  That is, the slowness is not inHD-audio driver probe itself.  Rather it's likely because of parallelprobing with other multiple devices.thanks,Takashi",Technical
,
"Dear Takashi,I agree. But that also makes it clear, that the probe can be done inasync task, doesnâ€™t it?Kind regards,Paul",Technical
,
"On Tue, 24 Apr 2018 16:03:53 +0200,Paul Menzel wrote:Yes, but it's no fix, either.  The probe callback itself doesn't takeany long time, but the problem is the stage before that.  By declaringthe async probe, you can hide it, but it doesn't mean that the wholeissue is solved by that.thanks,Takashi",Technical
,
"On Mon, 23 Apr 2018 14:11:02 -0500""Gustavo A. R. Silva"" <gustavo@embeddedor.com> wrote:Thanks, I 'll mark this series as rejected at patchwork.linuxtv.org.Please feel free to resubmit any patch if they represent a realthreat, adding a corresponding description about the threat scenarioat the body of the e-mail.Anytime.Thanks,Mauro",Technical
,
Yeah. I got it.Much appreciated. :)Thanks--Gustavo,Technical
,
"Hi Dan,Em Tue, 24 Apr 2018 12:35:00 +0300Dan Carpenter <dan.carpenter@oracle.com> escreveu:The intent of that comment is to be provocative, in the sense thatpeople would argue against and point flaws (if any) on my rationale.As I explained when reviewing this patch, I don't care much if anautomatic tool is saying that there's a vulnerability at the code,as it could be a false positive. So, what I want at the patch descriptionis a threat analysis explaining how an algorithm is exploited.With regards to Spectre, I never tried to write an exploit myself, norhad to study it in detail in order to mitigate it. So, what I know aboutit is what I read on a few places. From the places where I read, theboundaries for an array exploit are limited to L1 cache, but,as I said before, I can be wrong on that.It will be great to hear to Peter's comment on that, as he knows alot more than me about it.Thanks,Mauro",Technical
,
"TL;DR: read the papers [1] & [2]I suspect you didn't get the gist of Spectre V1 [1], let me explain:Suppose userspace provides f->index > ARRAY_SIZE(format), and we predictthe branch to -EINVAL to not be taken.Then the CPU _WILL_ load (out of bounds) format[f->index] intof->pixelformat and continue onwards to use this bogus value, all the wayuntil it figures out the branch was mis-predicted.Once it figures out the mispredict, it will throw away the state andstart over at the condition site. So far, so basic.The thing is, is will not (and cannot) throw away all state. Suppose ourspeculation continues into v4l_fill_fmtdesc() and that switch there iscompiled as another array lookup, it will then feed our f->pixelformat(which contains random kernel memory) into that array to find therequested descr pointer.Now, imagine userspace having flushed cache on the descr pointer array,having trained the branch predictor to mis-predict the branch (seebranchscope paper [2]) and doing that out-of-bounds ioctl().It can then speculative do the out-of-bounds array access, followed bythe desc array load, then figure out it was wrong and redo.Then usespace probes which part of the descr[] array is now in cache andfrom that it can infer the initial out-of-bound value.So while format[] is static and bound, it can read random kernel memoryup to format+4g, including your crypto keys.As far as V1 goes, this is actually a fairly solid exploit candidate. Nofalse positive about it.Now kernel policy is to kill any and all speculation on user controlledarray indexing such that we don't have to go look for subsequent sidechannels (the above cache side channel is the one described in theSpectre paper and by far the easiest, but there are other possible sidechannels) and we simply don't want to worry about it.So even from that pov, the proposed patch is good.[1] https://spectreattack.com/spectre.pdf[2] www.cs.ucr.edu/~nael/pubs/asplos18.pdf",Technical
,
"Just had a better look at v4l_fill_fmtdesc() and actually read thecomment. The code cannot be compiled as a array because it is big andsparse. But the log(n) condition tree is a prime candidate for thebranchscope side-channel, which would be able to reconstruct asignificant number of bits of the original value. A denser tree givesmore bits etc.",Technical
,
"Hi Mauro,Just to let you know, I was running smatch during the weekend and thetool is still reporting all these Spectre media warnings (and a lot more):https://patchwork.linuxtv.org/project/linux-media/list/?submitter=7277Thanks--Gustavo",Technical
,
"Yep. I get the same warning multiple times.BTW, Mauro, you sent a patch to fix an spectre v1 issue in this fileyesterday: dvb_ca_en50221.c:1480, but it seems there is another instanceof the same issue some lines above:diff --git a/drivers/media/dvb-core/dvb_ca_en50221.cb/drivers/media/dvb-core/dvb_ca_en50221.cindex 1310526..7edd9db 100644--- a/drivers/media/dvb-core/dvb_ca_en50221.c+++ b/drivers/media/dvb-core/dvb_ca_en50221.c@@ -1398,6 +1398,7 @@ static int dvb_ca_en50221_io_do_ioctl(struct file*file,                 info->type = CA_CI_LINK;                 info->flags = 0;+               slot = array_index_nospec(slot, ca->slot_count + 1);                 sl = &ca->slot_info[slot];                 if ((sl->slot_state != DVB_CA_SLOTSTATE_NONE) &&                     (sl->slot_state != DVB_CA_SLOTSTATE_INVALID)) {Thanks--Gustavo",Technical
,
"On Thu, 17 May 2018 08:43:24 -0300Mauro Carvalho Chehab <mchehab+samsung@kernel.org> wrote:It seems that something is broken... getting this error/warning:DBD::SQLite::db do failed: unrecognized token: ""'end + strlen("""" at /devel/smatch/smatch_scripts/../smatch_data/db/fill_db_sql.pl line 32, <WARNS> line 2938054.Thanks,Mauro",Technical
,
"On Thu, 17 May 2018 08:34:40 -0300Mauro Carvalho Chehab <mchehab+samsung@kernel.org> wrote:Never mind. Found it using grep. I'm running this:	make allyesconfig	/devel/smatch/smatch_scripts/build_kernel_data.sh	/devel/smatch/smatch_scripts/build_kernel_data.shThanks,Mauro",Technical
,
"On Thu, 17 May 2018 05:36:03 -0500""Gustavo A. R. Silva"" <gustavo@embeddedor.com> wrote:How? Here, I just pull from your git tree and do a ""make"". At most,make clean; make.That makes more sense to me, as the same pattern is used by almost allVIDIOC_ENUM_foo ioctls.Thanks,Mauro",Technical
,
"Interesting, I've rebuild the db twice and now I get a total of 75Spectre warnings in drivers/media--Gustavo",Technical
,
"Hi Dan,After rebuilding the db (once), these are all the Spectre media warningsI get:drivers/media/pci/ddbridge/ddbridge-core.c:233 ddb_redirect() warn:potential spectre issue 'ddbs'drivers/media/pci/ddbridge/ddbridge-core.c:243 ddb_redirect() warn:potential spectre issue 'pdev->port'drivers/media/pci/ddbridge/ddbridge-core.c:252 ddb_redirect() warn:potential spectre issue 'idev->input'drivers/media/dvb-core/dvb_ca_en50221.c:1400dvb_ca_en50221_io_do_ioctl() warn: potential spectre issue'ca->slot_info' (local cap)drivers/media/dvb-core/dvb_ca_en50221.c:1479 dvb_ca_en50221_io_write()warn: potential spectre issue 'ca->slot_info' (local cap)drivers/media/dvb-core/dvb_net.c:252 handle_one_ule_extension() warn:potential spectre issue 'p->ule_next_hdr'drivers/media/dvb-core/dvb_net.c:1483 dvb_net_do_ioctl() warn: potentialspectre issue 'dvbnet->device' (local cap)drivers/media/cec/cec-pin-error-inj.c:170 cec_pin_error_inj_parse_line()warn: potential spectre issue 'pin->error_inj_args'I just want to double check if you are getting the same output. In caseyou are getting the same, then what Mauro commented about these issues:https://patchwork.linuxtv.org/project/linux-media/list/?submitter=7277being resolved by commit 3ad3b7a2ebaefae37a7eafed0779324987ca5e56 seemsto be correct.Thanks--Gustavo",Technical
,
"Em Wed, 16 May 2018 16:11:08 +0300Dan Carpenter <dan.carpenter@oracle.com> escreveu:Yeah, I was thinking that is would be harder to clean this up onsmatch. I proposed a patch to the ML that simplifies the logic,making easier for both humans and Smatch to better understand howthe arrays are indexed.Thanks!Regards,Mauro",Technical
,
"It's hard to silence this because Smatch stores the current usercontrolled range list, not what it was initially.  I wrote all this codeto detect bounds checking errors, so there wasn't any need to save therange list before the bounds check.  Since ""op"" is a u32, I can't evengo by the type of the index....Oh...  Huh.  This is a bug in smatch.  That line looks like:	p->ule_sndu_type = ntohs(*(__be16 *)(p->ule_next_hdr + ((p->ule_dbit ? 2 : 3) * ETH_ALEN)));Smatch see the ntohs() and marks everything inside it as untrustednetwork data.  I'll fix this.regards,dan carpenter",Technical
,
"You'd need to rebuild the db (possibly twice but definitely once).regards,dan carpenter",Technical
,
"On Tue, 15 May 2018 12:29:10 -0500""Gustavo A. R. Silva"" <gustavo@embeddedor.com> wrote:Yeah, that's the same I'm getting from media upstream.This one seems a false positive, as the index var is u8 and thearray has 256 elements, as the userspace input from 'op' isinitialized with:	u8 v;	u32 op;	if (!kstrtou8(token, 0, &v))		op = v;This one seems a real issue to me. Sent a patch for it.I failed to see what's wrong here, or if this is exploited.Here, I'm at this commit:commit 2f66d40cbf57b0bd581fe75447d2a8625fc7bb1d (origin/master, origin/HEAD)Author: Dan Carpenter <dan.carpenter@oracle.com>Date:   Tue May 15 16:35:20 2018 +0300    db: make call_implies rows uniquePlus the diff below (that won't affect Spectre errors).Regards,Maurodiff --git a/check_missing_break.c b/check_missing_break.cindex 434b7283fc94..5bba6e919521 100644--- a/check_missing_break.c+++ b/check_missing_break.c@@ -73,7 +73,7 @@ static void print_missing_break(struct expression *expr) 	last_print_expr = get_switch_expr(); 	name = expr_to_var(expr);-	sm_msg(""warn: missing break? reassigning '%s'"", name);+//	sm_msg(""warn: missing break? reassigning '%s'"", name); 	free_string(name); }diff --git a/smatch_flow.c b/smatch_flow.cindex dc0e78824370..cd72a9ded375 100644--- a/smatch_flow.c+++ b/smatch_flow.c@@ -1005,8 +1005,7 @@ void __split_stmt(struct statement *stmt) 		__bail_on_rest_of_function = 1; 		final_pass = 1;-		sm_msg(""Function too hairy.  Giving up. %lu seconds"",-		       stop.tv_sec - fn_start_time.tv_sec);+		sm_msg(""__split_smt: function too hairy.  Giving up.""); 		fake_a_return(); 		final_pass = 0;  /* turn off sm_msg() from here */ 		return;diff --git a/smatch_implied.c b/smatch_implied.cindex 3588816361fe..f3ccd4b6d79e 100644--- a/smatch_implied.c+++ b/smatch_implied.c@@ -594,7 +594,7 @@ static void separate_and_filter(struct sm_state *sm, int comparison, struct rang 	gettimeofday(&time_after, NULL); 	sec = time_after.tv_sec - time_before.tv_sec;-	if (sec > 20) {+	if (sec > 60) { 		sm->nr_children = 4000; 		sm_msg(""Function too hairy.  Ignoring implications after %d seconds."", sec); 	}diff --git a/smatch_slist.c b/smatch_slist.cindex e1eb1b999b2a..2f8ba34a4b9a 100644--- a/smatch_slist.c+++ b/smatch_slist.c@@ -237,12 +237,14 @@ char *alloc_sname(const char *str) int out_of_memory(void) { 	/*-	 * I decided to use 50M here based on trial and error.+	 * I decided to use 6GB here based on trial and error. 	 * It works out OK for the kernel and so it should work 	 * for most other projects as well. 	 */-	if (sm_state_counter * sizeof(struct sm_state) >= 100000000)+	if (sm_state_counter * sizeof(struct sm_state) >= 6000000000) {+		sm_msg(""Out of memory""); 		return 1;+	} 	return 0; }Thanks,Mauro",Technical
,
"Thanks, Mauro.Dan,These are all the Spectre media issues I see smatch is reporting inlinux-next-20180515:drivers/media/cec/cec-pin-error-inj.c:170 cec_pin_error_inj_parse_line()warn: potential spectre issue 'pin->error_inj_args'drivers/media/dvb-core/dvb_ca_en50221.c:1479 dvb_ca_en50221_io_write()warn: potential spectre issue 'ca->slot_info' (local cap)drivers/media/dvb-core/dvb_net.c:252 handle_one_ule_extension() warn:potential spectre issue 'p->ule_next_hdr'I pulled the latest changes from the smatch repository and compiled it.I'm running smatch v0.5.0-4459-g2f66d40 now. Is this the latest version?I wonder if there is anything I might be missing.Thanks--Gustavo",Technical
,
"Possibly...  There was an ancient bug in Smatch's function pointerhandling.  I just pushed a fix for it now so the warning is there onlinux-next.regards,dan carpenter",Technical
,
"On Mon, 14 May 2018 22:31:37 -0500""Gustavo A. R. Silva"" <gustavo@embeddedor.com> wrote:There was no direct fix for it, but maybe this patch has somethingto do with the smatch error report cleanup:commit 3ad3b7a2ebaefae37a7eafed0779324987ca5e56Author: Sami Tolvanen <samitolvanen@google.com>Date:   Tue May 8 13:56:12 2018 -0400    media: v4l2-ioctl: replace IOCTL_INFO_STD with stub functions    This change removes IOCTL_INFO_STD and adds stub functions where    needed using the DEFINE_V4L_STUB_FUNC macro. This fixes indirect call    mismatches with Control-Flow Integrity, caused by calling standard    ioctls using a function pointer that doesn't match the function type.    Signed-off-by: Sami Tolvanen <samitolvanen@google.com>    Signed-off-by: Hans Verkuil <hansverk@cisco.com>    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>Thanks,Mauro",Technical
,
"Hi Mauro,I'm curious about how you finally resolved to handle these issues.I noticed Smatch is no longer reporting them.Thanks--Gustavo",Technical
,
"On Thu, 26 Apr 2018 16:41:56 -0500""Gustavo A. R. Silva"" <gustavo@embeddedor.com> wrote:Yes.Well, the issues will be there everywhere on all media drivers.I marked your patches because I need to study it carefully, afterPeter's explanations. My plan is to do it next week. Still notsure if the approach you took is the best one or not.As I said, one possibility is to change the way v4l2-core handlesVIDIOC_ENUM_foo ioctls, but that would be make harder to -stablebackports.I need a weekend to sleep on it.Thanks,Mauro",Technical
,
"Sadly no; the whole crux is the array bound check itself. You couldmaybe pass around the array size to the core code and then do somethinglike:	if (f->index >= f->array_size)		return -EINVAL;	f->index = nospec_array_index(f->index, f->array_size);in generic code, and have all the drivers use f->index as usual, buteven that would be quite a bit of code churn I guess.",Technical
,
"Hi Mauro,I saw your comment on LWN.  You argue on LWN that since the format arrayis static the CPU won't speculatively read past the L1 cache?I don't know if that's true.  It should be easy enough to filter outthe reads into static arrays.  Peter do you know the answer here?regards,dan carpenter",Technical
,
"Hi Mauro,I noticed you changed the status of this series from rejected to new.Also, there are other similar issues in media/pci/I can write proper patches for all of them if you agree those are notFalse Positives:diff --git a/drivers/media/pci/cx18/cx18-ioctl.cb/drivers/media/pci/cx18/cx18-ioctl.cindex 80b902b..63f4388 100644--- a/drivers/media/pci/cx18/cx18-ioctl.c+++ b/drivers/media/pci/cx18/cx18-ioctl.c@@ -36,6 +36,8 @@  #include <media/tveeprom.h>  #include <media/v4l2-event.h>+#include <linux/nospec.h>+  u16 cx18_service2vbi(int type)  {         switch (type) {@@ -488,8 +490,9 @@ static int cx18_enum_fmt_vid_cap(struct file *file,void *fh,                 },         };-       if (fmt->index > ARRAY_SIZE(formats) - 1)+       if (fmt->index >= ARRAY_SIZE(formats))                 return -EINVAL;+       fmt->index = array_index_nospec(fmt->index, ARRAY_SIZE(formats));         *fmt = formats[fmt->index];         return 0;  }diff --git a/drivers/media/pci/saa7134/saa7134-video.cb/drivers/media/pci/saa7134/saa7134-video.cindex 1a50ec9..d93cf09 100644--- a/drivers/media/pci/saa7134/saa7134-video.c+++ b/drivers/media/pci/saa7134/saa7134-video.c@@ -30,6 +30,8 @@  #include <media/v4l2-event.h>  #include <media/i2c/saa6588.h>+#include <linux/nospec.h>+  /* ------------------------------------------------------------------ */  unsigned int video_debug;@@ -1819,6 +1821,8 @@ static int saa7134_enum_fmt_vid_cap(struct file*file, void  *priv,         if (f->index >= FORMATS)                 return -EINVAL;+       f->index = array_index_nospec(f->index, FORMATS);+         strlcpy(f->description, formats[f->index].name,                 sizeof(f->description));diff --git a/drivers/media/pci/tw68/tw68-video.cb/drivers/media/pci/tw68/tw68-video.cindex 8c1f4a0..a6cfb4b 100644--- a/drivers/media/pci/tw68/tw68-video.c  #include <media/v4l2-event.h>  #include <media/videobuf2-dma-sg.h>+#include <linux/nospec.h>+  #include ""tw68.h""  #include ""tw68-reg.h""@@ -789,6 +791,8 @@ static int tw68_enum_fmt_vid_cap(struct file *file,void  *priv,         if (f->index >= FORMATS)                 return -EINVAL;+       f->index = array_index_nospec(f->index, FORMATS);+         strlcpy(f->description, formats[f->index].name,                 sizeof(f->description));diff --git a/drivers/media/pci/tw686x/tw686x-video.cb/drivers/media/pci/tw686x/tw686x-video.cindex c3fafa9..281d722 100644--- a/drivers/media/pci/tw686x/tw686x-video.c+++ b/drivers/media/pci/tw686x/tw686x-video.c@@ -25,6 +25,8 @@  #include ""tw686x.h""  #include ""tw686x-regs.h""+#include <linux/nospec.h>+  #define TW686X_INPUTS_PER_CH           4  #define TW686X_VIDEO_WIDTH             720  #define TW686X_VIDEO_HEIGHT(id)                ((id & V4L2_STD_525_60)? 480 : 576)@@ -981,6 +983,7 @@ static int tw686x_enum_fmt_vid_cap(struct file*file, void *priv,  {         if (f->index >= ARRAY_SIZE(formats))                 return -EINVAL;+       f->index = array_index_nospec(f->index, ARRAY_SIZE(formats));         f->pixelformat = formats[f->index].fourcc;         return 0;  }Thanks--Gustavo",Technical
,
"These files are generated from other files, so any future update to themwill bring back the spelling mistakes, so, as Andi pointed outpreviously, we better fix the spellings in the original files,maintained by Intel.- Arnaldo",Technical
,
Thanks. I forwarded to the right people.-Andi,Technical
,
"On Mon, 30 Apr 2018 12:25:46 +0800Shrirang Bagul <shrirang.bagul@canonical.com> wrote:Looks like part of the problem was introduced in that patch, part well predatedit (BDU).As you way, this needs to be a bit different to take into accountthe change to regmap.  We'll need to have that upstream before we lookat a back port.  One element inline surprises me and needs furtherexplanation.Why drop the enable setting?  Seems that we want to do this 'as well',if the device was previous enabled.",Technical
,
"I have sent a patch based on iio-for-4.17b [1], Lorenzo and I are stilldiscussing our findings. It's not just the CTRL1 reg, but also the AV_CONF(0x10) reg.which loses it's contents coming out of suspend.[1] https://marc.info/?l=linux-iio&m=152534455701742&w=2Yes, will cover this in v2.",Technical
,
"Greg doesn't accept patches without a commit message.  Just say whichtool warned for example.regards,dan carpenter_______________________________________________devel mailing listdevel@linuxdriverproject.orghttp://driverdev.linuxdriverproject.org/mailman/listinfo/driverdev-devel",Technical
,
"Quoting Tejas Patel (2018-05-03 02:25:35)Is your divider using the CLK_DIVIDER_ROUND_CLOSEST flag? Whendivider_get_val() is called, the incoming rate should already be roundedto something that is what the actual frequency would be so the roundinghere hopefully doesn't matter.Maybe something is lost in translation though, because we doround_rate() to figure out some divider based on a requested rate, andthen we return that rate we calculated that we can achieve to theframework. In turn, that rate comes back into this divider_get_val()function to get the divider out of the rate again. It's sort of annoyinghow circular this is. Perhaps your example can show this call sequenceand the associated math gymnastics that go on and then I'll be convincedthat we need to update this part of the code.",Technical
,
"From: Wenwen Wang <wang6495@umn.edu>Date: Fri,  4 May 2018 02:05:05 -0500gen_tunnel() may not ever return a value larger than 255.data->tgenerator is a u8 and therefore can never take on a valueoutside of the range of 0 to 255.I'm not applying this patch, sorry.",Technical
,
"I only read the code and find this possible data race.It is not found in real driver execution.I am not sure of it, so I use ""may"" and ""possible"" here.Best wishes,Jia-Ju Bai",Technical
,
"Guys, any comments? That is a kinda useful feature, in worst case only some ofmemory could get corrupted instead of trashing the whole memory. In myexperience with T20/30, the interrupt handling latency is low and blockinghappens immediately after the first page fault.",Technical
,
"One potential issue is with host1x clients where userspace processes cansubmit jobs with invalid memory accesses (addresses not mapped toIOMMU). If when such a failure happens, we disable the DMA for the wholehost1x client, unrelated userspace processes may see failures eventhough there is no problem with their jobs.Mikko",Technical
,
"Good point, I'll take a look at partial resurrection of patch [0]. Anyway Ithink it's still better to fail even the unrelated jobs, rather than to havecorrupted memory.[0] https://github.com/grate-driver/linux/commit/c0351a9d01491af2b2fefc162de1c2e4fcfaa94c#diff-20226be476307cb7ec9f60e26a9c30deR378",Technical
,
"Tsukada-san,I am not familiar with memcg so can't comment about whether the patchsetis the right way to solve the problem outlined in the cover letter buthad a couple of comments about this patch.TSUKADA Koutaro <tsukada@ascade.co.jp> writes:Please move this before Patch 1/7. This is to prevent wrong accountingof pages to memcg for size != PMD_SIZE.Instead of replacing calls to hpage_nr_pages(), is it possible to modifyit to do the calculation?Thanks,Punit",Technical
,
Punit Agrawal <punit.agrawal@arm.com> writes:I just noticed that the default state is off so the change isn't enableduntil the sysfs node is exposed in the next patch. Please ignore thiscomment.One below still applies.,Technical
,
"Thank you for review my code and please just call me Tsukada.I think it is possible to modify the inside of itself rather thanreplacing the call to hpage_nr_pages().Inferring from the processing that hpage_nr_pages() desires, I thoughtthat the definition of hpage_nr_pages() could be moved outside theCONFIG_TRANSPARENT_HUGEPAGE. It seems that THP and HugeTLBfs can behandled correctly because compound_order() is judged by seeing whether itis PageHead or not.Also, I would like to use compound_order() inside hpage_nr_pages(), butsince huge_mm.h is included before mm.h where compound_order() is defined,move hpage_nr_pages to mm.h.Instead of patch 3/7, are the following patches implementing what youintended?diff --git a/include/linux/huge_mm.h b/include/linux/huge_mm.hindex a8a1262..1186ab7 100644--- a/include/linux/huge_mm.h+++ b/include/linux/huge_mm.h@@ -204,12 +204,6 @@ static inline spinlock_t *pud_trans_huge_lock(pud_t *pud,  	else  		return NULL;  }-static inline int hpage_nr_pages(struct page *page)-{-	if (unlikely(PageTransHuge(page)))-		return HPAGE_PMD_NR;-	return 1;-}  struct page *follow_devmap_pmd(struct vm_area_struct *vma, unsigned long addr,  		pmd_t *pmd, int flags);@@ -254,8 +248,6 @@ static inline bool thp_migration_supported(void)  #define HPAGE_PUD_MASK ({ BUILD_BUG(); 0; })  #define HPAGE_PUD_SIZE ({ BUILD_BUG(); 0; })-#define hpage_nr_pages(x) 1-  static inline bool transparent_hugepage_enabled(struct vm_area_struct *vma)  {  	return false;diff --git a/include/linux/mm.h b/include/linux/mm.hindex 1ac1f06..082f2ee 100644--- a/include/linux/mm.h+++ b/include/linux/mm.h@@ -673,6 +673,12 @@ static inline unsigned int compound_order(struct page *page)  	return page[1].compound_order;  }+static inline int hpage_nr_pages(struct page *page)+{+	VM_BUG_ON_PAGE(PageTail(page), page);+	return (1 << compound_order(page));+}+  static inline void set_compound_order(struct page *page, unsigned int order)  {  	page[1].compound_order = order;--Thanks,Tsukada",Technical
,
"Hi Tsukada,I was staring at memcg code to better understand your changes and hadthe below thought.TSUKADA Koutaro <tsukada@ascade.co.jp> writes:[...]Instead of tying the surplus huge page charging control per-hstate,could the control be made per-memcg?This can be done by introducing a per-memory controller file in sysfs(memory.charge_surplus_hugepages?) that indicates whether surplushugepages are to be charged to the controller and forms part of thetotal limit. IIUC, the limit already accounts for page and swap cachepages.This would allow the control to be enabled per-cgroup and also keep theuserspace control interface in one place.As said earlier, I'm not familiar with memcg so the above might not be afeasible but think it'll lead to a more coherent userinterface. Hopefully, more knowledgeable folks on the thread can chimein.Thanks,Punit",Technical
,
TSUKADA Koutaro <tsukada@ascade.co.jp> writes:That looks a lot better. Thanks for giving it a go.,Technical
,
"Hi Punit,Thank you for good advise.As you mentioned, it is better to be able to control by per-memcg. Afterorganizing my thoughts, I will develop the next version patch-set that cansolve issues and challenge again.Thanks,Tsukada",Technical
,
"Thank you for your feedback.That makes sense, surplus hugepages are charged to both memcg and hugetlbcgroup, which may be contrary to cgroup design philosophy.Based on the above advice, I have considered the following improvements,what do you think about?The 'charge_surplus_hugepages' of v2 patch-set was an option to switch""whether to charge memcg in addition to hugetlb cgroup"", but it will beabolished. Instead, change to ""switch only to memcg instead of hugetlbcgroup"" option. This is called 'surplus_charge_to_memcg'.The surplus_charge_to_memcg option is created in per hugetlb cgroup.If it is false(default), charge destination cgroup of various page typesis the same as the current kernel version. If it become true, hugetlbcgroup stops accounting for surplus hugepages, and memcg starts accountinginstead.A table showing which cgroups are charged:page types          | current  v2(off)  v2(on)   v3(off)   v3(on)-------------------------------------------------------------------normal + THP        |       m       m       m         m        mhugetlb(persistent) |       h       h       h         h        hhugetlb(surplus)    |       h       h     m+h         h        m------------------------------------------------------------------- v2: charge_surplus_hugepages option v3: next version, surplus_charge_to_memcg option  m: memory cgroup  h: hugetlb cgroupI stared at the commit log of mm/hugetlb_cgroup.c, but it did not seem tohave specially considered of surplus hugepages. Later, I will send a mailto hugetlb cgroup's committer to ask about surplus hugepages chargespecifications.--Thanks,Tsukada",Technical
,
"I went back and looked at surplus huge page allocation.  Previously, I madea statement that the hugetlb controller accounts for surplus huge pages.Turns out that may not be 100% correct.Thanks to Michal, all surplus huge page allocation is performed via thealloc_surplus_huge_page() routine.  This will ultimately call into thebuddy allocator without any cgroup charges.  Calls to alloc_surplus_huge_pageare made from:- alloc_huge_page() when allocating a huge page to a mapping/file.  In this  case, appropriate calls to the hugetlb controller are in place.  So, any  limits are enforced here.- gather_surplus_pages() when allocating and setting aside 'reserved' huge  pages. No accounting is performed here.  Do note that in this case the  allocated huge pages are not assigned to the mapping/file.  Even though  'reserved', they are deposited into the global pool and also counted as  'free'.  When these reserved pages are ultimately used to populate a  file/mapping, the code path goes through alloc_huge_page() where appropriate  calls to the hugetlb controller are in place.So, the bottom line is that surplus huge pages are not accounted for whenthey are allocated as 'reserves'.  It is not until these reserves are actuallyused that accounting limits are checked.  This 'seems' to align with generalallocation of huge pages within the pool.  No accounting is done until theyare actually allocated to a mapping/file.--Mike Kravetz",Technical
,
"Thank you for your time.I do not know if it is really a strong use case, but I will explain mymotive in detail. English is not my native language, so please pardonmy poor English.I am one of the developers for software that managing the resource usedfrom user job at HPC-Cluster with Linux. The resource is memory mainly.The HPC-Cluster may be shared by multiple people and used. Therefore, thememory used by each user must be strictly controlled, otherwise theuser's job will runaway, not only will it hamper the other users, it willcrash the entire system in OOM.Some users of HPC are very nervous about performance. Jobs are executedwhile synchronizing with MPI communication using multiple compute nodes.Since CPU wait time will occur when synchronizing, they want to minimizethe variation in execution time at each node to reduce waiting times asmuch as possible. We call this variation a noise.THP does not guarantee to use the Huge Page, but may use the normal page.This mechanism is one cause of variation(noise).The users who know this mechanism will be hesitant to use THP. However,the users also know the benefits of the Huge Page's TLB hit rateperformance, and the Huge Page seems to be attractive. It seems naturalthat these users are interested in HugeTLBfs, I do not know at allwhether it is the right approach or not.At the very least, our HPC system is pursuing high versatility and wehave to consider whether we can provide it if users want to use HugeTLBfs.In order to use HugeTLBfs we need to create a persistent pool, but inour use case sharing nodes, it would be impossible to create, delete orresize the pool.One of the answers I have reached is to use HugeTLBfs by overcommittingwithout creating a pool(this is the surplus hugepage).Surplus hugepages is hugetlb page, but I think at least that consumingbuddy pool is a decisive difference from hugetlb page of persistent pool.If nr_overcommit_hugepages is assumed to be infinite, allocating pages forsurplus hugepages from buddy pool is all unlimited even if being limitedby memcg. In extreme cases, overcommitment will allow users to exhaustthe entire memory of the system. Of course, this can be prevented by thehugetlb cgroup, but even if we set the limit for memcg and hugetlb cgrouprespectively, as I asked in the first mail(set limit to 10GB), thecontrol will not work.I thought I could charge surplus hugepages to memcg, but maybe I did nothave enough knowledge about memcg. I would like to reply to another mailfor details.Actually, I am opposed to the 64KB page, but the proposal to change thepage size is expected to be dismissed as a problem.--Thanks,Tsukada",Technical
,
"[...]Because they have already allocated from the buddy allocator so the endresult is very same.But this is simply not correct. Surplus pages are fluid. If you increasethe hugetlb size they will become regular persistent hugetlb pages.Not really. Memcg accounts primarily for reclaimable memory. We doaccount for some non-reclaimable slabs but the life time should be atleast bound to a process life time. Otherwise the memcg oom killerbehavior is not guaranteed to unclutter the situation. Hugetlb pages aresimply persistent. Well, to be completely honest tmpfs pages have asimilar problem but lacking the swap space for them is kindaconfiguration bug.Ohh, it is very much interested. The primary goal of memcg is to enforcethe limit. How are you going to do that in an absence of the reclaimablememory? And quite a lot of it because hugetlb pages usually consume alot of memory.It does change when ou change the hugetlb pool size, migrate pagesbetween per-numa pools (have a look at adjust_pool_surplus).--Michal HockoSUSE Labs",Technical
,
"[...]Sure, asking for guarantee makes hugetlb pages attractive. But nothingis really for free, especially any resource _guarantee_, and you have topay an additional configuration price usually.Why? I can see this would be quite a PITA but not really impossible.Not really, you can specify how much you can overcommit hugetlb pages.--Michal HockoSUSE Labs",Technical
,
"I really can not understand what's wrong with this. That page is obviouslyreleased before being added to the persistent pool, and at that time it isuncharged from memcg to which the task belongs(This assumes my patch-set).After that, the same page obtained from the pool is not surplus hugepageso it will not be charged to memcg again.Absolutely you are saying the right thing, but, for example, can mlock(2)edpages be swapped out by reclaim?(What is the difference between mlock(2)edpages and hugetlb page?)Simply kill any of the tasks belonging to that memcg. Maybe, no one wantsreclaim at the time of account of with surplus hugepages.[...]As I looked at, what kind of fatal problem is caused by charging surplushugepages to memcg by just manipulating counter of statistical information?--Thanks,Tsukada",Technical
,
"I do not see anything like that. adjust_pool_surplus is simply andaccounting thing. At least the last time I've checked. Maybe yourpatchset handles that?No mlocked pages cannot be reclaimed and that is why we restrict them toa relatively small amount.But that will not release the hugetlb memory, does it?Fatal? Not sure. It simply tries to add an alien memory to the memcgconcept so I would pressume an unexpected behavior (e.g. not being ableto reclaim memcg or, over reclaim, trashing etc.).--Michal HockoSUSE Labs",Technical
,
"[...][...]Yes. If do not support multiple size hugetlb pages such as x86, becausenumber of pages between THP and hugetlb is same, the failure rate ofobtaining a compound page is same, as you said.I think that what you say is absolutely right.I understand the superiority of THP, but there are scenes where khugepagedoccupies cpu due to page fragmentation. Instead of overcommit, setup apersistent pool once, I think that hugetlb can be superior, such as memoryallocation performance exceeding THP. I will try to find a good way to usehugetlb page.I sincerely thank you for your help.--Thanks,Tsukada",Technical
,
"Note.  You do not want to use THP because ""THP does not guarantee"".Using hugetlbfs overcommit also does not provide a guarantee.  Withoutdoing much research, I would say the failure rate for obtaining a hugepage via THP and hugetlbfs overcommit is about the same.  The mostdifficult issue in both cases will be obtaining a ""huge page"" number ofpages from the buddy allocator.I really do not think hugetlbfs overcommit will provide any benefit overTHP for your use case.  Also, new user space code is required to ""fall back""to normal pages in the case of hugetlbfs page allocation failure.  Thisis not needed in the THP case.--Mike Kravetz",Technical
,
"This is inconsistent with the ext2 and xfs implementations ...I'm worried this is too much complexity to push down to the filesystems.When should errors get reported through the return value; when should theybe reported through the errseq_t?Can we hide all of this?  Maybe ext4 could do:	errseq_set(&sb->s_wb_err, __sync_blockdev(sb->s_bdev, wait));	return ret;(we'd need to make calling errseq_set(x, 0) be a no-op instead of an error)and then the caller is the one who takes care of callingerrseq_check_and_advance() so we don't have to pass 'since' into eachfilesystem.",Technical
,
"Thanks, I wasn't sure about xfs. I'll drop this hunk.FWIW, I think pushing this call down into the sync_fs routines is stillprobably the right thing to do, regardless of the state of the laterpatches.I patterned the name after the call_mmap (and now-defunct call_fsync)helpers. I'll rename it and change it to be non-inlined.Thanks,--Jeff Layton <jlayton@kernel.org>",Technical
,
"An earlier patch that pushed this down into the sync_fs routines. Wecall this today for all filesystems, and I wasn't sure about xfs.Christoph already pointed out that it's not needed so it's removed frommy current branch.Ok, sounds good. I'll fix that too.FWIW, we'll actually want to advance the cursor even if xfs_log_forcereturns an error to ensure that we don't end up reporting errors twice,but that's simple enough to do.Thanks!--Jeff Layton <jlayton@kernel.org>",Technical
,
"XFS never uses the block device mapping for anything, so this isnot needed.The proper name for this would be vfs_sync_fs.  And I don't think itwarrants an inline.",Technical
,
"fs/udf/unicode.c also uses char2uni and uni2char but evades your SMPLpatch. So you'll need to fix that up manually. Also note that I have somechanges to that area queued in my tree.								Honza--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"Ah, OK, now I see that you've handled that in patch 3. Sorry for the noise.--Jan Kara <jack@suse.com>SUSE Labs, CR",Technical
,
"Hi Olaf,Thank you for the patch! Yet something to improve:[auto build test ERROR on linus/master][also build test ERROR on v4.17-rc7][cannot apply to next-20180530][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Gabriel-Krisman-Bertazi/NLS-refactor-and-UTF-8-normalization/20180522-234546config: openrisc-allmodconfig (attached as .config)compiler: or1k-linux-gcc (GCC) 6.0.0 20160327 (experimental)reproduce:        wget https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross        chmod +x ~/bin/make.cross        # save the attached .config to linux build tree        make.cross ARCH=openriscAll errors (new ones prefixed by >>):   make[3]: Target '__build' not remade because of errors.---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
"On Thu, May 24, 2018 at 4:24 PM, Sebastian Andrzej Siewior<bigeasy@linutronix.de> wrote:Hmm.  Don't we also need to cover suspend-to-idle?",Technical
,
"Well, if you agree with the approach then I would look into it.Sebastian",Technical
,
"On Thu, May 24, 2018 at 5:45 PM, Sebastian Andrzej Siewior<bigeasy@linutronix.de> wrote:As long as the SYSTEM_SUSPEND system state is defined unambiguously, Idon't have a problem with doing this.",Technical
,
Should be fixed in my for-next branch:https://git.kernel.org/pub/scm/linux/kernel/git/wsa/linux.git/commit/drivers/i2c/busses/i2c-i801.c?h=i2c/for-next&id=4b2f9bd5e39fb47011074c9a26b64b616acc18f0,Technical
,
"The help text above should be indented (as below), with one tab + 2 spaces.--~Randy",Technical
,
"   Sure, I will send v2 patch with the corrected indentation.Best Regards,Ladvine",Technical
,
"On Mon, May 28 2018 at 11:54am -0400,Arnd Bergmann <arnd@arndb.de> wrote:Thanks, I've picked this up.",Technical
,
"__builtin_expect returns always long, see the GCC documentation (it usedto return int in very old gcc versions such as 2.96).I think this is a bug in the macro __branch_check__. The variable ______rshould be long, but it is int. This bug may cause misbehavior of otherkernel parts (i.e. truncation of long value to int), so it should be fixedin __branch_check__ - not in dm-writecache.Mikulas",Technical
,
"On Wed, 30 May 2018 08:19:22 -0400 (EDT)Mikulas Patocka <mpatocka@redhat.com> wrote:Nice catch.I'm curious to what that bug was.Anyway, I can pull this in my tree and test it.-- Steve",Technical
,
"printk(""%ld"", writecache_has_error(wc))... and writecache_has_error was defined as#define writecache_has_error(wc)	(unlikely(READ_ONCE((wc)->error)))Mikulas",Technical
,
"On Mon, May 28, 2018 at 11:37 PM, Nick Desaulniers<nick.desaulniers@gmail.com> wrote:Eric points out this wont initialize the rest of the dest if src ifless than size.",Technical
,
"Hi,This should be the very first line.And this is redundant with the SPDX header.These two pinctrl property aren't needed.Each step should increase the perceived brightness by roughly 1/Nth, Nbeing the number of steps. Usually PWM backlights don't work like that.You can drop these two pinctrl properties as wellAnd all these nodes.Thanks!Maxime--Maxime Ripard, Bootlin (formerly Free Electrons)Embedded Linux and Kernel engineeringhttps://bootlin.com",Technical
,
"The X11 license notice states explicitly that the notice has to beincluded in the file.  Wouldn't removing it be a violation of the license?FYI, this was copied from another .dts file.  All of the otherbrightness-levels settings in sun{4,5,7}i .dts files follow similarpatterns:sun4i-a10-dserve-dsrv9703c.dts:               brightness-levels = <0 1020 30 40 50 60 70 80 90 100>;sun4i-a10-inet1.dts:          brightness-levels = <0 10 20 30 40 50 6070 80 90 100>;sun4i-a10-pov-protab2-ips9.dts:               brightness-levels = <0 1020 30 40 50 60 70 80 90 100>;sun5i-a13-empire-electronix-d709.dts:         brightness-levels = <0 1020 30 40 50 60 70 80 90 100>;sun5i-a13-utoo-p66.dts:       brightness-levels = <0 30 40 50 60 70 8090 100>;sun5i-gr8-evb.dts:            brightness-levels = <0 10 20 30 40 50 6070 80 90 100>;sun7i-a20-wexler-tab7200.dts:         brightness-levels = <0 10 20 30 4050 60 70 80 90 100>;I'll take the brightness-levels from sun8i-a83t-tbs-a711.dts whichfollows a more appropriate pattern:sun8i-a83t-tbs-a711.dts:              brightness-levels = <0 1 2 4 8 1632 64 128 255>;Thanks,Bob--Bob Ham <rah@settrans.net>for (;;) { ++pancakes; }",Technical
,
"Well, the top bit that I quoted above says that the licenses refer toonly that one file in particular and not the project as a whole.  Thenthe X11 license states that the notice can't be removed from 'thissoftware and associated documentation files (the ""Software"")' whichwould seem to refer to the single file.  Therefore, removing the noticefrom the single file and replacing it with an SPDX header would seem toviolate the license.It's a fine point but it makes me nervous.  I originally based my .dtson sun4i-a10-inet1.dts.  I've CC'd the original copyright holder, Hansde Goede.  Hans, are you willing to give permission for the licensenotice to be replaced with just an SPDX header indicating the duallicensing?While we're at it, there are a number of other files with the samelicense text.  Hans, are you prepared to give permission for your otherlicense notices to be replaced with SPDX headers?Thanks,Bob--Bob Ham <rah@settrans.net>for (;;) { ++pancakes; }",Technical
,
"Hi,Yes that is fine by me and you've my permission to switch to usingjust the SPDX header.FWIW I do not believe the ""can't be removed from 'this software andassociated documentation files (the ""Software"")'"" languageapplies to the software as a whole and not individual files.Yes you may make the same change to all files with my copyright.Regards,Hans",Technical
,
"Excellent, thanks! :-)--Bob Ham <rah@settrans.net>for (;;) { ++pancakes; }",Technical
,
Hi AlexanderThis looks a lot like phy_write_mmd().     Andrew,Technical
,
"Hi Andrewthanks for the hint. But actually I cannot confirm - or I don't see it yet.Without having tested, just from the code, the struct phy_driver instance for PHY_ID_KSZ8061 in micrel.c does not have a .write_mmd function assigned, thus phy_write_mmd should evaluate to its else-clause (see below) and not to mdiobus_write (as in phy_write).Also the ksz8061_extended_write() function which I have added uses the same principle as already existing HW-specific functions in micrel.c for simular reasons (kszphy_extended_write and ksz9031_extended_write).They use phy_write all over the place in that file and never phy_write_mmd - for whatever reason they had.Thus I thought it would be a good idea ...best regards, Alexstatic inline int phy_write(struct phy_device *phydev, u32 regnum, u16 val){	return mdiobus_write(phydev->mdio.bus, phydev->mdio.addr, regnum, val);}int phy_write_mmd(struct phy_device *phydev, int devad, u32 regnum, u16 val){	int ret;	if (regnum > (u16)~0 || devad > 32)		return -EINVAL;	if (phydev->drv->write_mmd) {		ret = phydev->drv->write_mmd(phydev, devad, regnum, val);	} else if (phydev->is_c45) {		u32 addr = MII_ADDR_C45 | (devad << 16) | (regnum & 0xffff);		ret = mdiobus_write(phydev->mdio.bus, phydev->mdio.addr,				    addr, val);	} else {		struct mii_bus *bus = phydev->mdio.bus;		int phy_addr = phydev->mdio.addr;		mutex_lock(&bus->mdio_lock);		mmd_phy_indirect(bus, phy_addr, devad, regnum);		/* Write the data into MMD's selected register */		bus->write(bus, phy_addr, MII_MMD_DATA, val);		mutex_unlock(&bus->mdio_lock);		ret = 0;	}	return ret;}-----Original Message-----From: Andrew Lunn <andrew@lunn.ch>Sent: Mittwoch, 6. Juni 2018 14:40To: Onnasch, Alexander (EXT) <Alexander.Onnasch@landisgyr.com>Cc: Florian Fainelli <f.fainelli@gmail.com>; netdev@vger.kernel.org; linux-kernel@vger.kernel.orgSubject: Re: [PATCH] net/phy: Micrel KSZ8061 PHY link failure after cable connectHi AlexanderThis looks a lot like phy_write_mmd().     Andrew",Technical
,
"Hi Andrewthanks for your feedback. I was on holiday, thus just delayed, not forgotten...Sorry for top-posting - odd company default mail setup.I checked again phy_write_mmd(), you are right !Patch with changed implementation will follow.Best regards, Alex-----Original Message-----From: Andrew Lunn <andrew@lunn.ch>Sent: Dienstag, 19. Juni 2018 17:29To: Onnasch, Alexander (EXT) <Alexander.Onnasch@landisgyr.com>Cc: Florian Fainelli <f.fainelli@gmail.com>; netdev@vger.kernel.org; linux-kernel@vger.kernel.orgSubject: Re: [PATCH] net/phy: Micrel KSZ8061 PHY link failure after cable connectHi AlexanderPlease don't top post. And wrap your lines at around 75 charactersLook closely at the two implementations. Look at whatmmd_phy_indirect() does. I _think_ these are identical. So don't add your own helper, please use the core code.     Andrew",Technical
,
Thanks Logan.Series:Acked-by: Allen Hubbe <allenbh@gmail.com>,Technical
,
Acked-by: Dave Jiang <dave.jiang@intel.com>for the Intel parts and the generic parts,Technical
,
"ntb.c is more of a glue layer, and this is more device specific.While I like adding it here for more common code, it should probablyreside in the ntb_hw_*.c files to enforce the hw specific code allreside in that layer.  So, this probably needs to be replaced with apatch which adds the setting of the mask to the switchtec driver.Thanks,Jon",Technical
,
"This is a very long way of saying ""no clients are checking the errorcodes, so removing them"". :)I think the history and references to follow-on patches are notnecessary in the commit message and belong more in a 0/X.This is more of a feature than a bug fix.  Can you break this (and thepingpong and perf changes caused by this) off into a separate series,as I'll want to apply this to the ntb-next and not bugfixes branch?Thanks,Jon",Technical
,
"I disagree strongly. You can tell it's not device specific seeing wehave 4 devices that need the exact same code. In fact, there is nothingdevice specific in those lines of code as the device specific part comeswhen a driver sets the PCI parent device's DMA mask. These lines justinitialize the dma_mask for the new NTB device with its parent's mask.This is just sensible given that nothing now works if it is not done andtrusting driver writers to get it right is not a good idea seeing wealready screwed it up once. Furthermore, it violates DRY (do not repeatyourself).If there is something driver specific that must be done (although Ican't actually imagine what this would be) the drivers are free tochange the mask after calling ntb_register but getting the common casesetup in common code is just good design.Logan",Technical
,
"Good day, Logan.Thanks for the patchset you submitted. My hopefully useful comments areunder the corresponding patches.Regards,-Sergey",Technical
,
"This is weird. Neither me nor the folks' who tested the script saw this warning.I tried it on my laptop with bash and on a target device with busybox-shell. Thewarning never occurred. I even tried a simple command like:[[ $(echo -ne ""\x4e\x0a\00"") == ""N"" ]] && echo ""True""It might be that your bash is more modern than mine. Anyway if this patch solves theproblem you see, that's great. Thanks for it.-Sergey",Technical
,
"As a part of the multi-port NTB API the port-index interface was freshlyintroduced. The main idea was to somehow address local/peer domains within oneNTB device, since from now there can be more than one peer domain to sendmessage to or to set MWs up with. For this we invented the two-spaces interfacewhich mapped in general non-linear ports space to the locally linear portsindexes space, and vise-versa. That mapping was implemented by new callbacks:ntb_port*()/ntb_peer_port*().Even though it perfectly fitted the IDT NTB functions, the Intel/AMD devicesdidn't have explicit ports numbering. Instead we decided to assign the numbersby using the topology type. So the Primary and B2B US sides got portNTB_PORT_PRI_USD, Secondary and B2B DS sides got port NTB_PORT_SEC_DSD.In order to make it being default for all pure two-ports devices likeIntel/AMD the new methods ntb_default_port_number() andntb_default_peer_port_number() were developed and utilized in thentb_port*()/ntb_peer_port*() API functions (see ntb.h header file).So to speak the main purpose of the default methods is to assign some uniqueport number to the NTB devices based on the topology at current implementation.Please note, that it is essential for the NTB API to have each port uniquelyenumerated within one device. This is the way the multi-port NTB API has beendesigned in the first place. That was the reason we altered the Intel/AMD andIDT drivers about two years ago.Based on this I redeveloped the ntb_tool/ntb_perf/ntb_pingpong drivers.Needless to say that I was sure all the NTB devices followed the API conventionregarding the port numbers. Since the Switchtec driver doesn't provide theexplicit port-index API callbacks, the NTB API internals uses the defaultmethods, which as you can see don't know anything about SWITCH and CROSSLINKtopologies. That's why the methods return -EINVAL so the test drivers don'twork properly.Concerning the fix of the discovered issues and fixes introduced by thispatchset. I'd suggest to add the ports-index callbacks to the Switchtecdriver, which identify local and peer ports. After this the current versionof all the test drivers shall perfectly work.As far as I can see the PFX family switches documentation operates with thedefinitions like Ports/Partitions (similar to the IDT switches) as well asthe switchtec management driver. It might be a clue to the switch functionality,which can be used to find something similar to the ports numbering.Regards,-Sergey",Technical
,
"Thanks for the patch. It was the original version of the ping-pong driver,I was going to submit. But I've decided to develop it a bit different. Andhere is why.My goal was to create the multi-port version of the ping-pong test.The idea of the new driver was to implement the cyclic port-to-portping-pong algorithm. Simply speaking each port selects two partner-ports,one partner would be used as the source of pings and another one would betarget of pongs sent to with the defined delay.Since IDT got a global Doorbell register, which is shared between allthe ports, I had to assign an unique doorbell bit to each port. I created asimple algorithm, which linearised in general non-linear port numbers.Then I used the globally unique port index to select the correspondingdoorbell bit. pp_init_flds() methods implements the corresponding algorithm,while pp_find_next_peer() performs the next port selection to convey thepong to.Regarding the patch. The idea of using the port number instead of linearisedunique index should also work for Intel/AMD/IDT drivers. But the ports-spacelinearization algorithm was created for the case if the real port numberswould exceed the available Doorbell bits. I thought this might be the case ofmulti-ports version of the switchtec driver.Needless to say, that if Switchtec driver had the ports-index API implementation,this patch wouldn't be needed.Regards,-Sergey",Technical
,
"Good catch. Thanks. IDT got a lot of MWs especially if LookUpTables areenabled. That's why I didn't find the effect of this error.Regards,-Sergey",Technical
,
"Please, see the comment to the patch 3/8. I explained everything thereincluding the fact, that the Intel/AMD drivers do have unique port numbersassigned.Regards,-Sergey",Technical
,
Well that will work for the simple switchtec case. The crosslinktopology CAN NOT produce port numbers like you ask. It is perfectlysymmetric and the two hosts cannot reliably figure out which is port 0and which is port 1. So these patches support this case.Logan,Technical
,
"Hmm, this behavior is the feature of the driver and isn't a bug or race to befixed. ntb_perf driver returns -ENOLINK until the link is actually established,when the memory windows are properly initialized so the test can be performed.What do you think of leaving the algorithm as is, but instead to developthe polling scheme in the ntb_test.sh script and break the script execution ifthe link isn't established after sometime? At least we won't need to wait foreverin case if the peer hanged up or crashed while the NTB link negotiation algorithmwas in-progress.Regards,-Sergey",Technical
,
"Good catch. Thanks for the patch. I discovered this problem myself a few daysbefore you sent this patchset. So was going to submit the fix, but you werefaster.I also tested this script in the looped-back setup. It is the case when twoNTB-device ports are available at the same RootComplex. So the NTB can beconfigured from the single executional context. In this case the REMOTE_HOST is leftempty, so the colon is left prepended to the corresponding paths and causes multipleerrors including the one fixed by this patch. In order to fix it, we need to discardthe colon for remote-less case, for instance, by the next patch:@@ -482,7 +495,11 @@ function perf_test() function ntb_tool_tests() { 	LOCAL_TOOL=""$DEBUGFS/ntb_tool/$LOCAL_DEV""-	REMOTE_TOOL=""$REMOTE_HOST:$DEBUGFS/ntb_tool/$REMOTE_DEV""+	if [[ ""${REMOTE_HOST}"" != """" ]]; then+		REMOTE_TOOL=""$REMOTE_HOST:$DEBUGFS/ntb_tool/$REMOTE_DEV""+	else+		REMOTE_TOOL=""$DEBUGFS/ntb_tool/$REMOTE_DEV""+	fi 	echo ""Starting ntb_tool tests...""And so on for REMOTE_PP and REMOTE_PERF. It is necessary for NTB devices, which portsare looped-back to the same Root-Port. Would you be amenable if you resent this patchtogether with the fix I suggested?Regards,-Sergey",Technical
,
"Well, the switchtec driver splits its 64 doorbells in two sets, one foreach port right now. That will likely have to change when we go to amulti-port implementation. In that case we will have 64 doorbells and amaximum 48 ports. So I don't think we have to concern ourselves withmore ports than doorbells.As I've said, it's impossible to write for the crosslink topology so theclients must support that case.Logan",Technical
,
"I think polling is really ugly and doesn't really address solve theissue of waiting forever. It's pretty easy to interrupt out of the waitand provides a much better clue to whats going on than an error.If we want to be more explicit, it would be pretty easy to start a timerin the bash script and use SIGALRM to exit if the link doesn't come upafter 30 seconds or something.Logan",Technical
,
See my comments as to why this is impossible.Logan,Technical
,
Thanks. It would be good to get Acked-bys or Reviewed-bys on the patchesyou approved.Logan,Technical
,
SLAB_PANIC was added to not worry about error handling.,Technical
,
"Hi,Thank you for the patch! Perhaps something to improve:[auto build test WARNING on linus/master][also build test WARNING on v4.17 next-20180608][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/linux-kernel-owner-vger-kernel-org/proc-add-error-handling-for-kmem_cache_create/20180612-122737config: i386-randconfig-x012-201823 (attached as .config)compiler: gcc-7 (Debian 7.3.0-16) 7.3.0reproduce:        # save the attached .config to linux build tree        make ARCH=i386All warnings (new ones prefixed by >>):   fs/proc/inode.c: In function 'proc_init_kmemcache':      return -ENOMEM;             ^   fs/proc/inode.c:96:13: note: declared here    void __init proc_init_kmemcache(void)                ^~~~~~~~~~~~~~~~~~~vim +/return +108 fs/proc/inode.c    95    96	void __init proc_init_kmemcache(void)    97	{    98		proc_inode_cachep = kmem_cache_create(""proc_inode_cache"",    99						     sizeof(struct proc_inode),   100						     0, (SLAB_RECLAIM_ACCOUNT|   101							SLAB_MEM_SPREAD|SLAB_ACCOUNT|   102							SLAB_PANIC),   103						     init_once);   104		pde_opener_cache =   105			kmem_cache_create(""pde_opener"", sizeof(struct pde_opener), 0,   106					  SLAB_ACCOUNT|SLAB_PANIC, NULL);   107		if (!proc_inode_cachep || !pde_opener_cache) > 108			return -ENOMEM;   109   110		proc_dir_entry_cache = kmem_cache_create_usercopy(   111			""proc_dir_entry"", sizeof(struct proc_dir_entry), 0, SLAB_PANIC,   112			offsetof(struct proc_dir_entry, inline_name),   113			sizeof_field(struct proc_dir_entry, inline_name), NULL);   114	}   115---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
"Hi Borys,Thank you for the patch! Perhaps something to improve:[auto build test WARNING on iio/togreg][also build test WARNING on v4.17 next-20180613][if your patch is applied to the wrong git tree, please drop us a note to help improve the system]url:    https://github.com/0day-ci/linux/commits/Borys-Movchan/dt-bindings-iio-light-add-ISL29033-device-bindings/20180613-220725base:   https://git.kernel.org/pub/scm/linux/kernel/git/jic23/iio.git togregreproduce:        # apt-get install sparse        make ARCH=x86_64 allmodconfig        make C=1 CF=-D__CHECK_ENDIAN__sparse warnings: (new ones prefixed by >>)vim +235 drivers/iio/light/isl29033.c   220   221	static int isl29033_read_sensor_input(struct isl29033_chip *chip)   222	{   223		int ret;   224		u16 val;   225		struct device *dev = regmap_get_device(chip->regmap);   226   227		ret = regmap_bulk_read(chip->regmap, ISL29033_REG_ADD_DATA_LSB,   228					(u8 *)&val, 2);   229		if (ret < 0) {   230			dev_err(dev,   231				""Data bulk read error %d\n"", ret);   232			return ret;   233		}   234 > 235		val = be16_to_cpu(val);   236		dev_vdbg(dev, ""Data read: %x\n"", val);   237   238		return val;   239	}   240---0-DAY kernel test infrastructure                Open Source Technology Centerhttps://lists.01.org/pipermail/kbuild-all                   Intel Corporation",Technical
,
Commit msg missingPreferred name if there only one compatible is the full compatiblestring plus '.txt'.-ohms and -micro-ohms are the documented units. Please use '-ohms'unless there is a compelling reason not to.light-sensor is the documented node name for ALSs.,Technical
,
"The grammer is now incorrect :(Shouldn't we just have a SPDX line at the top here and this whole boilerplate text be removed?thanks,greg k-h",Technical
,
"Sure, will get right to it. I am actually newbie to all this.I watched your tutorial on youtube when you were at FOSDEM,Huge help, thank you for that.",Technical
,
"Are you sure you are not changing the logic here?I think it'd be nicer to refactor the code instead.Something like:--- drivers/staging/rtl8712/rtl871x_mlme.c | 73 +++++++++++++++++----------------- 1 file changed, 36 insertions(+), 37 deletions(-)diff --git a/drivers/staging/rtl8712/rtl871x_mlme.c b/drivers/staging/rtl8712/rtl871x_mlme.cindex ac547ddd72d1..d711305b33e1 100644--- a/drivers/staging/rtl8712/rtl871x_mlme.c+++ b/drivers/staging/rtl8712/rtl871x_mlme.c@@ -552,6 +552,19 @@ void r8712_survey_event_callback(struct _adapter *adapter, u8 *pbuf) 	spin_unlock_irqrestore(&pmlmepriv->lock2, flags); }+static bool r8712_under_linking_then_join(struct mlme_priv *pmlmepriv)+{+	set_fwstate(pmlmepriv, _FW_UNDER_LINKING);++	if (r8712_select_and_join_from_scan(pmlmepriv) != _SUCCESS)+		return false;++	mod_timer(&pmlmepriv->assoc_timer,+		  jiffies + msecs_to_jiffies(MAX_JOIN_TIMEOUT));++	return true;+}+ void r8712_surveydone_event_callback(struct _adapter *adapter, u8 *pbuf) { 	unsigned long irqL;@@ -565,45 +578,31 @@ void r8712_surveydone_event_callback(struct _adapter *adapter, u8 *pbuf) 		_clr_fwstate_(pmlmepriv, _FW_UNDER_SURVEY); 	}-	if (pmlmepriv->to_join) {-		if (check_fwstate(pmlmepriv, WIFI_ADHOC_STATE)) {-			if (!check_fwstate(pmlmepriv, _FW_LINKED)) {-				set_fwstate(pmlmepriv, _FW_UNDER_LINKING);+	if (!pmlmepriv->to_join)+		goto exit;++	if (check_fwstate(pmlmepriv, WIFI_ADHOC_STATE)) {+		if (check_fwstate(pmlmepriv, _FW_LINKED) ||+		    r8712_under_linking_then_join(pmlmepriv))+			goto exit;++		pmlmepriv->fw_state ^= _FW_UNDER_SURVEY;+		memcpy(&adapter->registrypriv.dev_network.Ssid,+		       &pmlmepriv->assoc_ssid,+		       sizeof(struct ndis_802_11_ssid));+		r8712_update_registrypriv_dev_network(adapter);+		r8712_generate_random_ibss(adapter->registrypriv.dev_network.MacAddress);+		pmlmepriv->fw_state = WIFI_ADHOC_MASTER_STATE;+		pmlmepriv->to_join = false;+	} else {+		pmlmepriv->to_join = false;+		if (r8712_under_linking_then_join(pmlmepriv))+			goto exit;-				if (r8712_select_and_join_from_scan(pmlmepriv)-				    == _SUCCESS) {-					mod_timer(&pmlmepriv->assoc_timer, jiffies +-						  msecs_to_jiffies(MAX_JOIN_TIMEOUT));-				} else {-					struct wlan_bssid_ex *pdev_network =-					  &(adapter->registrypriv.dev_network);-					u8 *pibss =-						 adapter->registrypriv.-							dev_network.MacAddress;-					pmlmepriv->fw_state ^= _FW_UNDER_SURVEY;-					memcpy(&pdev_network->Ssid,-						&pmlmepriv->assoc_ssid,-						sizeof(struct-							 ndis_802_11_ssid));-					r8712_update_registrypriv_dev_network-						(adapter);-					r8712_generate_random_ibss(pibss);-					pmlmepriv->fw_state =-						 WIFI_ADHOC_MASTER_STATE;-					pmlmepriv->to_join = false;-				}-			}-		} else {-			pmlmepriv->to_join = false;-			set_fwstate(pmlmepriv, _FW_UNDER_LINKING);-			if (r8712_select_and_join_from_scan(pmlmepriv) ==-			    _SUCCESS)-				mod_timer(&pmlmepriv->assoc_timer, jiffies +-					  msecs_to_jiffies(MAX_JOIN_TIMEOUT));-			else-				_clr_fwstate_(pmlmepriv, _FW_UNDER_LINKING);-		}+		_clr_fwstate_(pmlmepriv, _FW_UNDER_LINKING); 	}++exit: 	spin_unlock_irqrestore(&pmlmepriv->lock, irqL); }",Technical
,
"Actually this binding already exists for mediatek timers, it is uselessto add a new one.I note the binding inDocumentation/devicetree/bindings/timer/mediatek,mtk-timer.txtcontains: clocks = <&system_clk>, <&rtc_clk>However the existing driver does only use <&system_clk> AFAICT, I'mquestioning if <&rtc_clk> is really needed.So, I suggest you sort out and fixup the rtc_clk thing (drop it) andthen just add your new platform in the list in this binding.-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Technical
,
Recent platforms have the arch_arm_timer and it will be always selected.What is the benefit of adding this timer ?-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog,Technical
,
"Hi Daniel,To save power as much as possible, our platform enables""arch_timer_c3stop"" in arch_arm_timer, and thus another always-on timeris required for tick-broadcasting. System Timer is introduced for abovepurpose.Thanks.Stanley Chu",Technical
,
Obviously :)-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog,Technical
,
"Please merge mtk_systimer.c and mtk_timer.c into a single file:timer-mediatek.cPatch 1: git mv mtk_timer.c timer-mediatek.c Change the name in MakefilePatch 2: Change function prefix name to _gpt_Patch 2.1 [optional but recommended] : Move the gpt's init code to timer-ofPatch 3: Add code for syst in timer-mediatek.cA couple of comments below.Wouldn't make sense to clear the interrupt after disabling the timer ?Why do you need IRQF_TRIGGER_HIGH ?Why IRQF_PERCPU ?No ""mediatek,sys_timer"" but eg. ""mediatek,mt6765"", so it is consistentwith the DT binding.-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Technical
,
"Hi Daniel,OK! We'll fix it and merge two timers into single document file in v3.Thanks.Stanley Chu",Technical
,
"Thanks for suggestion.Will do above all in v3.The comment may mislead readers.The first step, we do both things in the same time,1. Clear interrupt status.2. Disable interrupt engine in timer hardware, so the interrupt cannotcome repeatedly.After that, we shall be safe enough to do followings.Both flags are wrong and will be removed.We will sort out bindings of these two timers in v3.Thanks.Stanley Chu",Technical
,
"Hi Shunyong,Thanks for the patch, but Andrew Jones has also posted a patch[1] whichI had a look but was not sure what is the best approach to fix it yet.I will think about it and respond to that.--Regards,Sudeep[1] https://patchwork.kernel.org/patch/10482261",Technical
,
"I'll send a v1 yet today. The RFC version was actually OK, as the concernwith ACPI nodes not being in the expected order wasn't actually a problem.The thread-id or core-id would only be reset to zero when a yet to beremapped core-id (and all its peers) was found when iterating the PEs.Since all peers were handled at the same time, the counter reset wascorrect, even when the ACPI nodes were out-of-order. The code didn't makethat very obvious, though, and there was some room for other cleanups,so I've reworked it. Once I run it through a couple more rounds of testingI'll repost.FYI, I'm able to easily test a variety of configs using a KVM guest andthis QEMU branch[*]. To use threads it's necessary to revert the lastQEMU patch and to hack KVM to set MPIDR.MT for the VCPUs.Thanks,drew[*] https://github.com/rhdrjones/qemu/commits/virt-cpu-topology",Technical
,
"OK sure. I liked the approach in Shunyong's patch. I was thinking if wecan avoid the list and dynamic allocation on each addition and make itmore simpler.--Regards,Sudeep",Technical
,
"This one reads simpler, but yes I agree we should try to avoid thedynamic allocation.OTOH, I think that dropping the dynamic allocation leads to an algorithmthat picks a value and replaces all the matches. Which of course isAndrew's patch, although I did have to read it a couple times to get agrasp how it works. I'm guessing that is due to the fact that he seemsto have optimized 3 double loops into a single loop with two individualnested loops. AKA its probably more efficient than the naiveimplementation, but readability seems to have suffered a bit in theinitial version he posted. I'm not sure the optimization is worth it,but I'm guessing there is a middle ground which makes it more readable.Finally, @Shunyong, thanks for putting the effort into this...",Technical
,
"[...]Completely agree. RFC from Andrew is not so readable and easy to understand.--Regards,Sudeep",Technical
,
"Middle ground coming up. At the expense of a triple-nested loop (whichwill never be N^3 iterations due to conditions at the start of each loop),we can avoid dynamic allocations and list iterations and still gainreadability.Thanks,drew",Technical
,
"Hi, AllI have a new approach. As we've already got the offset of the node with physical package bit set, which is the parent of the cpu we are querying. We can iterate from the begining of PPTT to count the nodes with physical package bit set till we reach the offset we've got. Then, the count value is the package id. This avoid list and dynamic allocation. And PPTT provides length for each node, iteration should be easy.I think this may implemented in pptt.c.I am writing this mail on my phone. Maybe I should try to write a patch to test in office tomorrow if you think it's feasible.Thanks.Shunyong.",Technical
,
"I was thinking of simple solution like add the offset to sorted arrayand assign the index to that. In this way if ACPI_PROCESSOR_ID_VALIDflag is set at the package level too and they start and increaselinearly from 0, we are matching them(requires 1 line change I posted inthe other thread)--Regards,SudeepIMPORTANT NOTICE: The contents of this email and any attachments are confidential and may also be privileged. If you are not the intended recipient, please notify the sender immediately and do not disclose the contents to any other person, use it for any purpose, or store or copy the information in any medium. Thank you.",Technical
,
I'm assuming this is no longer needed now that we have queued the seriesfrom Sudeep?Will,Technical
,
"Hi Will,[..]The series relating to topology/numa that you have queued helps us tore-introduces numa mask check that was reverted partial in v4.18 and isnot related to the issue reported or addressed by this patch.However, there's no proper solution to the issue reported in this threadand the one from Andrew Jones[1]. The only solution is to rely on ACPIfirmware for that instead of trying to fix in OS and we have alreadymerged the patch to fix that in acpi/pptt.c (Commit 30998033f62a (""ACPI/ PPTT: use ACPI ID whenever ACPI_PPTT_ACPI_PROCESSOR_ID_VALID is set""))In short, all the know issues are addressed so far and nothing elseneeds to be queued for now.--Regards,Sudeep[1]https://lore.kernel.org/lkml/20180629180308.zdl4taihzv2zwarc@kamzik.brq.redhat.com/T/#t",Technical
,
Same problem here :(,Technical
,
"Hi Greg,I wasn't expecting you to put them into your tree - the general concept/implementation is still too immature for that, let alone the commit messages :) However, I'll address this before sending another spin of the patches.Sorry for the noise and thanks for the quick response.Andrew",Technical
,
Will fix.,Technical
,
Will fix.,Technical
,
"It got a bit perverse from attempting to separate the devicetree handling from everything else. I'll fix the issues you've pointed out and rework the sysfs/kobj stuff.However, the patch (and the series) was intended as a straw man. I should have put more effort in to avoid some of the distraction (sorry), but I was also hoping to get feedback on the general approach (so devicetree design and how to expose the bits to userspace in a useful manner).Regarding the class, yeah, it's probably not the right choice and I'm not going to double down on it, but it collates the fields in an easy to discover location. Not doing something like this means a lot of grubbing around in /sys/device. Is there a better approach?Thanks for the feedback so far.Andrew",Technical
,
No changelog :(,Technical
,
"(cc'ing Peter and Ingo for lockdep)Hello, Sebastian.So, irq is always disabled in cgroup_rstat_flush_locked().Yes, the cpu locks should be irqsafe too; however, as irq is alwaysdisabled in that function, save/restore is redundant, no?We at least used to do this in the kernel - manipulating irqsafe lockswith spin_lock/unlock() if the irq state is known, whether enabled ordisabled, and ISTR lockdep being smart enough to track actual irqstate to determine irq safety.  Am I misremembering or is thisdifferent on RT kernels?Thanks.--tejun",Technical
,
"Hi Tejun,on not RT enabled kernels. On RT enabled kernels spin_lock_irq.*() isturned into a sleeping spinlock which do not disable interrupts.as I pointed out above only the raw_spin_lock_t really disablesinterrupts on -RT. That is the difference between those two.No, this is correct. So on !RT kernels the spin_lock_irq() disablesinterrupts and the raw_spin_lock() has the interrupts already disabled,everything is good. On RT kernels the spin_lock_irq() does not disableinterrupts and the raw_spin_lock() acquires the lock with enabledinterrupts and lockdep complains properly.lockdep sees the hardirq path via: {IN-HARDIRQ-W} state was registered at:   lock_acquire+0x9e/0x250   _raw_spin_lock_irqsave+0x38/0x50   cgroup_rstat_updated+0x57/0x100   cgroup_base_stat_cputime_account_end.isra.6+0x17/0x60   __cgroup_account_cputime_field+0x49/0x60   account_system_index_time+0xdb/0x1f0   account_system_time+0x3f/0x70   account_process_tick+0x59/0x80   update_process_times+0x1d/0x50   tick_sched_handle+0x20/0x60   tick_sched_timer+0x37/0x80   __hrtimer_run_queues+0x12c/0x6d0   hrtimer_interrupt+0xed/0x240   smp_apic_timer_interrupt+0x89/0x3c0   apic_timer_interrupt+0xf/0x20   pin_current_cpu+0xa/0x120   migrate_disable+0x9a/0x200   rt_spin_lock+0x1d/0x60   put_unused_fd+0x2c/0x50   do_sys_open+0x23a/0x250   __x64_sys_openat+0x1b/0x20   do_syscall_64+0x50/0x190   entry_SYSCALL_64_after_hwframe+0x49/0xbeSebastian",Technical
,
ping.Sebastian,Technical
,
"Hello, Sebastian.I feel weary about applying a patch which isn't needed in mainline,especially without annotations or at least comments.  I suppose it maynot be too common but this can't be the only place which needs thisand using irqsave/restore spuriously in all those sites doesn't soundlike a good solution.  Is there any other way of handling this?Thanks.--tejun",Technical
,
"This looks much better than the previous version.Yes, I think we need device links between the users of the powerdomains and the PGC devices. Since this is one of the use-cases forwhich device links were conceived I would guess that implementing thisshould be fairly straight-forward.If possible the regulator should also be disabled in the system suspendpath, as this might reduce power consumption some more. But then thismight have issues with suspend ordering of the regulator.As I don't want to send you down the rabbit hole too much with addingordering to this stuff, I won't object to this going in as-is. If thisis in fact due to a ordering limitation I would like to see thisdocumented in a code comment.Regards,Lucas",Technical
,
"I think anything is useful, thanks..The truth is that nobody is left that seems to really understand thiscode and syzkaller has shown it is full of various bugs..If there is someone out there that would like to tackle it, let meknow. There might be a possibility to support such work.Jason",Technical
,
"Bernd Edlinger <bernd.edlinger@hotmail.de> writes:You should use prefix ""nl80211: "" in the title.https://wireless.wiki.kernel.org/en/developers/documentation/submittingpatches#subject--Kalle Valo",Technical
,
"Thanks for cleaning this up!Correct.Yeah, I think this is fine.Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>--Josh",Technical
,
"2018-07-10 4:21 GMT+09:00 Josh Poimboeuf <jpoimboe@redhat.com>:Thanks for your review!I have one question.The package information is contained in the warning/error message.Is it better to keep this?If so, I will send v2to move the information to the help, like this: config STACK_VALIDATION         bool ""Compile-time stack metadata validation""         depends on HAVE_STACK_VALIDATION         depends on $(success,echo ""int main() {}"" | $(HOSTCC) -xc -o/dev/null -lelf -)         help          Add compile-time checks to validate stack metadata, including frame          pointers (if CONFIG_FRAME_POINTER is enabled).  This helps ensure          that runtime stack traces are more reliable.          This is also a prerequisite for generation of ORC unwind data, which          is needed for CONFIG_UNWINDER_ORC.+         To enable this, the host compiler needs to be able to link libelf.+         If it is missing, please install libelf-dev, libelf-devel or+         elfutils-libelf-devel.          For more information, see          tools/objtool/Documentation/stack-validation.txt.--Best RegardsMasahiro Yamada",Technical
,
"On Mon, 9 Jul 2018 14:05:02 +0800Mars Cheng <mars.cheng@mediatek.com> wrote:Acked-by: Marc Zyngier <marc.zyngier@arm.com>	M.--Without deviation from the norm, progress is not possible.",Technical
,
"As you can see, we have a long list of SoCs which are poorly supported.I'm not very keen to just add another SoC which supports booting into a ramdiskusing the serial console. Do you have a roadmap adding mainline support for thisSoC?Regards,Matthias",Technical
,
"Yes, that's a valid concern.mt6755 and mt6795 are in a similar state, the latter after three years.I'm all for supporting new SoCs, but this feels looks a box-tickingexercise (""hey, look, our SoC is supported in mainline"") which doesn'thelp anyone.My Ack still stands, but I'd definitely like to see some more completesupport before this patch goes in.Thanks,	M.--Jazz is not dead. It just smells funny...",Technical
,
"Hi Matthias/MarcYes, we do arrange more resources to do upstream task for mt6765,clk/pinctrl drivers are almost ready to submit. systimer is underreviewing (v9).http://lists.infradead.org/pipermail/linux-mediatek/2018-July/013989.htmlother drivers includingpmic/pwrap/i2c/rtc/kpd/spi/wdt/cqdma/auxadc/pwm/cmdq/disp. We havededicated owners to handle them and will cowork tightly with members tomake sure things happen in the following weeks.For previous chips, we did have no enough support after shell. It is dueto fast pace of smartphone SoC and other resource issues. We also knowthat is no excuse so that we already confirmed owners and theirschedules for mt6765.If there is any suggestion, please let us know.Thanks.",Technical
,
"Ok, so let's wait until pinctrl driver is submitted. I'd prefer if you could addthe clk driver to this series. This way we can get rid of the dummy clocks inthe device tree.I know that smartphone SoC is a fast paced business. Never the less I'mconvinced that the basic building blocks won't change much from one version toanother. And that mainline support for the previous version of your SoC willhelp you to get your new drivers faster upstream.For me the best example is the mt7622 which got to a reasonable upstream supportquite fast, thanks to a good foundation of mt7623 in mainline. I'd love to seethat happen on the smartphone SoCs as well.Not to mention that upstream support will help you internally when you have torebase your BSP code-base to a new kernel version.That said I think it is good news that you have already defined owner for thedifferent devices and hope to see submissions for them in the near future :)As a suggestion I would say that upstream submission takes time and effort andit will help your engineers if they can allocate some time to do so. But that'smost probably a management decision and all engineers know that management basesit's decision on some hard-to-understandable abbreviations like EBITDA etc. ;)Best regards,Matthias",Technical
,
"Hi Matthias[...]Got it, I will submit this series with clk support in v5. and pinctrlafter that.Thanks for your suggestions. We will try to catch up on this mission :-)",Technical
,
"Hi Andrew,In fact, it's not just trying to avoid confusing users. Kexec loadingand kexec_file loading are just do the same thing in essence. Just weneed do kernel image verification on uefi system, have to port kexecloading code to kernel.Kexec has been a formal feature in our distro, and customers owningthose kind of very large machine can make use of this feature to speedup the reboot process. On uefi machine, the kexec_file loading willsearch place to put kernel under 4G from top to down. As we know, the1st 4G space is DMA32 ZONE, dma, pci mmcfg, bios etc all try to consumeit. It may have possibility to not be able to find a usable space forkernel/initrd. From the top down of the whole memory space, we don'thave this worry.And at the first post, I just posted below with AKASHI'swalk_system_ram_res_rev() version. Later you suggested to uselist_head to link child sibling of resource, see what the code changelooks like.http://lkml.kernel.org/r/20180322033722.9279-1-bhe@redhat.comThen I posted v2http://lkml.kernel.org/r/20180408024724.16812-1-bhe@redhat.comRob Herring mentioned that other components which has this tree structhave planned to do the same thing, replacing the singly linked list withlist_head to link resource child sibling. Just quote Rob's words asbelow. I think this could be another reason.~~~~~ From RobThe DT struct device_node also has the same tree structure withparent, child, sibling pointers and converting to list_head had beenon the todo list for a while. ACPI also has some tree walkingfunctions (drivers/acpi/acpica/pstree.c). Perhaps there should be acommon tree struct and helpers defined either on top of list_head or a~~~~~new struct if that saves some size.Kexec was invented for kernel developer to speed up their kernelrebooting. Now high end sever admin, kernel developer and QE are alsokeen to use it to reboot large box for faster feature testing, bugdebugging. Kernel dev could know this well, about kernel loadingposition, admin or QE might not be aware of it very well.Understood. The list_head replacing patch truly involes too many codechanges, it's risky. I am willing to try any idea from reviewers, won'tpersuit they have to be accepted finally. If don't have a try, we don'tknow what it looks like, and what impact it may have. I am fine to takeAKASHI's simple version of walk_system_ram_res_rev() to lower risk, eventhough it could be a little bit low efficient.ThanksBaoquan",Technical
,
Please let's get all this into the changelogs?The larger patch produces a better result.  We can handle it ;),Technical
,
I do not have the full context here but let me note that you should becareful when doing top-down reservation because you can easily get intohotplugable memory and break the hotremove usecase. We even warn whenthis is done. See memblock_find_in_range_node--Michal HockoSUSE Labs,Technical
,
"Hi Andrew,Sorry for late reply because of some urgent customer hotplug issues.I am rewriting all change logs, and cover letter. Then found I was wrongabout the 2nd reason. The current kexec_file_load callskexec_locate_mem_hole() to go through all system RAM region, if oneregion is larger than the size of kernel or initrd, it will search aposition in that region from top to down. Since kexec will jump to 2ndkernel and don't need to care the 1st kernel's data, we can always finda usable space to load kexec kernel/initrd under 4G.So the only reason for this patch is keeping consistent with kexec_loadand avoid confusion.And since x86 5-level paging mode has been added, we have another issuefor top-down searching in the whole system RAM. That is we supportdynamic 4-level to 5-level changing. Namely a kernel compiled with5-level support, we can add 'no5lvl' to force 4-level. Then jumping froma 5-level kernel to 4-level kernel, e.g we load kernel at the top ofsystem RAM in 5-level paging mode which might be bigger than 64TB, thentry to jump to 4-level kernel with the upper limit of 64TB. For thiscase, we need add limit for kexec kernel loading if in 5-level kernel.All this mess makes me hesitate to choose a deligate method. Maybe Ishould drop this patchset.For this issue, if we stop changing the kexec top down searching code,I am not sure if we should post this replacing with list_head patchesseparately.ThanksBaoquan",Technical
,
"Kexec read kernel/initrd file into buffer, just search usable positionsfor them to do the later copying. You can see below struct kexec_segment,for the old kexec_load, kernel/initrd are read into user space buffer,the @buf stores the user space buffer address, @mem stores the positionwhere kernel/initrd will be put. In kernel, it callskimage_load_normal_segment() to copy user space buffer to intermediatepages which are allocated with flag GFP_KERNEL. These intermediate pagesare recorded as entries, later when user execute ""kexec -e"" to triggerkexec jumping, it will do the final copying from the intermediate pagesto the real destination pages which @mem pointed. Because we can't touchthe existed data in 1st kernel when do kexec kernel loading. With myunderstanding, GFP_KERNEL will make those intermediate pages beallocated inside immovable area, it won't impact hotplugging. But the@mem we searched in the whole system RAM might be lost along withhotplug. Hence we need do kexec kernel again when hotplug event isdetected.#define KEXEC_CONTROL_MEMORY_GFP (GFP_KERNEL | __GFP_NORETRY)struct kexec_segment {        /*         * This pointer can point to user memory if kexec_load() system         * call is used or will point to kernel memory if         * kexec_file_load() system call is used.         *         * Use ->buf when expecting to deal with user memory and use ->kbuf         * when expecting to deal with kernel memory.         */        union {                void __user *buf;                void *kbuf;        };        size_t bufsz;        unsigned long mem;        size_t memsz;};ThanksBaoquan",Technical
,
"I am not sure I am following. If @mem is placed at movable node then thememory hotremove simply won't work, because we are seeing reserved pagesand do not know what to do about them. They are not migrateable.Allocating intermediate pages from other nodes doesn't really help.The memblock code warns exactly for that reason.--Michal HockoSUSE Labs",Technical
,
"OK, I forgot the 2nd kernel which kexec jump into. It won't impact hotremovein 1st kernel, it does impact the kernel which kexec jump into if kernelis at top of system RAM and the top RAM is in movable node.",Technical
,
It will affect the 1st kernel (which does the memblock allocationtop-down) as well. For reasons mentioned above.--Michal HockoSUSE Labs,Technical
,
"And btw. in the ideal world, we would restrict the memblock allocationtop-down from the non-movable nodes. But I do not think we have thatinformation ready at the time when the reservation is done.--Michal HockoSUSE Labs",Technical
,
"Oh, you could mix kexec loading up with kdump kernel loading. For kdumpkernel, we need reserve memory region during bootup with memblockallocator. For kexec loading, we just operate after system up, and donot need to reserve any memmory region. About memory used to load them,it's quite different way.ThanksBaoquan",Technical
,
I didn't know about that. I thought both use the same underlyingreservation mechanism. My bad and sorry for the noise.--Michal HockoSUSE Labs,Technical
,
Not at all. It's truly confusing. I often need take time to recall thosedetails.,Technical
,
"Hi Mathieu,The patch looks correct to me. In fact I have a patch [1], whichdoes the same thing and switches to using per-cpu variable for thepaths.I think it is safe to use cpu_online_mask outside theget/put_online_cpus(). Using present_mask may fail aswe could fail to create a path for a CPU that is not online.Please could you check if [1] fixes the problem for you ?[1]http://lists.infradead.org/pipermail/linux-arm-kernel/2018-July/591606.htmlCheersSuzuki",Technical
,
"Not only did you beat me to the punch but I think using a per-cpuvariable is cleaner, so let's go with yours.Mathieu",Technical
,
"This will still deadlock if ->runtime_suspend commences before thehotplug event and the hotplug event occurs before polling has beendisabled by ->runtime_suspend.The correct fix is to call pm_runtime_get_sync() *conditionally* inthe atomic commit which enables the display, using the same conditionalas d61a5c106351, i.e. if (!drm_kms_helper_is_poll_worker()).Now I realize I sent you down the wrong path when I suggested tointroduce a DRM helper here.  My apologies, I didn't fully appreciatewhat is going awry here!Anything that happens in nouveau's poll worker never needs to acquirea runtime PM ref because polling is only enabled while runtime active,and ->runtime_suspend waits for an ongoing poll to finish.Thinking a bit more about this, our mistake is to acquire runtime PMrefs too far down in the call stack.  As a fix that can be backportedto stable, adding if (!drm_kms_helper_is_poll_worker()) conditionalsseems fine to me, but the long term fix is to push acquisition of refsfurther up in the call stack.E.g., if the user forces connector probing via sysfs, a runtime PM refshould be acquired in status_store() in drm_sysfs.c before invokingconnector->funcs->fill_modes().  That way, if the user forces connectorprobing while the GPU is powering down, rpm_resume() will correctly waitfor rpm_suspend() to finish before resuming the card.  So if we architectit like this, we're actually using the functionality provided by thePM core in the way that it's supposed to be used.The problem is that adding pm_runtime_get_sync() to status_store()conflicts with the desire to have a library of generic DRM functions:Some GPUs may be able to probe connectors without resuming to runtimeactive state, others don't use runtime PM at all.  One solution thatcomes to mind is a driver_features flag which tells the DRM core whetherto acquire a runtime PM ref in various places.In your original patches 4 and 5, what exactly was the call stack whichled to i2c being accessed while runtime suspended?  Was it sysfs accessvia /sys/class/i2c-adapter/* ?  If so, acquisition of the runtime PM refneeds to likewise happen in that sysfs entry point, rather than deep downin the call stack upon accessing the i2c bus.Thanks,Lukas",Technical
,
"Hm, a runtime PM ref is already acquired in nouveau_connector_detect().I'm wondering why that's not sufficient?Thanks,Lukas",Technical
,
"                      ^^^^^^As an additional note, I realized this might seem wrong but it isn'tpm_runtime_put_sync() calls down to nouveau's runtime idle callback, whichdoes this:static intnouveau_pmops_runtime_idle(struct device *dev){	if (!nouveau_pmops_runtime()) {		pm_runtime_forbid(dev);		return -EBUSY;	}	pm_runtime_mark_last_busy(dev);	pm_runtime_autosuspend(dev);	/* we don't want the main rpm_idle to call suspend - we want toautosuspend */	return 1;}So, it doesn't actually synchronously suspend the GPU, it just starts up theautosuspend threadJust wanted to make sure there wasn't any confusion :)--Cheers,	Lyude Paul",Technical
,
"Why do we need all this? i915 has full rpm support, including i2c and dpaux correctly working, and everything else too. Why is nouveau special?Also, there's a metric pile of other drivers using the existing helpers aninfrastructure, with full rpm support, all seemingly being happy too.Given all that it smells a bit like nouveau has it's rpm design backwards,which would indicate that these new helpers should be nouveau-specificwrappers and not generic. If that's not the case, then I'd like to firstunderstand why nouveau needs them and why no one else seems to need these.-Daniel--Daniel VetterSoftware Engineer, Intel Corporationhttp://blog.ffwll.ch",Technical
,
"Because there's a difference between DPMST connectors and encoders vs. therest of the device's encoders. Every DP MST topology will take up a single""physical"" DP connector on the device that will be marked as disconnected.This connector also owns the ""mstm"" (MST manager, referred to as thedrm_dp_mst_topology_mgr in DRM), which through the callbacks nouveau providesis responsible for creating the fake DP MST ports and encoders. All of thesefake ports will have DPMST encoders as opposed to the physical DP ports, whichwill have TMDS encoders. Hence-mstms are only on physical connectors withTMDS, not fake connectors with DPMST.--Cheers,	Lyude Paul",Technical
,
"Hoping for some review from Gergory, Ralph or Richard who all seemto use this driver!Yours,Linus Walleij",Technical
,
"Hi Linus and AditaWould it be possible to resend the series adding me in CC?  I wouldlike to comment the patches, but unfortunately it seems that I was innone of the mailing list where the series had been sent.I found the patches on patchwork, and started to have a look on it forexample, in the patch ""gpio: mvebu: Add support for multiple PWM linesper GPIO chip"", I wonder why the id is stored as it was not used at all.Having the patch inlined in an email would male the review easier.Thanks,Gregory--Gregory Clement, Bootlin (formerly Free Electrons)Embedded Linux and Kernel engineeringhttp://bootlin.com",Technical
,
Same for me :),Technical
,
"Sorry, for the noise, but please use my gmail address.Thanks !Richard",Technical
,
"CC hexagonhexagon != H8/300 != SuperHThe version in asm-generic deoes use ""unsigned long"".See also ""m68k/bitops: convert __ffs to match generic declaration""https://git.kernel.org/pub/scm/linux/kernel/git/geert/linux-m68k.git/commit/?h=for-v4.19&id=4b538d3dca3e590cdb0234746011a6d9c245cfa3Same hereGr{oetje,eeting}s,                        Geert--Geert Uytterhoeven -- There's lots of Linux beyond ia32 -- geert@linux-m68k.orgIn personal conversations with technical people, I call myself a hacker. Butwhen I'm talking to journalists I just say ""programmer"" or something like that.                                -- Linus Torvalds",Technical
,
"Hi Geert,Thanks for all your catches here.  So ffs() and fls() return int,while __ffs() and __fls() return unsigned long.(hm, arch/arc/include/asm/bitops.h is a little different.)(and unicore32)I'll send a v2 patch (for hexagon).That will still fix the printk format warning above.--~Randy",Technical
,
"Do you want me to try to write a patch that does that change?Yeah, true. Should I just remove the method name from the pr_err_once?Or should I also use one of the _ratelimited things and print multiplemessages?I guess that would conform to normal kernel coding standards a bit better.Thanks for the quick feedback!",Technical
,
"    Protect posix clock array access against speculationDocumentation/process/submitting-patches.rst:  For these reasons, the ``summary`` must be no more than 70-75  characters, and it must describe both what the patch changes, as well  as why the patch might be necessary.  It is challenging to be both  succinct and descriptive, but that is what a well-written summary  should do.The above $subject violates all of these rules.We should? Changelogs are about facts. So having:  The ""array_index_mask_nospec"" code has been updated to allow index  argument to have const-qualified type.  So the stack variable ""idx"" which was introduced in commit 19b558db12f9  (""posix-timers: Protect posix clock array access against speculation"") to  cast the const argument 'id' is not longer required.is factual and precise. Hmm?This SOB chain is wrong. Please read and follow the Docuentation.Thanks,	tglx",Technical
,
"How does the caller know whether or not a particular attribute hasmultiple values?  Is that a fundamental attribute of a particularattribute?  (e.g., the documentation for each attribute must statewhether or not that attribute returns multiple attributes or not)	       	    	      	      - Ted",Technical
,
"Theodore Y. Ts'o <tytso@mit.edu> wrote:It's fundamental to each separate attribute.  I have an attribute that givesinformation actually on fsinfo() itself; I could add another that allows youto enumerate the attribute type table.  Then you'd be able to query the basictype (string/struct), the size (struct only) and whether it's 0D, 1D or 2D.All the values of an attribute must have the same type of value, and ifthey're structure types rather than string types, the values will all have thesame size and be based on the same structure.Note that a struct attribute FSINFO_ATTR_XXX has a struct fsinfo_xxxassociated with it that defines its value, e.g.:      FSINFO_ATTR_TIMESTAMP_INFO              This retrieves information about what timestamp  resolution  and              scope  is  supported  by a filesystem for each of the file timeâ€              stamps.  The following structure is filled in:                  struct fsinfo_timestamp_info {                       __s64 minimum_timestamp;                       __s64 maximum_timestamp;                       __u16 atime_gran_mantissa;                       __u16 btime_gran_mantissa;                       __u16 ctime_gran_mantissa;                       __u16 mtime_gran_mantissa;                       __s8  atime_gran_exponent;                       __s8  btime_gran_exponent;                       __s8  ctime_gran_exponent;                       __s8  mtime_gran_exponent;                       __u32 __reserved[1];                  };Note that I have a manual page on this (see attached).David---'\"" t.\"" Copyright (c) 2018 David Howells <dhowells@redhat.com>.\"".\"" %%%LICENSE_START(VERBATIM).\"" Permission is granted to make and distribute verbatim copies of this.\"" manual provided the copyright notice and this permission notice are.\"" preserved on all copies..\"".\"" Permission is granted to copy and distribute modified versions of this.\"" manual under the conditions for verbatim copying, provided that the.\"" entire resulting derived work is distributed under the terms of a.\"" permission notice identical to this one..\"".\"" Since the Linux kernel and libraries are constantly changing, this.\"" manual page may be incorrect or out-of-date.  The author(s) assume no.\"" responsibility for errors or omissions, or for damages resulting from.\"" the use of the information contained herein.  The author(s) may not.\"" have taken the same level of care in the production of this manual,.\"" which is licensed free of charge, as they might when working.\"" professionally..\"".\"" Formatted or processed versions of this manual, if unaccompanied by.\"" the source, must acknowledge the copyright and authors of this work..\"" %%%LICENSE_END.\"".TH FSINFO 2 2018-06-06 ""Linux"" ""Linux Programmer's Manual"".SH NAMEfsinfo \- Get filesystem information.SH SYNOPSIS.nf.B #include <sys/types.h>.br.B #include <sys/fsinfo.h>.br.B #include <unistd.h>.br.BR ""#include <fcntl.h>           "" ""/* Definition of AT_* constants */"".PP.BI ""int fsinfo(int "" dirfd "", const char *"" pathname "","".BI ""           struct fsinfo_params *"" params "","".BI ""           void *"" buffer "", size_t "" buf_size );.fi.PP.IR Note :There is no glibc wrapper for.BR fsinfo ();see NOTES..SH DESCRIPTION.PPfsinfo() retrieves the desired filesystem attribute, as selected by theparameters pointed to by.IR params ,and stores its value in the buffer pointed to by.IR buffer ..PPThe parameter structure is optional, defaulting to all the parameters being 0if the pointer is NULL.  The structure looks like the following:.PP.in +4n.nfstruct fsinfo_params {    __u32 at_flags;     /* AT_SYMLINK_NOFOLLOW and similar flags */    __u32 request;      /* Requested attribute */    __u32 Nth;          /* Instance of attribute */    __u32 Mth;          /* Subinstance of Nth instance */    __u32 __reserved[6]; /* Reserved params; all must be 0 */};.fi.in.PPThe filesystem to be queried is looked up using a combination of.IR dfd "", "" pathname "" and "" params->at_flags.This is discussed in more detail below..PPThe desired attribute is indicated by.IR params->request .If.I paramsis NULL, this will default to.BR FSINFO_ATTR_STATFS ,which retrieves some of the information returned by.BR statfs ().The available attributes are described below in the ""THE ATTRIBUTES"" section..PPSome attributes can have multiple values and some can even have multipleinstances with multiple values.  For example, a network filesystem might usemultiple servers.  The names of each of these servers can be retrieved byusing.I params->Nthto iterate through all the instances until error.B ENODATAoccurs, indicating the end of the list.  Further, each server might havemultiple addresses available; these can be enumerated using.I params->Nthto iterate the servers and.I params->Mthto iterate the addresses of the Nth server..PPThe amount of data written into the buffer depends on the attribute selected.Some attributes return variable-length strings and some return fixed-sizestructures.  If either.IR buffer "" is  NULL  or "" buf_size "" is 0""then the size of the attribute value will be returned and nothing will bewritten into the buffer..PPThe.I params->__reservedparameters must all be 0..\""_______________________________________________________.SSAllowance for Future Attribute Expansion.PPTo allow for the future expansion and addition of fields to any fixed-sizestructure attribute,.BR fsinfo ()makes the following guarantees:.RS 4m.IP (1) 4mIt will always clear any excess space in the buffer..IP (2) 4mIt will always return the actual size of the data..IP (3) 4mIt will truncate the data to fit it into the buffer rather than giving anerror..IP (4) 4mAny new version of a structure will incorporate all the fields from the oldversion at same offsets..RE.PPSo, for example, if the caller is running on an older version of the kernelwith an older, smaller version of the structure than was asked for, the kernelwill write the smaller version into the buffer and will clear the remainder ofthe buffer to make sure any additional fields are set to 0.  The function willreturn the actual size of the data..PPOn the other hand, if the caller is running on a newer version of the kernelwith a newer version of the structure that is larger than the buffer, the writeto the buffer will be truncated to fit as necessary and the actual size of thedata will be returned..PPNote that this doesn't apply to variable-length string attributes..\""_______________________________________________________.SSInvoking \fBfsinfo\fR():.PPTo access a file's status, no permissions are required on the file itself, butin the case of.BR fsinfo ()with a path, execute (search) permission is required on all of the directoriesin.I pathnamethat lead to the file..PP.BR fsinfo ()uses.IR pathname "", "" dirfd "" and "" params->at_flagsto locate the target file in one of a variety of ways:.TP[*] By absolute path..I pathnamepoints to an absolute path and.I dirfdis ignored.  The file is looked up by name, starting from the root of thefilesystem as seen by the calling process..TP[*] By cwd-relative path..I pathnamepoints to a relative path and.IR dirfd "" is "" AT_FDCWD .The file is looked up by name, starting from the current working directory..TP[*] By dir-relative path..I pathnamepoints to relative path and.I dirfdindicates a file descriptor pointing to a directory.  The file is looked up byname, starting from the directory specified by.IR dirfd ..TP[*] By file descriptor..IR pathname "" is "" NULL "" and "" dirfdindicates a file descriptor.  The file attached to the file descriptor isqueried directly.  The file descriptor may point to any type of file, not justa directory..PP.I flagscan be used to influence a path-based lookup.  A value for.I flagsis constructed by OR'ing together zero or more of the following constants:.TP.BR AT_EMPTY_PATH.\"" commit 65cfc6722361570bfe255698d9cd4dccaf47570dIf.I pathnameis an empty string, operate on the file referred to by.IR dirfd(which may have been obtained using the.BR open (2).B O_PATHflag).If.I dirfdis.BR AT_FDCWD ,the call operates on the current working directory.In this case,.I dirfdcan refer to any type of file, not just a directory.This flag is Linux-specific; define.B _GNU_SOURCE.\"" Before glibc 2.16, defining _ATFILE_SOURCE sufficedto obtain its definition..TP.BR AT_NO_AUTOMOUNTDon't automount the terminal (""basename"") component of.I pathnameif it is a directory that is an automount point.  This allows the caller togather attributes of the filesystem holding an automount point (rather thanthe filesystem it would mount).  This flag can be used in tools that scandirectories to prevent mass-automounting of a directory of automount points.The.B AT_NO_AUTOMOUNTflag has no effect if the mount point has already been mounted over.This flag is Linux-specific; define.B _GNU_SOURCE.\"" Before glibc 2.16, defining _ATFILE_SOURCE sufficedto obtain its definition..TP.B AT_SYMLINK_NOFOLLOWIf.I pathnameis a symbolic link, do not dereference it:instead return information about the link itself, like.BR lstat ()..SH THE ATTRIBUTES.PPThere is a range of attributes that can be selected from.  These are:.\"" __________________ FSINFO_ATTR_STATFS __________________.TP.B fsinfo_attr_statfsThis retrieves the ""dynamic"".B statfsinformation, such as block and file counts, that are expected to change whilsta filesystem is being used.  This fills in the following structure:.PP.RS.in +4n.nfstruct fsinfo_statfs {    __u64 f_blocks;	/* Total number of blocks in fs */    __u64 f_bfree;	/* Total number of free blocks */    __u64 f_bavail;	/* Number of free blocks available to ordinary user */    __u64 f_files;	/* Total number of file nodes in fs */    __u64 f_ffree;	/* Number of free file nodes */    __u64 f_favail;	/* Number of free file nodes available to ordinary user */    __u32 f_bsize;	/* Optimal block size */    __u32 f_frsize;	/* Fragment size */};.fi.in.RE.IPThe fields correspond to those of the same name returned by.BR statfs ()..\"" __________________ FSINFO_ATTR_FSINFO __________________.TP.B FSINFO_ATTR_FSINFOThis retrieves information about the.BR fsinfo ()system call itself.  This fills in the following structure:.PP.RS.in +4n.nfstruct fsinfo_fsinfo {    __u32 max_attr;    __u32 max_cap;};.fi.in.RE.IPThe.I max_attrvalue indicates the number of attributes supported by the.BR fsinfo ()system call, and.I max_capindicates the number of capability bits supported by the.B FSINFO_ATTR_CAPABILITIESattribute.  The first corresponds to.I fsinfo_attr__nrand the second to.I fsinfo_cap__nrin the header file..\"" __________________ FSINFO_ATTR_IDS __________________.TP.B FSINFO_ATTR_IDSThis retrieves a number of fixed IDs and other static information otherwiseavailable through.BR statfs ().The following structure is filled in:.PP.RS.in +4n.nfstruct fsinfo_ids {    char  f_fs_name[15 + 1]; /* Filesystem name */    __u64 f_flags;	/* Filesystem mount flags (MS_*) */    __u64 f_fsid;	/* Short 64-bit Filesystem ID */    __u64 f_sb_id;	/* Internal superblock ID */    __u32 f_fstype;	/* Filesystem type from linux/magic.h */    __u32 f_dev_major;	/* As st_dev_* from struct statx */    __u32 f_dev_minor;};.fi.in.RE.IPMost of these are filled in as for.BR statfs (),with the addition of the filesystem's symbolic name in.I f_fs_nameand an identifier for use in notifications in.IR f_sb_id ..\"" __________________ FSINFO_ATTR_LIMITS __________________.TP.B FSINFO_ATTR_LIMITSThis retrieves information about the limits of what a filesystem can support.The following structure is filled in:.PP.RS.in +4n.nfstruct fsinfo_limits {    __u64 max_file_size;    __u64 max_uid;    __u64 max_gid;    __u64 max_projid;    __u32 max_dev_major;    __u32 max_dev_minor;    __u32 max_hard_links;    __u32 max_xattr_body_len;    __u16 max_xattr_name_len;    __u16 max_filename_len;    __u16 max_symlink_len;    __u16 __reserved[1];};.fi.in.RE.IPThese indicate the maximum supported sizes for a variety of filesystem objects,including the file size, the extended attribute name length and body length,the filename length and the symlink body length..IPIt also indicates the maximum representable values for a User ID, a Group ID,a Project ID, a device major number and a device minor number..IPAnd finally, it indicates the maximum number of hard links that can be made toa file..IPNote that some of these values may be zero if the underlying object or conceptis not supported by the filesystem or the medium..\"" __________________ FSINFO_ATTR_SUPPORTS __________________.TP.B FSINFO_ATTR_SUPPORTSThis retrieves information about what bits a filesystem supports in variousmasks.  The following structure is filled in:.PP.RS.in +4n.nfstruct fsinfo_supports {    __u64 stx_attributes;    __u32 stx_mask;    __u32 ioc_flags;    __u32 win_file_attrs;    __u32 __reserved[1];};.fi.in.RE.IPThe.IR stx_attributes "" and "" stx_maskfields indicate what bits in the struct statx fields of the matching namesare supported by the filesystem..IPThe.I ioc_flagsfield indicates what FS_*_FL flag bits as used through the FS_IOC_GET/SETFLAGSioctls are supported by the filesystem..IPThe.I win_file_attrsindicates what DOS/Windows file attributes a filesystem supports, if any..\"" __________________ FSINFO_ATTR_CAPABILITIES __________________.TP.B FSINFO_ATTR_CAPABILITIESThis retrieves information about what features a filesystem supports as aseries of single bit indicators.  The following structure is filled in:.PP.RS.in +4n.nfstruct fsinfo_capabilities {    __u8 capabilities[(fsinfo_cap__nr + 7) / 8];};.fi.in.RE.IPwhere the bit of interest can be found by:.PP.RS.in +4n.nf	p->capabilities[bit / 8] & (1 << (bit % 8))).fi.in.RE.IPThe bits are listed by.I enum fsinfo_capabilityand.B fsinfo_cap__nris one more than the last capability bit listed in the header file..IPNote that the number of capability bits actually supported by the kernel can befound using the.B FSINFO_ATTR_FSINFOattribute..IPThe capability bits and their meanings are listed below in the ""THECAPABILITIES"" section..\"" __________________ FSINFO_ATTR_TIMESTAMP_INFO __________________.TP.B FSINFO_ATTR_TIMESTAMP_INFOThis retrieves information about what timestamp resolution and scope issupported by a filesystem for each of the file timestamps.  The followingstructure is filled in:.PP.RS.in +4n.nfstruct fsinfo_timestamp_info {	__s64 minimum_timestamp;	__s64 maximum_timestamp;	__u16 atime_gran_mantissa;	__u16 btime_gran_mantissa;	__u16 ctime_gran_mantissa;	__u16 mtime_gran_mantissa;	__s8  atime_gran_exponent;	__s8  btime_gran_exponent;	__s8  ctime_gran_exponent;	__s8  mtime_gran_exponent;	__u32 __reserved[1];};.fi.in.RE.IPwhere.IR minimum_timestamp "" and "" maximum_timestampare the limits on the timestamps that the filesystem supports and.IR *time_gran_mantissa "" and "" *time_gran_exponentindicate the granularity of each timestamp in terms of seconds, using theformula:.PP.RS.in +4n.nfmantissa * pow(10, exponent) Seconds.fi.in.RE.IPwhere exponent may be negative and the result may be a fraction of a second..IPFour timestamps are detailed: \fBA\fPccess time, \fBB\fPirth/creation time,\fBC\fPhange time and \fBM\fPodification time.  Capability bits are definedthat specify whether each of these exist in the filesystem or not..IPNote that the timestamp description may be approximated or inaccurate if thefile is actually remote or is the union of multiple objects..\"" __________________ FSINFO_ATTR_VOLUME_ID __________________.TP.B FSINFO_ATTR_VOLUME_IDThis retrieves the system's superblock volume identifier as a variable-lengthstring.  This does not necessarily represent a value stored in the medium butmight be constructed on the fly..IPFor instance, for a block device this is the block device identifier(eg. ""sdb2""); for AFS this would be the numeric volume identifier..\"" __________________ FSINFO_ATTR_VOLUME_UUID __________________.TP.B FSINFO_ATTR_VOLUME_UUIDThis retrieves the volume UUID, if there is one, as a little-endian binaryUUID.  This fills in the following structure:.PP.RS.in +4n.nfstruct fsinfo_volume_uuid {    __u8 uuid[16];};.fi.in.RE.IP.\"" __________________ FSINFO_ATTR_VOLUME_NAME __________________.TP.B FSINFO_ATTR_VOLUME_NAMEThis retrieves the filesystem's volume name as a variable-length string.  Thisis expected to represent a name stored in the medium..IPFor a block device, this might be a label stored in the superblock.  For anetwork filesystem, this might be a logical volume name of some sort..\"" __________________ FSINFO_ATTR_CELL/DOMAIN __________________.PP.B FSINFO_ATTR_CELL_NAME.br.B FSINFO_ATTR_DOMAIN_NAME.br.IPThese two attributes are variable-length string attributes that may be used toobtain information about network filesystems.  An AFS volume, for instance,belongs to a named cell.  CIFS shares may belong to a domain..\"" __________________ FSINFO_ATTR_REALM_NAME __________________.TP.B FSINFO_ATTR_REALM_NAMEThis attribute is variable-length string that indicates the Kerberos realm thata filesystem's authentication tokens should come from..\"" __________________ FSINFO_ATTR_SERVER_NAME __________________.TP.B FSINFO_ATTR_SERVER_NAMEThis attribute is a multiple-value attribute that lists the names of theservers that are backing a network filesystem.  Each value is a variable-lengthstring.  The values are enumerated by calling.BR fsinfo ()multiple times, incrementing.I params->Ntheach time until an ENODATA error occurs, thereby indicating the end of thelist..\"" __________________ FSINFO_ATTR_SERVER_ADDRESS __________________.TP.B FSINFO_ATTR_SERVER_ADDRESSThis attribute is a multiple-instance, multiple-value attribute that lists theaddresses of the servers that are backing a network filesystem.  Each value isa structure of the following type:.PP.RS.in +4n.nfstruct fsinfo_server_address {    struct __kernel_sockaddr_storage address;};.fi.in.RE.IPWhere the address may be AF_INET, AF_INET6, AF_RXRPC or any other type asappropriate to the filesystem..IPThe values are enumerated by calling.IR fsinfo ()multiple times, incrementing.I params->Nthto step through the servers and.I params->Mthto step through the addresses of the Nth server each time until ENODATA errorsoccur, thereby indicating either the end of a server's address list or the endof the server list..IPBarring the server list changing whilst being accessed, it is expected that the.I params->Nthwill correspond to.I params->Nthfor.BR FSINFO_ATTR_SERVER_NAME ..\"" __________________ FSINFO_ATTR_PARAMETER __________________.TP.B FSINFO_ATTR_PARAMETERThis attribute is a 2D multiple-value attribute that lists the values of themount parameters for a filesystem as variable-length strings..IPThe parameters are enumerated by calling.BR fsinfo ()multiple times, incrementing.IR params->Nth and params->Mthto step through them until error ENODATA is given..IPParameter strings are presented in a form akin to the way they're passed to thecontext created by the.BR fsopen ()system call.  For example, straight text parameters will be rendered assomething like:.PP.RS.in +4n.nf""source=/dev/sda1""""data=journal""""noquota"".fi.in.RE.IPwhere the first parameters correspond on a 1-to-1 basis by.I params->Nthwith the parameters defined by.IR FSINFO_ATTR_PARAM_SPECIFICATION .Additional parameters may also be presented.  Further, any particular parametermay have multiple values (multiple sources for example).  These can beenumerated with params->Mth..\"" __________________ FSINFO_ATTR_NAME_ENCODING __________________.TP.B FSINFO_ATTR_NAME_ENCODINGThis attribute is variable-length string that indicates the filename encodingused by the filesystem.  The default is ""utf8"".  Note that this may indicate anon-8-bit encoding if that's what the underlying filesystem actually supports..\"" __________________ FSINFO_ATTR_NAME_CODEPAGE __________________.TP.B FSINFO_ATTR_NAME_CODEPAGEThis attribute is variable-length string that indicates the codepage used totranslate filenames from the filesystem to the system if this is applicable tothe filesystem..\"" __________________ FSINFO_ATTR_IO_SIZE __________________.TP.B FSINFO_ATTR_IO_SIZEThis retrieves information about the I/O sizes supported by the filesystem.The following structure is filled in:.PP.RS.in +4n.nfstruct fsinfo_io_size {    __u32 dio_size_gran;    __u32 dio_mem_align;};.fi.in.RE.IPWhere.I dio_size_granindicate the fundamental I/O block size that the size of O_DIRECT read/writecalls must be a multiple of and.I dio_mem_alignindicates the memory alignment requirements of the data buffer in any O_DIRECTread/write call..IPNote that any of these may be zero if inapplicable or indeterminable..\"" __________________ FSINFO_ATTR_PARAM_DESCRIPTION __________________.TP.B FSINFO_ATTR_PARAM_DESCRIPTIONThis retrieves basic information about the superblock configuration parametersused by the filesystem.  The value returned is of the following type:.PP.RS.in +4n.nfstruct fsinfo_param_description {    __u32 nr_params;		/* Number of individual parameters */    __u32 nr_names;		/* Number of parameter names */    __u32 nr_enum_names;		/* Number of enum names  */};.fi.in.RE.IPWhere.I nr_params indicates the number of described parameters (it's possible forthe configuration to take more than this - cgroup-v1 for example);.I nr_namesindicates the number of parameter names that there are defined (nr_names can bemore than nr_params if there are synonyms); and.I nr_enum_namesindicates the number of enum value names that there are defined..\"" __________________ FSINFO_ATTR_PARAM_SPECIFICATION __________________.TP.B FSINFO_ATTR_PARAM_SPECIFICATIONThis retrieves information about the Nth superblock configuration parameteravailable in the filesystem.  This is enumerated by incrementing.I params->Ntheach time.  Each value is a structure of the following type:.PP.RS.in +4n.nfstruct fsinfo_param_specification {	__u32		type;	__u32		flags;};.fi.in.RE.IPWhere.I typeindicates the type of value by way of one of the following constants:.PP.RS.in +4n.nf  FSINFO_PARAM_SPEC_NOT_DEFINED  FSINFO_PARAM_SPEC_TAKES_NO_VALUE  FSINFO_PARAM_SPEC_IS_BOOL  FSINFO_PARAM_SPEC_IS_U32  FSINFO_PARAM_SPEC_IS_U32_OCTAL  FSINFO_PARAM_SPEC_IS_U32_HEX  FSINFO_PARAM_SPEC_IS_S32  FSINFO_PARAM_SPEC_IS_ENUM  FSINFO_PARAM_SPEC_IS_STRING  FSINFO_PARAM_SPEC_IS_BLOB  FSINFO_PARAM_SPEC_IS_BLOCKDEV  FSINFO_PARAM_SPEC_IS_PATH  FSINFO_PARAM_SPEC_IS_FD.fi.in.RE.IPdepending on whether the kernel (incorrectly) didn't define the type, theparameter takes no value, or takes a bool, one of a number of integers, a namedenum value, a string, a binary blob, a blockdev, an arbitrary path or a filedescriptor..PP.I flagsqualifies the form of the value accepted:.PP.RS.in +4n.nf  FSINFO_PARAM_SPEC_VALUE_IS_OPTIONAL  FSINFO_PARAM_SPEC_PREFIX_NO_IS_NEG  FSINFO_PARAM_SPEC_EMPTY_STRING_IS_NEG  FSINFO_PARAM_SPEC_DEPRECATED.fi.in.RE.IPThese indicate whether the value is optional, the parameter can be madenegative by prefixing with 'no' or giving it an empty value or whether theparameter is deprecated and a warning issued if it used..\"" __________________ FSINFO_ATTR_PARAM_NAME __________________.TP.B FSINFO_ATTR_PARAM_NAMEThis retrieves information about the Nth superblock configuration parameteravailable in the filesystem.  This is enumerated by incrementing.I params->Ntheach time.  Each value is a structure of the following type:.PP.RS.in +4n.nfstruct fsinfo_param_name {	__u32		param_index;	char		name[252];};.fi.in.RE.IPWhere.I param_indexis refers to the Nth parameter returned by FSINFO_ATTR_PARAM_SPECIFICATION and.I nameis a name string that maps to the specified parameter..\"" __________________ FSINFO_ATTR_PARAM_ENUMs __________________.TP.B FSINFO_ATTR_PARAM_ENUMThis can be used to list all the enum value symbols available for all theconfiguration parameters available in the filesystem.  This is enumerated byincrementing.I params->Ntheach time.  Each value is a structure of the following type:.PP.RS.in +4n.nfstruct fsinfo_param_enum {	__u32		param_index;	/* Index of the relevant parameter specification */	char		name[252];	/* Name of the enum value */};.fi.in.RE.IPWhere.I param_indexindicates the enumeration-type parameter to which this value corresponds and.I nameis the symbolic name.  Note that all the enum values from all the enumparameters are in one list together.SH THE CAPABILITIES.PPThere are number of capability bits in a bit array that can be retrieved using.BR fsinfo_attr_capabilities .These give information about features of the filesystem driver and the specificfilesystem..\"" __________________ FSINFO_CAP_IS_*_FS __________________.PP.B FSINFO_CAP_IS_KERNEL_FS.br.B FSINFO_CAP_IS_BLOCK_FS.br.B FSINFO_CAP_IS_FLASH_FS.br.B FSINFO_CAP_IS_NETWORK_FS.br.B FSINFO_CAP_IS_AUTOMOUNTER_FS.IPThese indicate the primary type of the filesystem..B kernelfilesystems are special communication interfaces that substitute files forsystem calls; examples include procfs and sysfs..B blockfilesystems require a block device on which to operate; examples include ext4and XFS..B flashfilesystems require an MTD device on which to operate; examples include JFFS2..B networkfilesystems require access to the network and contact one or more servers;examples include NFS and AFS..B automounterfilesystems are kernel special filesystems that host automount points andtriggers to dynamically create automount points.  Examples include autofs andAFS's dynamic root..\"" __________________ FSINFO_CAP_AUTOMOUNTS __________________.TP.B FSINFO_CAP_AUTOMOUNTSThe filesystem may have automount points that can be triggered by pathwalk..\"" __________________ FSINFO_CAP_ADV_LOCKS __________________.TP.B FSINFO_CAP_ADV_LOCKSThe filesystem supports advisory file locks.  For a network filesystem, thisindicates that the advisory file locks are cross-client (and also betweenserver and its local filesystem on something like NFS)..\"" __________________ FSINFO_CAP_MAND_LOCKS __________________.TP.B FSINFO_CAP_MAND_LOCKSThe filesystem supports mandatory file locks.  For a network filesystem, thisindicates that the mandatory file locks are cross-client (and also betweenserver and its local filesystem on something like NFS)..\"" __________________ FSINFO_CAP_LEASES __________________.TP.B FSINFO_CAP_LEASESThe filesystem supports leases.  For a network filesystem, this means that theserver will tell the client to clean up its state on a file before passing thelease to another client..\"" __________________ FSINFO_CAP_*IDS __________________.PP.B FSINFO_CAP_UIDS.br.B FSINFO_CAP_GIDS.br.B FSINFO_CAP_PROJIDS.IPThese indicate that the filesystem supports numeric user IDs, group IDs andproject IDs respectively..\"" __________________ FSINFO_CAP_ID_* __________________.PP.B FSINFO_CAP_ID_NAMES.br.B FSINFO_CAP_ID_GUIDS.IPThese indicate that the filesystem employs textual names and/or GUIDs asidentifiers..\"" __________________ FSINFO_CAP_WINDOWS_ATTRS __________________.TP.B FSINFO_CAP_WINDOWS_ATTRSIndicates that the filesystem supports some Windows FILE_* attributes..\"" __________________ FSINFO_CAP_*_QUOTAS __________________.PP.B FSINFO_CAP_USER_QUOTAS.br.B FSINFO_CAP_GROUP_QUOTAS.br.B FSINFO_CAP_PROJECT_QUOTAS.IPThese indicate that the filesystem supports quotas for users, groups andprojects respectively..\"" __________________ FSINFO_CAP_XATTRS/FILETYPES __________________.PP.B FSINFO_CAP_XATTRS.br.B FSINFO_CAP_SYMLINKS.br.B FSINFO_CAP_HARD_LINKS.br.B FSINFO_CAP_HARD_LINKS_1DIR.br.B FSINFO_CAP_DEVICE_FILES.br.B FSINFO_CAP_UNIX_SPECIALS.IPThese indicate that the filesystem supports respectively extended attributes;symbolic links; hard links spanning direcories; hard links, but only within adirectory; block and character device files; and UNIX special files, such asFIFO and socket..\"" __________________ FSINFO_CAP_*JOURNAL* __________________.PP.B FSINFO_CAP_JOURNAL.br.B FSINFO_CAP_DATA_IS_JOURNALLED.IPThe first of these indicates that the filesystem has a journal and the secondthat the file data changes are being journalled..\"" __________________ FSINFO_CAP_O_* __________________.PP.B FSINFO_CAP_O_SYNC.br.B FSINFO_CAP_O_DIRECT.IPThese indicate that O_SYNC and O_DIRECT are supported respectively..\"" __________________ FSINFO_CAP_* for names __________________.PP.B FSINFO_CAP_VOLUME_ID.br.B FSINFO_CAP_VOLUME_UUID.br.B FSINFO_CAP_VOLUME_NAME.br.B FSINFO_CAP_VOLUME_FSID.br.B FSINFO_CAP_CELL_NAME.br.B FSINFO_CAP_DOMAIN_NAME.br.B FSINFO_CAP_REALM_NAME.IPThese indicate if various attributes are supported by the filesystem, where.B FSINFO_CAP_Xhere corresponds to.BR fsinfo_attr_X ..\"" __________________ FSINFO_CAP_IVER_* __________________.PP.B FSINFO_CAP_IVER_ALL_CHANGE.br.B FSINFO_CAP_IVER_DATA_CHANGE.br.B FSINFO_CAP_IVER_MONO_INCR.IPThese indicate if.I i_versionon an inode in the filesystem is supported andhow it behaves..B all_changeindicates that i_version is incremented on metadata changes as well as datachanges..B data_changeindicates that i_version is only incremented on data changes, includingtruncation..B mono_incrindicates that i_version is incremented by exactly 1 for each change made..\"" __________________ FSINFO_CAP_RESOURCE_FORKS __________________.TP.B FSINFO_CAP_RESOURCE_FORKSThis indicates that the filesystem supports some sort of resource fork oralternate data stream on a file.  This isn't the same as an extended attribute..\"" __________________ FSINFO_CAP_NAME_* __________________.PP.B FSINFO_CAP_NAME_CASE_INDEP.br.B FSINFO_CAP_NAME_NON_UTF8.br.B FSINFO_CAP_NAME_HAS_CODEPAGE.IPThese indicate certain facts about the filenames in a filesystem: whetherthey're case-independent; if they're not UTF-8; and if there's a codepageemployed to map the names..\"" __________________ FSINFO_CAP_SPARSE __________________.TP.B FSINFO_CAP_SPARSEThis indicates that the filesystem supports sparse files..\"" __________________ FSINFO_CAP_NOT_PERSISTENT __________________.TP.B FSINFO_CAP_NOT_PERSISTENTThis indicates that the filesystem is not persistent, and that any data storedhere will not be saved in the event that the filesystem is unmounted, themachine is rebooted or the machine loses power..\"" __________________ FSINFO_CAP_NO_UNIX_MODE __________________.TP.B FSINFO_CAP_NO_UNIX_MODEThis indicates that the filesystem doesn't support the UNIX mode permissionsbits..\"" __________________ FSINFO_CAP_HAS_*TIME __________________.PP.B FSINFO_CAP_HAS_ATIME.br.B FSINFO_CAP_HAS_BTIME.br.B FSINFO_CAP_HAS_CTIME.br.B FSINFO_CAP_HAS_MTIME.IPThese indicate as to what timestamps a filesystem supports, including: Accesstime, Birth/creation time, Change time (metadata and data) and Modificationtime (data only)..\"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""".\"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""".\"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""".SH RETURN VALUEOn success, the size of the value that the kernel has available is returned,irrespective of whether the buffer is large enough to hold that.  The datawritten to the buffer will be truncated if it is not.  On error, \-1 isreturned, and.I errnois set appropriately..SH ERRORS.TP.B EACCESSearch permission is denied for one of the directoriesin the path prefix of.IR pathname .(See also.BR path_resolution (7).).TP.B EBADF.I dirfdis not a valid open file descriptor..TP.B EFAULT.I pathnameis NULL or.IR pathname "", "" params "" or "" bufferpoint to a location outside the process's accessible address space..TP.B EINVALReserved flag specified in.IR params->at_flags "" or one of "" params->__reserved[]is not 0..TP.B EOPNOTSUPPUnsupported attribute requested in.IR params->request .This may be beyond the limit of the supported attribute set or may just not beone that's supported by the filesystem..TP.B ENODATAUnavailable attribute value requested by.IR params->Nth "" and/or "" params->Mth ..TP.B ELOOPToo many symbolic links encountered while traversing the pathname..TP.B ENAMETOOLONG.I pathnameis too long..TP.B ENOENTA component of.I pathnamedoes not exist, or.I pathnameis an empty string and.B AT_EMPTY_PATHwas not specified in.IR params->at_flags ..TP.B ENOMEMOut of memory (i.e., kernel memory)..TP.B ENOTDIRA component of the path prefix of.I pathnameis not a directory or.I pathnameis relative and.I dirfdis a file descriptor referring to a file other than a directory..SH VERSIONS.BR fsinfo ()was added to Linux in kernel 4.18..SH CONFORMING TO.BR fsinfo ()is Linux-specific..SH NOTESGlibc does not (yet) provide a wrapper for the.BR fsinfo ()system call; call it using.BR syscall (2)..SH SEE ALSO.BR ioctl_iflags (2),.BR statx (2),.BR statfs (2)",Technical
,
"Adding fall through isn't wrong but its reasonable to ask why there is acomplex hand unrolled loop here in the first place (and doubly sowithout a comment). The whole switch statement would be much clearexpressed as:	for (j=0; j<bytesperword; j++)		*c++ = printable_char(*cp++);	addr += bytesperword;Daniel.",Technical
,
"Hi Daniel,Yeah, I agree. I can send a patch for that.Thanks for the feedback.--Gustavo",Technical
,
"Hi Jiang,Thanks for your patch. Since erofs and gasket are different feature, it is better to seperate into two patches.and could you please cc linux-erofs mailing list <linux-erofs@lists.ozlabs.org> as well?Yes, there is an extra semicolon in z_erofs_vle_unzip_all, it was reported by Julia Lawall several days ago.Actually, there is a patch in linux-erofs mailing list, but it seems that Chao hasn't reviewed it yet...https://lists.ozlabs.org/pipermail/linux-erofs/2018-August/000303.htmlI will add Signed-off-by: zhong jiang <zhongjiang@huawei.com> to the original patch if if you don't mind, do you?Thanks,Gao Xiang",Technical
,
"Hi Xiang,Oh, sorry, I missed this one, let me check/review all recent patches again andupdate them in tree later.Thanks,",Technical
,
"Hi Chao,It is nothing. :) I will send v2 version of this patch if zhong jiang doesn't mind.Thanks,Gao Xiang",Technical
,
" do it.  Thanks.  Then I will just resend the gasket feature separately. Thanks, zhong jiang",Technical
,
"Thanks for your understanding :)Thanks,Gao Xiang",Technical
,
"Hi Stefan,Stefan Agner <stefan@agner.ch> wrote on Mon,  6 Aug 2018 11:29:08 +0200:Why not just one call with:	vf610_nfc_clear(nfc, NFC_IRQ_STATUS, WERR_EN_BIT | DONE_EN_BIT | IDLE_EN_BIT);The comment applies for the next patch as well.Thanks,MiquÃ¨l",Technical
,
"Hi Dan,it seems like you missed to fix part of the subject as Jacek suggested.I think it should be: ""dt-bindings: leds: Add bindings for lm3697 driver""Best regards,Michal",Technical
,
"Hi Michal.Thanks for the heads-up.""dt-"" prefix is indeed more preferred than ""dt: "".Dan - I will fix it by myself, no need to resend.Best regards,Jacek Anaszewski",Technical
,
"This is quite long way to describe a bitmask, no? Could we makeit so that control-bank-cfg is not needed?Can we compute control-bank-cfg from this?Does the example show correct config? AFAICT all controls go to bankA according to control-bank-cfg, yet led@1 describes bank B...									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Hi!That's rather long and verbose way to describe a bitmap, right?Is rbtree good idea? You don't have that many registers.....No error checking required here?This checks if we have just one bank, I see it. Should it also checkthe led actually uses the correct bank?Is not the fwnode_handle_put() done twice for non-error case?The if is not needed here.Misleading, this does nothing with regulators.									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Hi!Can we forget about the LED strings, and just expose the sinks asLinux LED devices?									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
2 sinks 3 LED strings.  How do you know which LED string is which and what bank it belongsto when setting the brightness.  Each Bank has a separate register for brightness control.Dan--------------------Dan Murphy,Technical
,
"Yes, and LED strings are statically assigned to banks, right?So why not simply forget about LED strings for sake of hwabstractions, and work just with banks?									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
How would you set the control bank register for the correct LED string configuration?Dan--------------------Dan Murphy,Technical
,
JacekI could change the name to led-sources.  But this part does not really follow the 1 output to a1 LED string topology.--------------------Dan Murphy,Technical
,
"Have property at each LED saying which which HVLEDs it controls?									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Hi!Yes.No, I don't want that.I'd like 2 child nodes, each specifying which HVLEDs it controls.Let me edit the original proposal.									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"What I'd like to see:Remove control-bank-cfg.Add required child property:        - hvleds = <list> -- set of outputs this child controls.									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Dan,led-sources was designed for describing the topology where one LED canbe connected to more then one output, see bindings ofmax77693-led (in Documentation/devicetree/bindings/mfd/max77693.txt).Here the topology is a bit different - more than one LED (string) can beconnected to a single bank, but this is accomplished inside the chip.Logically LEDs configured that way can be treated as a single LED(string) connected to two outputs, and what follows they should bedescribed by a single DT child node.led-sources will fit very well for this purpose. You could dothe following mapping:0 - HVLED11 - HVLED22 - HVLED3Then, in the child DT nodes you would use these identifiers to describethe topology:Following node would describe strings connected to the outputsHVLED1 and HVLED2 controlled by bank A.led@0 {	reg = <0>;	led-sources = <0>. <1>;	label = ""white:first_backlight_cluster"";	linux,default-trigger = ""backlight"";};IOW I agree with Pavel, but I propose to use already documented commonDT LED property.--Best regards,Jacek Anaszewski",Technical
,
"Jacek and PavelI agree to use the led-sources but I still believe this approach may be confusing to other sw devsand will lead to configuration issues by users.This implementation requires the sw dev to know which strings are controlled by which bank.And this method may produce a misconfiguration like something below where HVLED2 is declared inboth bank A and bank Bled@0 {	reg = <0>;	led-sources = <0>. <1>;	label = ""white:first_backlight_cluster"";	linux,default-trigger = ""backlight"";};led@1 {	reg = <1>;	led-sources = <1>. <2>;	label = ""white:keypad_cluster"";	linux,default-trigger = ""backlight"";};The driver will need to be intelligent and declare a miss configuration on the above.Not saying this cannot be done but I am not sure why we want to add all of these extra LoC and intelligencein the kernel driver.The driver cannot make assumptions on the intention.  And the device tree documentation will need topretty much need a lengthy explanation on how to configure the child nodes.The implementation I suggested removes that ambiguity.  It is a simple integer that is written to the deviceas part of the device configuration, which the config is a setting for the device.The child nodes denote which bank the exposed LED node will control.  Removing any needfor the sw developers new or old to know the specific device configurations.Dan--------------------Dan Murphy",Technical
,
Yes I know that the driver can check the string but if the same string is declared by another child thenthe driver must exit with -EINVAL.  Again a lot of code for little pay off.I believe we should keep drivers as simple as possible.I will add the changes.Unfortunately in either case this high level of documentation will need to be done.I believe both solutions will raise questions and concerns.There does not seem to be a good way to describe this device.Both solutions are wrought with issues and concerns.But like I said I will re-write the code with the above suggestion.Dan--------------------Dan Murphy,Technical
,
"Hi!Yes. But please do it that way, it is still better than beingdifferent from all the other drivers.Thanks,									Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
PavelThanks for the reviewIt will be removed with v3ackAckIt will be removed with v3AckAckAck--------------------Dan Murphy,Technical
,
PavelIsn't that what I have already using the reg property?Then we would have to aggregate the configuration and make a determination in the driver.But that does not follow the LED child node ideology.Each output of the LED driver should have a child node.In this case the outputs are the sinks(inputs) and there are only 2 sinks so having 3 LED child nodes would be confusingand there are required properties for each child like label.Each child node would then need to present 1 LED node to the user space to control the LED string.  Which wouldbe technically incorrect because you would have 2 LED nodes controlling the same control bank sink.--------------------Dan Murphy,Technical
,
"Besides this, please split it into two patches. The RCU change does notbelong to ""comment fix"" for sure.Thanks",Technical
,
"Thanks for the reminder.Because this change is trivial, I change the subject.--Regards,Wang Jian",Technical
,
"Why ""bridge"" and not ""host"" or even something to stand for ""root complex""?Or maybe it can still be ""host_bridge""?",Technical
,
"This looks fishy, as bridge->private is not set at this point AFAICS,unless one of the previous patches changes that.",Technical
,
"bridge->private what comes after the bridge structure, and it's allocatedby pci_alloc_host_bridge() passing the size of the structure we wantfor this private area.         Arnd",Technical
,
"I did this for consistency with the naming in drivers/pci/probe.c,which always declares the local variable as 'struct pci_host_bridge *bridge'.It's easy to change here if you feel strongly about it (I don't).        Arnd",Technical
,
I would leave host_bridge here.  It would make the patch smaller too I think.,Technical
,
"I see, sorry for the noise.",Technical
,
"Ok, I've changed my local copy as you suggested now.      Arnd",Technical
,
"I really like the idea behind this series.I wonder if there is a way to avoid some of that by adding a fewmore helpers, but even without the helpers that approach looksok to me.Do you have a git tree somewhere to play around with the changes?",Technical
,
"Ok, thanks for taking a first look.One core part that gets duplicated a lot (also in existing drivers)is the chunk that could be handled by this:int pci_host_bridge_init(struct pci_host_bridge *bridge,                   struct device *parent, int bus,                   struct pci_ops *ops, void *sysdata,                   struct list_head *resource_list){       if (resources)              list_splice_init(resources, &bridge->windows);       bridge->dev.parent = parent;       bridge->sysdata = sysdata;       bridge->busnr = bus;       bridge->ops = ops;}That would probably help, but we should think carefully aboutthe set of fields that we want pass here, specifically because theidea of splitting the probing into two parts was to avoid havingto come up with a new interface every time that list changesdue to some rework.For instance, the numa node is something that might get passedhere, and if we decide to split out the operations into a separatepci_host_bridge_ops structure, the pointer to that would alsobe something we'd want to pass this way.I now uploaded it (with fixes incorporated) tohttps://git.kernel.org/pub/scm/linux/kernel/git/arnd/playground.gitpci-probe-rework       arnd",Technical
,
Hm... are you turning direct calls into retpolined indirect calls?,Technical
,
He does.  But not anywhere near the fast path.,Technical
,
"Sorry for the late response to this.I think I'm generally on-board with this.  I admit I'm a littlehesitant about adding 200 lines of code when this is really more""cleanup"" than new functionality, but I think a lot of that is becausethis series contains costs (e.g., duplicating code) for everybody butonly has the corresponding benefits for a few (ACPI, x86, xenfront).Those cases are much closer to parity in terms of lines added/removed.I saw some minor comments that suggested you had some updates, so I'llwatch for an updated posting.Bjorn",Technical
,
"Hi Calvin,I'm inclined to apply this -- because it will not break anything,and it would at least enable testing by people, who have this hardware.thoughts?-Len--Len Brown, Intel Open Source Technology Center",Technical
,
"(Whoops, resending this message. Forgot that Gmail defaulted toHTML...)Hi Len,By all means go ahead and apply the package power patch as well. I'vetested it on both Summit (single-die desktop) and Raven (desktop/laptopapu) with good results. The worst case as it stands is that if themulti-die packages (EPYC/TR) don't aggregate the value per package,then package power will be under-reported.(I previously wrote that this would be easier to test with the patchapplied, because the package power is reported with the -Dump option,but I'm not sure that's actually the case - the value might still onlybe collected once per package?)Calvin.",Technical
,
"Right -- we'd have to move it to a per-core or per-CPU data structureto capture it on a finer granularity than per package.Of course, if you want to see if you get different values on the cpus,you can always dump the raw values from each cpu using rdmsr(1).Unfortunately, I don't have that AMD hardware -- somebody with aninterest in it can test it out.thanks,Len Brown, Intel Open Source Technology Center",Technical
,
"Applied, thanks!--Len Brown, Intel Open Source Technology Center",Technical
,
"As enable is required and direction is optional, enable should comefirst. So fix the pwms property instead. (And perhaps make the bindingmore explicit as to what the order should be.",Technical
,
"You are right. The XFS filesystem was created on a small ramfs deviceand so the disk space was tiny. The microbenchmark that I used exposessome extreme cases that may not be normally observed.Those were part of the perf trace that I marked down:Before patch:+   69.69%    69.17%  reaim            [kernel.vmlinux]            [k]native_queued_spin_lock_-   54.48%     0.01%  reaim            [kernel.vmlinux]            [k]do_sys_open   - 54.46% do_sys_open      - 54.35% do_filp_open         - 54.34% path_openat            - 42.18% do_truncate               - 42.17% notify_change                  - 42.12% xfs_vn_setattr                     - 42.09% xfs_setattr_size                        - 42.08% xfs_setattr_nonsize                           - 27.31% xfs_trans_alloc                              - 27.28% xfs_trans_reserve                                 - xfs_log_reserve                                    - 27.20% xlog_grant_head_check                                       + 13.79% queued_spin_lock_slowpath                                       + 12.95% xlog_grant_head_wait                           + 14.72% __xfs_trans_commit            - 8.90% xfs_generic_create               - 5.81% security_inode_init_security                  - 5.72% xfs_initxattrs                     - xfs_attr_set                        - 2.90% xfs_bmap_add_attrfork                           + 1.88% xfs_trans_alloc                           + 1.02% __xfs_trans_commit                        + 1.78% xfs_trans_alloc                        + 1.01% __xfs_trans_commit               + 3.08% xfs_create            + 2.62% down_write1500    99.36    3982.81 351.51  91485.51   60.99      15.87    20.05    79After patch:-   41.68%     0.07%  reaim  [kernel.vmlinux] [k] do_sys_open   - 41.62% do_sys_open      - 41.23% do_filp_open         - 41.20% path_openat            - 30.32% do_truncate               - 30.27% notify_change                  - 30.06% xfs_vn_setattr                     - 29.90% xfs_setattr_size                        - 29.88% xfs_setattr_nonsize                           - 20.61% xfs_trans_alloc                              - 20.46% xfs_trans_reserve                                 - 20.43% xfs_log_reserve                                    - 19.96% xlog_grant_head_check                                       + 10.24% queued_spin_lock_slowpath                                       + 9.04% xlog_grant_head_wait                           + 9.06% __xfs_trans_commit            - 7.16% xfs_generic_create               + 4.27% security_inode_init_security               + 2.87% xfs_create            + 1.44% down_write+   39.59%    38.98%  reaim  [kernel.vmlinux] [k] native_queued_spin_lock1500    22.88    414.82  365.48  397290.21  264.86     3.40     18.41    81A spurious wakeup shouldn't change the behavior as the waiter shouldfind that it is still being queued (list not empty) and so will sleepagain. However, if the waiter is rightfully waken but find that there isnot enough log space somehow, it will put itself back to the end of thequeue. That is a change in behavior that I think could be an issue.I am just wondering why the code doesn't reserve the actual log space atthe time a task is being waken. Instead, it has to try to get it itselfafter being waken.Also I think the current code allows consecutive waiters to come in andwake up the same set of tasks again and again. That may be where a partof the performance slowdown come from.As I said above, spurious wakeup shouldn't cause problem. However,consecutive waiters will probably wake up more tasks than there is logspace available. In this case, some of the tasks will be put back to thequeue. Maybe a counter to record the log space temporarily reserved forthe waken-up task can help to prevent over-subscription.The wake_q should work correctly as it is used by mutexes and rwsems. Wewill see a lot of problem reports if that is not the case.That is probably true.I am using a old git (1.8). I should probably upgrade to a newer one.OKIt is because the wake_q uses a field in the task structure for queuing.So a task can only be in one wake_q at a time. Leaving the ticket in thequeue may cause the task to be put into multiple wake_q causing missedwakeup, perhaps.Yes, you are right. The xlog_grant_head_wake_all() need to be modifiedas well.OK, I need more time to think about some of the questions that youraise.  Thanks for reviewing the patch.Cheers,Longman",Technical
,
"The original is better than the new version.  Please leave it as is.regards,dan carpenter",Technical
,
"Oh, I just noticed you are using a ramfs for this benchmark,tl; dr: Once you pass a certain point, ramdisks can be *much* slowerthan SSDs on journal intensive workloads like AIM7. Hence it would beuseful to see if you have the same problems on, say, highperformance nvme SSDs.-----Ramdisks have substantially different means log IO completion andwakeup behaviour compared to real storage on real productionsystems. Basically, ramdisks are synchronous and real storage isasynchronous.That is, on a ramdisk the IO completion is run synchronously in thesame task as the IO submission because the IO is just a memcpy().Hence a single dispatch thread can only drive an IO queue depth of 1IO - there is no concurrency possible. This serialises large partsof the XFS journal - the journal is really an asynchronous IO enginethat gets it's performance from driving deep IO queues and batchingcommits while IO is in flight.Ramdisks also have very low IO latency, which means there's only avery small window for ""IO in flight"" batching optimisations to bemade effectively. It effectively stops such algorithms from workingcompletely. This means the XFS journal behaves very differently onramdisks when compared to normal storage.The submission batching techniques reduces log IOs by a factor of10-20 under heavy synchrnous transaction loads when there is anynoticeable journal IO delay - a few tens of microseconds is enoughfor it to function effectively, but a ramdisk doesn't even have thisdelay on journal IO.  The submission batching also has theeffect of reducing log space wakeups by the same factor there areless IO completions signalling that space has been made available.Further, when we get async IO completions from real hardware, theyget processed in batches by a completion workqueue - this leads tothere typically only being a single reservation space update fromall batched IO completions. This tends to reduce log space wakeupsdue to log IO completion by a factor of 6-8 as the log can have upto 8 concurrent IOs in flight at a time.And when we throw in the lack of batching, merging and IO completionaggregation of metadata writeback because ramdisks are synchrnousand don't queue or merge adjacent IOs, we end up with lots morecontention on the AIL lock and much more frequent log space wakeups(i.e. from log tail movement updates). This futher exacerbates theproblems the log already has with synchronous IO.IOWs, log space wakeups on real storage are likely to be 50-100xlower than on a ramdisk for the same metadata and journal intensiveworkload, and as such those workloads often run faster on realstorage than they do on ramdisks.This can be trivially seen with dbench, a simple IO benchmark thathammers the journal. On a ramdisk, I can only get 2-2.5GB/sthroughput from the benchmark before the log bottlenecks at about20,000 log tiny IOs per second. In comparison, on an old, badlyabused Samsung 850EVO SSD, I see 5-6GB/s in 2,000 log IOs per secondbecause of the pipelining and IO batching in the XFS journal asyncIO engine and the massive reduction in metadata IO due to merging ofadjacent IOs in the block layer. i.e. the journal and metadatawriteback design allows the filesystem to operate at a much highersynchronous transaction rate than would otherwise be possible bytaking advantage of the IO concurrency that storage provides uswith.So if you use proper storage hardware (e.g. nvme SSD) and/or anappropriately sized log, does the slowpath wakeup contention goaway? Can you please test both of these things and report theresults so we can properly evaluate the impact of these changes?Cheers,Dave.--Dave Chinnerdavid@fromorbit.com",Technical
,
"Note that all these ramdisk issues you mentioned below will also applyto using the pmem driver on nvdimms, which might be a more realisticversion.  Even worse at least for cases where the nvdimms aren'tactually powerfail dram of some sort with write through caching andADR the latency is going to be much higher than the ramdisk as well.",Technical
,
"Oh sorry, I made a mistake.There were some problems with my test configuration. I was actuallyrunning the test on a regular enterprise-class disk device mount on /.Filesystem                              1K-blocks     Used AvailableUse% Mounted on/dev/mapper/rhel_hp--xl420gen9--01-root  52403200 11284408  41118792  22% /It was not an SSD, nor ramdisk. I reran the test on ramdisk, theperformance of the patched kernel was 679,880 jobs/min which was a bitmore than double the 285,221 score that I got on a regular disk.So the filesystem used wasn't tiny, though it is still not very large.The test was supposed to create 16 ramdisks and distribute the testtasks to the ramdisks. Instead, they were all pounding on the samefilesystem worsening the spinlock contention problem.Cheers,Longman",Technical
,
"Yes, I realise that.I am expecting that when it comes to optimising for pmem, we'llactually rewrite the journal to map pmem and memcpy() directlyrather than go through the buffering and IO layers we currently doso we can minimise write latency and control concurrency ourselves.Hence I'm not really concerned by performance issues with pmem atthis point - most of our still users have traditional storage andwill for a long time to come....Cheers,Dave.--Dave Chinnerdavid@fromorbit.com",Technical
,
"Hi Andi,Is it ok to share VTune GUI screenshots I sent you the last timeto demonstrate the advantage of AIO trace streaming?Thanks,Alexey",Technical
,
"Hi,I am not sure it would be representative in perf stat data howeverthat could be visible there as well. I could share screenshots ofVTune GUI that demonstrate the advantage of Perf implementing AIOstreaming in comparison with the serial streaming. Data loss metricscan be easily understood from that. Is it ok to post it here?",Technical
,
"Hi,VTune release manager permitted to share it, well, sorry for bothering.",Technical
,
"Which branch is this works based on?I don't see any out label in current code.Please add same test in ovl_can_decode_fh().Problem: none of the ovl_export_operations functions override creds.I guess things are working now because nfsd is privileged enough.IOW, the capability check you added doesn't check mounter credswhen coming from nfs export ops - I guess that is not what you wantalthough you probably don'r enable nfs export.Thanks,Amir.",Technical
,
<sigh> I can only truly test this on 4.14 (android's current top oftree) and on Hikey with that. Lack of due diligence for Top of Linux.AhhhhNFS export/import blocked on Android devices.,Technical
,
"Well, not sure how that review is going to work out.anyway, this case should not return an error.returning NULL should be just fine.",Technical
,
I have picked this up Dave.,Technical
,
"Thanks, Jeffrey.--Gustavo",Technical
,
"(Hi, Florian!)Are you sure you did this right?  With the clocksource set to TSC(which is the only reasonable choice unless KVM has seriously cleanedup its act), with retpolines enabled, I get 24ns for CLOCK_MONOTONICwithout your patch and 32ns with your patch.  And there is indeed aretpoline in the disassembled output:  e5:   e8 07 00 00 00          callq  f1 <__vdso_clock_gettime+0x31>  ea:   f3 90                   pause  ec:   0f ae e8                lfence  ef:   eb f9                   jmp    ea <__vdso_clock_gettime+0x2a>  f1:   48 89 04 24             mov    %rax,(%rsp)  f5:   c3                      retqYou're probably going to have to set -fno-jump-tables or do somethingclever like adding a whole array of (seconds, nsec) in gtod andindexing that array by the clock id.Meanwhile, I wrote the following trivial patch to add a__vdso_clock_gettime_monotonic export.  It runs in 21ns, and I suspectthat the speedup is even a bit bigger when cache-cold because itavoids some branches.  What do you all think?  Florian, do you thinkglibc would be willing to add some magic to turnclock_gettime(CLOCK_MONOTONIC, t) into__vdso_clock_gettime_monotonic(t) when CLOCK_MONOTONIC is a constant?",Technical
,
"What's the goal here?  Turn the indirect call/conditional jump/indirectcall sequence into a single indirect call, purely for performance reasons?Thanks,Florian",Technical
,
"Almost.  It's to bypass some of the branches in__vdso_clock_gettime(), which is supposed to be very fast.  AFAIK mostuser code that uses clock_gettime() passes a constant for the firstargument, and we can squeeze out some performance by optimizing thatcase.  The indirect branches internal to the vDSO are a separate issueand should be solved separately.(It's really too bad that x86 doesn't have a 64-bit call instruction.If it did, then the PLT could get rewritten at dynamic link time toavoid indirect calls entirely, and presumably glibc could use the sametechnique to call into the vDSO without indirect calls.)",Technical
,
"See the patch below. It's integrating TAI without slowing down everythingand it definitely does not result in indirect calls.On a HSW it slows down clock_gettime() by ~0.5ns. On a SKL I get a speedupby ~0.5ns. On a AMD Epyc server it's 1.2ns speedup. So it somehow dependson the uarch and I also observed compiler version dependend variations.Thanks,	tglx------- a/arch/x86/entry/vdso/vclock_gettime.c+++ b/arch/x86/entry/vdso/vclock_gettime.c@@ -203,39 +203,18 @@ notrace static inline u64 vgetsns(int *m 	return v * gtod->mult; }-/* Code size doesn't matter (vdso is 4k anyway) and this is faster. */-notrace static int __always_inline do_realtime(struct timespec *ts)+notrace static int __always_inline do_hres(struct timespec *ts, clockid_t clk) {-	unsigned long seq;-	u64 ns;+	struct vgtod_ts *base = &gtod->basetime[clk & VGTOD_HRES_MASK];+	unsigned int seq; 	int mode;--	do {-		seq = gtod_read_begin(gtod);-		mode = gtod->vclock_mode;-		ts->tv_sec = gtod->wall_time_sec;-		ns = gtod->wall_time_snsec;-		ns += vgetsns(&mode);-		ns >>= gtod->shift;-	} while (unlikely(gtod_read_retry(gtod, seq)));--	ts->tv_sec += __iter_div_u64_rem(ns, NSEC_PER_SEC, &ns);-	ts->tv_nsec = ns;--	return mode;-}--notrace static int __always_inline do_monotonic(struct timespec *ts)-{-	unsigned long seq; 	u64 ns;-	int mode; 	do { 		seq = gtod_read_begin(gtod); 		mode = gtod->vclock_mode;-		ts->tv_sec = gtod->monotonic_time_sec;-		ns = gtod->monotonic_time_snsec;+		ts->tv_sec = base->sec;+		ns = base->nsec; 		ns += vgetsns(&mode); 		ns >>= gtod->shift; 	} while (unlikely(gtod_read_retry(gtod, seq)));@@ -246,58 +225,50 @@ notrace static int __always_inline do_mo 	return mode; }-notrace static void do_realtime_coarse(struct timespec *ts)+notrace static void do_coarse(struct timespec *ts, clockid_t clk) {+	struct vgtod_ts *base = &gtod->basetime[clk]; 	unsigned long seq;-	do {-		seq = gtod_read_begin(gtod);-		ts->tv_sec = gtod->wall_time_coarse_sec;-		ts->tv_nsec = gtod->wall_time_coarse_nsec;-	} while (unlikely(gtod_read_retry(gtod, seq)));-}-notrace static void do_monotonic_coarse(struct timespec *ts)-{-	unsigned long seq; 	do { 		seq = gtod_read_begin(gtod);-		ts->tv_sec = gtod->monotonic_time_coarse_sec;-		ts->tv_nsec = gtod->monotonic_time_coarse_nsec;+		ts->tv_sec = base->sec;+		ts->tv_nsec = base->nsec; 	} while (unlikely(gtod_read_retry(gtod, seq))); } notrace int __vdso_clock_gettime(clockid_t clock, struct timespec *ts) {-	switch (clock) {-	case CLOCK_REALTIME:-		if (do_realtime(ts) == VCLOCK_NONE)-			goto fallback;-		break;-	case CLOCK_MONOTONIC:-		if (do_monotonic(ts) == VCLOCK_NONE)-			goto fallback;-		break;-	case CLOCK_REALTIME_COARSE:-		do_realtime_coarse(ts);-		break;-	case CLOCK_MONOTONIC_COARSE:-		do_monotonic_coarse(ts);-		break;-	default:-		goto fallback;-	}+	unsigned int msk;-	return 0;-fallback:+	/* Sort out negative (CPU/FD) and invalid clocks */+	if (unlikely((unsigned int) clock >= MAX_CLOCKS))+		return vdso_fallback_gettime(clock, ts);++	/*+	 * Convert the clockid to a bitmask and use it to check which+	 * clocks are handled in the VDSO directly.+	 */+	msk = 1U << clock;+	if (likely(msk & VGTOD_HRES)) {+		if (do_hres(ts, clock) != VCLOCK_NONE)+			return 0;+	} else if (msk & VGTOD_COARSE) {+		do_coarse(ts, clock);+		return 0;+	} 	return vdso_fallback_gettime(clock, ts); }+ int clock_gettime(clockid_t, struct timespec *) 	__attribute__((weak, alias(""__vdso_clock_gettime""))); notrace int __vdso_gettimeofday(struct timeval *tv, struct timezone *tz) { 	if (likely(tv != NULL)) {-		if (unlikely(do_realtime((struct timespec *)tv) == VCLOCK_NONE))+		struct timespec *ts = (struct timespec *) tv;++		if (unlikely(do_hres(ts, CLOCK_REALTIME) == VCLOCK_NONE)) 			return vdso_fallback_gtod(tv, tz); 		tv->tv_usec /= 1000; 	}@@ -318,7 +289,7 @@ int gettimeofday(struct timeval *, struc notrace time_t __vdso_time(time_t *t) { 	/* This is atomic on x86 so we don't need any locks. */-	time_t result = READ_ONCE(gtod->wall_time_sec);+	time_t result = READ_ONCE(gtod->basetime[CLOCK_REALTIME].sec); 	if (t) 		*t = result;--- a/arch/x86/entry/vsyscall/vsyscall_gtod.c+++ b/arch/x86/entry/vsyscall/vsyscall_gtod.c@@ -31,6 +31,8 @@ void update_vsyscall(struct timekeeper * { 	int vclock_mode = tk->tkr_mono.clock->archdata.vclock_mode; 	struct vsyscall_gtod_data *vdata = &vsyscall_gtod_data;+	struct vgtod_ts *base;+	u64 nsec; 	/* Mark the new vclock used. */ 	BUILD_BUG_ON(VCLOCK_MAX >= 32);@@ -45,34 +47,37 @@ void update_vsyscall(struct timekeeper * 	vdata->mult		= tk->tkr_mono.mult; 	vdata->shift		= tk->tkr_mono.shift;-	vdata->wall_time_sec		= tk->xtime_sec;-	vdata->wall_time_snsec		= tk->tkr_mono.xtime_nsec;--	vdata->monotonic_time_sec	= tk->xtime_sec-					+ tk->wall_to_monotonic.tv_sec;-	vdata->monotonic_time_snsec	= tk->tkr_mono.xtime_nsec-					+ ((u64)tk->wall_to_monotonic.tv_nsec-						<< tk->tkr_mono.shift);-	while (vdata->monotonic_time_snsec >=-					(((u64)NSEC_PER_SEC) << tk->tkr_mono.shift)) {-		vdata->monotonic_time_snsec -=-					((u64)NSEC_PER_SEC) << tk->tkr_mono.shift;-		vdata->monotonic_time_sec++;+	base = &vdata->basetime[CLOCK_REALTIME];+	base->sec = (gtod_long_t)tk->xtime_sec;+	base->nsec = tk->tkr_mono.xtime_nsec;++	base = &vdata->basetime[VGTOD_TAI];+	base->sec = (gtod_long_t)(tk->xtime_sec + (s64)tk->tai_offset);+	base->nsec = tk->tkr_mono.xtime_nsec;++	base = &vdata->basetime[CLOCK_MONOTONIC];+	base->sec = (gtod_long_t)(tk->xtime_sec + tk->wall_to_monotonic.tv_sec);+	nsec = tk->tkr_mono.xtime_nsec;+	nsec +=	((u64)tk->wall_to_monotonic.tv_nsec << tk->tkr_mono.shift);+	while (nsec >= (((u64)NSEC_PER_SEC) << tk->tkr_mono.shift)) {+		nsec -= ((u64)NSEC_PER_SEC) << tk->tkr_mono.shift;+		base->sec++; 	}+	base->nsec = nsec;-	vdata->wall_time_coarse_sec	= tk->xtime_sec;-	vdata->wall_time_coarse_nsec	= (long)(tk->tkr_mono.xtime_nsec >>-						 tk->tkr_mono.shift);--	vdata->monotonic_time_coarse_sec =-		vdata->wall_time_coarse_sec + tk->wall_to_monotonic.tv_sec;-	vdata->monotonic_time_coarse_nsec =-		vdata->wall_time_coarse_nsec + tk->wall_to_monotonic.tv_nsec;--	while (vdata->monotonic_time_coarse_nsec >= NSEC_PER_SEC) {-		vdata->monotonic_time_coarse_nsec -= NSEC_PER_SEC;-		vdata->monotonic_time_coarse_sec++;+	base = &vdata->basetime[CLOCK_REALTIME_COARSE];+	base->sec = (gtod_long_t)tk->xtime_sec;+	base->nsec = tk->tkr_mono.xtime_nsec >> tk->tkr_mono.shift;++	base = &vdata->basetime[CLOCK_MONOTONIC_COARSE];+	base->sec = (gtod_long_t)(tk->xtime_sec + tk->wall_to_monotonic.tv_sec);+	nsec = tk->tkr_mono.xtime_nsec >> tk->tkr_mono.shift;+	nsec += tk->wall_to_monotonic.tv_nsec;+	while (nsec >= NSEC_PER_SEC) {+		nsec -= NSEC_PER_SEC;+		base->sec++; 	}+	base->nsec = nsec; 	gtod_write_end(vdata); }--- a/arch/x86/include/asm/vgtod.h+++ b/arch/x86/include/asm/vgtod.h@@ -5,33 +5,41 @@ #include <linux/compiler.h> #include <linux/clocksource.h>+#include <uapi/linux/time.h>+ #ifdef BUILD_VDSO32_64 typedef u64 gtod_long_t; #else typedef unsigned long gtod_long_t; #endif++struct vgtod_ts {+	gtod_long_t	sec;+	u64		nsec;+};++#define VGTOD_BASES	(CLOCK_MONOTONIC_COARSE + 1)+#define VGTOD_HRES	(BIT(CLOCK_REALTIME) | BIT(CLOCK_MONOTONIC) | BIT(CLOCK_TAI))+#define VGTOD_COARSE	(BIT(CLOCK_REALTIME_COARSE) | BIT(CLOCK_MONOTONIC_COARSE))++/* Abuse CLOCK_THREAD_CPUTIME_ID for VGTOD CLOCK TAI */+#define VGTOD_HRES_MASK	0x3+#define VGTOD_TAI	(CLOCK_TAI & VGTOD_HRES_MASK)+ /*  * vsyscall_gtod_data will be accessed by 32 and 64 bit code at the same time  * so be carefull by modifying this structure.  */ struct vsyscall_gtod_data {-	unsigned seq;+	unsigned int	seq;++	int		vclock_mode;+	u64		cycle_last;+	u64		mask;+	u32		mult;+	u32		shift;-	int vclock_mode;-	u64	cycle_last;-	u64	mask;-	u32	mult;-	u32	shift;--	/* open coded 'struct timespec' */-	u64		wall_time_snsec;-	gtod_long_t	wall_time_sec;-	gtod_long_t	monotonic_time_sec;-	u64		monotonic_time_snsec;-	gtod_long_t	wall_time_coarse_sec;-	gtod_long_t	wall_time_coarse_nsec;-	gtod_long_t	monotonic_time_coarse_sec;-	gtod_long_t	monotonic_time_coarse_nsec;+	struct vgtod_ts	basetime[VGTOD_BASES]; 	int		tz_minuteswest; 	int		tz_dsttime;@@ -44,9 +52,9 @@ static inline bool vclock_was_used(int v 	return READ_ONCE(vclocks_used) & (1 << vclock); }-static inline unsigned gtod_read_begin(const struct vsyscall_gtod_data *s)+static inline unsigned int gtod_read_begin(const struct vsyscall_gtod_data *s) {-	unsigned ret;+	unsigned int ret; repeat: 	ret = READ_ONCE(s->seq);",Technical
,
"and actually this wants to become u64 unconditionally as we need to providethe full seconds even on 32bit for the upcoming y2038 support. We stillhave to truncate it for the current 32bit interface, but the core codecan be made ready now.Thanks,	tglx",Technical
,
"Does this mean glibc can keep using a single vDSO entrypoint, the one wehave today?Thanks,Florian",Technical
,
"We have no intention to change that.But we surely could provide separate entry points as an extra to avoid abunch of conditionals.Thanks,	tglx",Technical
,
"Okay, I was wondering because Andy seemed to have proposed just that.We could adjust to that, but the benefit would be long-term because it'san ABI change for glibc, and they tend to take a long time to propagate.But I must say that clock_gettime is an odd place to start.  I wouldhave expected any of the type-polymorphic multiplexer interfaces (fcntl,ioctl, ptrace, futex) to be a more natural starting point. 8-)Thanks,Florian",Technical
,
"Well, the starting point of this was to provide clock_tai support in thevdso. clock_gettime() in the vdso vs. the real syscall is a factor of 10 inspeed. clock_gettime() is a pretty hot function in some workloads.Andy then noticed that some conditionals could be avoided entirely by usinga different entry point and offered one along with a 10% speedup. We don'thave to go there, we can.The multiplexer interfaces need much more surgery and talking about futex,we'd need to sit down with quite some people and identify the things theyactually care about before just splitting it up and keeping the existingoverloaded trainwreck the same.Thanks,	tglx",Technical
,
"Thereâ€™s also the issue of how much the speedup matters. For futex, maybe a better interface saves 3ns, but a futex syscall is hundreds of ns. clock_gettime() is called at high frequency and can be ~25ns. Saving a few ns is a bigger deal.",Technical
,
"My concern is that the userspace system call wrappers currently do notknow how many arguments the individual operations take and what typesthe arguments have (hence the â€œtype-polymorphicâ€ nature I mentioned).This could be a problem for on-stack argument passing (where you mightread values beyond the end of the stack, and glibc avoids that most ofthe time by having enough cruft on the stack), and for architectureswhich pass pointers and integers in different registers (like some m68kABIs do for the return value).Thanks,Florian",Technical
,
"Isnâ€™t clock_gettime already special because of the vDSO entry point, though?",Technical
,
"Somewhat special, yes, but not overly so, and not in thetype-polymorphic sense.  We can't give direct access of the vDSOimplementation to applications because the kernel does not know aboutthe userspace errno variable.  We do that for time on x86_64, whereapplications call into the vDSO directly, bypassing glibc completelyafter binding.I suspect most Linux libcs that know about the vDSO at all have genericvsyscall support, just like they have generic support for plain systemcalls.Thanks,Florian",Technical
,
"If the vDSO adds special helpers for CLOCK_MONOTONIC and CLOCK_REALTIME, I think we can reasonably safely promise that they never fail. (seccomp can obviously break that promise if thereâ€™s no TSC, but I think that seccomp users who do that get to keep both pieces.)",Technical
,
"I agree, I thought about the same thing.  We already do not returnEFAULT for invalid pointers, for obvious reasons.  And if the clock IDis fixed, the EINVAL error is impossible.That would shave off a few nanoseconds more if the calling convention isidentical to what glibc exposes to applications.  If the vDSO is notavailable or the symbol is missing, we can provide an implementationbased on the current clock_gettime in glibc.Thanks,Florian",Technical
,
"Now tfm could be removed from the macro arguments, no?Best regards,Alexander",Technical
,
"Are you sure this is a representative sampling? I haven't doublechecked myself, but we have plenty of drivers for peripherals indrivers/crypto that implement block ciphers, and they would not turnup in tcrypt unless you are running on a platform that provides thehardware in question.",Technical
,
"On Wed, Sep 5, 2018 at 2:18 AM, Ard Biesheuvel<ard.biesheuvel@linaro.org> wrote:Hrm, excellent point. Looking at this again:The core part of the VLA is using this in the ON_STACK macro:static inline unsigned int crypto_skcipher_reqsize(struct crypto_skcipher *tfm){        return tfm->reqsize;}I don't find any struct crypto_skcipher .reqsize static initializers,and the initial reqsize is here:static int crypto_init_skcipher_ops_ablkcipher(struct crypto_tfm *tfm){...        skcipher->reqsize = crypto_ablkcipher_reqsize(ablkcipher) +                            sizeof(struct ablkcipher_request);with updates via crypto_skcipher_set_reqsize().So I have to examine ablkcipher reqsize too:static inline unsigned int crypto_ablkcipher_reqsize(        struct crypto_ablkcipher *tfm){        return crypto_ablkcipher_crt(tfm)->reqsize;}And of the crt_ablkcipher.reqsize assignments/initializers, I found:ablkcipher reqsize:1       struct dcp_aes_req_ctx8       struct atmel_tdes_reqctx8       struct cryptd_blkcipher_request_ctx8       struct mtk_aes_reqctx8       struct omap_des_reqctx8       struct s5p_aes_reqctx8       struct sahara_aes_reqctx8       struct stm32_cryp_reqctx8       struct stm32_cryp_reqctx16      struct ablk_ctx24      struct atmel_aes_reqctx48      struct omap_aes_reqctx48      struct omap_aes_reqctx48      struct qat_crypto_request56      struct artpec6_crypto_request_context64      struct chcr_blkcipher_req_ctx80      struct spacc_req80      struct virtio_crypto_sym_request136     struct qce_cipher_reqctx168     struct n2_request_context328     struct ccp_des3_req_ctx400     struct ccp_aes_req_ctx536     struct hifn_request_context992     struct cvm_req_ctx2456    struct iproc_reqctx_sThe base ablkcipher wrapper is:80      struct ablkcipher_requestAnd in my earlier skcipher wrapper analysis, lrw was the largestskcipher wrapper:384     struct rctxiproc_reqctx_s is an extreme outlier, with cvm_req_ctx at a bit less than half.Making this a 2920 byte fixed array doesn't seem sensible at all(though that's what's already possible to use with existingSKCIPHER_REQUEST_ON_STACK users).What's the right path forward here?-Kees--Kees CookPixel Security",Technical
,
"The skcipher implementations based on crypto IP blocks are typicallyasynchronous, and I wouldn't be surprised if a fair number ofSKCIPHER_REQUEST_ON_STACK() users are limited to synchronousskciphers.So we could formalize this and limit SKCIPHER_REQUEST_ON_STACK() tosynchronous skciphers, which implies that the reqsize limit only hasto apply synchronous skciphers as well. But before we can do this, wehave to identify the remaining occurrences that allow asynchronousskciphers to be used, and replace them with heap allocations.",Technical
,
"On Wed, Sep 5, 2018 at 3:49 PM, Ard Biesheuvel<ard.biesheuvel@linaro.org> wrote:Looks similar to ahash vs shash. :) Yes, so nearly allcrypto_alloc_skcipher() users explicitly mask away ASYNC. What's leftappears to be:crypto/drbg.c:  sk_tfm = crypto_alloc_skcipher(ctr_name, 0, 0);crypto/tcrypt.c:        tfm = crypto_alloc_skcipher(algo, 0, async ? 0: CRYPTO_ALG_ASYNC);drivers/crypto/omap-aes.c:      ctx->ctr =crypto_alloc_skcipher(""ecb(aes)"", 0, 0);drivers/md/dm-crypt.c:          cc->cipher_tfm.tfms[i] =crypto_alloc_skcipher(ciphermode, 0, 0);drivers/md/dm-integrity.c:              ic->journal_crypt =crypto_alloc_skcipher(ic->journal_crypt_alg.alg_string, 0, 0);fs/crypto/keyinfo.c:    struct crypto_skcipher *tfm =crypto_alloc_skcipher(""ecb(aes)"", 0, 0);fs/crypto/keyinfo.c:    ctfm = crypto_alloc_skcipher(mode->cipher_str, 0, 0);fs/ecryptfs/crypto.c:   crypt_stat->tfm =crypto_alloc_skcipher(full_alg_name, 0, 0);I'll cross-reference this with SKCIPHER_REQUEST_ON_STACK...Sounds good; thanks!-Kees--Kees CookPixel Security",Technical
,
"On Thu, Sep 6, 2018 at 1:49 AM, Ard Biesheuvel<ard.biesheuvel@linaro.org> wrote:According to Herbert, SKCIPHER_REQUEST_ON_STACK() may only be usedfor invoking synchronous ciphers.In fact, due to the way the crypto API is built, if you try using itwith any transformation that uses DMAyou would most probably end up trying to DMA to/from the stack whichas we all know is not a great idea.Any such occurrences are almost for sure broken already due to the DMAissue I've mentioned.Gilad--Gilad Ben-YossefChief Coffee Drinkervalues of Î² will give rise to dom!",Technical
,
"Ah yes, I found [0] which contains that quote.So that means that Kees can disregard the occurrences that are asynconly, but it still implies that we cannot limit the reqsize like heproposes unless we take the sync/async nature into account.It also means we should probably BUG() or WARN() inSKCIPHER_REQUEST_ON_STACK() when used with an async algo.I am not convinced of this. The skcipher request struct does notcontain any payload buffers, and whether the algo specific ctx structis used for DMA is completely up to the driver. So I am quite surethere are plenty of async algos that work fine withSKCIPHER_REQUEST_ON_STACK() and vmapped stacks.[0] https://www.redhat.com/archives/dm-devel/2018-January/msg00087.html",Technical
,
"Something like this should do the trick:diff --git a/include/crypto/skcipher.h b/include/crypto/skcipher.hindex 2f327f090c3e..70584e0f26bc 100644--- a/include/crypto/skcipher.h+++ b/include/crypto/skcipher.h@@ -142,7 +142,9 @@ struct skcipher_alg { #define SKCIPHER_REQUEST_ON_STACK(name, tfm) \        char __##name##_desc[sizeof(struct skcipher_request) + \                crypto_skcipher_reqsize(tfm)] CRYPTO_MINALIGN_ATTR; \-       struct skcipher_request *name = (void *)__##name##_desc+       struct skcipher_request *name = WARN_ON( \+               crypto_skcipher_alg(tfm)->base.cra_flags & CRYPTO_ALG_ASYNC) \+               ? NULL : (void *)__##name##_desc /**  * DOC: Symmetric Key Cipher APIThat way, we will almost certainly oops on a NULL pointer dereferenceright after, but we at least the stack corruption.",Technical
,
"On Thu, Sep 6, 2018 at 10:21 AM, Ard Biesheuvel<ard.biesheuvel@linaro.org> wrote:You are right that it is up to the driver but the cost is an extramemory allocation and release*per request* for any per request data that needs to be DMAable beyondthe actual plainand cipher text buffers such as the IV, so driver writers have anincentive against doing that :-)Gilad--Gilad Ben-YossefChief Coffee Drinkervalues of Î² will give rise to dom!",Technical
,
"A crash is just as bad as a BUG_ON.Is this even a real problem? Do we have any users of this constructthat is using it on async algorithms?Cheers,--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt",Technical
,
"Perhaps not, but it is not enforced atm.In any case, limiting the reqsize is going to break things, so thatneeds to occur based on the sync/async nature of the algo. That alsomeans we'll corrupt the stack if we ever end up usingSKCIPHER_REQUEST_ON_STACK() with an async algo whose reqsize isgreater than the sync reqsize limit, so I do think some additionalsanity check is appropriate.",Technical
,
"I'd prefer compile-time based checks.  Perhaps we can introducea wrapper around crypto_skcipher, say crypto_skcipher_sync whichcould then be used by SKCIPHER_REQUEST_ON_STACK to ensure thatonly sync algorithms can use this construct.Cheers,--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt",Technical
,
"That would require lots of changes in the callers, including ones thatalready take care to use sync algos only.How about we do something like the below instead?diff --git a/include/crypto/skcipher.h b/include/crypto/skcipher.hindex 2f327f090c3e..ace707d59cd9 100644--- a/include/crypto/skcipher.h+++ b/include/crypto/skcipher.h@@ -19,6 +19,7 @@ /**  *     struct skcipher_request - Symmetric key cipher request+ *     @__onstack: 1 if the request was allocated by SKCIPHER_REQUEST_ON_STACK  *     @cryptlen: Number of bytes to encrypt or decrypt  *     @iv: Initialisation Vector  *     @src: Source SG list@@ -27,6 +28,7 @@  *     @__ctx: Start of private context data  */ struct skcipher_request {+       unsigned char __onstack;        unsigned int cryptlen;        u8 *iv;@@ -141,7 +143,7 @@ struct skcipher_alg { #define SKCIPHER_REQUEST_ON_STACK(name, tfm) \        char __##name##_desc[sizeof(struct skcipher_request) + \-               crypto_skcipher_reqsize(tfm)] CRYPTO_MINALIGN_ATTR; \+               crypto_skcipher_reqsize(tfm)] CRYPTO_MINALIGN_ATTR = { 1 }; \        struct skcipher_request *name = (void *)__##name##_desc /**@@ -437,6 +439,10 @@ static inline int crypto_skcipher_encrypt(structskcipher_request *req) {        struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);+       if (req->__onstack &&+           (crypto_skcipher_alg(tfm)->base.cra_flags & CRYPTO_ALG_ASYNC))+               return -EINVAL;+        if (crypto_skcipher_get_flags(tfm) & CRYPTO_TFM_NEED_KEY)                return -ENOKEY;@@ -458,6 +464,10 @@ static inline int crypto_skcipher_decrypt(structskcipher_request *req) {        struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);+       if (req->__onstack &&+           (crypto_skcipher_alg(tfm)->base.cra_flags & CRYPTO_ALG_ASYNC))+               return -EINVAL;+        if (crypto_skcipher_get_flags(tfm) & CRYPTO_TFM_NEED_KEY)                return -ENOKEY;",Technical
,
"On Thu, Sep 6, 2018 at 7:49 AM, Ard Biesheuvel<ard.biesheuvel@linaro.org> wrote:Oh, I like this, thanks!-Kees--Kees CookPixel Security",Technical
,
"All of these are ASYNC (they're all crt_ablkcipher), so IIUC, I can ignore them.None of these use SKCIPHER_REQUEST_ON_STACK that I can find.crypto_init_skcipher_ops_blkcipher() doesn't touch reqsize at all, sothe only places I can find it gets changed are with direct callers ofcrypto_skcipher_set_reqsize(), which, when wrapping a sync blkcipherstart with a reqsize == 0. So, the remaining non-ASYNC callers askfor:4       struct sun4i_cipher_req_ctx96      struct crypto_rfc3686_req_ctx375     sum:                160     crypto_skcipher_blocksize(cipher) (max)                152     struct crypto_cts_reqctx                63      align_mask (max)384     struct rctxSo, following your patch to encrypt/decrypt, I can add reqsize checkthere. How does this look, on top of your patch?--- a/include/crypto/skcipher.h+++ b/include/crypto/skcipher.h@@ -144,9 +144,10 @@ struct skcipher_alg { /*  * This must only ever be used with synchronous algorithms.  */+#define MAX_SYNC_SKCIPHER_REQSIZE      384 #define SKCIPHER_REQUEST_ON_STACK(name, tfm) \        char __##name##_desc[sizeof(struct skcipher_request) + \-               crypto_skcipher_reqsize(tfm)] CRYPTO_MINALIGN_ATTR = { 1 } \+               MAX_SYNC_SKCIPHER_REQSIZE] CRYPTO_MINALIGN_ATTR = { 1 } \        struct skcipher_request *name = (void *)__##name##_desc /**@@ -442,10 +443,14 @@ static inline int crypto_skcipher_encrypt(structskcipher_request *req) {        struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);-       if (req->__onstack &&-           WARN_ON(crypto_skcipher_alg(tfm)->base.cra_flags &-                       CRYPTO_ALG_ASYNC))-               return -EINVAL;+       if (req->__onstack) {+               if (WARN_ON(crypto_skcipher_alg(tfm)->base.cra_flags &+                               CRYPTO_ALG_ASYNC))+                       return -EINVAL;+               if (WARN_ON(crypto_skcipher_reqsize(tfm) >+                               MAX_SYNC_SKCIPHER_REQSIZE))+                       return -ENOSPC;+       }...etc--Kees CookPixel Security",Technical
,
"If the lack of named initializer is too ugly, we could do something crazy like:#define MAX_SYNC_SKCIPHER_REQSIZE       384struct skcipher_request_on_stack {        union {                struct skcipher_request req;                char bytes[sizeof(struct skcipher_request) +                           MAX_SYNC_SKCIPHER_REQSIZE];        };};/* * This must only ever be used with synchronous algorithms. */#define SKCIPHER_REQUEST_ON_STACK(name)                         \        struct skcipher_request_on_stack __##name##_req =       \                { req.__onstack = 1 };                          \        struct skcipher_request *name = &(__##name##_req.req)-Kees--Kees CookPixel Security",Technical
,
"Hi Alexander,Any comments about this patch?BRsZhi Jin",Technical
,
"Zhi Jin <zhi.jin@intel.com> writes:The description is slightly confusing, but the patch looks correct andthe original code is clearly wrong. Thank you for finding this!Basically, if you request 1 channel 3 times, release the first two andthen request 4 channels, you'll be stuck, right?Thanks,--Alex",Technical
,
"Yes, you are right.But the real case that I reproduced the issue is a little different:I have 2 stp-policy:""console"": masters ""256 259""  channels ""7 10""""user""   : masters ""256 1024"" channels ""0 127""I understand the policies should not be overlapped, which is caused by someother issues.So if someone uses ""console"" to request a channel (who will get Channel #7)and then another uses ""user"" to request more than 8 channels, it will be stuck.The commit message is what I trying to abstract the above case, sorry for theconfusion.",Technical
,
"OK, so given that all SKCIPHER_REQUEST_ON_STACK occurrences areupdated in this series anyway, perhaps we should addskcipher_[en|de]crypt_onstack() flavors that encapsulate theadditional check? Only question is how to enforce at compile time thatthose are used instead of the ordinary ones when using a stackallocated request. Would you mind using some macro foo here involving__builtin_types_compatible_p() ?",Technical
,
"I'll continue to investigate alternatives, but I wanted to point outthat the struct change actually fills an existing padding byte (so nochange in memory usage) and marking this as an unlikely() test meansit wouldn't even be measurable due to the branch predictor (so nochange in speed). encrypt/decrypt entry is a tiny tiny fraction of theactual work done during encryption/decryption, etc.-Kees--Kees CookPixel Security",Technical
,
"Something like a completely new type which in reality is just awrapper around skcipher:	struct crypto_sync_skcipher {		struct crypto_skcipher base;	} tfm;	tfm = crypto_alloc_sync_skcipher(...);	crypto_sync_skcipher_encrypt(...)	crypto_sync_skcipher_decrypt(...)These functions would just be trivial inline functions around theircrypto_skcipher counterparts.Cheers,--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt",Technical
,
"The point is the ON_STACK request stuff is purely for backwardscompatibility and we don't want it to proliferate and pollute thecore API.Cheers,--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt",Technical
,
"On Mon, Sep 10, 2018 at 10:52 PM, Herbert Xu<herbert@gondor.apana.org.au> wrote:This means new wrappers for the other helpers too, yes? For example:        SKCIPHER_REQUEST_ON_STACK(nreq, ctx->null);        skcipher_request_set_tfm(nreq, ctx->null);        skcipher_request_set_callback(nreq, req->base.flags, NULL, NULL);        skcipher_request_set_crypt(nreq, req->src, req->dst, nbytes, NULL);        return crypto_skcipher_encrypt(nreq);For the above, we'd also need:sync_skcipher_request_set_tfm()sync_skcipher_request_set_callback()sync_skcipher_request_set_crypt()-Kees--Kees CookPixel Security",Technical
,
"Wait, I think I misunderstood you. Did you mean a new top-level thing(tfm?) not a new request type?That would mean at least replacing skcipher_request_set_tfm() with awrapper (since the tfm argument is different), but _not_encrypt/decrypt like you mention. I could perform a type test inSKCIPHER_REQUEST_ON_STACK().Globally:- add struct crypto_sync_skcipher wrapper- add crypto_alloc_sync_skcipher() to check non-ASYNC and request sizeof actual tfm- add skcipher_request_set_sync_tfm() to attach the wrapped tfm to the request- SKCIPHER_REQUEST_ON_STACK() would verify the tfm was a structcrypto_sync_skcipher.Two changes per user:- change allocation to use new crypto_alloc_sync_skcipher() which doesthe runtime checking- change skcipher_request_set_tfm() to skcipher_request_set_sync_tfm()This means struct skcipher_request is unchanged, along with_set_callback, _set_crypt, _zero, and en/decrypt.API misuse would be caught at build-time (viaSKCIPHER_REQUEST_ON_STACK type checking) and any request size problemswould be caught at allocation time.Does this sound like what you had in mind?-Kees--Kees CookPixel Security",Technical
,
"Hi,Please document both of these kernel parameters inDocumentation/admin-guide/kernel-parameters.txt.thanks,--~Randy",Technical
,
"This setup *should* work. It should be possible to set cpu.scheduledindependent of the cpu.scheduled values of parent and child task groups.Any intermediate regular task group (i.e. cpu.scheduled==0) will stillcontribute the group fairness aspects.That said, I see a hang, too. It seems to happen, when there is acpu.scheduled!=0 group that is not a direct child of the root task group.You seem to have ""/sys/fs/cgroup/cpu/machine"" as an intermediate group.(The case ==0 within !=0 within the root task group works for me.)I'm going to dive into the code.[...]If you're willing, you can try to get rid of the intermediate ""machine""cgroup in your setup for the moment. This might tell us, whether we'relooking at the same issue.Thanks,Jan",Technical
,
"Ah I see, that makes sense, thank you.Yep I will do this now. Note that if I just try to set machine'scpu.scheduled to 1, with no other changes (not even changing any childcgroup's cpu.scheduled yet), I get the following trace:[16052.164259] ------------[ cut here ]------------[16052.168973] rq->clock_update_flags < RQCF_ACT_SKIP[16052.168991] WARNING: CPU: 59 PID: 59533 at kernel/sched/sched.h:1303 assert_clock_updated.isra.82.part.83+0x15/0x18[16052.184424] Modules linked in: act_police cls_basic ebtable_filter ebtables ip6table_filter iptable_filter nbd ip6table_raw ip6_tables xt_CT iptable_raw ip_tables s[16052.255653]  xxhash raid10 raid0 multipath linear raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq ses libcrc32c raid1 enclosure scsi[16052.276029] CPU: 59 PID: 59533 Comm: bash Tainted: G           O      4.19.0-rc2-amazon-cosched+ #1[16052.291142] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.4.9 06/29/2018[16052.298728] RIP: 0010:assert_clock_updated.isra.82.part.83+0x15/0x18[16052.305166] Code: 0f 85 75 ff ff ff 48 83 c4 08 5b 5d 41 5c 41 5d 41 5e 41 5f c3 48 c7 c7 28 30 eb 94 31 c0 c6 05 47 18 27 01 01 e8 f4 df fb ff <0f> 0b c3 48 8b 970[16052.324050] RSP: 0018:ffff9cada610bca8 EFLAGS: 00010096[16052.329361] RAX: 0000000000000026 RBX: ffff8f06d65bae00 RCX: 0000000000000006[16052.336580] RDX: 0000000000000000 RSI: 0000000000000096 RDI: ffff8f1edf756620[16052.343799] RBP: ffff8f06e0462e00 R08: 000000000000079b R09: ffff9cada610bc48[16052.351018] R10: 0000000000000000 R11: 0000000000000000 R12: ffff8f06e0462e80[16052.358237] R13: 0000000000000001 R14: ffff8f06e0462e00 R15: 0000000000000001[16052.365458] FS:  00007ff07ab02740(0000) GS:ffff8f1edf740000(0000) knlGS:0000000000000000[16052.373647] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[16052.379480] CR2: 00007ff07ab139d8 CR3: 0000002ca2aea002 CR4: 00000000007626e0[16052.386698] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[16052.393917] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[16052.401137] PKRU: 55555554[16052.403927] Call Trace:[16052.406460]  update_curr+0x19f/0x1c0[16052.410116]  dequeue_entity+0x21/0x8c0[16052.413950]  ? terminate_walk+0x55/0xb0[16052.417871]  dequeue_entity_fair+0x46/0x1c0[16052.422136]  sdrq_update_root+0x35d/0x480[16052.426227]  cosched_set_scheduled+0x80/0x1c0[16052.430675]  cpu_scheduled_write_u64+0x26/0x30[16052.435209]  cgroup_file_write+0xe3/0x140[16052.439305]  kernfs_fop_write+0x110/0x190[16052.443397]  __vfs_write+0x26/0x170[16052.446974]  ? __audit_syscall_entry+0x101/0x130[16052.451674]  ? _cond_resched+0x15/0x30[16052.455509]  ? __sb_start_write+0x41/0x80[16052.459600]  vfs_write+0xad/0x1a0[16052.462997]  ksys_write+0x42/0x90[16052.466397]  do_syscall_64+0x55/0x110[16052.470152]  entry_SYSCALL_64_after_hwframe+0x44/0xa9[16052.475286] RIP: 0033:0x7ff07a1e93c0[16052.478943] Code: 73 01 c3 48 8b 0d c8 2a 2d 00 f7 d8 64 89 01 48 83 c8 ff c3 66 0f 1f 44 00 00 83 3d bd 8c 2d 00 00 75 10 b8 01 00 00 00 0f 05 <48> 3d 01 f0 ff ff4[16052.497827] RSP: 002b:00007ffc73e335b8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001[16052.505498] RAX: ffffffffffffffda RBX: 0000000000000002 RCX: 00007ff07a1e93c0[16052.512715] RDX: 0000000000000002 RSI: 00000000023a0408 RDI: 0000000000000001[16052.519936] RBP: 00000000023a0408 R08: 000000000000000a R09: 00007ff07ab02740[16052.527156] R10: 00007ff07a4bb6a0 R11: 0000000000000246 R12: 00007ff07a4bd400[16052.534374] R13: 0000000000000002 R14: 0000000000000001 R15: 0000000000000000[16052.541593] ---[ end trace b20c73e6c2bec22c ]---I'll reboot and move some cgroups around :)Thanks,Nish",Technical
,
"Yep, this does fix the soft lockups for me, thanks! However, if I do a:# find /sys/fs/cgroup/cpu/machine -mindepth 2 -maxdepth 2 -name cpu.scheduled -exec /bin/sh -c ""echo 1 > {} "" \;which should co-schedule all the cgroups for emulator and vcpu threads,I see the same warning I mentioned in my other e-mail:[10469.832822] ------------[ cut here ]------------[10469.837555] rq->clock_update_flags < RQCF_ACT_SKIP[10469.837574] WARNING: CPU: 89 PID: 49630 at kernel/sched/sched.h:1303 assert_clock_updated.isra.82.part.83+0x15/0x18[10469.853042] Modules linked in: act_police cls_basic ebtable_filter ebtables ip6table_filter iptable_filter nbd ip6table_raw ip6_tables xt_CT iptable_raw ip_tables s[10469.924590]  xxhash raid10 raid0 multipath linear raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq ses libcrc32c raid1 enclosure scsi[10469.945010] CPU: 89 PID: 49630 Comm: sh Tainted: G           O      4.19.0-rc2-amazon-cosched+ #2[10469.960061] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.4.9 06/29/2018[10469.967657] RIP: 0010:assert_clock_updated.isra.82.part.83+0x15/0x18[10469.974126] Code: 0f 85 75 ff ff ff 48 83 c4 08 5b 5d 41 5c 41 5d 41 5e 41 5f c3 48 c7 c7 28 30 eb 8d 31 c0 c6 05 67 18 27 01 01 e8 14 e0 fb ff <0f> 0b c3 48 8b 970[10469.993018] RSP: 0018:ffffabc0b534fca8 EFLAGS: 00010096[10469.998341] RAX: 0000000000000026 RBX: ffff9d74d12ede00 RCX: 0000000000000006[10470.005559] RDX: 0000000000000000 RSI: 0000000000000096 RDI: ffff9d74dfb16620[10470.012780] RBP: ffff9d74df562e00 R08: 0000000000000796 R09: ffffabc0b534fc48[10470.020005] R10: 0000000000000000 R11: 0000000000000000 R12: ffff9d74d2849800[10470.027226] R13: 0000000000000001 R14: ffff9d74df562e00 R15: 0000000000000001[10470.034445] FS:  00007fea86812740(0000) GS:ffff9d74dfb00000(0000) knlGS:0000000000000000[10470.042678] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[10470.048511] CR2: 00005620f00314d8 CR3: 0000002cc55ea004 CR4: 00000000007626e0[10470.055739] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[10470.062965] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[10470.070186] PKRU: 55555554[10470.072976] Call Trace:[10470.075508]  update_curr+0x19f/0x1c0[10470.079211]  dequeue_entity+0x21/0x8c0[10470.083056]  dequeue_entity_fair+0x46/0x1c0[10470.087321]  sdrq_update_root+0x35d/0x480[10470.091420]  cosched_set_scheduled+0x80/0x1c0[10470.095892]  cpu_scheduled_write_u64+0x26/0x30[10470.100427]  cgroup_file_write+0xe3/0x140[10470.104523]  kernfs_fop_write+0x110/0x190[10470.108624]  __vfs_write+0x26/0x170[10470.112236]  ? __audit_syscall_entry+0x101/0x130[10470.116943]  ? _cond_resched+0x15/0x30[10470.120781]  ? __sb_start_write+0x41/0x80[10470.124871]  vfs_write+0xad/0x1a0[10470.128268]  ksys_write+0x42/0x90[10470.131668]  do_syscall_64+0x55/0x110[10470.135421]  entry_SYSCALL_64_after_hwframe+0x44/0xa9[10470.140558] RIP: 0033:0x7fea863253c0[10470.144213] Code: 73 01 c3 48 8b 0d c8 2a 2d 00 f7 d8 64 89 01 48 83 c8 ff c3 66 0f 1f 44 00 00 83 3d bd 8c 2d 00 00 75 10 b8 01 00 00 00 0f 05 <48> 3d 01 f0 ff ff4[10470.163114] RSP: 002b:00007ffe7cb22d18 EFLAGS: 00000246 ORIG_RAX: 0000000000000001[10470.170783] RAX: ffffffffffffffda RBX: 00005620f002f4d0 RCX: 00007fea863253c0[10470.178002] RDX: 0000000000000002 RSI: 00005620f002f4d0 RDI: 0000000000000001[10470.185222] RBP: 0000000000000002 R08: 0000000000000001 R09: 000000000000006b[10470.192486] R10: 0000000000000008 R11: 0000000000000246 R12: 0000000000000001[10470.199705] R13: 0000000000000002 R14: 7fffffffffffffff R15: 0000000000000002[10470.206923] ---[ end trace fbf46e2c721c7acb ]---Thanks,Nish",Technical
,
"[snip]This goes away with the change below (which fixes patch 58/60).Thanks,Jandiff --git a/kernel/sched/cosched.c b/kernel/sched/cosched.cindex a1f0d3a7b02a..a98ea11ba172 100644--- a/kernel/sched/cosched.c+++ b/kernel/sched/cosched.c@@ -588,6 +588,7 @@ static void sdrq_update_root(struct sdrq *sdrq)        /* Get proper locks */        rq_lock_irqsave(rq, &rf);+       update_rq_clock(rq);        sdrq->is_root = is_root;        if (is_root)",Technical
,
"Yep, I can confirm this one as well, is now fixed.-Nish",Technical
,
"[...]I guess, it would be possible to flatten the task group hierarchy, that is usuallycreated when nesting cgroups. That is, enqueue task group SEs always within theroot task group.That should take away much of the (runtime-)overhead, no?The calculation of shares would need to be a different kind of complex than it isnow. But that might be manageable.CFS bandwidth control would also need to change significantly as we would nowhave to dequeue/enqueue nested cgroups below a throttled/unthrottled hierarchy.Unless *those* task groups don't participate in this flattening.(And probably lots of other stuff, I didn't think about right now.)RegardsJan",Technical
,
"That sounds like it will wreck the runnable_weight accounting. Although,if, as you write below, we do away with the hierarchical runqueues, thatisn't in fact needed anymore I think.Still, even without runnable_weight, I suspect we need the 'runnable'state, even for the other accounting.Can't do that, tasks might have individual constraints that are tighterthan the cpuset. Also, changing affinities isn't really a hot path, sowho cares.I have yet to go over your earlier email; but no. The scheduler is verymuch per-cpu. And as I mentioned earlier, CFS as is doesn't work rightif you share the runqueue between multiple CPUs (and 'fixing' that isnon trivial).Yes, Rik was going to look at trying this. Put all the tasks in the rootrq and adjust the vtime calculations. Facebook is seeing significantoverhead from cpu-cgroup and has to disable it because of that on atleast part of their setup IIUC.That is the hope; indeed. We'll still need to create the hierarchy foraccounting purposes, but it can be a smaller/simpler data structure.So the weight computation would be the normalized product of the parentsetc.. and since PELT only updates the values on ~1ms scale, we can keepa cache of the product -- that is, we don't have to recompute thatproduct and walk the hierarchy all the time either.Right, so the whole bandwidth thing becomes a pain; the simplestsolution is to detect the throttle at task-pick time, dequeue and tryagain. But that is indeed quite horrible.I'm not quite sure how this will play out.Anyway, if we pull off this flattening feat, then you can no longer usethe hierarchy for this co-scheduling stuff.Now, let me go read your earlier email and reply to that (in parts).",Technical
,
"You did mention this work first to me in the context of L1TF, so I mighthave jumped to conclusions here.Also, I have, of course, been looking at (SMT) co-scheduling,specifically in the context of L1TF, myself. I came up with a vastlydifferent approach. Tim - where are we on getting some of that posted?Note; that even though I wrote much of that code, I don't particularlylike it either :-)",Technical
,
"Specifically for L1TF I hooked into/extended KVM's preempt_notifierregistration interface, which tells us which tasks are VCPUs and towhich VM they belong.But if we want to actually expose this to userspace, we can either do aprctl() or extend struct sched_attr.Well, you mentioned it as an alternative to paravirt spinlocks -- I'msaying that co-scheduling cannot do that, you need full featuredgang-scheduling for that.",Technical
,
"The thing is, if you drop the full width gang scheduling, you instantlyrequire the paravirt spinlock / tlb-invalidate stuff again.Of course, the constraints of L1TF itself requires the explicitscheduling of idle time under a bunch of conditions.I did not read your [7] in much detail (also very bad quality scan that:-/; but I don't get how they leap from 'thrashing' to co-scheduling.Their initial problem, where A generates data that B needs and the 3scenarios: 1) A has to wait for B 2) B has to wait for A 3) the data gets bufferedSeems fairly straight forward and is indeed quite common, needingco-scheduling for that, I'm not convinced.We have of course added all sorts of adaptive wait loops in the kernelto deal with just that issue.With co-scheduling you 'ensure' B is running when A is, but that doesn'tmean you can actually make more progress, you could just be burning alot of CPu cycles (which could've been spend doing other work).I'm also not convinced co-scheduling makes _any_ sense outside SMT --does one of the many papers you cite make a good case for !SMTco-scheduling? It just doesn't make sense to co-schedule the LLC domain,that's 16+ cores on recent chips.",Technical
,
"I don't get the affinity part. If I create two cgroups by giving them onlycpu shares (no cpuset) and set their cpu.scheduled=1, will this ensureco-scheduling of each group on core level for all cores in the system?Thanks,Subhra",Technical
,
"Short answer: Yes. But ignoring the affinity part will very likely result in              a poor experience with this patch set.I was referring to the CPU affinity of a task, that you can set viasched_setaffinity() from within a program or via taskset from the commandline. For each task/thread within a cgroup, you should set the affinity toexactly one CPU. Otherwise -- as the load balancing part is still missing --you might end up with all tasks running on one CPU or some other unfortunateload distribution.Coscheduling itself does not care about the load, so each group will be(co-)scheduled at core level, no matter where the tasks ended up.RegardsJanPS: Below is an example to illustrate the resulting schedules a bit better,and what might happen, if you don't bind the to-be-coscheduled tasks toindividual CPUs.For example, consider a dual-core system with SMT (i.e. 4 CPUs in total),two task groups A and B, and tasks within them a0, a1, ..  and b0, b1, ..respectively.Let the system topology look like this:        System          (level 2)      /        \  Core 0      Core 1    (level 1)  /    \      /    \CPU0  CPU1  CPU2  CPU3  (level 0)If you set cpu.scheduled=1 for A and B, each core will be coscheduledindependently, if there are tasks of A or B on the core. Assuming thereare runnable tasks in A and B and some other tasks on a core, you willsee a schedule like:  A -> B -> other tasks -> A -> B -> other tasks -> ...(or some permutation thereof) happen synchronously across both CPUsof a core -- with no guarantees which tasks within A/within B/within the other tasks will execute simultaneously -- and with noguarantee what will execute on the other two CPUs simultaneously. (Thedistribution of CPU time between A, B, and other tasks follows the usualCFS weight proportional distribution, just at core level.) If neitherCPU of a core has any runnable tasks of a certain group, it won't be partof the schedule (e.g., A -> other -> A -> other).With cpu.scheduled=2, you lift this schedule to system-level and you wouldsee it happen across all four CPUs synchronously. With cpu.scheduled=0, youget this schedule at CPU-level as we're all used to with no synchronizationbetween CPUs. (It gets a tad more interesting, when you start mixing groupswith cpu.scheduled=1 and =2.)Here are some schedules, that you might see, with A and B coscheduled atcore level (and that can be enforced this way (along the horizontal dimension)by setting the affinity of tasks; without setting the affinity, it could beany of them):Tasks equally distributed within A and B:t   CPU0  CPU1  CPU2  CPU30    a0    a1    b2    b31    a0    a1   other other2    b0    b1   other other3    b0    b1    a2    a34   other other  a2    a35   other other  b2    b3All tasks within A and B on one CPU:t   CPU0  CPU1  CPU2  CPU30    a0    --   other other1    a1    --   other other2    b0    --   other other3    b1    --   other other4   other other other other5    a2    --   other other6    a3    --   other other7    b2    --   other other8    b3    --   other otherTasks within a group equally distributed across one core:t   CPU0  CPU1  CPU2  CPU30    a0    a2    b1    b31    a0    a3   other other2    a1    a3   other other3    a1    a2    b0    b34   other other  b0    b25   other other  b1    b2You will never see an A-task sharing a core with a B-task at any point in time(except for the 2 microseconds or so, that the collective context switch takes).",Technical
,
"AFAIK, changing the affinity of a cpuset overwrites the individual affinities of taskswithin them. Thus, it shouldn't be an issue.This kind of code path gets a little hotter, when a coscheduled set gets load-balancedfrom one core to another.Apart from that, I also think, that normal user-space applications should never haveto concern themselves with actual affinities. More often than not, they only want toexpress a relation to some other task (or sometimes resource), like ""run on the sameNUMA node"", ""run on the same core"", so that application design assumptions arefulfilled. That's an interface, that I'd like to see as a cgroup controller at somepoint. It would also benefit from the ability to move/balance whole runqueues.(It might also be a way to just bulk-balance a bunch of tasks in the current code,by exchanging two CFS runqueues. But that has probably some additional issues.)No sharing. Just not allocating runqueues that won't be used anyway.Assume you express this ""always run on the same core"" or have other reasonsto always restrict tasks in a task group to just one core/node/whatever. On anSMT system, you would typically need at most two runqueues for a core; the memoryfoot-print of a task group would no longer increase linearly with system size.It would be possible to (space-)efficiently express nested parallelism use caseswithout having to resort to managing affinities manually (which restrict thescheduler more than necessary).(And it would be okay for an adjustment of the maximum number of runqueues to failwith an -ENOMEM in dire situations, as this adjustment would be an explicit(user-)action.)Yeah. I might be a bit biased towards keeping or at least not fully throwing awaythe nesting of CFS runqueues. ;)However, the only efficient way that I can currently think of, is a hybrid modelbetween the ""full nesting"" that is currently there, and the ""no nesting"" you weredescribing above.It would flatten all task groups that do not actively contribute some function,which would be all task groups purely for accounting purposes and those for*unthrottled* CFS hierarchies (and those for coscheduling that contain exactlyone SE in a runqueue). The nesting would still be kept for *throttled* hierarchies(and the coscheduling stuff). (And if you wouldn't have mentioned a way to getrid of nesting completely, I would have kept a single level of nesting foraccounting purposes as well.)This would allow us to lazily dequeue SEs that have run out of bandwidth whenwe encounter them, and already enqueue them in the nested task group (whose SEis not enqueued at the moment). That way, it's still a O(1) operation to re-enableall tasks, once runtime is available again. And O(1) to throttle a repeat offender.RegardsJan",Technical
,
"No, it only shrinks the set. Also nothing stops you callingsched_setaffinity() once you're inside the cpuset. The only contraint isthat your mask is a subset of the cpuset mask.",Technical
,
You forget that SMT4 and SMT8 are fairly common outside of x86.,Technical
,
"I meant setting the affinity of the cpuset *after* setting an individual affinity.Like this:# mkdir /sys/fs/cgroup/cpuset/test# cat /sys/fs/cgroup/cpuset/cpuset.mems > /sys/fs/cgroup/cpuset/test/cpuset.mems# cat /sys/fs/cgroup/cpuset/cpuset.cpus > /sys/fs/cgroup/cpuset/test/cpuset.cpus# echo $$ > /sys/fs/cgroup/cpuset/test/tasks# taskset -c -p 0 $$pid 4745's current affinity list: 0-3pid 4745's new affinity list: 0# echo ""0-1"" > /sys/fs/cgroup/cpuset/test/cpuset.cpus# taskset -c -p $$pid 4745's current affinity list: 0,1#The individual affinity of $$ is lost, despite it being a subset.",Technical
,
"I do not have a strong bias either way. However, Iwould like the overhead of the cpu controller to beso low that we can actually use it :)Task priorities in a flat runqueue are relativelystraightforward, with vruntime scaling just likedone for nice levels, but I have to admit thatthrottled groups provide a challenge.Dequeueing throttled tasks is pretty straightforward,but requeueing them afterwards when they are nolonger throttled could present a real challengein some situations.I suspect most systems will have a number of runnabletasks no larger than the number of CPUs most of thetime.That makes ""re-enable all the tasks"" often equivalentto ""re-enable one task"".Can we handle the re-enabling (or waking up!) of onetask almost as fast as we can without the cpu controller?--All Rights Reversed.",Technical
,
"What are the other use cases, and what kind of performancenumbers do you have to show examples of workloads wherecoscheduling provides a performance benefit?--All Rights Reversed.",Technical
,
"[...]Do you know/have an idea how the flat approach would further skew theapproximations currently done in calc_group_shares()/calc_group_runnable()?With the nested hierarchy the (shared) task group SE is updatedwhenever something changes. With the flat approach, you'd only beable to update a task SE, when you have to touch the task anyway.Just from thinking briefly about it, it feels like values would beout of date for longer periods of time.We could start by transparently special-casing the ""just one SE in arunqueue"" case, where that single SE is enqueued directly into the nextparent, and everything falls back to nesting, the moment a second SE popsup.That might allow reaping the benefits for many cases without hurtingother cases. It's also more a gradual conversion of code.RegardsJan",Technical
,
"Ok got it. Can we have a more generic interface, like specifying a set oftask ids to be co-scheduled with a particular level rather than tying thiswith cgroups? KVMs may not always run with cgroups and there might be otheruse cases where we might want co-scheduling that doesn't relate to cgroups.",Technical
,
"For further use cases (still an incomplete list) let me redirect you to theunabridged Section B of the original e-mail:   https://lkml.org/lkml/2018/9/7/1521If you want me to, I can go into more detail and make the list from thate-mail more complete.Note, that many coscheduling use cases are not primarily about performance.Sure, there are the resource contention use cases, which are barely aboutanything else. See, e.g., [1] for a survey with further pointers to thepotential performance gains. Realizing those use cases would require eithera user space component driving this, or another kernel component performinga function similar to the current auto-grouping with some more complexitydepending on the desired level of sophistication. This extra component isout of my scope. But I see a coscheduler like this as an enabler forpractical applications of these kind of use cases.If you use coscheduling as part of a solution that closes a side-channel,performance is a secondary aspect, and hopefully we don't lose much of it.Then, there's the large fraction of use cases, where coscheduling isprimarily about design flexibility, because it enables different (old andnew) application designs, which usually cannot be executed in an efficientmanner without coscheduling.  For these use cases performance is important,but there is also a trade-off against development costs of alternativesolutions to consider. These are also the use cases where we can domeasurements today, i.e., without some yet-to-be-written extra component.For example, with coscheduling it is possible to use active waiting insteadof passive waiting/spin-blocking on non-dedicated systems, because lockholder preemption is not an issue anymore. It also allows usingapplications that were developed for dedicated scenarios in non-dedicatedsettings without loss in performance -- like an (unmodified) operatingsystem within a VM, or HPC code. Another example is cache optimization ofparallel algorithms, where you don't have to resort to cache-obliviousalgorithms for efficiency, but where you can stay with manually tuned orauto-tuned algorithms, even on non-dedicated systems. (You're even able todo the tuning itself on a system that has other load.)Now, you asked about performance numbers, that *I* have.If a workload has issues with lock-holder preemption, I've seen up to 5x to20x improvement with coscheduling. (This includes parallel programs [2] andVMs with unmodified guests without PLE [3].) That is of course highlydependent on the workload. I currently don't have any numbers comparingcoscheduling to other solutions used to reduce/avoid lock holderpreemption, that don't mix in any other aspect like resource contention.These would have to be micro-benchmarked.If you're happy to compare across some more moving variables, then more orless blind coscheduling of parallel applications with some automaticworkload-driven (but application-agnostic) width adjustment of coscheduledsets yielded an overall performance benefit between roughly 10% to 20%compared to approaches with passive waiting [2]. It was roughly on par withpure space-partitioning approaches (slight minus on performance, slightplus on flexibility/fairness).I never went much into the resource contention use cases myself. Though, Idid use coscheduling to extend the concept of ""nice"" to sockets by puttingall niced programs into a coscheduled task group with appropriately reducedshares.  This way, niced programs don't just get any and all idle CPUcapacity -- taking away parts of the energy budget of more important tasksall the time -- which leads to important tasks running at turbo frequenciesmore often. Depending on the parallelism of niced workload and theparallelism of normal workload, this translates to a performanceimprovement of the normal workload that corresponds roughly tothe increase in frequency (for CPU-bound tasks) [4]. Depending on theprocessor, that can be anything from just a few percent to about a factorof 2.RegardsJanReferences:[1] S. Zhuravlev, J. C. Saez, S. Blagodurov, A. Fedorova, and M. Prieto,    â€œSurvey of scheduling techniques for addressing shared resources in    multicore processors,â€ ACM Computing Surveys, vol. 45, no. 1, pp.    4:1â€“4:28, Dec. 2012.[2] J. H. SchÃ¶nherr, B. Juurlink, and J. Richling, â€œTACO: A scheduling    scheme for parallel applications on multicore architectures,â€    Scientific Programming, vol. 22, no. 3, pp. 223â€“237, 2014.[3] J. H. SchÃ¶nherr, B. Lutz, and J. Richling, â€œNon-intrusive coscheduling    for general purpose operating systems,â€ in Proceedings of the    International Conference on Multicore Software Engineering,    Performance, and Tools (MSEPT â€™12), ser. Lecture Notes in Computer    Science, vol. 7303. Berlin/Heidelberg, Germany: Springer, May 2012,    pp. 66â€“77.[4] J. H. SchÃ¶nherr, J. Richling, M. Werner, and G. MÃ¼hl, â€œA scheduling    approach for efficient utilization of hardware-driven frequency    scaling,â€ in Workshop Proceedings of the 23rd International Conference    on Architecture of Computing Systems (ARCS 2010 Workshops), M. Beigl    and F. J. Cazorla-Almeida, Eds. Berlin, Germany: VDE Verlag, Feb.    2010, pp. 367â€“376.",Technical
,
"Currently: no.At this point the implementation is tightly coupled to the cpu cgroupcontroller. This *might* change, if the task group optimizations mentionedin other parts of this e-mail thread are done, as I think, that it woulddecouple the various mechanisms.That said, what if you were able to disable the ""group-based fairness""aspect of the cpu cgroup controller? Then you would be able to controljust the coscheduling aspects on their own. Would that satisfy the usecase you have in mind?RegardsJan",Technical
,
"Sounds like a co-scheduling system would need thefollowing elements:1) Identify groups of runnable tasks to run together.2) Identify hardware that needs to be co-scheduled   (for L1TF reasons, POWER7/8 restrictions, etc).3) Pack task groups into the system in a way that   allows maximum utilization by co-scheduled tasks.4) Leave some CPU time for regular time sliced tasks.5) In some cases, leave some CPU time idle on purpose.Step 1 would have to be reevaluated periodically, astasks (eg. VCPUs) wake up and go to sleep.I suspect this may be much better done as its ownscheduler class, instead of shoehorned into CFS.I like the idea of having some co-scheduling functionalityin Linux, but I absolutely abhor the idea of making CFSeven more complicated than it already is.The current code is already incredibly hard to debugor improve.Are you getting much out of CFS with your current code?It appears that your patches are fighting CFS as much asthey are leveraging it, but admittedly I only looked atthem briefly.--All Rights Reversed.",Technical
,
"Can't say much about tlb-invalidate, but yes to the spinlock stuff: ifthere isn't any additional information available, all runnable tasks/vCPUshave to be coscheduled to avoid lock holder preemption.With additional information about tasks potentially holding locks orpotentially spinning on a lock, it would be possible to coschedule smallersubsets -- no idea if that would be any more efficient though.That is true for some of the resource contention use cases, too. Though,they are much more relaxed wrt. their requirements on the simultaneousnessof the context switch.In my personal interpretation, that analogy refers to the case where thewaiting time for a lock is shorter than the time for a context switch --but where the context switch was done anyway, ""thrashing"" the CPU.Anyway. I only brought it up, because everyone has a differentunderstanding of what ""coscheduling"" or ""gang scheduling"" actually means.The memorable quotes are from Ousterhout:  ""A task force is coscheduled if all of its runnable processes are exe-   cuting simultaneously on different processors. Each of the processes   in that task force is also said to be coscheduled.""(where a ""task force"" is a group of closely cooperating tasks), and fromFeitelson and Rudolph:  ""[Gang scheduling is defined] as the scheduling of a group of threads   to run on a set of processors at the same time, on a one-to-one   basis.""(with the additional assumption of time slices, collective preemption,and that threads don't relinquish the CPU during their time slice).That makes gang scheduling much more specific, while coscheduling justrefers to the fact that some things are executed simultaneously.I don't think, that coscheduling should be applied blindly.Just like the adaptive wait loops you mentioned: in the beginning therewas active waiting; it wasn't that great, so passive waiting was invented;turns out, the overhead is too high in some cases, so let's spin adaptivelyfor a moment.We went from uncoordinated scheduling to system-wide coordinated scheduling(which turned out to be not very efficient for many cases). And now we arein the phase to find the right adaptiveness. There is work on enablingcoscheduling only on-demand (when a parallel application profits from it)or to be more fuzzy about it (giving the scheduler more freedom); there iswork to go away from system-wide coordination to (dynamically) smallerisles (where I see my own work as well). And ""recently"" we also have theresource contention and security use cases leaving their impression on thetopic as well.There's the resource contention stuff, much of which targets the lastlevel cache or memory controller bandwidth. So, that is making a case forcoscheduling larger parts than SMT. However, I didn't find anything in ashort search that would already cover some of the more recent processorswith 16+ cores.There's the auto-tuning of parallel algorithms to a certain systemarchitecture. That would also profit from LLC coscheduling (and slightlylarger time slices) to run multiple of those in parallel. Again, no ideafor recent processors.There's work to coschedule whole clusters, which goes beyond the scope of asingle system, but also predates recent systems. (Search for, e.g.,""implicit coscheduling"").So, 16+ cores is unknown territory, AFAIK. But not every recent system has16+ cores, or will have 16+ cores in the near future.RegardsJan",Technical
,
"Both, Peter and Subhra, seem to prefer an interface different than cgroupsto specify what to coschedule.Can you provide some extra motivation for me, why you feel that way?(ignoring the current scalability issues with the cpu group controller)After all, cgroups where designed to create arbitrary groups of tasks andto attach functionality to those groups.If we were to introduce a different interface to control that, we'd need tointroduce a whole new group concept, so that you make tasks part of somegroup while at the same time preventing unauthorized tasks from joining agroup.I currently don't see any wins, just a loss in flexibility.RegardsJan",Technical
,
"I found another issue today, while attempting to test (with 61/60applied) separate coscheduling cgroups for vcpus and emulator threads[the default configuration with libvirt]./sys/fs/cgroup/cpu# cat cpu.scheduled1/sys/fs/cgroup/cpu# cd machine//sys/fs/cgroup/cpu/machine# cat cpu.scheduled0/sys/fs/cgroup/cpu/machine# cd VM-1.libvirt-qemu//sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu# cat cpu.scheduled0/sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu# cd vcpu0//sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu/vcpu0# cat cpu.scheduled0/sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu/vcpu0# echo 1 > cpu.scheduled/sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu/vcpu0# cd ../emulator//sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu/emulator# echo 1 > cpu.scheduled/sys/fs/cgroup/cpu/machine/VM-1.libvirt-qemu/emulator# <crash>Serial console output (I apologize that some lines got truncated)[ 1060.840120] BUG: unable to handle kernel NULL pointer dere0[ 1060.848782] PGD 0 P4D 0[ 1060.852068] Oops: 0000 [#1] SMP PTI[ 1060.856207] CPU: 44 PID: 0 Comm: swapper/44 Tainted: G           OE     4.19b[ 1060.867029] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.2.11 10/17[ 1060.874872] RIP: 0010:set_next_entity+0x15/0x1d0[ 1060.879770] Code: c8 48 8b 7d d0 eb 96 0f 1f 40 00 66 2e 0f 1f 84 00 00 00 00[ 1060.899165] RSP: 0018:ffffaa2b98c0fd78 EFLAGS: 00010046[ 1060.904720] RAX: 0000000000000000 RBX: ffff996940ba2d80 RCX: 0000000000000000[ 1060.912199] RDX: 0000000000000008 RSI: 0000000000000000 RDI: ffff996940ba2e00[ 1060.919678] RBP: ffffaa2b98c0fda0 R08: 0000000000000000 R09: 0000000000000000[ 1060.927174] R10: 0000000000000000 R11: 0000000000000001 R12: ffff996940ba2e00[ 1060.934655] R13: 0000000000000000 R14: ffff996940ba2e00 R15: 0000000000000000[ 1060.942134] FS:  0000000000000000(0000) GS:ffff996940b80000(0000) knlGS:00000[ 1060.950572] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[ 1060.956673] CR2: 0000000000000040 CR3: 00000064af40a006 CR4: 00000000007626e0[ 1060.964172] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[ 1060.971677] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[ 1060.979191] PKRU: 55555554[ 1060.982282] Call Trace:[ 1060.985126]  pick_next_task_fair+0x8a7/0xa20[ 1060.989794]  __schedule+0x13a/0x8e0[ 1060.993691]  ? update_ts_time_stats+0x59/0x80[ 1060.998439]  schedule_idle+0x2c/0x40[ 1061.002410]  do_idle+0x169/0x280[ 1061.006032]  cpu_startup_entry+0x73/0x80[ 1061.010348]  start_secondary+0x1ab/0x200[ 1061.014673]  secondary_startup_64+0xa4/0xb0[ 1061.019265] Modules linked in: act_police cls_basic ebtable_filter ebtables i[ 1061.093145]  mac_hid coretemp lp parport btrfs zstd_compress raid456 async_ri[ 1061.126494] CR2: 0000000000000040[ 1061.130467] ---[ end trace 3462ef57e3394c4f ]---[ 1061.147237] RIP: 0010:set_next_entity+0x15/0x1d0[ 1061.152510] Code: c8 48 8b 7d d0 eb 96 0f 1f 40 00 66 2e 0f 1f 84 00 00 00 00[ 1061.172573] RSP: 0018:ffffaa2b98c0fd78 EFLAGS: 00010046[ 1061.178482] RAX: 0000000000000000 RBX: ffff996940ba2d80 RCX: 0000000000000000[ 1061.186309] RDX: 0000000000000008 RSI: 0000000000000000 RDI: ffff996940ba2e00[ 1061.194109] RBP: ffffaa2b98c0fda0 R08: 0000000000000000 R09: 0000000000000000[ 1061.201908] R10: 0000000000000000 R11: 0000000000000001 R12: ffff996940ba2e00[ 1061.209698] R13: 0000000000000000 R14: ffff996940ba2e00 R15: 0000000000000000[ 1061.217490] FS:  0000000000000000(0000) GS:ffff996940b80000(0000) knlGS:00000[ 1061.226236] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[ 1061.232622] CR2: 0000000000000040 CR3: 00000064af40a006 CR4: 00000000007626e0[ 1061.240405] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[ 1061.248168] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[ 1061.255909] PKRU: 55555554[ 1061.259221] Kernel panic - not syncing: Attempted to kill the idle task![ 1062.345087] Shutting down cpus with NMI[ 1062.351037] Kernel Offset: 0x33400000 from 0xffffffff81000000 (relocation ra)[ 1062.374645] ---[ end Kernel panic - not syncing: Attempted to kill the idle -[ 1062.383218] WARNING: CPU: 44 PID: 0 at /build/linux-4.19-0rc3.ag.4/kernel/sc0[ 1062.394380] Modules linked in: act_police cls_basic ebtable_filter ebtables i[ 1062.469725]  mac_hid coretemp lp parport btrfs zstd_compress raid456 async_ri[ 1062.503656] CPU: 44 PID: 0 Comm: swapper/44 Tainted: G      D    OE     4.19b[ 1062.514972] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.2.11 10/17[ 1062.523357] RIP: 0010:set_task_cpu+0x193/0x1a0[ 1062.528624] Code: 00 00 04 e9 36 ff ff ff 0f 0b e9 be fe ff ff f7 43 60 fd f5[ 1062.549066] RSP: 0018:ffff996940b83dc8 EFLAGS: 00010046[ 1062.555134] RAX: 0000000000000200 RBX: ffff99c90f2a9e00 RCX: 0000000000000080[ 1062.563096] RDX: ffff99c90f2aa101 RSI: 000000000000000f RDI: ffff99c90f2a9e00[ 1062.571053] RBP: ffff996940b83de8 R08: 000000000000000f R09: 000000000000002c[ 1062.578990] R10: 0000000000000001 R11: 0000000000000009 R12: ffff99c90f2aa934[ 1062.586911] R13: 000000000000000f R14: 000000000000000f R15: 0000000000022d80[ 1062.594826] FS:  0000000000000000(0000) GS:ffff996940b80000(0000) knlGS:00000[ 1062.603681] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[ 1062.610182] CR2: 0000000000000040 CR3: 00000064af40a006 CR4: 00000000007626e0[ 1062.618061] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[ 1062.625919] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[ 1062.633762] PKRU: 55555554[ 1062.637186] Call Trace:[ 1062.640350]  <IRQ>[ 1062.643066]  try_to_wake_up+0x159/0x4b0[ 1062.647588]  default_wake_function+0x12/0x20[ 1062.652539]  autoremove_wake_function+0x12/0x40[ 1062.657744]  __wake_up_common+0x8c/0x130[ 1062.662340]  __wake_up_common_lock+0x80/0xc0[ 1062.667277]  __wake_up+0x13/0x20[ 1062.671170]  wake_up_klogd_work_func+0x40/0x60[ 1062.676275]  irq_work_run_list+0x55/0x80[ 1062.680860]  irq_work_run+0x2c/0x40[ 1062.684992]  flush_smp_call_function_queue+0xc0/0x100[ 1062.690687]  generic_smp_call_function_single_interrupt+0x13/0x30[ 1062.697430]  smp_call_function_single_interrupt+0x3e/0xe0[ 1062.703485]  call_function_single_interrupt+0xf/0x20[ 1062.709100]  </IRQ>[ 1062.711851] RIP: 0010:panic+0x1fe/0x244[ 1062.716329] Code: eb a6 83 3d 17 bc af 01 00 74 05 e8 b0 72 02 00 48 c7 c6 2f[ 1062.736366] RSP: 0018:ffffaa2b98c0fe60 EFLAGS: 00000286 ORIG_RAX: ffffffffff4[ 1062.744571] RAX: 000000000000004a RBX: ffff99693243bc00 RCX: 0000000000000006[ 1062.752328] RDX: 0000000000000000 RSI: 0000000000000096 RDI: ffff996940b96420[ 1062.760077] RBP: ffffaa2b98c0fed8 R08: 000000000000002c R09: 0000000000aaaaaa[ 1062.767814] R10: 0000000000000040 R11: 0000000000000001 R12: 0000000000000000[ 1062.775536] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000046[ 1062.783236]  do_exit+0x886/0xb20[ 1062.787023]  ? cpu_startup_entry+0x73/0x80[ 1062.791659]  rewind_stack_do_exit+0x17/0x20[ 1062.796364] ---[ end trace 3462ef57e3394c50 ]---[ 1062.801485] ------------[ cut here ]------------[ 1062.806599] sched: Unexpected reschedule of offline CPU#15![ 1062.812655] WARNING: CPU: 44 PID: 0 at /build/linux-4.19-0rc3.ag.4/arch/x86/0[ 1062.825264] Modules linked in: act_police cls_basic ebtable_filter ebtables i[ 1062.899387]  mac_hid coretemp lp parport btrfs zstd_compress raid456 async_ri[ 1062.932747] CPU: 44 PID: 0 Comm: swapper/44 Tainted: G      D W  OE     4.19b[ 1062.943874] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.2.11 10/17[ 1062.952057] RIP: 0010:native_smp_send_reschedule+0x3f/0x50[ 1062.958164] Code: c0 84 c0 74 17 48 8b 05 ff d9 36 01 be fd 00 00 00 48 8b 40[ 1062.978210] RSP: 0018:ffff996940b83de8 EFLAGS: 00010086[ 1062.984093] RAX: 0000000000000000 RBX: ffff99c90f2a9e00 RCX: 0000000000000006[ 1062.991894] RDX: 0000000000000007 RSI: 0000000000000086 RDI: ffff996940b96420[ 1062.999695] RBP: ffff996940b83de8 R08: 000000000000002c R09: 0000000000aaaaaa[ 1063.007501] R10: ffff996940b83dc8 R11: 0000000000000001 R12: ffff99c90f2aa934[ 1063.015303] R13: 0000000000000004 R14: 0000000000000046 R15: 0000000000022d80[ 1063.023110] FS:  0000000000000000(0000) GS:ffff996940b80000(0000) knlGS:00000[ 1063.031881] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[ 1063.038312] CR2: 0000000000000040 CR3: 00000064af40a006 CR4: 00000000007626e0[ 1063.046138] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[ 1063.053973] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[ 1063.061796] PKRU: 55555554[ 1063.065193] Call Trace:[ 1063.068323]  <IRQ>[ 1063.071021]  try_to_wake_up+0x3e3/0x4b0[ 1063.075534]  default_wake_function+0x12/0x20[ 1063.080485]  autoremove_wake_function+0x12/0x40[ 1063.085682]  __wake_up_common+0x8c/0x130[ 1063.090259]  __wake_up_common_lock+0x80/0xc0[ 1063.095172]  __wake_up+0x13/0x20[ 1063.099029]  wake_up_klogd_work_func+0x40/0x60[ 1063.104100]  irq_work_run_list+0x55/0x80[ 1063.108649]  irq_work_run+0x2c/0x40[ 1063.112767]  flush_smp_call_function_queue+0xc0/0x100[ 1063.118451]  generic_smp_call_function_single_interrupt+0x13/0x30[ 1063.125174]  smp_call_function_single_interrupt+0x3e/0xe0[ 1063.131209]  call_function_single_interrupt+0xf/0x20[ 1063.136807]  </IRQ>[ 1063.139535] RIP: 0010:panic+0x1fe/0x244[ 1063.144009] Code: eb a6 83 3d 17 bc af 01 00 74 05 e8 b0 72 02 00 48 c7 c6 2f[ 1063.164062] RSP: 0018:ffffaa2b98c0fe60 EFLAGS: 00000286 ORIG_RAX: ffffffffff4[ 1063.172269] RAX: 000000000000004a RBX: ffff99693243bc00 RCX: 0000000000000006[ 1063.180034] RDX: 0000000000000000 RSI: 0000000000000096 RDI: ffff996940b96420[ 1063.187781] RBP: ffffaa2b98c0fed8 R08: 000000000000002c R09: 0000000000aaaaaa[ 1063.195519] R10: 0000000000000040 R11: 0000000000000001 R12: 0000000000000000[ 1063.203243] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000046[ 1063.210950]  do_exit+0x886/0xb20[ 1063.214736]  ? cpu_startup_entry+0x73/0x80[ 1063.219371]  rewind_stack_do_exit+0x17/0x20[ 1063.224076] ---[ end trace 3462ef57e3394c51 ]---",Technical
,
"<snip>I got an non-truncated log as well:[  764.132461] BUG: unable to handle kernel NULL pointer dereference at 0000000000000040[  764.141001] PGD 0 P4D 0[  764.144020] Oops: 0000 [#1] SMP PTI[  764.147988] CPU: 70 PID: 0 Comm: swapper/70 Tainted: G           OE     4.19-0rc3.ag-generic #4+1536951040do~8680a1b[  764.159086] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.2.11 10/19/2017[  764.166968] RIP: 0010:set_next_entity+0x15/0x1d0[  764.171887] Code: c8 48 8b 7d d0 eb 96 0f 1f 40 00 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 55 48 89 e5 41 57 41 56 41 55 41 54 49 89 fc 53 <8b> 46 40 48 89 f30[  764.191276] RSP: 0018:ffffb97158cdfd78 EFLAGS: 00010046[  764.196888] RAX: 0000000000000000 RBX: ffff9806c0ee2d80 RCX: 0000000000000000[  764.204403] RDX: 0000000000000022 RSI: 0000000000000000 RDI: ffff9806c0ee2e00[  764.211918] RBP: ffffb97158cdfda0 R08: ffffb97178cd8000 R09: 0000000000006080[  764.219412] R10: 0000000000000000 R11: 0000000000000001 R12: ffff9806c0ee2e00[  764.226903] R13: 0000000000000000 R14: ffff9806c0ee2e00 R15: 0000000000000000[  764.234433] FS:  0000000000000000(0000) GS:ffff9806c0ec0000(0000) knlGS:0000000000000000[  764.242919] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[  764.249045] CR2: 0000000000000040 CR3: 00000002d720a004 CR4: 00000000007626e0[  764.256558] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[  764.264108] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[  764.271663] PKRU: 55555554[  764.274784] Call Trace:[  764.277633]  pick_next_task_fair+0x8a7/0xa20[  764.282292]  __schedule+0x13a/0x8e0[  764.286184]  schedule_idle+0x2c/0x40[  764.290161]  do_idle+0x169/0x280[  764.293816]  cpu_startup_entry+0x73/0x80[  764.298151]  start_secondary+0x1ab/0x200[  764.302513]  secondary_startup_64+0xa4/0xb0[  764.307127] Modules linked in: act_police cls_basic ebtable_filter ebtables ip6table_filter iptable_filter nbd ip6table_raw ip6_tables xt_CT iptable_raw ip_tables r[  764.381780]  coretemp lp parport btrfs zstd_compress raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid0 multipath linei[  764.414567] CR2: 0000000000000040[  764.418596] ---[ end trace 9b35e3cb99f8eacb ]---[  764.437343] RIP: 0010:set_next_entity+0x15/0x1d0[  764.442748] Code: c8 48 8b 7d d0 eb 96 0f 1f 40 00 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 55 48 89 e5 41 57 41 56 41 55 41 54 49 89 fc 53 <8b> 46 40 48 89 f30[  764.462845] RSP: 0018:ffffb97158cdfd78 EFLAGS: 00010046[  764.468788] RAX: 0000000000000000 RBX: ffff9806c0ee2d80 RCX: 0000000000000000[  764.476633] RDX: 0000000000000022 RSI: 0000000000000000 RDI: ffff9806c0ee2e00[  764.484476] RBP: ffffb97158cdfda0 R08: ffffb97178cd8000 R09: 0000000000006080[  764.492322] R10: 0000000000000000 R11: 0000000000000001 R12: ffff9806c0ee2e00[  764.500143] R13: 0000000000000000 R14: ffff9806c0ee2e00 R15: 0000000000000000[  764.507988] FS:  0000000000000000(0000) GS:ffff9806c0ec0000(0000) knlGS:0000000000000000[  764.516801] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[  764.523258] CR2: 0000000000000040 CR3: 00000002d720a004 CR4: 00000000007626e0[  764.531084] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[  764.538987] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[  764.546813] PKRU: 55555554[  764.550185] Kernel panic - not syncing: Attempted to kill the idle task![  764.557615] Kernel Offset: 0x1f400000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)[  764.581890] ---[ end Kernel panic - not syncing: Attempted to kill the idle task! ]---[  764.590574] WARNING: CPU: 70 PID: 0 at /build/linux-4.19-0rc3.ag.4/kernel/sched/core.c:1187 set_task_cpu+0x193/0x1a0[  764.601740] Modules linked in: act_police cls_basic ebtable_filter ebtables ip6table_filter iptable_filter nbd ip6table_raw ip6_tables xt_CT iptable_raw ip_tables r[  764.677788]  coretemp lp parport btrfs zstd_compress raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid0 multipath linei[  764.711018] CPU: 70 PID: 0 Comm: swapper/70 Tainted: G      D    OE     4.19-0rc3.ag-generic #4+1536951040do~8680a1b[  764.722332] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.2.11 10/19/2017[  764.730716] RIP: 0010:set_task_cpu+0x193/0x1a0[  764.735983] Code: 00 00 04 e9 36 ff ff ff 0f 0b e9 be fe ff ff f7 43 60 fd ff ff ff 0f 84 c8 fe ff ff 0f 0b e9 c1 fe ff ff 31 c0 e9 6d ff ff ff <0f> 0b e9 c9 fe ff5[  764.756428] RSP: 0018:ffff9806c0ec3e08 EFLAGS: 00010046[  764.762512] RAX: 0000000000000200 RBX: ffff980547829e00 RCX: 0000000000000080[  764.770492] RDX: ffff98054782a101 RSI: 0000000000000000 RDI: ffff980547829e00[  764.778456] RBP: ffff9806c0ec3e28 R08: 0000000000000000 R09: 0000000000000046[  764.786412] R10: 0000000000000001 R11: 0000000000000046 R12: ffff98054782a934[  764.794351] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000022d80[  764.802272] FS:  0000000000000000(0000) GS:ffff9806c0ec0000(0000) knlGS:0000000000000000[  764.811138] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[  764.817657] CR2: 0000000000000040 CR3: 00000002d720a004 CR4: 00000000007626e0[  764.825550] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[  764.833427] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[  764.841280] PKRU: 55555554[  764.844702] Call Trace:[  764.847857]  <IRQ>[  764.850581]  try_to_wake_up+0x159/0x4b0[  764.855146]  ? apic_timer_expired+0x70/0x70 [kvm][  764.860529]  wake_up_process+0x15/0x20[  764.864952]  swake_up_locked+0x24/0x40[  764.869370]  swake_up_one+0x1f/0x30[  764.873544]  apic_timer_expired+0x4b/0x70 [kvm][  764.878739]  apic_timer_fn+0x1b/0x50 [kvm][  764.883487]  __hrtimer_run_queues+0x106/0x270[  764.888496]  hrtimer_interrupt+0x116/0x240[  764.893237]  smp_apic_timer_interrupt+0x6f/0x140[  764.898497]  apic_timer_interrupt+0xf/0x20[  764.903228]  </IRQ>[  764.905967] RIP: 0010:panic+0x1fe/0x244[  764.910438] Code: eb a6 83 3d 17 bc af 01 00 74 05 e8 b0 72 02 00 48 c7 c6 20 f1 f8 a1 48 c7 c7 10 54 6d a1 e8 c0 a3 06 00 fb 66 0f 1f 44 00 00 <31> db e8 3f f5 0df[  764.930499] RSP: 0018:ffffb97158cdfe60 EFLAGS: 00000286 ORIG_RAX: ffffffffffffff13[  764.938726] RAX: 000000000000004a RBX: ffff9806b2501e00 RCX: 0000000000000006[  764.946509] RDX: 0000000000000000 RSI: 0000000000000096 RDI: ffff9806c0ed6420[  764.954282] RBP: ffffb97158cdfed8 R08: 0000000000000046 R09: 0000000000aaaaaa[  764.962038] R10: 0000000000000040 R11: 0000000000000001 R12: 0000000000000000[  764.969776] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000046[  764.977502]  do_exit+0x886/0xb20[  764.981305]  ? cpu_startup_entry+0x73/0x80[  764.985967]  rewind_stack_do_exit+0x17/0x20[  764.990699] ---[ end trace 9b35e3cb99f8eacc ]---[  764.995851] ------------[ cut here ]------------[  765.000984] sched: Unexpected reschedule of offline CPU#0![  765.006976] WARNING: CPU: 70 PID: 0 at /build/linux-4.19-0rc3.ag.4/arch/x86/kernel/smp.c:128 native_smp_send_reschedule+0x3f/0x50[  765.019617] Modules linked in: act_police cls_basic ebtable_filter ebtables ip6table_filter iptable_filter nbd ip6table_raw ip6_tables xt_CT iptable_raw ip_tables r[  765.094470]  coretemp lp parport btrfs zstd_compress raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid0 multipath linei[  765.127134] CPU: 70 PID: 0 Comm: swapper/70 Tainted: G      D W  OE     4.19-0rc3.ag-generic #4+1536951040do~8680a1b[  765.138261] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.2.11 10/19/2017[  765.146443] RIP: 0010:native_smp_send_reschedule+0x3f/0x50[  765.152543] Code: c0 84 c0 74 17 48 8b 05 ff d9 36 01 be fd 00 00 00 48 8b 40 30 e8 71 5e da 00 5d c3 89 fe 48 c7 c7 e8 b5 6c a1 e8 31 5b 03 00 <0f> 0b 5d c3 0f 1f0[  765.172572] RSP: 0018:ffff9806c0ec3d78 EFLAGS: 00010086[  765.178438] RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000006[  765.186228] RDX: 0000000000000007 RSI: 0000000000000082 RDI: ffff9806c0ed6420[  765.194020] RBP: ffff9806c0ec3d78 R08: 0000000000000046 R09: 0000000000aaaaaa[  765.201812] R10: ffff9806c0ec3c98 R11: 0000000000000001 R12: ffff9806c0622d80[  765.209601] R13: ffff9806c0622d80 R14: ffff9806c0ec3e48 R15: ffff9806c0622d80[  765.217394] FS:  0000000000000000(0000) GS:ffff9806c0ec0000(0000) knlGS:0000000000000000[  765.226154] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[  765.232575] CR2: 0000000000000040 CR3: 00000002d720a004 CR4: 00000000007626e0[  765.240395] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[  765.248211] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[  765.256028] PKRU: 55555554[  765.259416] Call Trace:[  765.262547]  <IRQ>[  765.265232]  resched_curr+0x79/0xf0[  765.269391]  check_preempt_curr+0x78/0xe0[  765.274073]  ttwu_do_wakeup+0x1e/0x150[  765.278485]  ttwu_do_activate+0x77/0x80[  765.282966]  try_to_wake_up+0x1d6/0x4b0[  765.287445]  ? apic_timer_expired+0x70/0x70 [kvm][  765.292775]  wake_up_process+0x15/0x20[  765.297151]  swake_up_locked+0x24/0x40[  765.301518]  swake_up_one+0x1f/0x30[  765.305637]  apic_timer_expired+0x4b/0x70 [kvm][  765.310800]  apic_timer_fn+0x1b/0x50 [kvm][  765.315515]  __hrtimer_run_queues+0x106/0x270[  765.320490]  hrtimer_interrupt+0x116/0x240[  765.325204]  smp_apic_timer_interrupt+0x6f/0x140[  765.330439]  apic_timer_interrupt+0xf/0x20[  765.335151]  </IRQ>[  765.337865] RIP: 0010:panic+0x1fe/0x244[  765.342304] Code: eb a6 83 3d 17 bc af 01 00 74 05 e8 b0 72 02 00 48 c7 c6 20 f1 f8 a1 48 c7 c7 10 54 6d a1 e8 c0 a3 06 00 fb 66 0f 1f 44 00 00 <31> db e8 3f f5 0df[  765.362254] RSP: 0018:ffffb97158cdfe60 EFLAGS: 00000286 ORIG_RAX: ffffffffffffff13[  765.370407] RAX: 000000000000004a RBX: ffff9806b2501e00 RCX: 0000000000000006[  765.378120] RDX: 0000000000000000 RSI: 0000000000000096 RDI: ffff9806c0ed6420[  765.385815] RBP: ffffb97158cdfed8 R08: 0000000000000046 R09: 0000000000aaaaaa[  765.393504] R10: 0000000000000040 R11: 0000000000000001 R12: 0000000000000000[  765.401172] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000046[  765.408830]  do_exit+0x886/0xb20[  765.412561]  ? cpu_startup_entry+0x73/0x80[  765.417147]  rewind_stack_do_exit+0x17/0x20[  765.421799] ---[ end trace 9b35e3cb99f8eacd ]---Thanks,Nish",Technical
,
"Yes that will suffice the use case. We wish to experiment at some pointwith co-scheduling of certain workers threads in DB parallel query and seeif there is any benefitThanks,Subhra",Technical
,
"I think cgroups will the get the job done for any use case. But we have,e.g. affinity control via both sched_setaffinity and cgroup cpusets. Itwill be good to have an alternative way to specify co-scheduling too forthose who don't want to use cgroup for some reason. It can be added lateron though, only how one will override the other will need to be sorted out.",Technical
,
"I got it reproduced.I will send a fix, when I have one.RegardsJan",Technical
,
"In case nobody else brought it up yet, you're going to need a handshaketo strengthen protection against L1TF attacks. Otherwise, there's stilla small window where an attack can occur during the reschedule. Perhapsone could then cause this to happen artificially by repeatedly have a VMdo some kind of pause/mwait type operation that might do a reschedule.Jon.--Computer Architect | Sent with my Fedora powered laptop",Technical
,
Have you considered using cpuset to specify the set of CPUs inside whichyou want to coschedule task groups in? Perhaps that would be more flexibleand intuitive to control than this cpu.scheduled value.Unless you require this feature to act always symmetrical through the branchesof a given domain tree?Thanks.,Technical
,
"Hi Jan,Do you know how much is the delay? i.e what is overlap time when a threadof new group starts executing on one HT while there is still thread ofanother group running on the other HT?Thanks,Subhra",Technical
,
"[...]Yes, I did consider cpusets. Though, there are two dimensions to it:a) at what fraction of the system tasks shall be coscheduled, andb) where these tasks shall execute within the system.cpusets would be the obvious answer to the ""where"". However, in the currentform they are too inflexible with too much overhead. Suppose, you want tocoschedule two tasks on SMT siblings of a core. You would be able torestrict the tasks to a specific core with a cpuset. But then, it is boundto that core, and the load balancer cannot move the group of two tasks to adifferent core.Now, it would be possible to ""invent"" relocatable cpusets to address thatissue (""I want affinity restricted to a core, I don't care which""), butthen, the current way how cpuset affinity is enforced doesn't scale formaking use of it from within the balancer. (The upcoming load balancingportion of the coscheduler currently uses a file similar to cpu.scheduledto restrict affinity to a load-balancer-controlled subset of the system.)Using cpusets as the mean to describe which parts of the system are to becoscheduled *may* be possible. But if so, it's a long way out. The currentimplementation uses scheduling domains for this, because (a) mostcoscheduling use cases require an alignment to the topology, and (b) itintegrates really nicely with the load balancer.AFAIK, there is already some interaction between cpusets and schedulingdomains. But it is supposed to be rather static and as soon as you haveoverlapping cpusets, you end up with the default scheduling domains.If we were able to make the scheduling domains more dynamic than they aretoday, we might be able to couple that to cpusets (or some similarinterface to *define* scheduling domains).RegardsJan",Technical
,
"Oh ok, I understand now. Affinity and node-scope mutual exclusion areentirely decoupled, I see.So what is the need for cosched_split_domains? What kind of corner case won'tfit into scheduler domains? Can you perhaps spare that part in this patchsetto simplify it somehow? If it happens to be necessary, it can still be addediteratively.Thanks.",Technical
,
"Oh boy, so the coscheduler is going to get itsown load balancer?At that point, why bother integrating thecoscheduler into CFS, instead of making it itsown scheduling class?CFS is already complicated enough that it borderson unmaintainable. I would really prefer to havethe coscheduler code separate from CFS, unlessthere is a really compelling reason to do otherwise.--All Rights Reversed.",Technical
,
"I guess he wants to reuse as much as possible from the CFS features andcode present or to come (nice, fairness, load balancing, power aware,NUMA aware, etc...).OTOH you're right, the thing has specific enough requirements to consider a newsched policy. And really I would love to see all that code separate from CFS,for the reasons you just outlined. So I cross my fingers on what Jan is going toanswer on a new policy.",Technical
,
"I wonder if things like nice levels, fairness,and balancing could be broken out into codethat could be reused from both CFS and a newco-scheduler scheduling class.A bunch of the cgroup code is already brokenout, but maybe some more could be broken outand shared, too?Some bits of functionality come to mind:- track groups of tasks that should be co-scheduled  (eg all the VCPUs of a virtual machine)- track the subsets of those groups that are runnable  (eg. the currently runnable VCPUs of a virtual machine)- figure out time slots and CPU assignments to efficiently  use CPU time for the co-scheduled tasks  (while leaving some configurable(?) amount of CPU time  available for other tasks)- configuring some lower-level code on each affected CPU  to ""run task A in slot X"", etcThis really does not seem like something that could beshoehorned into CFS without making it unmaintainable.Furthermore, it also seems like the thing that you couldnever really get into a highly efficient state as longas it is weighed down by the rest of CFS.--All Rights Reversed.",Technical
,
"Not ""its own"". The load balancer already aggregates statistics aboutsched-groups. With the coscheduler as posted, there is now a runqueue perscheduling group. The current ""ad-hoc"" gathering of data per schedulinggroup is then basically replaced with looking up that data at thecorresponding runqueue, where it is kept up-to-date automatically.Exactly. I want a user to be able to ""switch on"" coscheduling for thoseparts of the workload that profit from it, without affecting the behaviorwe are all used to. For both: scheduling behavior for tasks that are notcoscheduled, as well as scheduling behavior for tasks *within* the group ofcoscheduled tasks.Maybe.The primary issue that I have with a new scheduling class, is that they arestrictly priority ordered. If there is a runnable task in a higher class,it is executed, no matter the situation in lower classes. ""Coscheduling""would have to be higher in the class hierarchy than CFS. And then, allkinds of issues appear from starvation of CFS threads and other unfairness,to the necessity of (re-)defining a set of preemption rules, nice and otherthings that are given with CFS.cgroupsrunqueuesCFS runqueues and associated rules for preemption/time slices/etc.There is no ""slot"" concept, as it does not fit my idea of interactiveusage. (As in ""slot X will execute from time T to T+1.) It is purelyevent-driven right now (eg, ""group X just became runnable, it is consideredmore important than the currently running group Y; all CPUs (in theaffected part of the system) switch to group X"", or ""group X ran longenough, next group"").While some planning ahead seems possible (as demonstrated by the Tableauscheduler that Peter already pointed me at), I currently cannot imaginesuch an approach working for general purpose workloads. The absence of truepreemption being my primary concern.I still have this idealistic notion, that there is no ""weighing down"". Isee it more as profiting from all the hard work that went into CFS,avoiding the same mistakes, being backwards compatible, etc.If I were to do this ""outside of CFS"", I'd overhaul the scheduling classconcept as it exists today. Instead, I'd probably attempt to scheduleinstantiations of scheduling classes. In its easiest setup, nothing wouldchange: one CFS instance, one RT instance, one DL instance, strictlyordered by priority (on each CPU). The coscheduler as it is posted (andtask groups in general), are effectively some form of multiple CFSinstances being governed by a CFS instance.This approach would allow, for example, multiple CFS instances that arescheduled with explicit priorities; or some tasks that are scheduled with acustom scheduling class, while the whole group of tasks competes for timewith other tasks via CFS rules.I'd still keep the feature of ""coscheduling"" orthogonal to everything else,though. Essentially, I'd just give the user/admin the possibility to choosethe set of rules that shall be applied to entities in a runqueue.Your idea of further modularization seems to go in a similar direction, orat least is not incompatible with that. If it helps keeping thingsmaintainable, I'm all for it. For example, some of the (upcoming) loadbalancing changes are just generalizations, so that the functions don'toperate on *the* set of CFS runqueues, but just *a* set of CFS runqueues.Similarly in the already posted code, where task picking now starts at*some* top CFS runqueue, instead of *the* top CFS runqueue.RegardsJan",Technical
,
The leader doesn't kick the other cpus _immediately_ to switch to adifferent cosched group. So threads from previous cosched group will keeprunning in other HTs till their sched_slice is over (in worst case). Thiscan still keep the window of L1TF vulnerability open?,Technical
,
"It does. (Or at least, it should, in case you found evidence that it does not.)Specifically, the logic to not preempt the currently running task beforesome minimum time has passed, is without effect for a collective contextswitch.No. Per the above, the window due to the collective context switch shouldnot be as long as ""the remaining time slice"" but more towards the IPIdelay. During this window, tasks of different coscheduling groups mayexecute simultaneously.In addition (as mentioned in the quoted text above), there more cases wherea task of a coscheduled group on one SMT sibling may execute simultaneouslywith some other code not from the same coscheduled group: tasks inscheduling classes higher than CFS, and interrupts -- as both of themoperate outside the scope of the coscheduler.RegardsJan",Technical
,
"Can you point to where the leader is sending the IPI to other siblings?I did some experiment and delay seems to be sub microsec. I ran 2 threadsthat are just looping in one cosched group and affinitized to the 2 HTs ofa core. And another thread in a different cosched group starts runningaffinitized to the first HT of the same core. I time stamped just beforecontext_switch() in __schedule() for the threads switching from one toanother and one to idle. Following is what I get on cpu 1 and 45 that aresiblings, cpu 1 is where the other thread preempts:[Â  403.216625] cpu:45 sub1->idle:403216624579[Â  403.238623] cpu:1 sub1->sub2:403238621585[Â  403.238624] cpu:45 sub1->idle:403238621787[Â  403.260619] cpu:1 sub1->sub2:403260619182[Â  403.260620] cpu:45 sub1->idle:403260619413[Â  403.282617] cpu:1 sub1->sub2:403282617157[Â  403.282618] cpu:45 sub1->idle:403282617317..Not sure why the first switch on cpu to idle happened. But then onwardsthe difference in timestamps is less than a microsec. This is just a crudeway to get a sense of the delay, may not be exact.Thanks,Subhra",Technical
,
"Did your approach get posted to LKML? I never saw it I don't think, andI don't see it on lore. Could it be posted as an RFC, even if notsuitable for upstreaming yet, just for comparison?Thanks!-Nish",Technical
,
"I kind of agree with Jan here that this is just going to add yet another taskgroup mechanism, very similar to the existing one, with runqueues inside and all.Can you imagine kernel/sched/fair.c now dealing with both groups implementations?What happens when cgroup task groups and cosched sched groups don't match wrt.their tasks, their priorities, etc...I understand cgroup task group has become infamous. But it may be a better ideain the long run to fix it.",Technical
,
"One detail here, is that hierarchical task group a strong requirement for coschedor could you live with it flattened in the end?",Technical
,
"Currently, it is a strong requirement.As mentioned at the bottom of https://lkml.org/lkml/2018/10/19/859 it should bepossible to pull the hierarchical aspect out of CFS and implement it one levelhigher. But that would be a major re-design of everything.I use the hierarchical aspect to a) keep coscheduled groups in separate sets of runqeues,so that it is easy to select/balance tasks within a particular group; and b) to implementper-core, per-node, per-system runqueues that represent larger fractions of the system,which then fan out into per-CPU runqueues (eventually).RegardsJan",Technical
,
"Thanks for your patch.  Unfortunately, this entire function is scheduledfor deletion, so I won't be applying it.If you're interested in the radix tree, I'd recommend looking at itsreplacement, the XArray.  The current version is athttp://git.infradead.org/users/willy/linux-dax.git/shortlog/refs/heads/xarraybut I'll be pushing another version out in the next few days.",Technical
,
Why? What bug does this fix?-Dave.--Dave Chinnerdavid@fromorbit.com,Technical
,
"NACK for any bindings that are linux specific. The suspend feature is soplatform dependent that I see no need for generic Linux bindings for thesame.We have power domains and idle states. If you have platforms thatdoesn't support some of the states, just disable them in the DT.What makes any of the above linux specific. So once again NACK.--Regards,Sudeep",Technical
,
suspend to mem and suspend to disk are pretty generic states and i agreeimplementation is platform dependent so why not have properties thatconvey if they are supported?Is the disagreement over making the properties being linux specific?,Technical
,
"We already have power domains and idle states for that. If you need torestrict few states on some platform for whatever reasons, just disablethose states. I don't see the need to add any more bindings for the same.Yes.--Regards,Sudeep",Technical
,
"* Sudeep Holla <sudeep.holla@arm.com> [180912 11:41]:Oh do you mean the ""domain-idle-states"" property as mentioned in theDocumentation/devicetree/bindings/power/power_domain.txt?Yeah that should do and the DOMAIN_PWR_DN and DOMAIN_RET can be SoCspecific and then the board can select which ones to use depending onhow things are wired for GPIOs, memory, PMIC and so on.Hmm I don't see any users for this binding though?Regards,Tony",Technical
,
"Yes, exactly that.All the idle-states are platform specific. DOMAIN_RET and DOMAIN_PWR_DNare just examples used in the bindings.It was added specifically to deal with such SoC idles states orhierarchical CPU power domains states, no users in upstream yet. But IMOit fits what $subject is trying to address.--Regards,Sudeep",Technical
,
"* Sudeep Holla <sudeep.holla@arm.com> [180912 13:47]:OKOK great thanks for confirming that.Regards,Tony",Technical
,
"......The copypasta above and below is not my favorite, but I suppose it'seither this or wrap it all up in a macro that you stamp down 4 times.I'm not sure if that's really any cleaner, so I guess this is fine.CONFIGFS_ITEM_NAME_LEN is only 20. Is there anything preventing thedevice name passed in here from being longer than that? You'd have anasty overrun on your hands if not. Maybe snprintf here?",Technical
,
Agree. I need to use snprintf here. Will update.,Technical
,
Quoting Gregory CLEMENT (2018-09-14 08:34:21)So then why use devm_clk_get()? Please replace both so thadevm_clk_put() doesn't need to be used..,Technical
,
"Hi Stephen,Indeed between the successful devm_clk_get and the devm_clk_put we don'texit the function in error so I can use clk_get and clk_put.Gregory--Gregory Clement, BootlinEmbedded Linux and Kernel engineeringhttp://bootlin.com",Technical
,
"From: Romain Aviolat <r.aviolat@gmail.com>Date: Fri, 14 Sep 2018 22:25:40 +0200This kind of coding style fix has very little value for a subsystemwhich is essentially frozen from changes, and to which the lesschanges that happen to it the better in order to avoid potentialregressions.Therefore I am not applying this patch, sorry.",Technical
,
"Thanks Eric for reviewing the patch. rtnl_needed is not a shared variable, it is part of bonding structure, that is one per bonding driver instance. There can't be two parallel instances of bond_miimon_inspect for a single Â bonding driver instance at any given point of time. and only bond_miimon_inspect updates it. Thatâ€™s why I think there is no need of any synchronization here.Thank you for cautioning us on bool usage. even a u8 can meet our requirement.  we will change it.  but; if time permits can you share more on ""particularly dangerous here, at least on some arches"".F",Technical
,
"Thankyou Eric, we are making the changes and will repost the patch after testing it.-Manish",Technical
,
"Please review the updated patch, I have changed the rtnl_needed to an atomic variable, to avoid any race condition:From: Manish Kumar Singh <mk.singh@oracle.com>When link status change needs to be committed and rtnl lock couldn't be taken, avoid redisplay of same link status change message.Signed-off-by: Manish Kumar Singh <mk.singh@oracle.com>--- drivers/net/bonding/bond_main.c | 6 ++++-- include/net/bonding.h           | 1 + 2 files changed, 5 insertions(+), 2 deletions(-)diff --git a/drivers/net/bonding/bond_main.c b/drivers/net/bonding/bond_main.c index 217b790d22ed..fac5350bf19c 100644--- a/drivers/net/bonding/bond_main.c+++ b/drivers/net/bonding/bond_main.c@@ -2087,7 +2087,7 @@ static int bond_miimon_inspect(struct bonding *bond) 			bond_propose_link_state(slave, BOND_LINK_FAIL); 			commit++; 			slave->delay = bond->params.downdelay;-			if (slave->delay) {+			if (slave->delay && !atomic_read(&bond->rtnl_needed)) { 				netdev_info(bond->dev, ""link status down for %sinterface %s, disabling it in %d ms\n"", 					    (BOND_MODE(bond) == 					     BOND_MODE_ACTIVEBACKUP) ?@@ -2127,7 +2127,7 @@ static int bond_miimon_inspect(struct bonding *bond) 			commit++; 			slave->delay = bond->params.updelay;-			if (slave->delay) {+			if (slave->delay && !atomic_read(&bond->rtnl_needed)) { 				netdev_info(bond->dev, ""link status up for interface %s, enabling it in %d ms\n"", 					    slave->dev->name, 					    ignore_updelay ? 0 :@@ -2301,9 +2301,11 @@ static void bond_mii_monitor(struct work_struct *work) 		if (!rtnl_trylock()) { 			delay = 1; 			should_notify_peers = false;+			atomic_set(&bond->rtnl_needed, 1); 			goto re_arm; 		}+		atomic_set(&bond->rtnl_needed, 0); 		bond_for_each_slave(bond, slave, iter) { 			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER); 		}diff --git a/include/net/bonding.h b/include/net/bonding.h index 808f1d167349..ffc1219f7a07 100644--- a/include/net/bonding.h+++ b/include/net/bonding.h@@ -234,6 +234,7 @@ struct bonding { 	struct	 dentry *debug_dir; #endif /* CONFIG_DEBUG_FS */ 	struct rtnl_link_stats64 bond_stats;+	atomic_t rtnl_needed; }; #define bond_slave_get_rcu(dev) \--2.14.1Thanks,Manish",Technical
,
What happens to pmus that got added later?The rest looks good.Can you post a non RFC version?-Andi,Technical
,
"There is a hunk a bit lower in the patch where in perf_pmu_register theinitial setting is assigned from the global sysctl.Sure!Regards,Tvrtko",Technical
,
"On Fri, Sep 28, 2018 at 3:22 PM Tvrtko Ursulin<tvrtko.ursulin@linux.intel.com> wrote:Which paranoia level would be used for the i915.perf_event_paranoidsetting in such a case?Perhaps also CC kernel-hardening@lists.openwall.com on the next version.",Technical
,
"Hello,Thomas, thanks a lot for involving the folks!If you ask me then, IMHO, unprivileged access to CBOX pmu looks unsafeand is now governed by traditional *core* perf_event_paranoid setting.But *core* paranoid >= 1 (per-process mode) prevents simultaneous perfrecord sampling and perf stat -I reading from IMC, UPI, PCIe and otheruncore counters.This kind of monitoring could make process performance observabilitythru Perf subsystem more flexible and better tailored for cloud andcluster environments. However it requires fine-tuning controlcapabilities in order to still keep system as secure as possible.Could i915, IMC, UPI, PCIe pmus be safe enough to be governed bya separate perf_event_paranoid settings?Thanks!Alexey",Technical
,
"There's also been prior discussion on these feature in other contexts(e.g. android expoits resulting from out-of-tree drivers). It would benice to see those considered.IIRC The conclusion from prior discussions (e.g. [1]) was that we wantedfiner granularity of control such that we could limit PMU access tospecific users -- e.g. disallow arbitrary android apps from poking *any*PMU, while allowing some more trusted apps/users to uses *some* specificPMUs.e.g. we could add /sys/bus/event_source/devices/${PMU}/device, protectthis via the usual fs ACLs, and pass the fd to perf_event_open()somehow. A valid fd would act as a capability, taking precedence overperf_event_paranoid.Thanks,Mark.[1] https://patchwork.kernel.org/patch/9249919/",Technical
,
That sounds like an orthogonal feature. I don't think the originalpatchkit would need to be hold up for this. It would be somethingin addition.BTW can't you already do that with the syscall filter? I assumethe Android sandboxes already use that. Just forbid perf_event_openfor the apps.-Andi,Technical
,
"I have to say that I disagree -- these controls will have to interactsomehow, and the fewer of them we have, the less complexity we'll haveto deal with longer-term.Note that this was about providing access to *some* PMUs in some cases.IIUC, if that can be done today via a syscall filter, the same is trueof per-pmu paranoid settings.Thanks,Mark.",Technical
,
"Alexey,Just to make it clear. I'm not against separate settings at all. But I'magainst adding knobs for every PMU the kernel supports wholesale withoutanalysis and documentation just because we can and somebody wants it.Right now we have a single knob, which is poorly documented and that shouldbe fixed first. But some googling gives you the information that allowingunprivilegded access is a security risk. So the security focussed sysadminwill deny access to the PMUs no matter what.Now we add more knobs without documentation what the exposure and risk ofeach PMU is. The proposed patch set does this wholesale for every PMUsupported by the kernel. So the GPU user will ask the sysadmin to allow himaccess. How can he make an informed decision? If he grants it then the nextuser comes around and wants it for something else arguing that the othergot it for the GPU already. How can he make an informed decision aboutthat one?We provide the knobs, so it's also our responsibility towards our users togive them the information about their usage and scope. And every single PMUknob has a different scope.The documentation of the gazillion of knobs in /proc and /sysfs is notreally brilliant, but we should really not continue this bad practiceespecially not when these knobs have potentially security relevantimplcations. Yes, I know, writing documentation is work, but it's valuableand is appreciated by our users.To make this doable and not blocked by requiring every PMU to be analyzedand documented at once, I suggested to make this opt-in. Do analysis for agiven PMU, decide whether it should be exposed at all. If so, document itproper and flip the bit. That way this can be done gradually as the needarises and we can exclude the riskier ones completely.I don't think this is an unreasonable request as it does not require thei915 folks to look at PMUs they are not familiar with and does not getblocked by waiting on every PMU wizard on the planet to have time.Start with something like Documentation/admin-guide/perf-security.rst orwhatever name fits better and add a proper documentation for the existingknob. With the infrastructure for fine grained access control add thegeneral explanation for fine grained access control. With each PMU whichopt's in for the knob, add a section with guidance about scope and risk forthis particular one.Thanks,	tglx",Technical
,
"You're proposing to completely redesign perf_event_open.This new file descriptor argument doesn't exist today so it wouldneed to create a new system call with more arguments(and BTW it would be more than the normal 6 argument limitwe have, so actually it couldn't even be a standard sycall)Obviously we would need to keep the old system call aroundfor compability, so you would need to worry about thisinteraction in any case!So tying it together doesn't make any sense, becausethe problem has to be solved separately anyways.The difference is that the Android sandboxes likely already doing thisand have all the infrastructure, and it's just another rule.Requiring syscall filters just to use the PMU on xn systemthat otherwise doesn't need them would be very odd.-Andi",Technical
,
"And I think it would be a very good redesign. :) I love things thatuse file descriptors to represent capabilities.Is that true? The first argument is a pointer to a struct thatcontains its own size, so it can be expanded without an ABI break. Idon't see any reason why you couldn't cram more stuff in there.",Technical
,
"You're right we could put the fd into the perf_event, but the following isstill true:-Andi",Technical
,
"<blasphemy>Is that true? IIRC if you want to use the perf tools after a kernelupdate, you have to install a new version of perf anyway, no? I thinkafter I run a kernel update, when I run ""perf top"", it just refuses tostart and tells me to go install a newer version. Would the users ofperf_event_open() that want to monitor this graphics stuff normallykeep working after a kernel version bump?I realize that the kernel is very much against breaking userspaceinterfaces, but if userspace has already decided to break itself afterevery update, we might as well take advantage of that...</blasphemy>",Technical
,
"Not at all. perf is fully ABI compatible.Yes Ubuntu/Debian make you do it, but there is no reason for it otherthan their ignorance. Other sane distributions don't.Usually the first step when I'm forced to use one of those machine is toremove the useless wrapper and call the perf binary directly.-Andi",Technical
,
"Ah, I guess the answer is ""0"", since you want to see data about whatother users are doing.Does the i915 PMU expose sampling events, counting events, or both?The thing about sampling events is that they AFAIK always let the userpick arbitrary data to collect - like register contents, or userspacestack memory -, and independent of the performance counter beingmonitored, this kind of access should not be permitted to othercontexts. (But it might be that I misunderstand how perf works - I'mnot super familiar with its API.)",Technical
,
"And why so? You can keep the original functionality around with theexisting restrictions without breaking any existing user space. Thatexisting functionality does not require new knobs. It stays as is.So if you want to use the enhanced version with per PMU permissions basedon file descriptors you need a new version of perf. That's nothing new, ifthe kernel adds new features to any syscall, then you need new tools, newlibraries etc. The only guarantee the kernel makes is not to break existinguser space, but there is no guarantee that you can utilize new featureswith existing userspace.Thanks,	tglx",Technical
,
"Hello,<SNIP>Sounds like a plan. Thanks!BR,Alexey",Technical
,
"Hello Jann,<SNIP>There are usages in production where perf_event_open() syscallaccompanied with read(), mmap() etc. is embedded into applicationon per-thread basis and is used for self monitoring and dynamicexecution tuning.There are also other Perf tools around that, for example, arestatically linked and then used as on Linux as on Android.Backward compatibility does matter in these cases.Thanks,Alexey",Technical
,
"Hello Jann and Kees,<SNIP>Currently *core* paranoid >= 1 (per-process mode) prevents simultaneoussampling on CPU events (perf record) and reading of uncore HW counters(perf stat -I), because uncore counters count system wide and that isallowed only when *core* paranoid <= 0.Uncore counts collected simultaneously with CPU event samples can becorrelated using timestamps taken from some common system clock e.g.CLOCK_MONOTONIC_RAW.Could it be secure enough to still allow reading of system wide uncoreHW counters when sampling of CPU events is limited to specific processesby *core* paranoid >= 1?Thanks,Alexey",Technical
,
"Alexey,Well, it's nothing fundamentally new, that new features require changes toapplications, libraries etc. It's nice if it can be avoided of course.From a design POV, Jann's idea to have a per PMU special file which youneed to open for getting access is way better than the extra knobs. Itallows to use all existing security mechanisms to be used.Peter and I discussed that and we came up with the idea that the filedescriptor is not even required, i.e. you could make it backwardcompatible.perf_event_open() knows which PMU is associated with the event the callertries to open. So perf_event_open() can try to access/open the special perPMU file on behalf of the caller. That should get the same securitytreatment like a regular open() from user space. If that succeeds, accessis granted.The magic file could still be writeable for root to give generalrestrictions aside of the file based ones similar to what you areproposing.The analysis and documentation requirements still remain of course.Thanks,	tglx",Technical
,
"(That was Mark's idea, not mine, I just agree with his idea a lot.)",Technical
,
"Hello,<SNIP>Let me wrap up all the requirements and ideas that have been captured so far.1. A file [1] is added so that it can belong to a group of users allowed to use ${PMU},   something like this:ls -alh /sys/bus/event_source/devices/${PMU}/caps/total 0drwxr-xr-x 2 root root            0 Oct  1 20:36 .drwxr-xr-x 6 root root            0 Oct  1 20:36 ..-r--r--r-- 1 root root         4.0K Oct  1 20:36 branches-r--r--r-- 1 root root         4.0K Oct  1 20:36 max_precise-r--r--r-- 1 root root         4.0K Oct  1 20:36 pmu_name-rw-r--r--   root ${PMU}_users                   paranoid        <===   Modifications of file content are allowed to those who can   modify /proc/sys/kernel/perf_event_paranoid setting.2. Semantics and content of the introduced paranoid file is   similar to /proc/sys/kernel/perf_even_paranoid [2]:   The perf_event_paranoid file can be set to restrict access   to the performance counters.   2   allow only user-space measurements (default since Linux 4.6).   1   allow both kernel and user measurements (default before Linux 4.6).   0   allow access to CPU-specific data but not raw traceâ€point samples.  -1  no restrictions.   The existence of the perf_event_paranoid file is the official method   for determining if a kernel supports perf_event_open().3. Every time an event for ${PMU} is created over perf_event_open():   a) the calling thread's euid is checked to belong to ${PMU}_users group      and if it does then the event's fd is allocated;   b) then traditional checks against perf_event_pranoid content are applied;   c) if the file doesn't exist the access is governed by global setting      at /proc/sys/kernel/perf_even_paranoid;4. Documentation/admin-guide/perf-security.rst file is introduced that:   a) contains general explanation for fine grained access control;   b) contains a section with guidance about scope and risk for each PMU      which is enabled for fine grained access control;   c) file is extended when more PMUs are enabled for fine grain control;Security analysis for uncore IMC, QPI/UPI, PCIe PMUs is still requiredto be enabled for fine grain control.Thanks,Alexey[1] https://patchwork.kernel.org/patch/9249919/#19714087[2] http://man7.org/linux/man-pages/man2/perf_event_open.2.html",Technical
,
"Alexey,Right, though I personaly prefer something like 'access_control' as filename, but that's bike shed painting realm.Not only the user group, it really should do the full security checks whichare done on open().Hmm, not sure about that because that might be conflicting.Correct.     0) Better documentation of /proc/sys/kernel/perf_even_paranoidThanks,	tglx",Technical
,
"Hello,<SNIP>I expect it is already implemented by some internal kernel API so thatit could be reused.Well, possible contradictions could be converged to some reasonable pointduring technical review stage.Current perf_event_paranoid semantics is still required for PMUsthat are governed by global setting at /proc/sys/kernel/perf_event_paranoid.<SNIP>Exactly. perf_event_open man7 [1] requires update as well, howeverthis is not a part of kernel source tree so these docs changes areto be mailed TO: mtk.manpages@gmail.com and CC: linux-api@vger.kernel.org.Thanks,Alexey[1] http://man7.org/linux/man-pages/man2/perf_event_open.2.html",Technical
,
"On Mon, Oct 1, 2018 at 10:53 PM Alexey Budankov<alexey.budankov@linux.intel.com> wrote:You'll also have to make sure that this thing in kernel/events/core.cdoesn't have any bad effect:    /*    * Special case software events and allow them to be part of    * any hardware group.    */As in, make sure that you can't smuggle in arbitrary software eventsby attaching them to a whitelisted hardware event.And you can't whitelist anything that permits using sampling eventswith arbitrary sample_type.",Technical
,
"Hi,<SNIP>Yes, makes sense. Please see and comment below.<SNIP>It appears that there is a dependency on the significance of data that PMUs capturesfor later analysis. Currently there are following options for data being captured(please correct or extend if something is missing from the list below):1) Monitored process details:   - system information on a process as a container (of threads, memory data and     IDs (e.g. open fds) from process specific namespaces and etc.);   - system information on threads as containers (of execution context details);2) Execution context details:   - memory addresses;   - memory data;   - calculation results;   - calculation state in HW;3) Monitored process and execution context telemetry data, used for building   various performance metrics and can come from:   - user mode code and OS kernel;   - various parts of HW e.g. core, uncore, peripheral and etc.Group 2) is the potential leakage source of sensitive process data so if a PMU,at some mode, samples execution context details then the PMU, working in that mode,is the subject for *access* and *scope* control.On the other hand if captured data contain only the monitored process detailsand/or associated execution telemetry, there is probably no sensitive data leakagethru that captured data.For example, if cpu PMU samples PC addresses overtime, e.g. for providinghotspots-by-function profile, then this requires to be controlled as from access asfrom scope perspective, because PC addresses is execution context details thatcan contain sensitive data.However, if cpu PMU does counting of some metric value, or if software PMU readsvalue of thread active time from the OS, possibly overtime, for later building somerating profile, or reading of some HW counter value without attribution to anyexecution context details, that is probably not that risky as in the case ofPC address sampling.Uncore PMUs e.g. memory controller (IMC), interconnect (QPI/UPI) and peripheral (PCIe)currently only read counters values that are captured system wide by HW, and provideno attribution to any specific execution context details, thus, sensitive process data.Based on that,A) paranoid knob is required for a PMU if it can capture data from group 2)B) paranoid knob limits scope of capturing sensitive data:   -3 - *scope* is defined by some high level setting   -2 - disabled - no allowed *scope*   -1 - no restrictions - max *scope*    0 - system wide    1 - process user and kernel space    2 - process user space onlyC) paranoid knob has to be checked every time the PMU is going to start   capturing sensitive data to avoid capturing beyond the allowed scope.PMU *access* semantics is derived from fs ACLs and could look like this:r - read PMU architectural and configuration details, read PMU *access* settingsw - modify PMU *access* settingsx - modify PMU configuration and collect dataSo levels of *access* to PMU could look like this:root=rwx, ${PMU}_users=r-x, other=r--.Possible examples of *scope* control settings could look like this:1) system wide user+kernel mode CPU sampling with context switches   and uncore counting:	/proc/sys/kernel/perf_event_paranoid (-2, 2): 0	SW.paranoid  (-3, 2):(root=rwx, SW_users=r-x,other=r--): -3	CPU.paranoid (-3, 2):(root=rwx,CPU_users=r-x,other=r--): -3	IMC.paranoid (-3,-1):(root=rwx,IMC_users=r-x,other=r--): -3	UPI.paranoid (-3,-1):(root=rwx,UPI_users=r-x,other=r--): -3	PCI.paranoid (-3,-1):(root=rwx,PCI_users=r-x,other=r--): -32) per-process CPU sampling with context switches and uncore counting:	/proc/sys/kernel/perf_event_paranoid (-2, 2): 1|2	SW.paranoid  (-3, 2):(root=rwx, SW_users=r-x,other=r--): -3	CPU.paranoid (-3, 2):(root=rwx,CPU_users=r-x,other=r--): -3	IMC.paranoid (-3,-1):(root=rwx,IMC_users=r-x,other=r--): -1	UPI.paranoid (-3,-1):(root=rwx,UPI_users=r-x,other=r--): -1	PCI.paranoid (-3,-1):(root=rwx,PCI_users=r-x,other=r--): -13) per-process user mode CPU sampling allowed to specific ${PMU}_groups only:	/proc/sys/kernel/perf_event_paranoid (-2, 2): -2	SW.paranoid  (-3, 2):(root=rwx, SW_users=r-x,other=r--):  2	CPU.paranoid (-3, 2):(root=rwx,CPU_users=r-x,other=r--):  2	IMC.paranoid (-3,-1):(root=rwx,IMC_users=r-x,other=r--): -3	UPI.paranoid (-3,-1):(root=rwx,UPI_users=r-x,other=r--): -3	PCI.paranoid (-3,-1):(root=rwx,PCI_users=r-x,other=r--): -34) uncore HW counters monitoring, possibly overtime:	/proc/sys/kernel/perf_event_paranoid (-2, 2): -2	SW.paranoid  (-3, 2):(root=rwx, SW_users=r-x,other=r--): -3	CPU.paranoid (-3, 2):(root=rwx,CPU_users=r-x,other=r--): -3	IMC.paranoid (-3,-1):(root=rwx,IMC_users=r-x,other=r--): -1	UPI.paranoid (-3,-1):(root=rwx,UPI_users=r-x,other=r--): -1	PCI.paranoid (-3,-1):(root=rwx,PCI_users=r-x,other=r--): -1Please share more thought so that it eventually could go intoDocumentation/admin-guide/perf-security.rst.Thanks,Alexey",Technical
,
I missed this and do the wrong thing.I'm really sorry for this.,Technical
,
"This patch doesn't apply to cryptodev because the bug has alreadybeen fixed by another patch.Thanks,--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt",Technical
,
"While I agree that it is polling anyway, this change can add significantburden when debugging and trace is enabled for cpu_idle, if idle state 0is used often.For example: Phoronix dbench test, 96 clients: 900 second trace:Kernel 4.20-rc1:idle state 0 entry exits: 686,724Does trace being enabled effect the system under test: Yes.Kernel 4.20-rc1 with this patch reverted:idle state 0 entry exits: 66,185Does trace being enabled effect the system under test: No, or minimal.... Doug",Technical
,
"Hi JiadaThank you for your patchIf my understanding was correct, the chance to use BUSIFx is when TDM split mode.And this patch selects it on runtime (= hw_param) ?But, I think we can/should select it on probe timing from DT connection.Am I misunderstanding ?I'm not sure how to select, but adding new ssiuX0 - ssiuX7is realistic idea (parse sound card is not realistic...) ?If so, your rxu/txu DMA can be more simple ?",Technical
,
"Hi Morimoto-sanYes, only when SSI works in Split/Ex-Split mode, BUSIFx other than 0 isnecessaryBecause, in order to automatically determine BUSIF number,information like SSI mode (non-Split/Split/Ex-Split), runtime channel,are required(in our internal implementation, SSI mode is selected by kctrl)because of this, in this patch, BUSIF is selected on runtimewith the above reasoning, BUSIF is selected on runtime.what do you think?Thanks,Jiada",Technical
,
"Hi JiadaThank you for your feedback(snip)I have no objection that you are customizing your kernel locally.But, upstreaming kernel based on it is not acceptable for me.I'm not sure detail of your local implementation, but I don't think weneed to select SSI mode by kctrl.If my understanding was correct, it can also be selected automatically somehow.Or, am I misunderstanding ?I could understand what you want to do, and yes, I can agree that we want/needto have it on upstream. Thank you very much to indicating it to me.But we need to consider more how to implement it.Especially, it is related to DT bindings.As you already know, if it is implemented on upstream kernel, we need to keepcompatibility in the future, and it is very difficult.So, my opinions for BUSIFn support are	- SSI mode should be selected automatically	- BUSIFn connection should be selected on DT	  (I think we don't want random sound output position ?)	  - To select it, we need to have new ""ssiu"" DT seetings,	    or parse sound card. Maybe adding ssiu is realistic.Best regards---Kuninori Morimoto",Technical
,
"Hi Morimoto-sanThanks for your commentsSSI can work in following modes1. Basic Mode: (channel 1, 2, 4, 6, 8, 16)2. TDM Extended Mode: (channel 6, 8)3. TDM Split Mode: (channel 1, 2)4. TDM Ex-Split mode: (Channel 2, 4, 6, 8, 10)for example user asks dai-link0 to playback 2ch audio stream,driver can't determine which mode to work, as it can be Basic mode,Split mode or Ex-Split mode.Yes, I agree with you, upstream need to consider lots of thingscan you give me your idea, how to automatically determine working mode,when user plays 2 channel stream on playback dai-linksince which BUSIFx is used during audio data transfer, is notconsideration of user,I think your previous suggestion, (automatically select BUSIFx) makesmore senseThanks,Jiada",Technical
,
"Hi Jiada(snip)If my understanding was correct, we can do like thisIf DT indicated sound card has dai-link x N, tdm-slots = <M>,	If (N, M) = (1, 2) : Basic mode	If (N, M) = (1, >2): TDM mode	If (N, M) = (2, 4) : TDM Split mode	If (N, M) = (2, >4): TDM Ex-Split mode	If (N, M) = (>2, 8): TDM Split mode	...Maybe some combination was wrong, but we can do something like this ?Why do we need to use Basic mode if HW has TDM Split mode connection?If user playbacks 2ch audio in such situation,we can use TDM Split mode (= only 2ch has sound, other channel has no sound ?)user might start to playback for other channels.I'm not sure how it works...I'm not yet sure detail, but in your idea, does it mean,BUSIFx connection might be exchanged runtime ?I think BUSIFx connection shouldn't exchanged runtime IMO.Otherwise, sound position can't be fixed, and user can't controlsound, I think...Best regards---Kuninori Morimoto",Technical
,
"Hi Morimoto-sanThanks for your commentThe idea to consider tdm_slot when determine SSI mode makes sense to me,by checking runtime channel and tdm_slots combination,I think SSI mode can be automatically selected like following:1ch:Â  (tdm_slots < 4) Basic mode, (tdm_slots >= 4) TDM Split mode2ch: (2 <= tdm_slots < 8) Basic mode, (tdm_slots >= 8) TDM Ex-Split mode4ch: (4 <= tdm_slots < 8) Basic mode, (tdm_slots >= 8) TDM Ex-Split mode6ch: (6 <= tdm_slots < 8) Basic mode, (tdm_slots == 8) TDM Extendedmode, (8 < tdm_slots) TDM Ex-Split mode8ch: (6 <= tdm_slots < 8) TDM Extended mode, (8 <= tdm_slots < 16) Basicmode, (tdm_slots == 16) TDM Ex-Split10ch: TDM Ex-Split mode16ch: Basic Modeno BUSIFx shouldn't be changed during runtime, my idea is BUSIFx can beautomatically selectedwhen corresponding dai-link is not activeThe reason I added rsnd_ssi_select_busif(io, chan) in rsnd_hw_params()in patch ASoC: rsnd: add busif property to dai stream of v2 patch-set,is because runtime channel is necessary information to determine whichBUSIFx to select,(which is mentioned in above)and at this stage (rsnd_hw_params()), all other control settings(register setting, dma address calculation etc)haven't been done, so corresponding dai-link can be considered to be notactive at this timingbut maybe you have better suggestion when to automatically select BUSIFxWhat is your opinion?Thanks,Jiada",Technical
,
"Hi JiadaThanks for your feedbackSorry, but I couldn't understand what this table means ?For example, what does ""1ch"" mean ?It looks like ""1ch playback by TDM""...My image is like this.	sound {		compatible = ""simple-scu-audio-card or new card"";		...		simple-audio-card,convert-channels = <8>;		...		busif0: simple-audio-card,cpu@0 { sound-dai = <&rcar_sound 0>; };		busif1: simple-audio-card,cpu@1 { sound-dai = <&rcar_sound 1>; };		busif2: simple-audio-card,cpu@2 { sound-dai = <&rcar_sound 2>; };		busif3: simple-audio-card,cpu@3 { sound-dai = <&rcar_sound 3>; };		        simple-audio-card,codec { sound-dai = <&xxx>;          };	};	rcar_sound {		dai0 { playback = <&ssiu0 ssi0>; }		dai1 { playback = <&ssiu1 ssi0>; }		dai2 { playback = <&ssiu2 ssi0>; }		dai3 { playback = <&ssiu3 ssi0>; }	};Best regards---Kuninori Morimoto",Technical
,
"Hi Morimoto-sanThanks for your feedbacksorry for vague explanation,by ""1ch"" I mean runtime 1 channel playbackfor example:if user plays 1 channel stream, by checking tdm_slots value,if it is < 4, then it can't be working in Split mode, so driver willautomatically set SSI to work in Basic mode, otherwise, SSI willwork in TDM Split mode.After re-think about BUSIFx selection, I agree with you,it shouldn't be random, and select it via device-tree, as you havealready demonstratedis a good ideaBased on our discussion so far, I think we both agree on the followingpoints1. Driver select SSI mode automatically (by checking tdm_slots, runtimechannel, etc)2. Driver parse BUSIFx for each dai-link from device-treeI will review my v2 patch-set, drop changes violate to above two pointsThanks,Jiada",Technical
,
"Hi JiadaHmm... ??Maybe, we are misunderstanding each other...In my understanding, if platform can use TDM 8ch Split mode,user interface will be for example dai0, dai1, dai2, dai3 (= for TDM 8ch).Here, each daiX can handle stereo sound only.Then, user can playback like this	aplay -D plughw:0,0 xxx.wav (= will be 1ch, 2ch)	aplay -D plughw:0,1 xxx.wav (= will be 3ch, 4ch)	aplay -D plughw:0,2 xxx.wav (= will be 5ch, 6ch)	aplay -D plughw:0,3 xxx.wav (= will be 7ch, 8ch)1ch sound will be converted to 2ch by alsalib, and daiX will receiveconverted 2ch sound.SSI always playbacks it as part of TDM 8ch Split mode.In this platform, it can handle stereo sound only on each daiX,and always works as TDM Split mode, never works as Basic Mode / TDM Ex-Split mode.If DAI was dai0, dai1 only, it will be TDM Ex-Split mode.It depends on tdm-slots, I think.if tdm-slots was 6ch...	aplay -D plughw:0,0 xxx.wav (= will be 1ch, 2ch, 3ch, 4ch)	aplay -D plughw:0,1 xxx.wav (= will be 5ch, 6ch)if tdm-slots was 8ch...	aplay -D plughw:0,0 xxx.wav (= will be 1ch, 2ch, 3ch, 4ch, 5ch, 6ch)	aplay -D plughw:0,1 xxx.wav (= will be 7ch, 8ch)something like this, is my understanding.Thank you for understanding my idea.Nice to knowBest regards---Kuninori Morimoto",Technical
,
"I believe this hasn't addressed my questions inhttp://lkml.kernel.org/r/20181002143015.GX18290@dhcp22.suse.cz. Namely""It is the more general idea that I am not really sure about. First ofall. Does it make _any_ sense to randomize 4MB blocks by default? Whycannot we simply have it disabled? Then and more concerning question is,does it even make sense to have this randomization applied to higherorders than 0? Attacker might fragment the memory and keep recycling thelowest order and get the predictable behavior that we have right now.""--Michal HockoSUSE Labs",Technical
,
This is the biggest portion of the series and I am wondering why do weneed it at all. Why it isn't sufficient to rely on the patch 3 here?Pages freed from the bootmem allocator go via the same path so theymight be shuffled at that time. Or is there any problem with that?Not enough entropy at the time when this is called or the final resultis not randomized enough (some numbers would be helpful).--Michal HockoSUSE Labs,Technical
,
"Hi Michal,I'm not aware of any CVE that this would directly preclude, but thatsaid the entropy injected at 4MB boundaries raises the bar on heapattacks. Environments that want more can adjust that with the bootparameter. Given the potential benefits I think it would only makesense to default disable it if there was a significant runtime impact,from what I have seen there isn't.Certainly I expect there are attacks that can operate within a 4MBwindow, as I expect there are attacks that could operate within a 4Kwindow that would need sub-page randomization to deter. In fact Ibelieve that is the motivation for CONFIG_SLAB_FREELIST_RANDOM.Combining that with page allocator randomization makes the kernel lesspredictable.Is that enough justification for this patch on its own? It'sdebatable. Combine that though with the wider availability ofplatforms with memory-side-cache and I think it's a reasonable defaultbehavior for the kernel to deploy.",Technical
,
"In fact we started with only patch3 and it had no measurable impact onthe cache conflict rate.So the reason front-back randomization is not enough is due to thein-order initial freeing of pages. At the start of that processputting page1 in front or behind page0 still keeps them closetogether, page2 is still near page1 and has a high chance of beingadjacent. As more pages are added ordering diversity improves, butthere is still high page locality for the low address pages and thisleads to no significant impact to the cache conflict rate. Patch3 isenough to keep the entropy sustained over time, but it's not enoughinitially.",Technical
,
"Hi Michal,Does the above address your concerns? v4.20 is perhaps the lastupstream kernel release in advance of wider hardware availability.",Technical
,
That should be in the changelog IMHO.--Michal HockoSUSE Labs,Technical
,
"I am sorry but this hasn't explained anything (at least to me). I canstill see a way to bypass this randomization by fragmenting the memory.With that possibility in place this doesn't really provide the promissedadditional security. So either I am missing something or the per-orderthreshold is simply a wrong interface to a broken security misfeature.I do not think so from what I have heard so far.OK, this sounds a bit more interesting. I am going to speculate becausememory-side-cache is way too generic of a term for me to imagineanything specific. Many years back while at a university I was playingwith page coloring as a method to reach a more stable performanceresults due to reduced cache conflicts. It was not always a performancegain but it definitely allowed for more stable run-to-run comparableresults. I can imagine that a randomization might lead to a similar effectalthough I am not sure how much and it would be more interesting to hearabout that effect. If this is really the case then I would assume on/offknob to control the randomization without something as specific asorder.--Michal HockoSUSE Labs",Technical
,
"I think a similar argument can be made againstCONFIG_SLAB_FREELIST_RANDOM the randomization benefits can be defeatedwith more effort, and more effort is the entire point.I'm missing what bar you are judging the criteria for these patches,my bar is increased protection against allocation ordering attacks asseconded by Kees, and the memory side caching effects. That said Idon't have a known CVE in my mind that would be mitigated by 4MB pageshuffling.No need to imagine, a memory side cache shipped on a previous productas Robert linked in his comments.Cache coloring is effective up until your workload no longer fits inthat color. Randomization helps to attenuate the cache conflict ratewhen that happens. For workloads that may fit in the cache, and/orenvironments that need more explicit cache control we have the recentchanges to numa_emulation [1] to arrange for cache sized numa nodes.Are we only debating the enabling knob at this point? I'm not opposedto changing that, but I do think we want to keep the rest of theinfrastructure to allow for shuffling on a variable page size boundaryin case there is enhanced security benefits at smaller buddy-pagesizes.[1]: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=cc9aec03e58f",Technical
,
"[..]Fair enough, I'll fold that in when I rebase on top of -next.",Technical
,
"If there is relatively simple way to achieve that (which I dunno aboutthe slab free list randomization because I am not familiar with theimplementation) then the feature is indeed questionable. I wouldunderstand an argument about feasibility if bypassing was extremely hardbut fragmenting the memory is relatively a simple task.As said above, if it is quite easy to bypass the randomization thencalling and advertizing this as a security feature is a dubious. Notenough to ouright nak it of course but also not something I would put mystamp on. And arguments would be much more solid if they were backed bysome numbers (not only for the security aspect but also the side cachingeffects).Could you make this a part of the changelog? I would really appreciateto see justification based on actual numbers rather than quite hand wavy""it helps"".Yes, that was my observation back then more or less. But even when youdo not fit into the cache a color aware strategy (I was playing with binhoping as well) produced a more deterministic/stable results. But thatis just a side note as it doesn't directly relate to your change.I can imagine that. Do we have any numbers to actually back that claimthough?Could you point me to some more documentation. My google-fu is failingme and ""5.2.27.5 Memory Side Cache Information Structure"" doesn't pointto anything official (except for your patch referencing it).I am still trying to understand the benefit of this change. If thecaching effects are actually the most important part and there is areasonable cut in allocation order to keep the randomization effectiveduring the runtime then I would like to understand the thinking behindthat. In other words does the randomization at smaller orders thanbiggest order still visible in actual benchmarks? If not then on/offknob should be sufficient with potential auto tuning based on actual HWrather than to expect poor admin to google for $RANDOM_ORDER to use on aspecific HW and all the potential cargo cult that will grow around it.As I've said before, I am not convinced about the security argument buteven if I am wrong here then I am still quite sure that you do not wantto expose the security aspect as ""chose an order to randomize from""because admins will have no real way to know what is the $RANDOM_ORDERto set. So even then it should be on/off thing. You are going to paysome of the performance because you would lose some page allocatoroptimizations (e.g. pcp lists) but that is unavoidable AFAICS.With all that being said, I think the overal idea makes sense but youshould try much harder to explain _why_ we need it and back yourjustification by actual _data_ before I would consider my ack.--Michal HockoSUSE Labs",Technical
,
"In fact you don't even need to fragment since you'll have 4MBcontiguous targets by default, but that's not the point. We'll nowhave more entropy in the allocation order to compliment the entropyintroduced at the per-SLAB level with CONFIG_SLAB_FREELIST_RANDOM....and now that I've made that argument I think I've come around toyour point about the shuffle_page_order parameter. The only entitythat might have a better clue about ""safer"" shuffle orders thanMAX_ORDER is the distribution provider. I'll cut a v4 to move all ofthis under a configuration symbol and make the shuffle order a compiletime setting.I put in the changelog that these patches reduced the cache conflictrate by 2.5X on a Java benchmark. I specifically did not put KNL datadirectly into the changelog because that is not a general purposeserver platform.Note, you can also think about this just on pure architecture terms.I.e. that for a direct mapped cache anywhere in a system you can havea near zero cache conflict rate on a first run of a workload and highconflict rate on a second run based on how lucky you are with memoryallocation placement relative to the first run. Randomization keepsyou out of such performance troughs and provides more reliable averageperformance.  With the numa emulation patch I referenced anadministrator could constrain a workload to run in a cache-sizedsubset of the available memory if they really know what they are doingand need firmer guarantees.The risk if Linux does not have this capability is unstable hacks likezonesort and rebooting, as referenced in that KNL article, which arenot suitable for a general purpose kernel / platform.Yes, 2.5X cache conflict rate reduction, in the change log.http://www.uefi.org/sites/default/files/resources/ACPI%206_2_A_Sept29.pdfSo, I've come around to your viewpoint on this. Especially when wehave CONFIG_SLAB_FREELIST_RANDOM the security benefit of smaller thanMAX_ORDER shuffling is hard to justify and likely does not need kernelparameter based control.I don't have a known CVE, I only have the ack of people moreknowledgeable about security than myself like Kees to say in effect,""yes, this complicates attacks"". If you won't take Kees' word for it,I'm not sure what other justification I can present on the securityaspect.2.5X cache conflict reduction on a Java benchmark workload that theexceeds the cache size by multiple factors is the data I can providetoday. Post launch it becomes easier to share more precise data, butthat's post 4.20. The hope of course is to have this capabilityavailable in an upstream released kernel in advance of wider hardwareavailability.",Technical
,
"[...]And how is somebody providing a kernel for large variety of workloadssupposed to know?[...]I am not disagreeing here. That reliable average might be worse thanwhat you get with the non-randomized case. And that might be a fairdeal for some workloads. You are, however, providing a functionalitywhich is enabled by default without any actual numbers (well except for_a_java_ workload that seems to benefit) so you should really do yourhomework stop handwaving and give us some numbers and/or convincingarguments please.Then mention how and what you can achieve by that in the changelog.We could have lived without those for quite some time so this doesn'tseem to be anything super urgent to push through without a properjustification.Which is a single benchmark result which is not even described in detailto be able to reproduce that measurement. I am sorry for nagginghere but I would expect something less obscure. How does this behave forusual workloads that we test cache sensitive workloads. I myself am nota benchmark person but I am pretty sure there are people who can helpyou to find proper ones to run and evaluate.Thanks![...]In general (nothing against Kees here of course), I prefer a strongerjustification than ""somebody said it will make attacks harder"". At leastmy concern about fragmented memory which is not really hard to achieveat all should be reasonably clarified. I am fully aware there is noabsolute measure here but making something harder under ideal conditionsdoesn't really help for common attack strategies which can prepare thesystem into an actual state to exploit allocation predictability. I amno expert here but if an attacker can deduce the allocation pattern thenfragmenting the memory is one easy step to overcome what people wouldconsider a security measure.So color me unconvinced for now.I will not comment on timing but in general, any performance relatedchanges should come with numbers for a wider variety of workloads.In any case, I believe the change itself is not controversial as long itis opt-in (potentially autotuned based on specific HW) with a reasonableAPI. And no I do not consider $RANDOM_ORDER a good interface.--Michal HockoSUSE Labs",Technical
,
"True, this would be a much easier discussion with a wider / deeper data set.The latest version of the patches no longer enable it by default. I'mgiving you the data I can give with respect to pre-productionhardware.The numa_emulation aspect is orthogonal to the randomizationimplementation. It does not belong in the randomization changelog.We lived without them previously because memory-side-caches werelimited to niche hardware, now this is moving into general purposeserver platforms and the urgency / impact goes up accordingly.No need to apologize.I wouldn't pick benchmarks that are cpu-cache sensitive since thoseare small number of MBs in size, a memory-side cache is on the orderof 10s of GBs.Another way to attack heap randomization without fragmentation is tojust perform heap spraying and hope that lands the data the attackerneeds in the right place. I still think that allocation entropy > 0 ispositive benefit, but I don't know how to determine the curve ofsecurity benefit relative to shuffle order.That's fair.Do you mean disable shuffling on systems that don't have amemory-side-cache unless / until we can devise a security benefitcurve relative to shuffle-order? The former I can do, the latter, I'mat a loss.I think the current v4 proposal of compile-time setting is reasonableonce we have consensus / guidance on the default shuffle-order.",Technical
,
"[...]Yes, enable when the HW requires that for whatever reason and make add aglobal knob to enable it for those that might find it useful forsecurity reasons with a clear cost/benefit description. Not ""this is thasecurity thingy enable and feel safe(r)""--Michal HockoSUSE Labs",Technical
,
"Hello,Can anyone please confirm this bug and apply the patch? Thanks!Wenwen",Technical
,
"Hi Lokesh,On Sat, 06 Oct 2018 08:28:12 +0100,Lokesh Vutla <lokeshvutla@ti.com> wrote:I assume that this co-processor only deals with the routing itself,and doesn't need to be talked to during interrupt processing, right?I don't really see the point of making this user-selectable. If you'recompiling support for a given platform, this platform configurationfragment should itself select the necessary dependencies for thesystem to work as expected. Here, you are leaving the choice to theuser, with a 50% chance of getting a system that doesn't boot...nit: s/(HWIRQ)/(hwirq)/gOh great. So this is reinventing the GICv3 ITS, only for SPIs. :-(Now, this structure seems completely useless, see below.Maybe it would make sense to have a macro that hides this:      	       *hwirq = FWSPEC_TO_HWIRQ(fwspec);This looks horrible. Why doesn't your firmware interface have a helperfunctions that hides this? Something like:	ti_sci_free_direct_irq(intr, src_id, src_index, dst_irq);and you could even add some error checking.And put this where it belongs (in the helper function).I don't think this structure serves any purpose. src_id and src_indexare just a decomposition of hwirq. dst_irq is the GIC interrupt, whichis stored... by the GIC driver. Also, it is worth realising thatyou're allocating per-interrupt data, but none of the per-interruptcallbacks are using it. In my book, that's a sure sign that thisstructure is pointless.Am I missing anything here?Same remarks about the horrible interface.Please address this. But it also worth realising that this code willnever be called with nr_irqs!=1 (that's only for things like PCIMulti-MSI).Do you expect other drivers to require similar resource request? Ifso, It might be worth getting the firmware interface to do thatwork. Specially the ""give me my SCI"" part.Thanks,	M.--Jazz is not dead, it just smell funny.",Technical
,
"On Sat, 06 Oct 2018 08:28:11 +0100,Lokesh Vutla <lokeshvutla@ti.com> wrote:I would drop the GIC here, and replace it by ""parent interruptcontroller"", as nothing here is GIC specific.Are all trigger types supported?Why that constraint? From what I can see, the two are fairlyindependent, and the constraint looks more of a Linux driver issuethan a DT constraint.Thanks,	M.--Jazz is not dead, it just smell funny.",Technical
,
"Rob, DT maintainers,I'd like a feedback from DT maintainers on this 'range' topic.TISCI Firmware [1] currently seems to define a type corresponding to adevice ID[2]. in AM6 device, for example, this is different, howeverhave a 1 to 1 correspondence. However, there is expectation that type willend up as device ID in a future SoC.While this is subject to much debate internally, I'd like some feedback if thisis OK from Device tree representation - it is true that Firmware doeslook at it as type, however in some future SoC, it could be that thevalues themselves may correspond one to one with a device id -> Theoriginal wish was that types might be something reusable across SoCs,but that is turning out to be more of a theoretical wish than any thingpractical.[1]http://software-dl.ti.com/tisci/esd/latest/5_soc_doc/am6x/resasg_types.html[2]http://software-dl.ti.com/tisci/esd/latest/5_soc_doc/am6x/devices.html--Regards,Nishanth Menon",Technical
,
"Hi Marc,Nope, only level interrupts are supported. Will fix it in v2.Driver when calling irq_domain_alloc_irqs_parent(), the fwspec node that getspassed assumes that parent is gic. parameters are filled in with suchassumption. Do you suggest anything to make it more generic?Thanks a lot for the review. Also, I need a suggestion regarding one moreinterrupt controller(Interrupt Aggregator) on the same SoC controlled byTISCI_PROTOCOL.The Interrupt Aggregator (INTA) provides a centralized machinewhich handles the termination of system events to that they canbe coherently processed by the host(s) in the system. Integration lookssomething similar https://pastebin.ubuntu.com/p/T32vbrwsch/ .Configuration of the Intmap registers that maps global events to vint is doneby a system controller (like the Device Memory and Security Controller on K3AM654 SoC). Driver should request the system controller to get the rangeof global events and vints assigned to the requesting host. Managementof these requested resources should be handled by driver and requestssystem controller to map specific global event to vint, bit pair.There can be cases such that IRQ routes can involve both INTR and INTA like below:	IP ---> INTA ---> INTR ----> GIC.In these cases TISCI involves only one message with parametes(source id, sourceoffset, inta_id, dst id) for configuring IRQ route till the destination. Coprocessor will detect there is INTR in the IRQ path and configure that as well.Right now I kind of differentiated this scenario in INTA driver by passing aflag(TI_SCI_EVENT) to INTR driver. If such flag comes, INTR driver should avoidcalling ti_sci api for configuring. Do you think this is the right direction ordo you suggest a better solution.If I am not clear in the above description, I can post an RFC for INTA driverfor continuing this discussion.Thanks and regards,Lokesh",Technical
,
"Hi Marc,Yes, that's right.There are 2 reasons why I made it tristate:- Not all interrupts go through this irqchip(At least in the AM6 SoCusing this). Most of the legacy peripherals still are directly connectedto GIC- TI_SCI_PROTOCOL is defined as tristate.If you still feel I should not make it user-selectable, I can drop it.okay.okay.All existing TISCI users follow the same convention, so I did not bother addingany such wrapper. Will update TISCI with these wrappers and see what firmwaremaintainer says.hmm..you are right, these 3 fields can be dropped completely.will fix it in v2.I tried to consolidate sci resource part under devm_ti_sci_get_of_resource() apibut dst-id is something that is used by irqchip driver. So couldn't consolidateit and had to get it from dt in the driver probe.Thanks and regards,Lokesh",Technical
,
"Hi Lokesh,But as you said, these are ""legacy"" interrupts, and most of theinteresting stuff is routed through the system controller. We also trynot to have core interrupt controllers as modules. As for having thefirmware interface as a module, I wonder what the use-case is.I really wonder what the added value is for the user.Frankly, exposing all kind of data structures to the world is a prettypoor form of abstraction, which is what the firmware is supposed toprovide.I'd strongly suggest that include/linux/soc/ti/ti_sci_protocol.h getscleaned up, and that the whole ti_sci_ops disappears from the that file.Nobody outside of the firmware *implementation* needs to know about its,and it would be much better served by a set of helpers.Finally, please make the TISCI interrupt management part of this series,so that I can review it as part of the code that uses it.Thanks,	M.--Jazz is not dead. It just smells funny...",Technical
,
"As I said, that's a Linux driver issue, not a DT specification at all.It is not worth it trying to generalize it in the driver implementation,but the DT spec it self should be generic enough.I'm sorry, but I really have no idea what the global events and thevints are. Maybe you should describe what this is all about, and maybeprovide a pointer to some documentation...Frankly, it mostly indicates that the firmware does too much, and shouldbe more flexible.That'd be preferable, IMO. Please provide definitions for all the abovejargon, as well as pointers to publicly available documentation, if any.Thanks,	M.--Jazz is not dead. It just smells funny...",Technical
,
"okay, will not make it use configurable in v2.Sure, my next version will include TISCI interrupt management as well.Thanks and regards,Lokesh",Technical
,
"okay, will fix it in next version.Sorry I should have done that earlier. TRM is available here[1], Section 9.3talks about Interrupt Router, Section 10.2.7 talks about Interrupt aggregator.Documentation for TISCI IRQ management is available here[2].[1] http://www.ti.com/lit/ug/spruid7a/spruid7a.pdf[2] http://downloads.ti.com/tisci/esd/latest/2_tisci_msgs/rm/rm_irq.htmlSure, will try to post the consolidated series asap. Thanks a lot for the help.Regards,Lokesh",Technical
,
"Hi Rob, DT maintainers,Any help on this topic?Thanks and regards,Lokesh",Technical
,
"I'm not sure I follow all the terminology here of type, subtype, ""dsthost irq"", etc. It looks to me like you should be using interrupt-map property.Rob",Technical
,
"On Mon, 8 Oct 2018 20:42:41 +0000Peter Rosin <peda@axentia.se> wrote:I agree with you in principle Peter and have tweaked the patch descriptionto make it clearer that we are doing this to make GCC static analysis morehelpful (suppressing a false warning is a worthwhile if you are dealing withlots of them).However, nice though it is to have elegant comment structure I think weshould still have this patch in place.  This effort to 'fix' thesewarnings has already identified a few places where it was wrong soI'm keen to see it applied by default even if it isn't perfect.Jonathan",Technical
,
"Thanks, Jonathan. Below are some examples of cases in which the fall-throughwarning turned out to be an actual bug:commit c24bfa8f21b59283580043dada19a6e943b6e426commit ad0eaee6195db1db1749dd46b9e6f4466793d178commit 9ba8376ce1e2cbf4ce44f7e4bee1d0648e10d594commit dc586a60a11d0260308db1bebe788ad8973e2729commit a8e9b186f153a44690ad0363a56716e7077ad28ccommit 4e57562b4846e42cd1c2e556f0ece18c1154e116commit 7c92e5fbf4dac0dd4dd41a0383adc54f16f403e2commit c5b974bee9d2ceae4c441ae5a01e498c2674e100commit 2c930e3d0aed1505e86e0928d323df5027817740commit 882518debc8487147d618d5f26f4bb0bea1cc05bcommit f745e9cc7e40c4570ab5e8d5ef32bfaa6e8ced46commit 5dc874252faa818426480a7c00fa05738fe05402commit 4a00aa057759d713e1296ecbc614fa560d569977commit 6d3f06a0042ebd59a5e9d4ba6e8a85596901e140commit 827d240a232d27cc12e9657d012f2e5ba953e98acommit a28b259b43914b04746184cec318c67bded7234ccommit 9e7b319e1d1e6cba41ae96f791789a7806b29584commit d393be3ed0bebb30a4666d7f5ed4486cd6b31716commit 680682d4d537565e2c358483e1feeca30a8cf3d4commit 06af9b0f4949b85b20107e6d75f5eba15111d220So, yeah. This effort is worth it.Thanks--Gustavo",Technical
,
"On Sat, 13 Oct 2018 15:14:34 +0000Peter Rosin <peda@axentia.se> wrote:Done the first of the above...Thanks,Jonathan",Technical
,
"Indeed. I meant to respond earlier, but then forgot... Thank you!Cheers,Peter",Technical
,
"Thank you, Jonathan.--Gustavo",Technical
,
"x86_64 is our case, I should have documented it more clearly.Right, as you said, this is easy to fix.I found recent discussion about why x86-64 is using generic stringfunction here:+cc John, x86https://lkml.org/lkml/2018/10/3/818--Jack WangLinux Kernel DeveloperProfitBricks GmbHGreifswalder Str. 207D - 10405 BerlinTel:       +49 30 577 008  042Fax:      +49 30 577 008 299Email:    jinpu.wang@profitbricks.comURL:      https://www.profitbricks.deSitz der Gesellschaft: BerlinRegistergericht: Amtsgericht Charlottenburg, HRB 125506 BGeschÃ¤ftsfÃ¼hrer: Achim Weiss, Matthias Steinberg, Christoph Steffens",Technical
,
"Repeating my comment on version 1:My understanding of the concern behind this change is that we should beable to use an email address for the current development practices, suchas Reported-by, Suggested-by, etc tags when the email address wasprovided in what is a public space for the project.  The public spaceis visible to anyone in the world who desires to access it.I do not understand how ""ordinarily collected by the project"" is equivalentto ""an email address that was provided in a public space for the project"".Ordinarily collected could include activities that can be expected to beprivate and not visible to any arbitrary person in the world.My issue is with the word choice.  I agree with the underlying concept.-Frank",Technical
,
"I don't think it is ... or should be.  This section is specificallyenumerating unacceptable behaviours.  The carve out ""email address notordinarily collected by the project"" means that adding someone's emailaddress in a tag isn't immediately sanctionable in the code of conductas unacceptable behaviour if a question about whether you askedexplicit permission arises.  Equally, a carve out from unacceptablebehaviours doesn't make the action always acceptable, so it's not alicence to publish someone's email address regardless of context.It's not a blanket permission, it's an exclusion from being consideredunacceptable behaviour.  I would be interested to know what informationwe ordinarily collect in the course of building linux that should beconsidered private because I might have missed something about theimplications here.James",Technical
,
"Acked-by : Shuah Khan <shuah@kernel.org>thanks,-- Shuah",Technical
,
"does that include bugzilla.kernel.org, or should we think of those emailaddresses (of bug submitters) as private?  They look public to me.--~Randy",Technical
,
"[...]No, that's not my desired goal.   The section is not about givingpermission it's about making sure listed unacceptable behaviours don'toverlap what we normally do.  The goal is to exclude email the projectordinarily collects from immediate sanction under the unacceptablebehaviours clause.  I deliberately didn't add anything about permissionbecause that's up to the project to define in its more standardcontribution documents.I agree, but, as I said, my goal wasn't to provide explicit permission(because the list is too long and too dependent on the way the projectoperates) it was to carve out an exclusion from sanction for stuff thekernel normally does.  The carve out doesn't translate into explicitpermission because the project can define other standards for the wayemail addresses are added to the tags.I think the crux of the disagreement is that you think the carve outequates to a permission which is not specific enough and I think itdoesn't equate to a permission at all, which is why there's no need tomake it more explicit.  Is that a fair characterisation?James",Technical
,
"Hello,What about properly formatted patches (with From and SoB) sent to themaintainer, without copying any mailing lists? To me, a patch sent to amaintainer is obviously sent for inclusion in the kernel.--Alexandre Belloni, BootlinEmbedded Linux and Kernel engineeringhttps://bootlin.com",Technical
,
"OK.  I am fine with the goal of wording that excludes certain thingsfrom unacceptable behavior instead providing permissions for certainthings.  I think me phrasing as permission instead of carve out iscreating a lot of the miscommunication.Please re-read my comments, but in every place where I state thingsin a way of providing permissions, re-state it in your mind as thesame sentence _except_ phrased as excluding from unacceptablebehavior.  (I started to do that explicitly, but it looked likeI was just going to create a whole lot of distracting text.)Nope.  That is a big place where I was not transferring my thoughtsto clear communication.  I agree that what I wrote should have beenwritten in terms of carve out instead of permission.Nope.  My concern is ""which email addresses"".-Frank",Technical
,
"[...]The idea here was because it's a carve out that doesn't give permissionand because the permission is ruled by the project contributiondocuments, the carve out should be broad enough to cover anything theymight say hence ""email addresses not ordinarily collected by theproject"" are still included as unacceptable behaviour.Perhaps if you propose the wording you'd like to see it would helpbecause there still looks to be some subtlety I'm not getting.James",Technical
,
"From the beginning of the thread:  > @@ -31,7 +31,7 @@ Examples of unacceptable behavior by participants include:  >  * Trolling, insulting/derogatory comments, and personal or political attacks  >  * Public or private harassment  >  * Publishing othersâ€™ private information, such as a physical or electronic  > -  address, without explicit permission  > +  address not ordinarily collected by the project, without explicit permission  >  * Other conduct which could reasonably be considered inappropriate in a  >    professional settingAlternative (and I'm sure someone else can probably clean this up a little bit):+ address that has been provided in a public space for the project, without explicit permissionSee you in Edinburgh,-Frank",Technical
,
"This ends up reading like so:----Examples of unacceptable behavior by participants include:...* Publishing othersâ€™ private information, such as a physical or electronicaddress that has been provided in a public space for the project, withoutexplicit permission.----I think that in context, you want a 'not' in there.  That is: unacceptablebehavior includes publishing others' private information... that has *not*been provided in a public space.  So, I think the suggested text needssome fixing, IMHO.I looked at this issue upstream, and decided to leave the wording inthe CoC itself alone - favoring instead to add a clarifying additionto the upstream CoC FAQ, about some email addresses not beingprivate information.The reason I took that approach, rather than try to change the wordinginside the CoC, is that the current wording seems to me to be sufficient.The thing that is unacceptable is publishing private information.  The ""such as...""clause is intended to convey examples of the types of thing that mightusually be considered private information.  But it is not exhaustive, noris it necessarily correct, depending on the circumstances.  In particular,email addresses are sometimes private information and sometimes not.In the context of kernel development, many email addresses are not private.I am sympathetic to the argument that we use emails as public informationso much in kernel development processes, that it makes sense to omit this orqualify it more.My own views are that:1) if we change this line at all, we should simply omit the ""such as..."" part ofthe phrase, and leave it at:* Publishing othersâ€™ private information without explicit permissionbut also2) I'm OK with leaving the phrase as is and handling the concernsin an clarifying document.Just my 2 cents. -- Tim",Technical
,
"You beat me to this one.  However, there is another issue that I didtouch on but perhaps not in this subthread: For those of us who live inthe US, our addresses (that's physical and sometimes email) areactually provided in a public space because they're available in thepublic property records.  That's actually why I chose ""not ordinarilycollected by the project"" as opposed to ""not previously provided in thepublic space"" or an equivalent because doxxing in the US is mostlyfinding this information from public sources and broadcasting it.I think that's the sense of the people who acked this, yes.  PersonallyI'm happy with a separate clarification in another document, but I canalso see the argument that we do need our single CoC to be consistentwith our operational method, which is why I proposed the patch.This looks OK to me too ... the problem with the original is that theadditional qualification overlaps our normal project method ofoperation, this solves the issue as well.James",Technical
,
"Yes, thank you.That clarification helps a _lot_ in understanding what you have saidpreviously in this thread.  Thanks.  :-)Looks good to me.-Frank",Technical
,
"James, and our other friends,On Tue, Oct 16, 2018 at 2:59 PM James Bottomley<James.Bottomley@hansenpartnership.com> wrote:More than one ambiguity. This whole file needs to go.Who decides what is trolling, and what is a technique for raisingawareness or sparking discussion on an issue?Why should this last bit remain?  Any literate person with access to adictionary should know how ambiguous the word professional is.  As anamateur contributor to the FOSS ecosystem I am more than a bitoffended by the decision to use such divisive, politically charged,and financially discriminatory language in a project of such massivetechnical importance.  This entire file should be expunged from therepository and replaced by well defined minimalistic guidelines formaintaining order on the mailing lists, rather than a set of ambiguouscodes that force maintainers to take politically motivated actionsagainst contributors for undefined reasons.Using words like professional is a distressing red flag because itdoesn't add any clarification on the issue (what was the issueagain?), it only raises more questions.  I can't think of any reasonthat word would be needed unless you're trying to push out unpaidcontributors.  Why should someones employment status be held againstthem when contributing ideas or code to a technical project that hasbenefited greatly from amateur contributions?I fear for the kernels future now that irrational politics arebeginning to creep.",Technical
,
"On Thu, 18 Oct 2018 12:10:28 +0200,Philipp K wrote:No any reason I know of.  It must be just an old convention.Yes, please.thanks,Takashi",Technical
,
These kind of issues are usually fixed by fixing the network driver'sshutdown routine to ensure that MSI interrupts are cleared there.,Technical
,
"Sinan, I'm not sure shutdown handlers for drivers are called in panickexec (I remember of an old experiment I did, loading a kernelwith ""kexec -p"" didn't trigger the handlers).But this case is even worse, because the NICs were in PCI passthroughmode, using vfio. So, they were completely unaware of what happenedin the host kernel.Also, this is spec compliant - system reset events should guarantee thebits are cleared (although kexec is not exactly a system reset, it'ssimilar)Cheers,Guilherme",Technical
,
"AFAIK, all shutdown (not remove) routines are called before launching the nextkernel even in crash scenario. It is not safe to start the new kernel whilehardware is doing a DMA to the system memory and triggering interrupts.Shutdown routine in PCI core used to disable MSI/MSI-x on behalf of allendpoints but it was later decided that this is the responsibility of theendpoint driver.commit fda78d7a0ead144f4b2cdb582dcba47911f4952cAuthor: Prarit Bhargava <prarit@redhat.com>Date:   Thu Jan 26 14:07:47 2017 -0500     PCI/MSI: Stop disabling MSI/MSI-X in pci_device_shutdown()     The pci_bus_type .shutdown method, pci_device_shutdown(), is called from     device_shutdown() in the kernel restart and shutdown paths.     Previously, pci_device_shutdown() called pci_msi_shutdown() and     pci_msix_shutdown().  This disables MSI and MSI-X, which causes the device     to fall back to raising interrupts via INTx.  But the driver is still bound     to the device, it doesn't know about this change, and it likely doesn't     have an INTx handler, so these INTx interrupts cause ""nobody cared""     warnings like this:       irq 16: nobody cared (try booting with the ""irqpoll"" option)       CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.8.2-1.el7_UNSUPPORTED.x86_64 #1       Hardware name: Hewlett-Packard HP Z820 Workstation/158B, BIOS J63 v03.90 06/       ...     The MSI disabling code was added by d52877c7b1af (""pci/irq: let     pci_device_shutdown to call pci_msi_shutdown v2"") because a driver left MSI     enabled and kdump failed because the kexeced kernel wasn't prepared to     receive the MSI interrupts.    Subsequent commits 1851617cd2da (""PCI/MSI: Disable MSI at enumeration even     if kernel doesn't support MSI"") and  e80e7edc55ba (""PCI/MSI: Initialize MSI     capability for all architectures"") changed the kexeced kernel to disable     all MSIs itself so it no longer depends on the crashed kernel to clean up     after itself.     Stop disabling MSI/MSI-X in pci_device_shutdown().  This resolves the     ""nobody cared"" unhandled IRQ issue above.  It also allows PCI serial     devices, which may rely on the MSI interrupts, to continue outputting     messages during reboot/shutdown.     [bhelgaas: changelog, drop pci_msi_shutdown() and pci_msix_shutdown() calls     altogether]     Fixes: https://bugzilla.kernel.org/show_bug.cgi?id=187351     Signed-off-by: Prarit Bhargava <prarit@redhat.com>     Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>     CC: Alex Williamson <alex.williamson@redhat.com>     CC: David Arcari <darcari@redhat.com>     CC: Myron Stowe <mstowe@redhat.com>     CC: Lukas Wunner <lukas@wunner.de>     CC: Keith Busch <keith.busch@intel.com>     CC: Mika Westerberg <mika.westerberg@linux.intel.com>",Technical
,
"I don't want to expand the early quirk infrastructure unless there isabsolutely no other way to solve this.  The early quirk stuff isx86-specific, and it's not obvious that this problem is x86-only.This patch scans buses 0-255, but still only in domain 0, so it won'thelp with even more complicated systems that use other domains.I'm not an IRQ expert, but it seems wrong to me that we are enablingthis interrupt before we're ready for it.  The MSI should target anIOAPIC.  Can't that IOAPIC entry be masked until later?  I guess thekdump kernel doesn't know what MSI address the device might be using.Could the IRQ core be more tolerant of this somehow, e.g., if itnotices incoming interrupts with no handler, could it disable theIOAPIC entry and fall back to polling periodically until a handler isadded?",Technical
,
"Hi Sinan,I agree with you, it's definitely not safe to start a new kernel within-flight DMA transactions, but in the crash scenario I think therationale was that running kernel is broken so it's even more unreliableto try gracefully shutdown the devices than hope-for-the-best and startthe kdump kernel right away hehehFact is that the shutdown handlers are not called in the crash scenario.They come from device_shutdown(), the code paths are as follow:Regular kexec flow:syscall_reboot()  kernel_kexec()    kernel_restart_prepare()	  device_shutdown()	machine_kexec()Although if CONFIG_KEXEC_JUMP is set, it doesn't call device_shutdown()either.Crash kexec flow:  __crash_kexec()      machine_kexec()There are some entry points to __crash_kexec(), like panic() or die() inx86, for example.To validate this, one can load a kernel with ""initcall_debug"" parameter,and performs a kexec - if the shutdown handlers are called, there's adev_info() call that shows a message per device.This may be a good idea, using the pci layer to disable MSIs in thequiesce path of the broken kernel. I'll follow-up this discussion inBjorn's reply.Thanks,Guilherme",Technical
,
"Hi Bjorn, thanks for your quick reply.I understand your point, but I think this is inherently an architectureproblem. No matter what solution we decide for, it'll need to be appliedin early boot time, like before the PCI layer gets initialized.So, I think a first step would be to split the solution ""timing"" in 2possibilities:a) We could try to disable MSIs or whatever approach we take in thequiesce path of crash_kexec(), before the bootstrap of the kdump kernel.The pro is we could use PCI handlers to do it generically. The con isit'd touch that delicate shutdown path, from a broken kernel, and thisis unreliable. Also, I've noticed changes in those crash pathsusually gain huge amount of criticism by community, seems nobody wantsto change a bit of this code, if not utterly necessary.b) Continue using an early boot approach. IMO, this would be per-arch bynature.Currently, powerpc for example does not suffer this issue due to theirarch code performing a FW-aided PCI fundamental reset in the devices[0].On the other hand, x86 has no generic fundamental reset infrastructureto my knowledge (we tried some alternatives, like a Bridge reset[1] thatdidn't work, or zeroing the the command register, which worked), but ifwe go with the IOAPIC way of handling this (which we tried a bit andfailed too), it'll be even more arch-dependent, since IOAPIC is x86 concept.After discussing here internally, an alternative way for this MSIapproach work without requiring the change in the early PCIinfrastructure is to check if we're in kdump kernel and perform manuallythe full scan in that case, instead of changing the generic case asproposed here. This would still be x86-only, but again, it's difficultif not impossible to fix all archs using the same code here.Finally, about multi-domain PCI topologies, I've never saw it on x86, Iwasn't aware that such things existed in x86 - but if required we canquickly extend the logic to contemplate it too.Thanks again, looking forward for you suggestions.Cheers,Guilherme[0]https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/powerpc/platforms/powernv/pci-ioda.c#n3992[1] Based in https://patchwork.kernel.org/patch/2562841, adapted to workin early boot time.",Technical
,
"Thank you for the review.  Basically we use these prints to get anotification when a system is having thermal issues.  It's easy tolook in dmesg and see the prints and know that something temperaturerelated is going on.However, I agree that the current solution is a bit hacky, and inlooking at it a bit further we don't even cover all the paths that weneed to.  The processor_set_cur_state()  function indrivers/acpi/processor_thermal.c, for example, is used on the x86_64systems I'm testing with and wasn't augmented with prints.I'm going to take a step back and try and find another solution.  Theinfo you added to sysfs looks very promising, thank you for pointingit out.",Technical
,
"Hi Dan,Thank you for the patch. Nonetheless, I've just applied similar Liviu'spatch [0], since it arrived one week ago already.I'll send it upstream with LED fixes for 4-20-rc2.[0] https://lkml.org/lkml/2018/10/18/154Best regards,Jacek Anaszewski",Technical
,
"If people are hitting it this often, maybe it is time to push itearly? Linus should not have problem taking two pull requests in amerge window.Best regards,								Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Technical
,
"Thank you for your patch!It would be much better if you can send it using traditional tools,i.e. `git send-email ...`.--With Best Regards,Andy Shevchenko",Technical
,
"Hi,On Thu, Nov 1, 2018 at 5:07 AM Veerabhadrarao Badiganti<vbadigan@codeaurora.org> wrote:It's up to Rob of course, but IMO it seems a nicer way forward toinclude both the SoC-specific string and the ""version"" string in allcases.  I'd write this for the full text: - compatible: Should contain a SoC-specific string and a IP version string:      version strings:           ""qcom,sdhci-msm-v4"" for sdcc versions less than 5.0           ""qcom,sdhci-msm-v5"" for sdcc version 5.0      full compatible strings with SoC and version:           ""qcom,apq8084"", ""qcom,sdhci-msm-v4""           ""qcom,msm8974"", ""qcom,sdhci-msm-v4""           ""qcom,msm8916"", ""qcom,sdhci-msm-v4""           ""qcom,msm8992"", ""qcom,sdhci-msm-v4""           ""qcom,msm8996"", ""qcom,sdhci-msm-v4""           ""qcom,sdm845-sdhci"", ""qcom,sdhci-msm-v5""   NOTE that some old device tree files may be floating around that only   have the string ""qcom,sdhci-msm-v4"" without the SoC compatible string   but doing that should be considered a deprecated practice.-Doug",Technical
,
Fine by me if you update all the dts files.I assume you meant to append '-sdhci' here?,Technical
,
"Hi,Done and done.https://lkml.kernel.org/r/20181105210921.253707-1-dianders@chromium.orghttps://lkml.kernel.org/r/20181105210921.253707-2-dianders@chromium.orgOops, yes!           ""qcom,apq8084-sdhci"", ""qcom,sdhci-msm-v4""           ""qcom,msm8974-sdhci"", ""qcom,sdhci-msm-v4""           ""qcom,msm8916-sdhci"", ""qcom,sdhci-msm-v4""           ""qcom,msm8992-sdhci"", ""qcom,sdhci-msm-v4""           ""qcom,msm8996-sdhci"", ""qcom,sdhci-msm-v4""-Doug",Technical
,
Thank you. Will update the documentation.,Technical
,
"Assuming this is for arm64, I'm somewhat surprised that memset() couldbe that much faster than clear_page(), since they should effectivelyamount to the same thing (a DC ZVA loop). What hardware is this on?Profiling to try and see exactly where the extra time goes would beinteresting too.Or just mask it out in __iommu_dma_alloc_pages()?What if the pages came from highmem? I know that doesn't happen on arm64today, but the point of this code *is* to be generic, and other userswill arrive eventually.Robin.",Technical
,
"I am running with tegra186-p2771-0000.dtb so it's arm64 yes.I re-ran the test to get some accuracy within the function and got:1) pages = __iommu_dma_alloc_pages(count, alloc_sizes >> PAGE_SHIFT, gfp);   // reduced from 422 usec to 56 usec == 366 usec less2) if (!(prot & IOMMU_CACHE)) {...}	//flush routine   // reduced from 439 usec to 236 usec == 203 usec lessNote: new memset takes about 164 usec, resulting in 400 usec diff      for the entire iommu_dma_alloc() function call.It looks like this might be more than the diff between clear_pageand memset, and might be related to mapping and cache. Any idea?Yea, the change here would be neater then.Hmm, so it probably should use sg_miter_start/stop() too? Lookingat the flush routine doing in PAGE_SIZE for each iteration, wouldbe possible to map and memset contiguous pages together? Actuallythe flush routine might be also optimized if we can map contiguouspages.Thank youNicolin",Technical
,
And in what case does dma_alloc_* performance even matter?,Technical
,
"FYI, I have patches I plan to submit soon that gets rid of thestruct scatterlist use in this code to simplify it:http://git.infradead.org/users/hch/misc.git/commitdiff/84e837fc3248b513f73adde49e04e7c58f605113",Technical
,
...and I have some significant objections to that simplification which Iplan to respond with ;)(namely that it defaults the whole higher-order page allocation businesswhich will have varying degrees of performance impact on certain cases)Robin.,Technical
,
"Hmm, I guess it might not be so much clear_page() itself as all thegubbins involved in getting there from prep_new_page(). I could perhapsmake some vague guesses about how the A57 cores might get tickled by thedifferent code patterns, but the Denver cores are well beyond my abilityto reason about. Out of even further curiosity, how does the quick hackbelow compare?I suppose the ideal point at which to do it would be after the remappingwhen we have the entire buffer contiguous in vmalloc space and can makebest use of prefetchers etc. - DMA_ATTR_NO_KERNEL_MAPPING is a bit of aspanner in the works, but we could probably accommodate a special casefor that. As Christoph points out, this isn't really the place to belooking for performance anyway (unless it's pathologically bad as perthe DMA_ATTR_ALLOC_SINGLE_PAGES fun), but if we're looking at pullingthe remapping out of the arch code, maybe we could aim to rework thezeroing completely as part of that.Robin.----->8-----diff --git a/drivers/iommu/dma-iommu.c b/drivers/iommu/dma-iommu.cindex d1b04753b204..7d28db3bf4bf 100644--- a/drivers/iommu/dma-iommu.c+++ b/drivers/iommu/dma-iommu.c@@ -569,7 +569,7 @@ struct page **iommu_dma_alloc(struct device *dev,size_t size, gfp_t gfp,  		alloc_sizes = min_size;  	count = PAGE_ALIGN(size) >> PAGE_SHIFT;-	pages = __iommu_dma_alloc_pages(count, alloc_sizes >> PAGE_SHIFT, gfp);+	pages = __iommu_dma_alloc_pages(count, alloc_sizes >> PAGE_SHIFT, gfp& ~__GFP_ZERO);  	if (!pages)  		return NULL;@@ -581,15 +581,18 @@ struct page **iommu_dma_alloc(struct device *dev,size_t size, gfp_t gfp,  	if (sg_alloc_table_from_pages(&sgt, pages, count, 0, size, GFP_KERNEL))  		goto out_free_iova;-	if (!(prot & IOMMU_CACHE)) {+	{  		struct sg_mapping_iter miter;  		/*  		 * The CPU-centric flushing implied by SG_MITER_TO_SG isn't  		 * sufficient here, so skip it by using the ""wrong"" direction.  		 */  		sg_miter_start(&miter, sgt.sgl, sgt.orig_nents, SG_MITER_FROM_SG);-		while (sg_miter_next(&miter))+		while (sg_miter_next(&miter)) {+			clear_page(miter.addr);+			if (!(prot & IOMMU_CACHE))  			flush_page(dev, miter.addr, page_to_phys(miter.page));+		}  		sg_miter_stop(&miter);  	}",Technical
,
"Hi Christoph,Honestly, this was amplified by running a local iommu benchmarktest. Practically dma_alloc/free() should not be that stressful,but we cannot say the performance doesn't matter at all, right?Though many device drivers pre-allocte memory for DMA usage, itcould matter where a driver dynamically allocates and releases.And actually I have a related question for you: I saw that thedma_direct_alloc() cancels the __GFP_ZERO flag and does manualmemset() after allocation. Might that be possibly related to aperformance concern? Though I don't see any performance keywordfor that part of code, especially seems that memset() was therefrom the beginning.ThanksNicolin",Technical
,
"Hi Robin,I tried out that change. And the results are as followings:a. Routine (1) reduced from 422 usec to 55 usecb. Routine (2) increased from 441 usec to 833 usecc. Overall, it seems to remain the same: 900+ usecI would understand the point. So probably it'd be more plausibleto have the change if it reflects on some practical benchmark. Imight need to re-run some tests with heavier use cases.That'd be nice. I believe it'd be good to have.ThanksNicolin",Technical
,
"Well, please place your objection there.  The behavior does match whatevery other iommu-based dma ops implementation ouside of arm/arm64 does,so there is some precedent for it to say the least.  But if the onlycurrent users objects I'll surely find a way to accomodate it, but agood rationale including numbers would be useful to document it.",Technical
,
It's better to not have a mixture of nodes at a level with and withoutunit-addresses. So I'd move all the i2c nodes under an 'i2c-mux' node.Rob,Technical
,
Reviewed-by: Rob Herring <robh@kernel.org>,Technical
,
"Hi Luca<Top posting for new topic>I'm replying here rather than spam the IRC channel with a big paste.It's also a useful description to the probe sequence, so I've kept itwith the driver posting.I hope the following helps illustrate the sequences which are involved:max9286_probe() - max9286_i2c_mux_close() # Disable all links - max9286_configure_i2c # Configure early communication settings - max9286_init():   - regulator_enable() # Power up all cameras   - max9286_setup() # Most link setup is done here.   ... Set up v4l2/async/media-controller endpoints   - max9286_i2c_mux_init() # Start configuring cameras:     - i2c_mux_alloc() # Create our mux device     - for_each_source(dev, source)           i2c_mux_add_adapter() # This is where sensors get probed.So yes sensors are only communicated with once the link is brought up asmuch as possible.Because the sensors are i2c devices on the i2c_mux - they are not probeduntil their adapters are created and added.At this stage the i2c-mux core framework will iterate all the devicesdescribed by the DT for that adapter.As each one is probed - the i2c_mux framework will callmax9286_i2c_mux_select() and enable only the single link.This allows us to configure each camera independently(which is essential because they are all configured to the same i2caddress by default at power on)Hope this helps, and feel free to ask if you have any more questions.--RegardsKieran",Technical
,
"Hi Kieran,thanks for the clarification. One additional note below.For the records, an additional bit of explanation I got from Kieran via IRC.The fact that link is already up when the sensors are probed is due tothe fact that the power regulator has a delay of *8 seconds*. This isintended, because there's an MCU on the camera modules that talks on theI2C bus during that time, and thus the drivers need to wait after it's done.This delay happens before max9286_setup() is called.--Luca",Technical
,
"Hi Luca, Kieran,    sorry to jump up, but I feel this should be clarified.The 8sec delay is due to the fact an integrated MCU on the remotecamera module programs the local sensor and the serializer intgratedin the module in to some default configuration state. At power up, wejust want to let it finish, with all reverse channels closed(camera module -> SoC direction) not to have the MCU transmittedmessages repeated to the local side (our remote serializer does repeatmessages not directed to it on it's remote side, as our localdeserialier does).The ""link up"" thing is fairly more complicated for GMSL than justhaving a binary ""on"" or ""off"" mode. This technology defines two different""channels"", a 'configuration-channel' for transmitting control messageson the serial link (i2c messages for the deserializer/serializer pairthis patches support) and a 'video-channel' for transmission ofhigh-speed data, such as, no surprise, video and images :)GMSL also defines two ""link modes"": a clock-less ""configuration link""and an high-speed ""video link"". The ""configuration link"" is available afew msec after power up (roughly), while the ""video link"" needs a pixelclock to be supplied to the serializer for it to enter this mode andbe able to lock the status between itself and the deserializer. Then it canbegin serializing video data.The 'control channel' is available both when the link is in'configuration' and 'video' mode, while the 'video' channel isavailable only when the link is in 'video' mode (or, to put it moresimply: you can send i2c configuration messages while the link isserializing video).Our implementation uses the link in 'configuration mode' during theremote side programming phase, at 'max9286_i2c_mux_init()' time, withthe 'max9286_i2c_mux_select()' function enabling selectively the'configuration link' of each single remote end. It probes the remote deviceby instantiating a new i2c_adapter connected to the mux, one for eachremote end, and performs the device configuration by initially using itsdefault power up i2c address (it is safe to do so, all other links areclosed), then changes the remote devices address to an unique one(as our devices allows us to do so, otherwise you should use thedeserializer address translation feature to mask and translate theremote addresses).Now all remote devices have an unique i2c address, and we can operatewith all 'configuration links' open with no risk of i2c addressescollisions.At this point when we want to start the video stream, we send acontrol message to the remote device, which enables the pixel clockoutput from the image sensor, and activate the 'video channel' on theremote serializer. The local deserializer makes sure all 'video links'are locked (see 'max9286_check_video_links()') and at this point wecan begin serializing/deserializing video data.As you can see, the initial delay only plays a role in avoidingcollision before we properly configure the channels and the i2caddresses. The link setup phase is instead an integral part of thesystem configuration, and there are no un-necessary delays used towork around it setup procedure.Does this help clarifying the system startup procedure?Thanks   j",Technical
,
"Hi Jacopo,Yes, that's very informative, thank you very much.Given the complexity of the driver and the non-obviousness of someworkarounds to ""unfortunate hardware design choices"", I think [some of]this explanation should be committed together with the driver, in orderto make it more understandable to other people. Even more since you'vealready taken time to write it.Thanks,--Luca",Technical
,
"Hi Kieran, All,sorry for joining this late... See below my considerations.I find this kind of address mapping is the weak point in this patchset.The ser-deser chipset splits the world in ""local"" and ""remote"" side. Thecamera node belongs to the remote side, but the 0x51 and 0x61 addressesbelong to the local side. Think about supporting N different main boardsand M remote boards. 0x51 might be available on some main boards but notall. IMO under the camera@51 (even the i2c@0) node there should be onlyremote hardware description. To support the N*M possible combinations,there should be: * a DT for the main board mentioning only addresses for the   local i2c bus, down to the i2c@0 with address-cells, size-cells and   reg properties * a DT overlay for each remote board, mentioning the remote i2c   chips with their physical addresses, but no local addressesThe only way I could devise to be generic is to bind each physicalremote address to a local address at runtime.Also, to be implemented reliably, an address translation feature isrequired on the local (de)ser chip.So the question is: can the max9286 chip do i2c address translation?Thanks,--Luca",Technical
,
"Hi Kieran, All,below a few minor questions, and a big one at the bottom.[...]5 pads, 4 formats. Why does the source node have no fmt?                          ^This way you're clearing the V4L2_SUBDEV_FL_IS_I2C set byv4l2_i2c_subdev_init(), even though using devicetree I think this won'tmatter in the current kernel code. However I think ""max9286->sd.flags |=..."" is more correct here, and it's also what most other drivers do.According to the docs MEDIA_ENT_F_VID_IF_BRIDGE appears more fitting.I can't manage to like this initialization sequence, sorry. If at allpossible, each max9286 should initialize itself independently from eachother, like any normal driver.First, it requires that each chip on the remote side can configure itsown slave address. Not all chips do.Second, using a static i2c address map does not scale well and limitshotplugging, as I discussed in my reply to patch 1/4. The problem shouldbe solvable cleanly if the MAX9286 supports address translation like theTI chips.Thanks,--Luca",Technical
,
"Hi Luca,I'd say you're on time - not late,Thanks for joining :)Well, in our use case - in fact the camera has a set of fixed addresses(0x30,0x40,0x50) for each camera - and these are the addresses we arerequesting the camera to be updated to. Once the camera is communicatedwith - the first step is to reprogram the device to respond to theaddresses specified here.Of course - well in fact all of our I2C addresses across our two max9286instances, and 8 camera devices share the same bus 'address space'.It's crucial to provide this address on a per board level, which is whyit is specified in the DT.I wonder if perhaps it was a mistake to include the camera descriptionin this part of the example, as it's not related to the max9286specifically.Rob has already suggested moving these to a lower 'i2c-node' level whichI like the sound of, and might make this separation more clear.Yes, The max9286 (deser) can do i2c address translation - but so too canthe max9271 (serialiser)We do our address translation on the camera (serialiser) side.The cameras *all* boot with the same i2c address (and thus all conflict) - We disable all links - We enable /one/ link - We initialise and reprogram the address of that camera to the address   specified in the camera node. - Then we move to the next camera.The reality is we 'just need' a spare address on the I2C bus - but asyet - there is no mechanism in I2C core to request a spare address.Thus it is the responsibility of the DT node to ensure there is no conflict.For an example, here is our DT overlay file for our max9286 expansion board:https://git.kernel.org/pub/scm/linux/kernel/git/kbingham/rcar.git/commit/?h=gmsl/v5&id=6f2ec549e128b3ca36e9cae59256723cc39df2b1--Regards--Kieran",Technical
,
"Hi Luca,Thank you for your review,The source pad is a CSI2 link - so a 'frame format' would be inappropriate.A quick glance looks like you're right.That looks like a good catch!I've updated locally ready for v5.Yes, I agree. We recently updated the adv748x to this too.Also updated locally to add to v5.Yes, I think we're in agreement here, but unfortunately this section isa workaround for the fact that our devices share a common address space.We (currently) *must* disable both devices before we start theinitialisation process for either on our platform currently...That said - I think this section needs to be removed from the upstreampart at least for now. I think we should probably carry this'workaround' separately.This part is the core issue that I talked about in my presentation atALS-Japan [0] [0] https://sched.co/EaXaI don't think we can treat GMSL as hot-pluggable currently ... But as wediscussed - I see that we should think about this for FPD-LinkAlso as a further aside here, we use ""device_is_bound"" which is notexported, and means that this driver won't compile successfully as amodule currently (thanks to the kbuild test robot for highlighting that)--Regards--Kieran",Technical
,
"Hi Kieran,Yes, the way it works is clear.Interesting point. In my case I'm thinking DT overlays, they help me alot in finding a proper generalization. With some generalization, cameramodules [the same would happen with display modules] are similar tobeaglebone capes or rpi hats: 1. there can be different camera modules being designed over time 2. there can be different base boards being designed over time 3. there is a standard interconnection between them (mechanical,    electrical, communication bus) 4. camera modules and base boards are designed and sold independently    (thanks to point 3)Overlays are a natural choice in this case. Even bootloader-timeoverlays will suffice for my reasoning, let's remove the hotplug messfrom this discussion.Now, in this patch you are modeling the remote camera as if it were a""normal"" I2C device, except: a) it has 2 slave addresses (no problem with this) b) the 2 slave addresses in DT are not the physical onesWith this model it seems natural to write ""camera@51/reg = <0x51 0x61>""in the camera DT overlay. Except 0x51 and 0x61 do not exist on thecamera module, those numbers come from the base board, since you knowthose two addresses are not used on the bus where gmsl-deserializer@2cis. But it works.Then one year later a random SBC vendor starts selling a new base boardthat has on the same i2c bus a GMSL deser and a random i2c chip,unrelated to cameras, at address 0x51. Bang, the camera sensor does notwork anymore, but there is no hardware reason for it not to work. Well,easy to fix, find an address that is unused on all known base boards andreplace, say, 0x51->0x71 in the camera overlay. (OK, I violated the ""DTas a stable ABI"" principle)But then other boards appear and, taking this to an extreme, you can getto a situation where every i2c address is used on at least one board.How do you fix that?Maybe this scenario is a bit too apocalyptic, and maybe too much forcurrent automotive uses, but I think it illustrates how the currentmodel is not generic enough. Since there is no existing code in thekernel yet, I think we should strive to do better in order to minimizefuture problems.My approach is instead to clearly split the local and remote domain. Thelatter is what could be moved to an overlay. For example:&i2c0 {    serializer@3d {        reg = <0x3d>;        ...        /* Guaranteed not physically present on i2c0 */        i2c-alias-pool = /bits/ 16 <0x20 0x21 0x22 0x23 0x24 0x25>;        i2c-mux {            #address-cells = <1>;            #size-cells = <0>;	    i2c@0 {                reg = <0>;                #address-cells = <1>;                #size-cells = <0>;                // ------8<------ this could be moved to an overlay                sensor@50 {                    reg = <0x50>;                    ...                    endpoint {...};                };                eeprom@51 {                    reg = <0x51>;                    ...                };                // ------8<------            };	    i2c@1 {                reg = <1>;                #address-cells = <1>;                #size-cells = <0>;                // ------8<------                sensor@50 {                    reg = <0x50>;                    ...                    endpoint {...};                };                eeprom@51 {                    reg = <0x51>;                    ...                };                // ------8<------            };        };    };};The core difference is that I split the camera@51/reg property in two: * sensor@50/reg: the remote side (camera overlay);   carries the physical i2c address (note both sensors are at 0x50) * serializer@3d/i2c-alias-pool: the local side (base board);   lists a pool of addresses that are not used on the i2c busSee how there is no mixing between local and remote. The pool willdiffer from one base board to another.To implement this, I developed an ""i2c address translator"" that mapsphysical remote addresses to local addresses from the pool at runtime.It still needs some work, but address translation it is working.Good!By ""address translation"" I mean the i2c address is changed by somedevice in the middle between the i2c master and the slave. In this senseyou are not doing address translation, you are rather modifying the chipaddresses. Then transactions happen with the new (0x51/0x61) address,which does not get modified during subsequent transactions.Not a reliable one, definitely, since there could be i2c devices unknownto the software. This is why I had to introduce the alias pool: the DTwriter is required to know which addresses are available and list themin DT.--Luca",Technical
,
"Hi Kieran,Ok, thanks for the clarification.The model I proposed in my review to patch 1/4 (split remote physicaladdress from local address pool) allows to avoid this workaround.Oh, interesting, I hadn't noticed that you gave this talk -- at the sameconference as Vladimir's talk! No video recording apparently, but areslides available at least?I've been mixing hotplug and DT overlays and that generated confusion,sorry. My point exists even with no hotplug, see the reply to patch 1/4.--Luca",Technical
,
"Hi Kieran,I'm happy to see this will be well maintained. :-)A part of this driver looks like a driver for an OV camera sensor. Wouldthere be something that prevents separating the camera sensor driver fromthis one?Hmm. What are you using g_mbus_config() for?Do you need a busy loop? Could you use msleep()?return ov...(); ?You could use devm_kzalloc().|=, as in the other patch.You're missing v4l2_ctrl_handler_free() here.As well as here.Could you use probe_new, so you could remove the i2c ID table? Or do youneed that for something?--Regards,Sakari Ailuse-mail: sakari.ailus@iki.fi",Technical
,
"Hi Kieran,No problem.[...]Can the remote (max9271) translate addresses for transactionsoriginating from the local side? This would make it possible to do aproper address translation, although 2 addresses is a quite small amount.BTW all the TI chips I'm looking at can do address translation but, asfar as I understand, only when acting as ""slave proxy"", i.e. whenattached to the bus master. If the Maxim chips do the same, the ""remotetranslation"" would be unusable.Sadly, it looks pretty much unavoidable...Thanks.Indeed it would have been!But hey, The FOSDEM CFPs are still open!Bye,--Luca",Technical
,
"Hi Luca,Yes, that's true for systems with a single max9286 [1]We have a system with 2 de-serializers, and what happens is thefollowing:The system starts with the following configuration:1)                    +------- max9271@40                    +------- max9271@40Soc ----> max9286 --+------- max9271@40                    +------- max9271@40with a single max9286 it would be easy. We operate on one channel atthe time, do the reprogramming (or set up the translation, for the TIchip use case) when adding the adapter for the channel, and then wecan talk with all remotes, which now have a different address2)                    +-------- max9271@50                    +--- / -- max9271@40Soc ----> max9286 --+--- / -- max9271@40                    +--- / -- max9271@40                    +--- / -- max9271@50                    +-------- max9271@51Soc ----> max9286 --+--- / -- max9271@40                    +--- / -- max9271@40                    +--- / -- max9271@50                    +--- / -- max9271@51Soc ----> max9286 --+-------- max9271@52                    +--- / -- max9271@40                    +--- / -- max9271@50                    +--- / -- max9271@51Soc ----> max9286 --+--- / -- max9271@52                    +-------- max9271@53Of course, to do the reprogramming, we need to initially send messagesto the default 0x40 address each max9271 boots with. If we don't closeall channels but the one we intend to reprogram, all remotes wouldreceive the same message, and thus will be re-programmed to the sameaddress (not nice). [2]Now, if you have two max9286, installed on the same i2c bus, then youneed to make sure all channels of the 'others' are closed, before youcan reprogram your remotes, otherwise, you would end up reprogrammingall the remotes of the 'others' when trying to reprogram yours, as ourlocal de-serializers, bounces everything they receives, not directedto them, to their remote sides.3)                       +-------- max9271@50                       +--- / -- max9271@40Soc --+-> max9286@4c --+--- / -- max9271@40      |                +--- / -- max9271@40      |      |-> max9286@6c --+-------- max9271@50  <-- not nice                       +-------- max9271@50                       +-------- max9271@50                       +-------- max9271@50                       +--- / -- max9271@50                       +-------- max9271@51Soc --+-> max9286@4c --+--- / -- max9271@40      |                +--- / -- max9271@40      |      |-> max9286@6c --+-------- max9271@51 <-- not nice                       +-------- max9271@51                       +-------- max9271@51                       +-------- max9271@51....With the (not nice) 'max9286_is_bound()' we make sure we close allchannels on all max9286 first4)                       +--- / -- max9271@40                       +--- / -- max9271@40Soc --+-> max9286@4c --+--- / -- max9271@40      |                +--- / -- max9271@40      |      |-> max9286@6c --+--- / -- max9271@40                       +--- / -- max9271@40                       +--- / -- max9271@40                       +--- / -- max9271@40And then only the last one to probe calls the re-programmingphase for all its fellows de-serializers on the bus.5)                       +-------- max9271@50                       +--- / -- max9271@40Soc --+-> max9286@4c --+--- / -- max9271@40      |                +--- / -- max9271@40      |      |-> max9286@6c --+--- / -- max9271@40                       +--- / -- max9271@40                       +--- / -- max9271@40                       +--- / -- max9271@40    ....                       +--- / -- max9271@50                       +--- / -- max9271@51Soc --+-> max9286@4c --+--- / -- max9271@52      |                +--- / -- max9271@53      |      |-> max9286@6c --+-------- max9271@54                       +--- / -- max9271@40                       +--- / -- max9271@40                       +--- / -- max9271@40When addr reprogramming is done, we enter the image streaming phase,with all channels open, as now, all remotes, have a different i2caddress assigned.Suggestions on how to better handle this are very welcome. The pointhere is that, to me, this is a gmsl-specific implementation thing.Do you think for your chips, if they do translations, can you easy maskthem with the i2c address you want (being that specified in the remotenode or selected from an i2c-addr-pool, or something else) withouthaving to care about others remotes to be accidentally programmed toan i2c address they're not intended to be assigned to.Hope this helps clarify your concerns, and I think the actual issueto discuss, at least on bindings, would be the i2c-address assignmentmethod, as this impacts GMSL, as well as other implementation thatwould use the same binding style as this patches.Thanks   j[1] I still don't get why 'addr translation' >> 'addr reprogramming'.Even the GMSL application development examples uses addr reprogramming,so I guess this is how those chips are supposed to work.[2] If your local side supports address translation, you don't need totalk with the remote side to 'mask' it, so you don't need this workaround.",Technical
,
"Hi Jacopo,This last sentence is the one point that makes things so hard on theGMSL chips. In my previous email(s) I partially forgot about this, so Iwas hoping  a better implementation could be possible. Thanks forre-focusing me.It would have been lovely if the hardware designers had at least put ani2c mux between the soc and those chatty deserializers... :-\Yes. The TI chips have a ""passthrough-all"" option to propagate alltransactions with an unknown address, but it's mostly meant fordebugging. In normal usage the local chip will propagate (with addressestranslated) only transactions coming with a known slave address,including its own address(es), the remote (de)ser aliases and the remotechip aliases. All aliases are disabled until programmed.Absolutely.Bye,--Luca",Technical
,
"Hi Sakari,Thank you for your review,Well it means /someone/ should always be able to pick it up :DI didn't know who to put here - so I put all of the current blamees ;)We've all put a lot of time and work in to the GMSL bring up andrefactoring.If you think it's overkill, I can reduce the names. Same on max9286.I don't think there's anything preventing it - except (a fair bit of)development time.We also have the RDACM21 to support, which uses the max9271 and anOV10640. At that time - this will absolutely have to be split. Weshouldn't replicate the max9271 code.I mentioned briefly in the cover letter:But to get more dedicated time to work this - we need to show someprogress on GMSL up-streaming, so the max9286 and bindings take priorityfor now.A little bit catch 22 ... :DI'm sure there will be overlap between GMSL and FPD-Link with the RDACMrange [0] of cameras too, which also provide TI-FPD Link serialisers.I currently envisage that we would have an RDACM20 'driver' which wouldknow that it has a max9271 serialiser and an OV10635 sensor, and wouldhandle the links of any subdevices internally.As the RDACM20 is an object itself, I think this makes sense ... unlessanyone suggests that each part should be broken down into the DTdirectly ? (I think that would possibly be a bit too much)[0]https://www.global-imi.com/sites/default/files/Generic-Minicube-Catalogue-1020151.pdfGood point here ... I assumed it was passed through up to the VIN - butit's really not applicable here.Or if it is - then it should be describing the GMSL bus link!I'll bet this isn't even getting called and can likely be removed.Checkpatch warns here:WARNING: msleep < 20ms can sleep for up to 20ms; seeDocumentation/timers/timers-howto.txt#10: FILE: drivers/media/i2c/rdacm20.c:461:+       msleep(10);I think for this context, msleep(10) even with the warning is fine here,but perhaps we can meet that with a usleep_range(10000, 20000); too.Yes, that would be nicer.Will change.Bah - yes :)Good spot. ThanksAck.I believe probe_new is probably fine.I should really resurrect my i2c-probe-coccinelle patch and get thatconversion task done, so we can get to removing and replacing .probe :)(note to self ... starting projects when unemployed becomes difficult tocontinue when someone else gives you projects to work on all the time ...)Changes described above made and tested on a *single MAX9286* capturing4 cameras simultaneously, now on my rcar.git gmsl/v5 branch ... :D--Regards--Kieran",Technical
,
"Hi Kieran,Yes. Indeed the pool can be seen as a list of physical addresses that: - are unused by other chips on the local bus - and given to the ser/des to use for the remote devices - will physycally appear on the local bus to talk to remote devicesWhether they are runtime translated or reprogrammed on the remodedevices is not much relevant for the local bus.I don't foresee any problem in moving from a large pool at theserializer to small pools at each port.--Luca",Technical
,
"Hu Kieran,Apologies for the late reply.Not at all. There are too many drivers that do not receive the attentionthey'd need. :-IBtw. I think this might be worth a new comment to tell what devices can befound here --- it's not a camera sensor as such really. But I wonder howshould it be called. We do have ""Miscellaneous helper chips"" at the end.I'm not sure that'd be better. As-is could be fine, too.Oh, sorry; I missed that.Does the DT currently contain all the necessary information for the driversto get everything they need, if you separated them?I don't remember all the details, but my understanding is that RDACM20 ismuch more than just a box that contains the serialiser and the sensors. Sovery probably it'll need its own driver, too. Powering on the sensors, forinstance, seemed hard to make generic.There are two use cases I know for this --- SoC camera and something thatchanges dynamically. The former is obsolete and the latter is betteraddressed by the frame descriptors I'd like to see go in for 4.22.usleep_range(), then, but just setting the delay to precisely 10 ms is muchbetter than a 10 ms busy loop.That'd be nice!--Regards,Sakari Ailus",Technical
,
[]This bit is pretty unsightly.Especially the static in each inline[][][][],Technical
,
Hi Joe.I understood that you mean linestatic char str[256];This array will be defined several times.I will remove inline form function definition.It's not necessary.Thank you for comment.Cheers Pawel,Technical
,
"Hi Pawel,s/drivier/drivers/creaties/createss/in system/in-systemWhy not depend on USB instead of USB_XHCI_HCD?Need a coma between switch and Host-only.Why depend on Config options to populate resources? The resources should be there regardless.It is a lot simpler that way as it reflects the hardware as-is.dev_dbg() for this and all occurrences below?cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
"Is it better to split this patch into 3 parts?1) host support2) gadget support3) DRD support (along with patch 4)how about naming this to cnds3_get_current_role_driver() ?You are changing the role here. Shouldn't it just start whatever role is already in cdns->role?And you have a cnds3_set_role() function to set role.where is the balancing pm_runtime_put() for this?All role switching code can come as part of DRD driver.Here you are not checking for Kconfig options before getting resources which is the right thing.However this will be broken if you don't get rid of the Kconfig checks when you populate theresources in patch 1.What exactly does role_start have to do?Can you start the role before requesting irq?Shouldn't the order bepm_runtime_get_sync();cdns3_remove_roles();pm_runtime_put_noidle();pm_runtime_disable();you didn't call usb_phy_init() anywhere.Why is a call to host_driver_init() required?Why is OTG after END?Does OTG have a role driver as well? If not it must not come here. It is a mode, not a role.why is cdns3_host_driver_init() required?cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
"I think we need to make a clear distinction between mode and role.Mode is the controller mode. (Host-only, Device-only, dual-role[otg])Role is the USB controller state (A-Host, B-Device, Idle)cnds->dr_mode should correspond to enum usb_dr_mode which should be the argumentfor this function if you want to set mode.Why not just use cdns->dr_mode directly?Do you want to check if it is host role here? e.g. if dr_mode = USB_DR_MODE_OTG.Looks like this function should be on core.c?CDNS3_ROLE_HOST.should this be called cdns3_drd_init()?s/HOST/PERIPHERAL?cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
"<snip>Why does role driver need hook to irq handler?Can't each driver host or gadget handle it's respective irqon its own? If the same IRQ line is used it could be requestedas a shared IRQ.cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
"If we start with OTG mode and user says change mode to device will we stillswitch to host based on ID pin change?If it does then this isn't working correctly.We need to stop processing ID interrupts and keep the role static tillthe user switches it back to otg.cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
"Hi Roger,I will replace it with this:Depend on USB_SUPPORT && (USB l| USB_GADGET) && HAS_DMAYou're right. I will remove these Config options from this code.Ok , I replaced it.Thanks for all commentsRegards,Pawel Laszczak",Technical
,
"Currently we have:0003-usb-cdns3-Driver-initialization-code.patch - generic initialization common code.I agree that some fragment could be moved to next free patches. It could improve understanding of code.0004-usb-cdns3-Added-DRD-support.patch - it's short file so contains initialization and other related to DRD function.0005-usb-cdns3-Added-Wrapper-to-XCHI-driver.patch - host support - quite short patch0006-usb-cdns3-Initialization-code-for-Device-side - device initializationIt's better. I've changed it.The function cdns3_set_role currently do nothing.A little explanation. The main author of this file is Peter Chan.We use the same controller, but we have different platforms. I adopt this file to myplatform. I tried to keep the concept of his solution and remove only platform specific codes.I assume this approach allows him easily to re-use this code in the feature.In cdns3_set_role he makes some platform specific code that allow him to switch betweenHost and device. I do not need it In the  feature this function probably will call some platformspecific function.Currently this function is not used so I will remove it.I will remove this fragment.It will be implemented later in pm runtime functions.Detecting Host and Device mode can be achieved in different ways depending on platform.I assume that core.c file is generic part that allow to connect different way of detecting modes.In my solution I use OTG registers which are part of this controller. But someone can useextcon to get information about mode e.g:	host = extcon_get_state(cdns->extcon, EXTCON_USB_HOST);	device = extcon_get_state(cdns->extcon, EXTCON_USB);I treat drd.c file rather as platform specific extension for this driver.Ok, patch 1 will be changed.Start the Device or Host mode.  After this operation device/host can handle interrupts.A good point.It's works correct, but I will change this.It's look strange.Yes, I found it too. In next series this will be removed.Also, I will add the phy initialization, but I want to use generic phy instead of usb_phy.I'm not sure whether it is proper solution, but we have only generic simple phy driver.No OTG doesn't have role driver.It was the simplest solution. It's used only in debugfs.c  and drd.c files.I'll give it some thought how to change it without big impact to rest codes.It's initialize xhci driver with. Maybestatic const struct xhci_driver_overrides xhci_cdns3_overrides __initconst = {	.extra_priv_size = sizeof(struct xhci_hcd),	.reset = xhci_cdns3_setup,};void __init cdns3_host_driver_init(void){	xhci_init_driver(&xhci_cdns3_hc_driver, &xhci_cdns3_overrides);}I will move this function to  0005-usb-cdns3-Added-Wrapper-to-XCHI-driver.patch then all code will be in this some patch.Thanks for all comment,Regards,Pawel Laszczak.",Technical
,
"How often are these invoked?For I/O intensive cases dev_dbg() will not be useful as it will affect timing adverselybecause of which it might prevent the issue from happening when debug is enabled.How about using tracepoints instead?cheers,-roger--Texas Instruments Finland Oy, Porkkalankatu 22, 00180 Helsinki.Y-tunnus/Business ID: 0615521-4. Kotipaikka/Domicile: Helsinki",Technical
,
"Hi Roger,I agree with you,  In next set patch distinction between mode and role will be clear.The function will be slightly completed.After corrections:dr_mode holds the hardware configuration. It will be set during initialization and will not be changed.current_dr_mode will hold current mode. This mode can be changed by debugfs.This function will look: int cdns3_is_host(struct cdns3 *cdns){	if (cdns->current_dr_mode == USB_DR_MODE_HOST)		return 1;	else if (cdns->current_dr_mode == USB_DR_MODE_OTG)		if (!cdns3_otg_get_id(cdns))			return 1;	return 0;}If DRD mode is set to HOST then always return true, elsewhere it will be based on ID pin.So, for USB_DR_MODE_OTG driver will waiting for appropriate role but whencurrent_dr_mode == USB_DR_MODE_HOST then we know that only HOST role can be setand driver can return true immediately.>The name will be changed to cdns3_drd_update_mode and will be called during initialization,or when user change mode by means of debugfs.I found it too and was corrected.I changed the name cdns3_drd_init().  I call this cdns3_drd_probe, because I was not surewhether DRD will be part of whole driver or will be separate driver.Thanks for all your commentsCheers,Pawel Laszczak",Technical
