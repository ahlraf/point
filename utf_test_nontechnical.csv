"Hi BorisThe major feature close to USB is this one and it can be found in othersprotocols (standardization process).Just to close this topic I3C vs USB, IMO it's wrong to pass the messagethat the I3C is closer to USB than I2C even more because I3C support theI2C on the fly.Sorry, with the proliferation of sensors I cannot see a multi mastersensor network based on USB.Yes, we already talked about secondary master support.I would bet to do something like in i2c, we don't need the same level ofcomplexity found in USB.I agree with the controller folder but not with prefix. Please checkwhat is already in the kernel.In this case and taking what is already in the kernel it will bedrivers/i3c/{master, slave, dwc, other with the same architecture as dwc}.I miss to mention PCI but since the beginning refer the slave and thecommon part.Splitting the driver is something that soon or later I will have to do.If you prefer later I'm ok with that.I think this discussion is starting to be counterproductive with arguingof both parts. Unfortunately I don't see anyone given their inputs too.To be clear, the subsystem is nice and I working with daily. As I saidthis is something that I dealing now and I'm telling what I think thatis not correct.",Non-technical
,
"Hi Vitor,On Tue, 27 Nov 2018 11:50:53 +0000vitor <vitor.soares@synopsys.com> wrote:I think you didn't read my reply carefully. I'm not saying I3C == USB,I'm just saying that the way you interact with an I3C from a SW PoV isnot at all the same as you would do for an I2C device. Do you deny that?Looks like there's a misunderstanding here. The question is not whetherI3C will replace I2C or USB, of course it's meant to overcome thelimitations of I2C. I'm just pointing out that, if we have to exposeI3C devices, we should look at what other discoverable buses do (PCI,USB, ...), not what I2C does.There's a difference between a secondary master that waits for its timeto become the currrent master, and a secondary master that provides I3Cdevice features when it's acting as a slave (sensor, GPIOcontroller, ...). So far we focused on supporting the former. Ifthere's a need for the latter, then we should start thinking about theslave framework...Can you detail a bit more what you have in mind? I don't think we cando like I2C, simply because we need to expose a valid DCR +manuf-ID/PID so that other masters can bind the device to theappropriate driver on their side. Plus, if we're about to exposegeneric profiles, we likely don't want each I3C slave controller driverto do that on its own.If we mix everything in the same subdir, I'd like to have an easy wayto quickly identify those that are slave controllers and those that aremaster controllers. For the dual-role thing, maybe we can consider themas master (ones with advances slave features).Would you be okay with drivers/i3c/controllers/{designware,dw}/..., sothat you can have all designware drivers (for both slave and masterblocks) in the same dir?For those that are placed directly under drivers/i3c/controllers/...(because they only have one .c file), I'd like to keep a standardprefix.And again, I'm questioning the necessity of per-IP directories at theroot level. I'm not against per-IP directories, as long as they areclassified like other HW blocks: drivers/i3c/{master,slave}/<ip>/...No it's not vain, it's how we do discuss things in the community. I'mnot saying I'm always right, but I need to understand the problemsyou're trying to solve to take a decision, and I don't think youinitially gave all the details I needed to understand your PoV. That'sa bit clearer now, even if I still disagree on a few aspects.They will come.Come on! All I've seen so far are complaints on tiny details, itdefinitely doesn't prevent you from adding new features.Regards,Boris",Non-technical
,
"On Tue, 4 Dec 2018 00:34:20 +0000vitor <vitor.soares@synopsys.com> wrote:If you want. Actually that's the most interesting part for me:discussing how we want to support I3C slave controllers or mixedmaster/slave controllers. All the driver split we're talking abouthere is just bikeshedding.Ok.I don't see why. If the driver is simple enough to fit in one file,there's no reason to create a new subdir. You think your DW IP is socomplex and configurable that it requires several source files, fine,but please don't force others to do the same.Yes.You mean, inside a sub-folder (drivers/i3c/controllers/{vendor}/)? Itdepends what you do with those source files. If they are to be exposeddirectly as modules, then they should be prefixed(i3c-<role>-<vendor>.c). On the other hand, if you create a singlemodule out of several source files, source files don't need to beprefixed, as long as the resulting module as a proper prefix.I'm not saying the discussion is useless, just that it's happening waytoo early compared to the other things we should work on. If you wereadding support for slaves, and were doing this split as part of thispatch series explaining that part of the code between slave and mastercan be shared, then we wouldn't have this debate. But right now, you'retelling me that we need to split the DW driver to prepare for featuresthat have not even been discussed/proposed. That's what I'm complainingabout.",Non-technical
,
So I strongly disagree with this. Anybody that has trouble with 0/1 vsfalse/true needs to stay the heck away from C.I would suggest we delete that stupid coccinelle scripts that generatesthese pointless warns.,Non-technical
,
Not to mention that WARN is gramatically incorrect. We're not assigning'bool' to 0/1 but the other way around.What crap..,Non-technical
,
"Then those tools are broken per the C spec.The C language spec, specifies _Bool as an integer type wide enough toat least store 0 and 1.IOW, 0 and 1 are perfectly valid valus to assign to a _Bool.And fundamentally that has to be so. That's how computers work. 0 isfalse, 1 is true.The kernel is not the place to try and abstract such stuff, C is ourportable assembler. We muck with hardware, we'd better know how the heckit works.",Non-technical
,
"Note that this patch does *not* remove the nasty trap caused by the garbagein question - struct file can be freed before we even return from->unlocked_ioctl().  Could you describe in details the desired behaviourof this interface?How about grabbing the references to all victims (*before* screwing withksys_close()), sticking them into a structure with embedded callback_headand using task_work_add() on it, the callback doing those fput()?The callback would trigger before the return to userland, so observabletiming of the final close wouldn't be changed.  And it would avoid thekludges like this.Of course, the proper fix would require TARDIS and set of instruments fortreating severe case of retrocranial inversion, so that this ""ABI"" would'venever existed, but...",Non-technical
,
"What's advertisement there?Huch? Care to tell what's a lie instead of making bold statements?Thanks,tglx",Non-technical
,
"""No problem here, no performance issues, nothing to be seen unless youare running VM.""Take a care to look at the patch I submitted?Lie:# A system with an up to date kernel is protected against attacks from# malicious user space applications.3GB system running 32bit kernel is not protected. Same is true for forreally big 64bit systems.If I do what dmesg suggests, this becomes untrue:# The Linux kernel contains a mitigation for this attack vector, PTE# inversion, which is permanently enabled and has no performance# impact.Limiting memory to 2GB _is_ going to have severe perfomance impact.Pavelcommit 9664b4dabdb132433a6843aefe05814953f1342fAuthor: Pavel <pavel@ucw.cz>Date:   Thu Jan 3 00:48:40 2019 +0100Ok, I guess L1TF was a lot of fun, and there was not time for a gooddocumentation.There's admin guide that is written as an advertisment, andunfortunately is slightly ""inaccurate"" at places (to the point oflying).Plus, I believe it should go to x86/ directory, as this is reallyIntel issue, and not anything ARM (or RISC-V) people need to know.Signed-off-by: Pavel Machek <pavel@ucw.cz>diff --git a/Documentation/admin-guide/l1tf.rst b/Documentation/admin-guide/l1tf.rstindex 9af9773..05c5422 100644--- a/Documentation/admin-guide/l1tf.rst+++ b/Documentation/admin-guide/l1tf.rst@@ -1,10 +1,11 @@L1TF - L1 Terminal Fault========================-L1 Terminal Fault is a hardware vulnerability which allows unprivileged-speculative access to data which is available in the Level 1 Data Cache-when the page table entry controlling the virtual address, which is used-for the access, has the Present bit cleared or other reserved bits set.+L1 Terminal Fault is a hardware vulnerability on most recent Intel x86+CPUs which allows unprivileged speculative access to data which is+available in the Level 1 Data Cache when the page table entry+controlling the virtual address, which is used for the access, has the+Present bit cleared or other reserved bits set.Affected processors-------------------@@ -76,12 +77,14 @@ Attack scenariosdeterministic and more practical.The Linux kernel contains a mitigation for this attack vector, PTE-   inversion, which is permanently enabled and has no performance-   impact. The kernel ensures that the address bits of PTEs, which are not-   marked present, never point to cacheable physical memory space.--   A system with an up to date kernel is protected against attacks from-   malicious user space applications.+   inversion, which is permanently enabled and has no measurable+   performance impact in most configurations. The kernel ensures that+   the address bits of PTEs, which are not marked present, never point+   to cacheable physical memory space. On x86-32, this physical memory+   needs to be limited to 2GiB to make mitigation effective.++   Mitigation is present in kernels v4.19 and newer, and in+   recent -stable kernels.2. Malicious guest in a virtual machine^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Non-technical
,
"Pavel,I agree that this statement is incorrect.Calling this a lie is a completly unjustified personal attack on those whospent quite a lot of time on writing up documentation in the firstplace. It's suggesting that this document was written with malicious intentand the purpose of deceiving someone. Care to explain why you are assumingthis to be the case?Sure. That still does not justify the ""changelog"" you provided.It's interesting that quite some people were actually happy about thatdocument. Sorry, that we weren't able to live up to your high standards.What is the advertisement part again?It's a document targeted at system administrators and it definitely shouldnot be burried somewhere in Documentation/x86. As there are more documentsbeing worked on for the other issues, I have a patch ready which moves thatstuff into a separate hardware vulnerabilites folder in the admin-guide.FWIW, to the best of my knowledge the documentation about writingchangelogs is neither incorrect nor is it optional to adhere to it.The 'Affected processors' section right below this is very clear about thisbeing an Intel only issue (for now). So what exactly is the point of thischange?On x86-32? That's incorrect, because there are a lot of x86-32 systemswhich are not affected. Also it has nothing to do with the bit-width of thehardware. A 32bit kernel booted on a 64bit capable CPU has the same issue.For further correctness, this needs to mention that !PAE enabled kernelscannot do PTE inversion at all.The 2G limitation is not a general limitation. The limitation depends onthe number of physical address bits supported by the cache (not the numberof physical addresss bits exposed as pins) and is definitely not hardcodedto 2G. Just because your machine emits the 2G number does not make ituniversally correct. On a system with 36bit physical address space thelimit is 32G and on some CPUs that's actually wrong as well, see:override_cache_bits().Quoting yourself:Where is the explanation for the 'really big 64bit systems' issue forcorrectness sake?Thanks,tglx",Non-technical
,
"So how should it be called? I initally used less strong words, only toget ""Care to tell what's a lie instead of making bold statements?""back. Also look at the timing of the thread.Ok, now can we have that document updated to meet the standards?Making it very clear from the begining this is x86-only issue. Yes,you can kind-of figure it out from the next section... except forIntel StrongArm.Next sentence speaks about ""present bit"" of ""page table entry"". Thatmay be confusing for people familiar with other architectures, whichmay not have such bit. We should mention this is x86 before usingx86-specific terminology.Ok.I don't know the detailed limits for each system; what about this?Signed-off-by: Pavel Machek <pavel@ucw.cz>Paveldiff --git a/Documentation/admin-guide/l1tf.rst b/Documentation/admin-guide/l1tf.rstindex 9af9773..cbf02a4 100644--- a/Documentation/admin-guide/l1tf.rst+++ b/Documentation/admin-guide/l1tf.rst@@ -1,10 +1,11 @@L1TF - L1 Terminal Fault========================-L1 Terminal Fault is a hardware vulnerability which allows unprivileged-speculative access to data which is available in the Level 1 Data Cache-when the page table entry controlling the virtual address, which is used-for the access, has the Present bit cleared or other reserved bits set.+L1 Terminal Fault is a hardware vulnerability on most recent Intel x86+CPUs which allows unprivileged speculative access to data which is+available in the Level 1 Data Cache when the page table entry+controlling the virtual address, which is used for the access, has the+Present bit cleared or other reserved bits set.Affected processors-------------------@@ -76,12 +77,15 @@ Attack scenariosdeterministic and more practical.The Linux kernel contains a mitigation for this attack vector, PTE-   inversion, which is permanently enabled and has no performance-   impact. The kernel ensures that the address bits of PTEs, which are not-   marked present, never point to cacheable physical memory space.--   A system with an up to date kernel is protected against attacks from-   malicious user space applications.+   inversion, which has no measurable performance impact in most+   configurations. The kernel ensures that the address bits of PTEs,+   which are not marked present, never point to cacheable physical+   memory space. For mitigation to be effective, physical memory needs+   to be limited in some configurations.++   Mitigation is present in kernels v4.19 and newer, and in+   recent -stable kernels. PAE needs to be enabled for mitigation to+   work.2. Malicious guest in a virtual machine^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Non-technical
,
"Pavel,You called it a lie from the very beginning or what do you think made metell you that? Here is what you said:Nice try.What is 'the standards'? Your's or is there a general agreement?It's pretty clear, but yes admittedly we forgot to mention that IntelStrongARM is not affected. That's truly important because its widelydeployed in the cloud space and elsewhere.X86 terminology? Care to check how pte_present() is implemented across thearchitectures? Most of them use the PRESENT bit naming convention, just afew use VALID. That's truly confusing and truly x86 specific.It's not about detailed limits for particular systems. It's about the waythe limit is determined on certain class of systems. And that can bededuced from the code.If you want to provide more accurate documentation then you better come upwith something which is helpful instead of completely useless blurb likethe below:How is the admin going to figure that out? What kind of systems might beaffected by this?No. The mitigation is available when the kernel provides it. Numbers areirrelevant because that documentation has to be applicable for stablekernels as well. And what is a recent -stable kernel?Also the PAE part needs to go to a completely different section.Thanks,tglx",Non-technical
,
"Hi!Actually, I still call it a lie. Document clearly says that bug isfixed in non-virtualized cases, when in fact it depends on PAE andlimited memory.At this point I want you to fix it yourself. Lying about security bugsbeing fixed when they are not is not cool. I tried to be helpful andsubmit a patch, but I don't feel like you are cooperating on gettingthe patch applied.Best regards,Pavel--DENX Software Engineering GmbH,      Managing Director: Wolfgang DenkHRB 165235 Munich, Office: Kirchenstr.5, D-82194 Groebenzell, Germany",Non-technical
,
"Again, no.",Non-technical
,
"I would drop this patch for being too ugly and if nothing else, for lackof users (epoll will no longer need dlock).Thanks,Davidlohr",Non-technical
,
"Since when is the cover letter mandatory?I understand that is helps for a complicated patch setto explain the problem and solution in the cover letter,but for this simple test case addition what's the point?And there is nothing forcing a cover letter inhttps://www.kernel.org/doc/html/v4.20/process/submitting-patches.htmlAlso double tags seams to be quite common for selftest.See git log tools/testing/selftests/Thanks,--Tadeusz",Non-technical
,
"I'm not sure that forcing a library on users is a good reason to break UAPI.The patch is going into the latest, but can also be backported on futurestables.I don't think ""not fixing it because it's not fixed yet"" is a goodreason to keep things the way they are. But maybe that's just me.Given that the structure has already been extended several times, thereis pretty much nothing to keep this from happening again and again.--Julien Gomes",Non-technical
,
"Thats a misleading statement.  We've never supported running newer applicationson older kernels, and no one is forcing anyone to use the lksctp-tools library,I was only suggesting that, if we were to support this compatibility, that mightbe a place to offer it.Its also worth noting that we have precident for this.  If you look at the gitlog, this particular structure has been extended about 6 times in the life ofsctp.Also misleading, as it assumes that we're not intentionally doing this.  I getwanting to support running applications built for newer kernels on olderkernels, but thats just not something that we do, and to say thats broken ismisleading.  Older applications are required to run on newer kernels, but notvice versa, which is what you are asking for.And yes, this patch can be backported to older stable kernels, but by that sametoken, so can the patches that extend the struct, which would also fix theproblem, while supporting the newer features, which seems to me to be the bettersolution for applications which are looking for that support.",Non-technical
,
"From: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>Date: Wed, 6 Feb 2019 18:37:54 -0200What a complete mess we have here.Use new socket option numbers next time, do not change the size and/orlayout of existing socket options.This whole thread, if you read it, is basically ""if we compatabilitythis way, that breaks, and if we do compatability this other way ohshit this other thing doesn't work.""I think we really need to specifically check for the difference sizesthat existed one by one, clear out the part not given by the user, andbackport this as far back as possible in a way that in the older kernelswe see if the user is actually trying to use the new features and if soerror out.Which, btw, is terrible behavior.  Newly compiled apps should work onolder kernels if they don't try to use the new features, and if theycan the ones that want to try to use the new features should be ableto fall back when that feature isn't available in a non-ambiguousand precisely defined way.The fact that the use of the new feature is hidden in the newstructure elements is really rotten.This patch, at best, needs some work and definitely a longer and moredetailed commit message.",Non-technical
,
"There probably is a decent compromise to find between ""not accepting asingle additional byte"" and accepting several GB.For example how likely is it that the growth of this structure make itgo over a page? I would hope not at all.By choosing a large but decent high limit, I think we can find afuture-compatible compromise that doesn't rely on a preliminarygetsockopt() just for structure trucation decision...--Julien Gomes",Non-technical
,
"I disagree with this, at least as a unilateral statement.  I would assert thatan old program, within the constraints of the issue being discussed here, willrun perfectly well, when built and run against a new kernel.At issue is the size of the structure sctp_event_subscribe, and the fact that inseveral instances over the last few years, its been extended to be larger andencompass more events to subscribe to.Nominally an application will use this structure (roughly) as follows:...struct sctp_event_subscribe events;size_t evsize = sizeof(events);memset(&events, 0, sizeof(events));events.sctp_send_failure_event = 1; /*example event subscription*/if (sctp_setsocktpt(sctp_fd, SOL_SCTP, SCTP_EVENTS, &events, &evsize) < 0) {/* do error recovery */}....Assume this code will be built and run against kernel versions A and B, inwhich:A) has a struct sctp_event_subscribe with a size of 9 bytesB) has a struct sctp_event_subscribe with a size of 10 bytes (due to the addedfield sctp_sender_dry_event)That gives us 4 cases to handle1) Application build against kernel A and run on kernel A.  This works fine, thesizes of the struct in question will always match2) Application is built against kernel A and run on kernel B.  In this case,everything will work because the application passes a buffer of size 9, and thekernel accepts it, because it allows for buffers to be shorter than the currentstruct sctp_event_subscribe size. The kernel simply operates on the optionsavailable in the buffer.  The application is none the wiser, because it has noknoweldge of the new option, nor should it because it was built against kernelA, that never offered that option3) Application is built against kernel B and run on kernel B.  This works finefor the same reason as (1).4) Application is built against kernel B and run on kernel A.  This will breakbecause the application is passing a buffer that is larger than what the kernelexpects, and rightly so.   The application is passing in a buffer that isincompatible with what the running kernel expects.We could look into ways in which to detect the cases in which this might be'ok', but I don't see why we should bother, because at some point its still anerror to pass in an incompatible buffer.  In my mind this is no different thantrying to run a program that allocates hugepages on a kernel that doesn'tsupport hugepages (just to make up an example).  Applications built againstnewer kernel can't expect all the features/semantics/etc to be identical toolder kernels.It shouldn't.  Assuming you have a program built against headers from kernel B(above), if you set a field in the structure that only exists in kernel B, andtry to run it on kernel A, you will get an EINVAL return, which is correctbehavior because you are attempting to deliver information to the kernel thatkernel A (the running kernel) doesn't know about.  Thats correct behavior.I won't disagree about the niceness of versioning, but that ship has sailed.To be clear,  this is situation (1) above, and yeah, running on the kernel youbuilt your application against should always work from a compatibilitystandpoint.Yes, but this is alawys the case for structures that change.  If you have anapplication built against kernel (B), and uses structure fields that only existin that version of the kernel (and not earlier) will fail to compile when builtagainst kernel (A) headers, and thats expected.  This happens with any kernelapi that exists in a newer kernel but not an older kernel.Any time you make a system call to the kernel, you have to be prepared to handlethe resulting error condition, thats not unexpected.  To assume that a systemcall will always work is bad programming practice.Neil",Non-technical
,
"Looking more flexible does not make it more correct.Thanks,tglx",Non-technical
,
"Interesting - I don't see the grant head reservation code in any ofmy performance benchmark profiling, even when running at over amillion transactions/s on a 2-socket 32-core 64-thread skylakesystem. I see other places in the transaction subsystem that arehot (e.g the CIL context lock), but not the space reservations.My initial suspect is that you have a tiny log on your testfilesystem, so it's permanently out of space and so always hittingthe slow path. Can you tell us what the storage is and it'sconfiguration? At minimum, I need to see the output of the xfs_infocommand on your test filesystem. Fixing this may simply be using alarger log on your benchmark systems.FWIW, can you post the actual profile you are seeing in the commitmessage? That helps us identify similar problems in the future, andit lets us know what paths are leading to the transactionreservation contention. i.e. this may not even be a problem with thetransaction reservation code itself.How does this impact on the strict FIFO queue behaviour the grantqueues currently have? The current code only wakes up enough waitersto consume the newly available space and it queues new waiters tothe tail of the queue. If there ever is a spurious wakeup then thewaiter that was woken from the head remains there until the nextwakeup comes in. This is intentional - spurious wakeups are rareenough we can ignore them because a) this is the slow path, and b)correctness is far more important that performance in this path.The fast path is already lockless, and we've already given uppeformance if we reach this slow path. hence we only care aboutcorrectness in this path, not performance optimisation.AFAICT the patch changes the spurious wakeup behaviour - it requeuestasks to the tail of the queue if there wasn't space available whenthey are woken, rather than leaving them as them at the head.  Theynow have to wait for all the other reservations to make progress.This breaks the guarantees of ordered forward progress the grantqueue provides permanent transaction reservations and hence opens usup to log space deadlocks because those transactions can't movetheir objects forward in the log to free up space in the log...Also, I note that wake_q_add() assumes that the wake queue is alocal stack object and so not subject to concurrency - it explicitlystates this in the code. That's not the case here - the wake queueis part of the grant head, and so is subject to extreme concurrencythat is tempered by a spin lock.  Does the wake_q code workcorrectly (e.g. have all the necessary memory barriers, etc) whenit's not a local stack object and instead protected from concurrencyby a spin lock? At minimum, the wake_q infrastructure comments anddocumentation need updating to accommodate this new use case thatwake queues are being used for.This doesn't generally doesn't happen because the space accountingtends to prevent multiple wakeups. i.e. we only wake the tasks wehave reservation space for, and log space being made available tendsto arrive in discrete chunks (because IO is slow!) such that thatpending wakeups have already been processed before the next chunk ofavailable space comes in....Yes, but they are very rare and we don't really care about this inthe slow path. If you see lots of them, it's typically a sign of aninappropriately configured filesystem for the workload being run. Ona correctly configured system, we should almost never use this slowpath....I'm betting that you'll get that and a whole lot more simply byincreasing the log size and not running the slow path at all.Where's the hunk context in your headers? You must be using anon-standard git option here.Linux kernel specific includes go in fs/xfs/xfs_linux.h, notindividual files.Why do you need to delete the ticket from the queue here? This leadsto landmines and incorrect non-FIFO behaviour....... here. This is a potential list corruption landmine because thisfunction now has unbalanced list add and removal contexts. IOWs, wecan't restart this loop without first having guaranteed the ticketis not already on the ticket queue. You need to document constraintslike this in comments and explain what code needs to guarantee thoseconstraints are met. [Because, as I noted at the end, you got thiswrong for xlog_grant_head_wake_all()]To maintian FIFO behaviour, the ticket needs to be left at the headof the grant head wait queue until it has space available to makeprogress, not get removed and requeued to the tail. Spurious wakeups are irrelevant here - forwards progress (i.e. correctness)requires FIFO ticket ordering behaviour be maintained.This push is needed to make the necessary space we are waiting onavailable in the log. Hence leaving it out of the loop you putbelow will cause the journal to get stuck in the spurious wakeuploop below and be unable to make progress. This will lead tofilesystem hangs.That's a new nested loop. Please implement it as a loop.This is buggy  - i will lead to hangs if the filesystem is shutdown and there is a spurious wakeup that triggers this to go back tosleep.The shutdown check needs to break the sleep loop.That's racy. You can't drop the spin lock betweenxlog_grant_head_wake() and xlog_grant_head_wait(), becausefree_bytes is only valid while while the spinlock is held.  Same forthe ""wake_all"" variable you added. i..e. while waking up thewaiters, we could have run out of space again and had more tasksqueued, or had the AIL tail move and now have space available.Either way, we can do the wrong thing because we dropped the lockand free_bytes and wake_all are now stale and potentially incorrect.That's another landmine. Just define the wakeq in the context whereit is used rather than use a function wide variable that requiresreinitialisation.Ok, what about xlog_grant_head_wake_all()? You didn't convert thatto use wake queues, and so that won't remove tickets for the granthead waiter list, and so those tasks will never get out of the newinner loop you added to xlog_grant_head_wait(). That meansfilesystem shutdowns will just hang the filesystem and leave itunmountable. Did you run this through fstests?Cheers,Dave--Dave Chinnerdavid@fromorbit.com",Non-technical
,
"Thanks for your detailed review of the patch. I now have a betterunderstanding of what should and shouldn't be done. I have sent out amore conservative v2 patchset which, hopefully, can address the concernsthat you raised.Cheers,Longman",Non-technical
,
"Can you please re-run and report the results for each patch on theramdisk setup? And, please, include the mkfs.xfs or xfs_info outputfor the ramdisk filesystem so I can see /exactly/ how muchconcurrency the filesystems are providing to the benchmark you arerunning.50GB is tiny for XFS. Personally, I've been using ~1PBfilesystems(*) for the performance testing I've been doingrecently...Cheers,Dave.(*) Yes, petabytes. Sparse image files on really fast SSDs are awonderful thing.--Dave Chinnerdavid@fromorbit.com",Non-technical
,
"I like the idea and I think it's good direction to go, but couldyou please share some from perf stat or whatever you used to meassurethe new performance?thanks,jirka",Non-technical
,
"Sorry but I don't like imposing a run-time check on everybody whenstack-based requests are the odd ones out.  If we're going to makethis a run-time check (I'd much prefer a compile-time check, but Iunderstand that this may involve too much churn), then please do itfor stack-based request users only.Thanks,--Email: Herbert Xu <herbert@gondor.apana.org.au>Home Page: http://gondor.apana.org.au/~herbert/PGP Key: http://gondor.apana.org.au/~herbert/pubkey.txt",Non-technical
,
"[ I am not subscribed to LKML, please keep me CC'd on replies ]I tried a simple test with several VMs (in my initial test, I have 48idle 1-cpu 512-mb VMs and 2 idle 2-cpu, 2-gb VMs) using libvirt, nonepinned to any CPUs. When I tried to set all of the top-level libvirt cpucgroups' to be co-scheduled (/bin/echo 1 >/sys/fs/cgroup/cpu/machine/<VM-x>.libvirt-qemu/cpu.scheduled), themachine hangs. This is using cosched_max_level=1.There are several moving parts there, so I tried narrowing it down, byonly coscheduling one VM, and thing seemed fine:/sys/fs/cgroup/cpu/machine/<VM-1>.libvirt-qemu# echo 1 > cpu.scheduled/sys/fs/cgroup/cpu/machine/<VM-1>.libvirt-qemu# cat cpu.scheduled1One thing that is not entirely obvious to me (but might be completelyintentional) is that since by default the top-level libvirt cpu cgroupsare empty:/sys/fs/cgroup/cpu/machine/<VM-1>.libvirt-qemu# cat tasksthe result of this should be a no-op, right? [This becomes relevantbelow] Specifically, all of the threads of qemu are in sub-cgroups,which do not indicate they are co-scheduling:/sys/fs/cgroup/cpu/machine/<VM-1>.libvirt-qemu# cat emulator/cpu.scheduled0/sys/fs/cgroup/cpu/machine/<VM-1>.libvirt-qemu# cat vcpu0/cpu.scheduled0When I then try to coschedule the second VM, the machine hangs./sys/fs/cgroup/cpu/machine/<VM-2>.libvirt-qemu# echo 1 > cpu.scheduledTimeout, server <HOST> not responding.On the console, I see the same backtraces I see when I try to set all ofthe VMs to be coscheduled:[  144.494091] watchdog: BUG: soft lockup - CPU#87 stuck for 22s! [CPU 0/KVM:25344][  144.507629] Modules linked in: act_police cls_basic ebtable_filter ebtables ip6table_filter iptable_filter nbd ip6table_raw ip6_tables xt_CT iptable_raw ip_tables s[  144.578858]  xxhash raid10 raid0 multipath linear raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor ses raid6_pq enclosure libcrc32c raid1 scsi[  144.599227] CPU: 87 PID: 25344 Comm: CPU 0/KVM Tainted: G           O      4.19.0-rc2-amazon-cosched+ #1[  144.608819] Hardware name: Dell Inc. PowerEdge R640/0W23H8, BIOS 1.4.9 06/29/2018[  144.616403] RIP: 0010:smp_call_function_single+0xa7/0xd0[  144.621818] Code: 01 48 89 d1 48 89 f2 4c 89 c6 e8 64 fe ff ff c9 c3 48 89 d1 48 89 f2 48 89 e6 e8 54 fe ff ff 8b 54 24 18 83 e2 01 74 0b f3 90 <8b> 54 24 18 83 e25[  144.640703] RSP: 0018:ffffb2a4a75abb40 EFLAGS: 00000202 ORIG_RAX: ffffffffffffff13[  144.648390] RAX: 0000000000000000 RBX: 0000000000000057 RCX: 0000000000000000[  144.655607] RDX: 0000000000000001 RSI: 00000000000000fb RDI: 0000000000000202[  144.662826] RBP: ffffb2a4a75abb60 R08: 0000000000000000 R09: 0000000000000f39[  144.670073] R10: 0000000000000000 R11: 0000000000000000 R12: ffff8a9c03fc8000[  144.677301] R13: ffff8ab4589dc100 R14: 0000000000000057 R15: 0000000000000000[  144.684519] FS:  00007f51cd41a700(0000) GS:ffff8ab45fac0000(0000) knlGS:0000000000000000[  144.692710] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033[  144.698542] CR2: 000000c4203c0000 CR3: 000000178a97e005 CR4: 00000000007626e0[  144.705771] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000[  144.712989] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400[  144.720215] PKRU: 55555554[  144.723016] Call Trace:[  144.725553]  ? vmx_sched_in+0xc0/0xc0 [kvm_intel][  144.730341]  vmx_vcpu_load+0x244/0x310 [kvm_intel][  144.735220]  ? __switch_to_asm+0x40/0x70[  144.739231]  ? __switch_to_asm+0x34/0x70[  144.743235]  ? __switch_to_asm+0x40/0x70[  144.747240]  ? __switch_to_asm+0x34/0x70[  144.751243]  ? __switch_to_asm+0x40/0x70[  144.755246]  ? __switch_to_asm+0x34/0x70[  144.759250]  ? __switch_to_asm+0x40/0x70[  144.763272]  ? __switch_to_asm+0x34/0x70[  144.767284]  ? __switch_to_asm+0x40/0x70[  144.771296]  ? __switch_to_asm+0x34/0x70[  144.775299]  ? __switch_to_asm+0x40/0x70[  144.779313]  ? __switch_to_asm+0x34/0x70[  144.783317]  ? __switch_to_asm+0x40/0x70[  144.787338]  kvm_arch_vcpu_load+0x40/0x270 [kvm][  144.792056]  finish_task_switch+0xe2/0x260[  144.796238]  __schedule+0x316/0x890[  144.799810]  schedule+0x32/0x80[  144.803039]  kvm_vcpu_block+0x7a/0x2e0 [kvm][  144.807399]  kvm_arch_vcpu_ioctl_run+0x1a7/0x1990 [kvm][  144.812705]  ? futex_wake+0x84/0x150[  144.816368]  kvm_vcpu_ioctl+0x3ab/0x5d0 [kvm][  144.820810]  ? wake_up_q+0x70/0x70[  144.824311]  do_vfs_ioctl+0x92/0x600[  144.827985]  ? syscall_trace_enter+0x1ac/0x290[  144.832517]  ksys_ioctl+0x60/0x90[  144.835913]  ? exit_to_usermode_loop+0xa6/0xc2[  144.840436]  __x64_sys_ioctl+0x16/0x20[  144.844267]  do_syscall_64+0x55/0x110[  144.848012]  entry_SYSCALL_64_after_hwframe+0x44/0xa9[  144.853160] RIP: 0033:0x7f51cf82bea7[  144.856816] Code: 44 00 00 48 8b 05 e1 cf 2c 00 64 c7 00 26 00 00 00 48 c7 c0 ff ff ff ff c3 66 2e 0f 1f 84 00 00 00 00 00 b8 10 00 00 00 0f 05 <48> 3d 01 f0 ff ff8[  144.875752] RSP: 002b:00007f51cd419a18 EFLAGS: 00000246 ORIG_RAX: 0000000000000010I am happy to do any further debugging I can do, or try patches on topof those posted on the mailing list.Thanks,Nish",Non-technical
,
"There seems to be a disconnect between what I am trying tocommunicate and what I perceive you to have understood.I'll add comments below to try to make more clear what I'm trying tosay.But first a general statement.  I understand that the intent of thepatch wording is to allow use of email addresses in the tags of a patchsubmittal or git commit without being an unacceptable behavior.  I donot think that the words in the patch accomplish that goal.The patch says ""Publishing ... electronic address not ordinarilycollected by the project, without explicit permission"".  (I think itis fair to abstract here with ""..."".)  This phrase specifies whichemail addresses can be published.  It does not specify in what casesthe email address can be published.  The desired goal is to be able topublish email addresses in patch and commit tags.Which email addresses are allowed to be published?  (This is the pointof my original comment.)  To me, the patch wording is describing howI can determine whether I can put a specific email address in a tagin a patch that I submit or commit.  I can put an email address in atag _if_ it is ""ordinarily collected by the project"".This then leads my mental process down the path of the disclosures (fromall of the companies that I do business with) that tell me what theyare going to do with my personal information, such as my address.  (Theyusually plan to share it with the world for their financial benefit.)In that context, my personal information is not _public_, but it is_ordinarily collected_ by the company.  I hope this provides someinsight into what I am reading into ""ordinarily collected by the project"".My original comment was trying to provide the concept behind a way tocreate an alternate wording in the patch to define ""which emailaddresses"".Where are email addresses allowed to be published?  I do not understandthe patch wording to address this at all.Trying to understand how you are understanding my comment vs what Iintended to communicate, it seems to me that you are focused on the""where allowed"" and I am focused on the ""which email addresses"".More clear?  Or am I still not communicating well enough?Permission vs exclusion is orthogonal to my comments.""building linux"" is not the patch wording.  ""ordinarily collected by theproject"" is a much broader universe.A very simplistic definition of public _could_ be:- Visible on a project mail list that any one can subscribe to- Visible on a project mail list whose archive is available viathe public internet- Visible on an interactive communication (""chat"") platform thatis open to the public internet- Published on a web page intended for public access (for examplethis could cover opt-in conference attendee lists and emailsthat conference presenters voluntarily place in their slides).- (I am guessing the above covers 97% or more of possible publicsources, but maybe there are some more common sources.)I'm sure that the professionals that deal with information privacycould provide better wording for the above list.  I am but anamateur in that field.Anything else collected by the project would not be considered public.For example, an email address provided in an email sent to me and notcopied to any mail list would not be public.-Frank",Non-technical
,
"On Mon, 11 Mar 2019 11:21:10 +0100Pavel Machek <pavel@ucw.cz> wrote:I would really like to get an ack from the people who have been deep intothis first.  If you can get that, and preferably resubmit with a lesscondescending changelog, I can pick it up.Thanks,jon",Non-technical
,
"Hi Lee, Pi-Hsun, Missatge de Lee Jones <lee.jones@linaro.org> del dia dc., 30 de gen.2019 a les 14:07:Pi-Hsun, is this patchset still an RFC or you really want to see thismerged ASAP? If I am not mistaken there is still some work in progresstrying to push all the SCP stuff?Lee, personally I have some concerns. Looks like the cros_* family isincreasing quickly lately (cros_ec, cros_pd, cros_scp, cros_ish,cros_fp ...) and I am wondering if we are really doing well all this.To be honest, I'd like to take a deeper look before merge this, btw Ithought there was no hurry because of the RFC and I guess there arestill some scp things that are missing. I might be wrong, and ifthat's not the case I can take a look deeper and the end of the week.Best regards,Enric",Non-technical
,
"You are missing a cover letter from this patch set. Please have it inv2. Also use tag ""selftests/tpm2"" instead of having two tags in theshort summaries. Now they look a bit weird.8<Remove.8<Remove.8<Remove.8<Remove.8<Remove./Jarkko",Non-technical
,
This is phenomenal. Thank you so much for digging into this. I'm hoping this will greatly reduce the risk of future leakage.--Sent from my Android device with K-9 Mail. Please excuse my brevity.,Non-technical
