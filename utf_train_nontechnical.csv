"Hi,Thanks for the details.Initially i was sceptical of rst & once instead of hitting the fly,hit ""make htmldocs"" on the keyboard :), and the opinion about it waschanged. It was easy to navigate through various docs & the realizedthat various topics (& many) were present (yes, it was there earlieralso, but had to dive inside Documentation & search, while viewing thetoplevel index.html made them standout). It was like earlier you hadto go after docs, but now it was docs coming after you, that is myopinion.Later while fighting with memory-barriers.txt, felt that it might begood for it as well as to be in that company.And the readability as a text is not hurt as well.It was thought that rst conversion could be done quickly, but sincethis was my first attempt with rst, had to put some effort to get anot so bad output, even if this patch dies, i am happy to have learntrst conversion to some extent.When one of the author of the original document objected, i felt it isbetter to backoff. But if there is a consensus, i will proceed.afzal",Non-technical
,
"As per the in-kernel documentation, I am now allowed to make fun of you.You are trying to ""out smart"" the kernel by getting rid of a warningmessage that was explicitly put there for you to do something.  To thinkthat by just providing an ""empty"" function you are somehow fulfillingthe API requirement is quite bold, don't you think?This has to be fixed.  I didn't put that warning in there for no goodreason.  Please go read the documentation again...greg k-h",Non-technical
,
Please do not repost with such a small changes. It is much moreimportant to sort out the big picture first and only then deal withminor implementation details. The more versions you post the morefragmented and messy the discussion will become.You will have to be patient because this is a rather big change and itwill take _quite_ some time to get sorted.Thanks!--Michal HockoSUSE Labs,Non-technical
,
"Pulled, and then immediately unpulled again.The code causes new compiler warnings, and the warnings are valid.If people don't care enough about their code to even check thewarnings, I'm not going to waste one second pulling the resultinggarbage. It's that simple.                    Linus",Non-technical
,
"Could you please just merge the obvious fix from Arnd instead?[ it was posted two weeks ago and ACKed by me ]https://patchwork.kernel.org/patch/10313313/Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Non-technical
,
"The init function is making sure cal_type is one or another. Can you fixit correctly by replacing the 'switch' by a 'if' instead of adding deadbranches to please gcc?if (data->cal_type == TYPE_TWO_POINT_TRIMMING) {	return ...;}return ...;-- <http://www.linaro.org/> Linaro.org â”‚ Open source software for ARM SoCsFollow Linaro:  <http://www.facebook.com/pages/Linaro> Facebook |<http://twitter.com/#!/linaroorg> Twitter |<http://www.linaro.org/linaro-blog/> Blog",Non-technical
,
"Did you actually test this?  The usual reason for wanting m/udelay isthat the timing must be exact.  The driver is filled with mdelay()s forthis reason.  The one you've picked on is in the init path so it won'taffect the runtime in any way.  I also don't think we have the hrtimermachinery for usleep_range() to work properly on parisc, so I don'tthink the replacement works.James",Non-technical
,
"This doesn't have to be on separate lines; as written, it just causesconfusion.Good find, but your patch is corrupted to the point where any attenpt tofix it up on my side failed. Please resend without corruption, and pleaseprovide a Fixes: line.Thanks,Guenter",Non-technical
,
"Sorry, but this is a hack to *try* to make multi-slot work and thisisn't sufficient. There were good reasons to why the earliernon-working multi slot support was removed from dw_mmc.Let me elaborate a bit for your understanding. The core uses a hostlock (mmc_claim|release_host()) to serialize operations and commands,as to confirm to the SD/SDIO/(e)MMC specs. The above changes gives noguarantees for this. To make that work, we would need a ""mmc bus lock""to be managed by the core.However, inventing a ""mmc bus lock"" would lead to other problemsrelated to I/O scheduling for upper layers - it simply breaks. Forexample, I/O requests for one card/slot can then starve I/O requestsreaching another card/slot.Kind regardsUffe",Non-technical
,
"On Mon, 23 Apr 2018 14:05:52 +0200,Paul Menzel wrote:What actually took so long?  Could you analyze further instead ofblindly putting the flag?thanks,Takashi",Non-technical
,
"Em Mon, 23 Apr 2018 12:38:03 -0500""Gustavo A. R. Silva"" <gustavo@embeddedor.com> escreveu:Please enlighten me: how do you think this could be exploited?When an application calls VIDIOC_ENUM_FMT from a /dev/video0 device,it will just enumerate a hardware functionality, with is constantfor a given hardware piece.The way it works is that userspace do something like:	int ret = 0;	for (i = 0; ret == 0; i++) {		ret = ioctl(VIDIOC_ENUM_FMT, ...);	}in order to read an entire const table.Usually, it doesn't require any special privilege to call this ioctl,but, even if someone changes its permission to 0x400, a simple lsusboutput is enough to know what hardware model is there. A lsmodor cat /proc/modules) also tells that the tm6000 module was loaded,with is a very good hint that the tm6000 is there or was there in thepast.In the specific case of tm6000, all hardware supports exactly thesame formats, as this is usually defined per-driver. So, a quick lookat the driver is enough to know exactly what the ioctl would answer.Also, the net is full of other resources that would allow anyoneto get the supported formats for a piece of hardware.Even assuming that the OS doesn't have lsusb, that /proc is notmounted, that /dev/video0 require special permissions, that thepotential attacker doesn't have physical access to the equipment (inorder to see if an USB board is plugged), etc... What possible harmhe could do by identifying a hardware feature?Similar notes for the other patches to drivers/media in thisseries: let's not just start adding bloatware where not needed.Please notice that I'm fine if you want to submit potentialSpectre variant 1 fixups, but if you're willing to do so,please provide an explanation about the potential threat scenariosthat you're identifying at the code.Dan,It probably makes sense to have somewhere at smatch a place wherewe could explicitly mark the false-positives, in order to avoiduse to receive patches that would just add an extra delay whereit is not needed.Regards,Mauro",Non-technical
,
"On Tue, Feb 27, 2018 at 8:54 PM, Dmitry Torokhov<dmitry.torokhov@gmail.com> wrote:Hi Dmitry - thanks for the review!okok - will have this in v2:// SPDX-License-Identifier: GPL-2.0//// Copyright (C) 2018 Gateworks Corporation//// This driver dispatches Linux input events for GSC interrupt events//oops, did not mean to submit thatit was for original debugging and not needed - will removeYes, that makes sense. I'll propose something like the following in v2:gsc_input {   compatible = ""gw,gsc-input"";   button {      label = ""user pushbutton"";      linux,code = <256>;      interrupts = <0>   };   key-erased {      label = ""key erased"";      linux,code = <257>;      interrupts = <1>   };   ...};right - thanks!I am using request_threaded_irq with thread_fn with thread_fn (vs handler).Do you mean why use a work procedure? I guess I don't need that andcan call input_report_key directly from the irq.okcan you point me to an example dts/driver?Tim",Non-technical
,
"I suppose these sort of patches are as much a PITA for the senderthan for the receivers.I hesitated between a single patch, a series or separated patches.In a sense, the single patch would have been the easier for both sidesbut I guessed it would not have been very well welcomed. Since for aseries, you're supposed to CC the whole series to everyone involved,it would have been, or at least at thought so, maximaly noisy for nogood reasons. Finally, as all of these patches are totally independent,I thought it would be the best to send them as separated patches,each drivers maintainers being then free to accept, reject or ignorethe patch(es) concerning him/her. It seems it was a bad guess, andyes, I see the point of having a series for this.I'll remember all this for the next time (if next time there is,of course, I was already quite hesitant to spend time to prepareand send patches for these issues with enum/integer mix-up).Sorry for the annoyance,-- Luc",Non-technical
,
"Either it does exist, or it doesn't.If it exists, it needs to be fixed.  If it doesn't exist, nothingneeds to be done.Which is the case?",Non-technical
,
It looks like you are not actually sure what you are doing then.,Non-technical
,
"I do share your view Mike!This all looks so hackish and ad-hoc that I would be tempted to give itan outright nack, but let's here more about why do we need this fiddlingat all. I've asked in other email so I guess I will get an answer therebut let me just emphasize again that I absolutely detest a possibilityto put hugetlb pages into the memcg mix. They just do not belong there.Try to look at previous discussions why it has been decided to have aseparate hugetlb pages at all.I am also quite confused why you keep distinguishing surplus hugetlbpages from regular preallocated ones. Being a surplus page is animplementation detail that we use for an internal accounting rather thansomething to exhibit to the userspace even more than we do currently.Just look at what [sw]hould when you need to adjust accounting - e.g.due to the pool resize. Are you going to uncharge those surplus pagesffrom memcg to reflect their persistence?--Michal HockoSUSE Labs",Non-technical
,
"Where did this come from? XFS doesn't use the underlying blockdevaddress space, so this does nothing at all and should not be here.So to return errors correctly, xfs_fs_sync_fs() needs to captureerrors from the log force (i.e. metadata errors such as filesystemshutdowns, journal IO errors, etc), then check for pending data IOerrors. i.e: STATIC int xfs_fs_sync_fs( 	struct super_block      *sb, 	int                     wait) { 	struct xfs_mount        *mp = XFS_M(sb);+	int			err; 	/* 	 * Doing anything during the async pass would be counterproductive. 	 */ 	if (!wait) 		return 0;-	xfs_log_force(mp, XFS_LOG_SYNC);+	err = xfs_log_force(mp, XFS_LOG_SYNC);+	if (err)+		return err;+ 	if (laptop_mode) { 		/* 		 * The disk must be active because we're syncing. 		 * We schedule log work now (now that the disk is 		 * active) instead of later (when it might not be). 		 */ 		flush_delayed_work(&mp->m_log->l_work); 	}-	return 0+	return errseq_check_and_advance(&sb->s_wb_err, since); }Cheers,Dave.--Dave Chinnerdavid@fromorbit.com",Non-technical
,
"The SPDX header is explicitly here to remove the license text andcreate a tag that is in a indirect reference to the license text inLICENSES. It's not going away.I never said we were perfect reviewers. Feel free to help in the process.Maxime--Maxime Ripard, Bootlin (formerly Free Electrons)Embedded Linux and Kernel engineeringhttps://bootlin.com",Non-technical
,
"But you did it again....Your email client should not be forcing you to top post. So pleasedon't.	Andrew",Non-technical
,
I took a closer look at this and it's not necessary. (Note: I do themajority of my testing in a looped-back setup).What you didn't notice is that split_remote() separates the colonwhether there is a host or not. It's not passed to ssh or cat (orwhatever) directly. So the change you propose will actually break thehow it was designed.Logan,Non-technical
,
There are no unexpected results.Making a non-fatal error fatal doesn't serve a useful purpose.NACKGuenter,Non-technical
,
"What is this crazy union for?  Why are you messing around with ""raw""kobject attributes?  This is a device, you should never have to messwith sysfs calls or kobject calls or structures directly.  If you do,that's a huge hint something is wrong here.You aren't ""adding"" any attributes here, you are only setting them up(in an odd way, see below...)That's an oddly-hard-coded array size for no good reason :(This works?  You normally have to manually initialize a dynamicattribute.  Why are you doing it this way and not using an attributegroup?Why are you using a custom device class for a single device?you need to document the heck out of this in the changelog to helpexplain all of these odd design decisions.thanks,greg k-h",Non-technical
,
"Randy,No, at this point it requires both I2C and OF. I may add platform datato support an older non-device-tree family of boards but it stillwould require I2C.I will remove the || COMPILE_TESTThanks for catching that.Tim",Non-technical
,
"Greg (and replying to your other comments as well)...This is an RFC series, it's not meant for you to take at this point,it's about discussing the overall approach to exposing BMC random""tunables"" as explained in patch 0 of the series.Yes the individual patches aren't yet at the level of polish for aformal submission, we (naively ?) thought that's what the whole RFC tagis about :-)Cheers,Ben.",Non-technical
,
"Well, it adds documentation :-) You can just read the patch which is... the documentation :)Yes, you did that's fine. Thanks.Cheers,Ben.",Non-technical
,
"Oh come on, putting a basic ""here is what this patch does"" commentshould be part of every patch, otherwise what is there to comment on ifwe don't know what is going on in the patch itself?Anyway, I provided a bunch of feedback to the ""real"" patch in thisseries...greg k-h",Non-technical
,
"Yeah, not going to happen. You grow that structure from 64 bytes to 96bytes and with that grow the static footprint of the kernel by 512k (inthe very best case) possibly again breaking things like sparc (whichhave a strict limit on the kernel image size).And all that for data that I've never needed and never even considereduseful when looking at lockdep output.",Non-technical
,
"I  confirm that in case of x86_64, the bss size is increased by ~1M [1]with standard v4.18-rc4 x86_64_defconfig + CONFIG_LOCKDEP.For sparc there seems to be a dedicated CONFIG_LOCKDEP_SMALL, whichseems to downsize the lockdep implementation anyway.It's likely because you infer about certain aspects which are notclearly stated in the deadlock report. As example, the original reportdoesn't say that the process which holds 'cpu_hotplug_lock.rw_sem'is different to the process which holds the other locks. On thecontrary, it tells the user that all the locks are being held by thesame task, which seems to be wrong.You likely also infer about the order of consuming the locks based onthe contents of the stack dump associated to each lock. Without doingsome mental diffs between the backtraces, it's not possible to see thechronological order of consuming the locks. Actually this only works forbacktraces with common history, i.e. there is no clue what is thetime/point of acquiring 'cpu_hotplug_lock.rw_sem' relative to the otherlocks.The patch mostly shares my personal experience of trying to make senseof lockdep output. It's OK if it doesn't reach mainline.I still hope that I can get some feedback from community regardingthe actual cpufreq-related issue pointed out in the splat. I can alsoreproduce it on v4.14, so it appears to be in the kernel for quitesome time.Thank you in advance.Best regards,Eugeniu.[1] BSS size increase after applying the patch$ bloaty -s vm vmlinux.after -- vmlinux.before     VM SIZE                           FILE SIZE --------------                     --------------  +8.2% +1024Ki .bss                      0  [ = ]  ----snip----  +2.6% +1024Ki TOTAL               +3.36Ki  +0.0%",Non-technical
,
"These calling conventions st^Ware rather suboptimal.  First of all,	* none of ->actor() callbacks will ever get called directly.	* there are only 4 callers.  3 of them (all in fs.h) areof the form return ....->actor(...) == 0;  The fourth is        return orig_ctx->actor(orig_ctx, name, namelen, offset, ino, d_type);in ovl_fill_real(), which itself is an ->actor() callback.So all these ""return -E..."" in the instances are completely pointless;we should just turn filldir_t into pointer-to-function-returning-booland get rid of that boilerplate, rather than adding more to it.Furthermore, who the hell cares which callback has stepped into it?""The first time it happened from getdents(2) in a 32bit process andthat's all you'll ever get out of me"" seems to be less than helpful...And frankly, I would prefer	buf->result = check_dirent_name(name, namelen);	if (unlikely(buf->result))		return false;making that thing return -EUCLEAN or 0.  Quite possibly - inlining itas well...",Non-technical
,
PavelThanks for the reviewThe problem we have here is there is a potential to control3 different LED string but only 2 sinks.  So control bank A can control 2 LED strings and controlbank b can control 1 LED string.These values represent device level control and configuration of the LED strings to a specific control bank.I racked my brain trying to figure out how to configure the control banks and associated LED strings.These values are for the device configuration itself and the reg below indicates which control bank the LEDnode is assigned to.Don't see how you could compute this.  There is no easy way to give indication to the driver which LEDnode belongs to which control bank.  The control-bank-cfg is a device level property and the reg under thechild is a LED string level property denoting the Class node to control bank mapping.Furthermore there are 2 device configurations that can be configured to only use 1 bank for all 3 LED strings.This will be answered in your comments in the code.This I can fix it should be a value between 1 and 6--------------------Dan Murphy,Non-technical
,
"Dan,It is better do add some complexity to the driver than to theuser configurable settings like DT. Besides - you will only need tocheck if given led-source is already taken by another node.Some description will be needed for sure, but I don't expect itto be overwhelmingly lengthy.Your control-bank-cfg seemed like having much room for improvement,and it would for sure raise questions on why it was implemented thatway. Documenting all available combinations of the configuration isseldom the best solution. It often obscures the issue.In your bindings device configuration is scattered among globalcontrol-bank-cfg property and child node's reg property.In my proposal each child node contains all the needed configuration,also in the form of two properties - led-sources and reg. IMHO havingall the LED class device related configuration in one place simplifiesthe analysis.--Best regards,Jacek Anaszewski",Non-technical
,
"From: Wang Jian <jianjian.wang1@gmail.com>Date: Thu, 16 Aug 2018 21:01:27 +0800This patch was corrupted by your email client, for example it turnedTAB characters into sequences of spaces.Please fix this, email a test patch to yourself, and do not resend thepatch to this mailing list until you can successfully extract andcleanly apply the test patch you email to yourself.Thank you.",Non-technical
,
"Again I'll ask: what is the performance when the log is made largeenough that your benchmark is *not hammering the slow path*?i.e. does running ""mkfs.xfs -l size=2000m ..."" instead of using thedefault tiny log on your tiny test filesystem make the problemgo away? Without that information, we have no idea what the slowpath impact on peformance actually is, and whether it is worthpersuing optimising slow path behaviour that very, very fewproduction environments see lock contention in....Cheers,Dave.--Dave Chinnerdavid@fromorbit.com",Non-technical
,
"Guenter,Thanks for the review!oops - left that in by mistake.It has 16x ADC channels where some can be temperatures and others canbe voltage inputs (based on device tree).understood - a much cleaner patternright - removedyikes - thanks for catching thatokyes, that static arrays are not very forward-thinking and yes myarrays are not consistent. I'll convert to dynamically allocating thechannels for v2right - certainly an issuewill dowill add validationokDo you mean stuffing a u32 into a u8?will fixwill fixwill docould also return -EINVAL but not with the args I'm passing in so I'llchange it to:return PTR_ERR_OR_ZERO(hwmon);Thanks!Tim",Non-technical
,
"Ick, this is still messy, just try making this:			err |= comedi_check_trigger_arg_min(&cmd->scan_begin_arg,							    cmd->convert_arg * cmd->chanlist_len);Yeah, it's over 80 columns, but it looks better and is easier to read,right?Also, all your patches have the whitespace turned from tabs into spaces,making them impossible to be applied even if I wanted to :)thanks,greg k-h",Non-technical
,
"I don't call this non-intrusive.I'll beg to differ; this isn't anywhere near something to considermerging. Also 'happened' suggests a certain stage of completeness, thisagain doesn't qualify.There are known scalability problems with the existing cgroup muck; youjust made things a ton worse. The existing cgroup overhead issignificant, you also made that many times worse.The cgroup stuff needs cleanups and optimization, not this.That is the whole and only reason you did this; and it doesn't evenbegin to cover the requirements for it.Not to mention I detest cgroups; for their inherent complixity and theperformance costs associated with them.  _If_ we're going to dosomething for L1TF then I feel it should not depend on cgroups.It is after all, perfectly possible to run a kvm thingy without cgroups.Note that in order to avoid PLE and paravirt spinlocks and paravirttlb-invalidate you have to gang-schedule the _entire_ VM, not just SMTsiblings.Now explain to me how you're going to gang-schedule a VM with a goodnumber of vCPU threads (say spanning a number of nodes) and preservingthe rest of CFS without it turning into a massive trainwreck?Such things (gang scheduling VMs) _are_ possible, but not within theconfines of something like CFS, they are also fairly inefficientbecause, as you do note, you will have to explicitly schedule idle timefor idle vCPUs.Things like the Tableau scheduler are what come to mind; but I'm notsure how to integrate that with a general purpose scheduling scheme. Youpretty much have to dedicate a set of CPUs to just scheduling VMs withsuch a scheduler.And that would call for cpuset-v2 integration along with a newscheduling class.And then people will complain again that partitioning a system isn'tdynamic enough and we need magic :/(and this too would be tricky to virtualize itself)You gloss over a ton of details here; many of which are non trivial andmarked broken in your patches. Unless you have solid suggestions on howto deal with all of them, this is a complete non-starter.The per-cpu IRQ/steal time accounting for example. The task timelineisn't the same on every CPU because of those.You now basically require steal time and IRQ load to match between CPUs.That places very strict requirements and effectively breaks virtinvariance. That is, the scheduler now behaves significantly differentinside a VM than it does outside of it -- without the guest being gangscheduled itself and having physical pinning to reflect the sametopology the coschedule=1 thing should not be exposed in a guest. Andthat is a mayor failing IMO.Also; I think you're sharing a cfs_rq between CPUs:+       init_cfs_rq(&sd->shared->rq.cfs);that is broken, the virtual runtime stuff needs nontrivial modificationsfor multiple CPUs. And if you do that, I've no idea how you're dealingwith SMP affinities.You don't even begin to outline how you preserve smp-nice fairness.IOW it's completely friggin useless for L1TF.Have you actually read your own code?What about that atrocious locking you sprinkle all over the place?'some additional lock contention' doesn't even begin to describe thathorror show.Hint: we're not going to increase the lockdep subclasses, and mostcertainly not for scheduler locking.All in all, I'm not inclined to consider this approach, it complicatesan already overly complicated thing (cpu-cgroups) and has a ton ofunresolved issues while at the same time it doesn't (and cannot) meetthe goal it was made for.",Non-technical
,
"Mm... there is certainly room for interpretation. :) For example, it is stillpossible to set affinities, to use nice, and to tune all the other existing CFSknobs. That is, if you have tuned the scheduler to your workload or your workloaddepends on some CFS feature to work efficiently (whether on purpose or not), thenrunning with this patch set should not change the behavior of said workload.This patch set should ""just"" give the user the additional ability to coordinatescheduling decisions across multiple CPUs. At least, that's my goal.If someone doesn't need it, they don't have to use it. Just like task groups.But maybe, people start experimenting with coordinated scheduling decisions --after all, there is a ton of research on what one *could* do, if there wascoscheduling. I did look over much of that research. What I didn't like aboutmany of them, is that evaluation is based on a ""prototype"", that -- whilemaking the point that coscheduling might be beneficial for that use case --totally screws over the scheduler for any other use case. Like coschedulingbased on deterministic, timed context switches across all CPUs. Bye byeinteractivity. That is, what I call intrusive.As mentioned before, existing scheduler features, like preemption, (should)still work as before with this variant of coscheduling, with the same look andfeel.And who knows, maybe someone will come up with a use case that moves coschedulingout of its niche; like the auto-grouping feature promoted the use of task groups.I agree, that this isn't ready to be merged. Still, the current state is goodto start a discussion about the involved mechanics.Are you referring to cgroups in general, or task groups (aka. the cpucontroller) specifically?With respect to scalability: many coscheduling use cases don't requiresynchronization across the whole system. With this patch set, only thoseparts that are actually coscheduled are involved in synchronization.So, conceptually, this scales to larger systems from that point of view.If coscheduling of a larger fraction of the system is required, costsincrease. So what? It's a trade-off. It may *still* be beneficial for ause case. If it is, it might get adopted. If not, that particular usecase may be considered impractical unless someone comes up with a betterimplementation of coscheduling.With respect to the need of cleanups and optimizations: I agree, thattask groups are a bit messy. For example, here's my current wish listoff the top of my head:a) lazy scheduler operations; for example: when dequeuing a task, don't bother   walking up the task group hierarchy to dequeue all the SEs -- do it lazily   when encountering an empty CFS RQ during picking when we hold the lock anyway.b) ability to move CFS RQs between CPUs: someone changed the affinity of   a cpuset? No problem, just attach the runqueue with all the tasks elsewhere.   No need to touch each and every task.c) light-weight task groups: don't allocate a runqueue for every CPU in the   system, when it is known that tasks in the task group will only ever run   on at most two CPUs, or so. (And while there is of course a use case for   VMs in this, another class of use cases are auxiliary tasks, see eg, [1-5].)Is this the level of optimizations, you're thinking about? Or do you wantto throw away the whole nested CFS RQ experience in the code?It really isn't. But as your mind seems made up, I'm not going to botherto argue.Yes it is. But, for example, you won't have group-based fairness betweenmultiple kvm thingies.Assuming, there is a cgroup-less solution that can prevent simultaneousexecution of tasks on a core, when they're not supposed to. How would youtell the scheduler, which tasks these are?You probably don't -- for the same reason, why it is a bad idea to givean endless loop realtime priority. It's just a bad idea. As I said in thetext you quoted: coscheduling comes with its own set of advantages anddisadvantages. Just because you find one example, where it is a bad idea,doesn't make it a bad thing in general.With gang scheduling as defined by Feitelson and Rudolph [6], you'd have toexplicitly schedule idle time. With coscheduling as defined by Ousterhout [7],you don't. In this patch set, the scheduling of idle time is ""merely"" a quirkof the implementation. And even with this implementation, there's nothingstopping you from down-sizing the width of the coscheduled set to take outthe idle vCPUs dynamically, cutting down on fragmentation.Hence my ""counter"" suggestion in the form of this patch set: Integratedinto a general purpose scheduler, no need to partition off a part of the system,not tied to just VM use cases.Yes, I do. :) I wanted a summary, not a design document. Maybe I was a bitto eager in condensing the design to just a few paragraphs...Address them one by one. Probably do some of the optimizations you suggestedto just get rid of some of them. It's work in progress. Though, at thisstage I am also really interested in things that are broken, that I am notaware of yet.I'll have to read up some more code to make a qualified statement here.It is not shared per se. There's only one CPU (the leader) making the schedulingdecision for that runqueue and if another CPU needs to modify the runqueue, itworks like it does for CPU runqueues as well: the other CPU works with theleader's time. There are also no tasks in a runqueue when it is responsible formore than one CPU.Assuming, that a runqueue is responsible for a core and there are runnabletasks within the task group on said core, then there will one SE enqueued inthat runqueue, a so called SD-SE (scheduling domain SE, or synchronizationdomain SE). This SD-SE represents the per CPU runqueues of this core of thistask group. (As opposed to a ""normal"" task group SE (TG-SE), which representsjust one runqueue in a different task group.) Tasks are still only enqueuedin the per CPU runqueues.Works as before (or will work as before): a coscheduled task group has itsown set of per CPU runqueues that hold the tasks of this group (per CPU).The load balancer will work on this subset of runqueues as it does on the""normal"" per CPU runqueues -- smp-nice fairness and all.Do you believe me now, that L1TF is not ""the whole and only reason"" I did this? :DCurrently, there are more code paths than I like, that climb up the se->parentrelation to the top. They need to go, if we want to coschedule larger parts ofthe system in a more efficient manner. Hence, parts of my wish list further up.That said, it is not as bad as you make it sound for the following three reasons:a) The amount of CPUs that compete for a lock is currently governed by the   ""cosched_max_level"" command line argument, making it a conscious decision to   increase the overall overhead. Hence, coscheduling at, e.g., core level   does not have a too serious impact on lock contention.b) The runqueue locks are usually only taken by the leader of said runqueue.   Hence, there is often only one user per lock even at higher levels.   The prominent exception at this stage of the patch set is that enqueue and   dequeue operations walk up the hierarchy up to the ""cosched_max_level"".   And even then, due to lock chaining, multiple enqueue/dequeue operations   on different CPUs can bubble up the shared part of the hierarchy in parallel.c) The scheduling decision does not cause any lock contention by itself. Each   CPU only accesses runqueues, where itself is the leader. Hence, once you   have a relatively stable situation, lock contention is not an issue.That's fine. Due to the overhead of nesting cgroups that you mentioned earlier,that many levels in the runqueue hierarchy are likely to be impracticableanyway. For the future, I imagine a more dynamic variant of task groups/schedulingdomains, that can provide all the flexibility one would want without that deepof a nesting. At this stage, it is just a way to experiment with larger systemswithout having to disable lockdep.Of course, if you have a suggestion for a different locking scheme, we candiscuss that as well. The current one, is what I considered most suitableamong some alternatives under the premise I was working: integrate coschedulingin a scheduler as an additional feature (instead of, eg, write a schedulercapable of coscheduling). So, I probably haven't considered all alternatives.Even if you're not inclined -- at this stage, if I may be so bold :) --your feedback is valuable. Thank you for that.RegardsJanReferences (for those that are into that kind of thing):[1] D. Kim, S. S.-w. Liao, P. H. Wang, J. del Cuvillo, X. Tian, X. Zou,    H. Wang, D. Yeung, M. Girkar, and J. P. Shen, â€œPhysical experimentation    with prefetching helper threads on Intelâ€™s hyper-threaded processors,â€    in Proceedings of the International Symposium on Code Generation and    Optimization (CGO â€™04). Los Alamitos, CA, USA: IEEE Computer    Society, Mar. 2004, pp. 27â€“38.[2] C. Jung, D. Lim, J. Lee, and D. Solihin, â€œHelper thread prefetching for    loosely-coupled multiprocessor systems,â€ in Parallel and Distributed Pro-    cessing Symposium, 2006. IPDPS 2006. 20th International, April 2006.[3] C. G. QuiÃ±ones, C. Madriles, J. SÃ¡nchez, P. Marcuello, A. GonzÃ¡lez,    and D. M. Tullsen, â€œMitosis compiler: An infrastructure for speculative    threading based on pre-computation slices,â€ in Proceedings of the 2005    ACM SIGPLAN Conference on Programming Language Design and    Implementation, ser. PLDI â€™05. New York, NY, USA: ACM, 2005, pp.    269â€“279.[4] J. Mars, L. Tang, and M. L. Soffa, â€œDirectly characterizing cross    core interference through contention synthesis,â€ in Proceedings of the    6th International Conference on High Performance and Embedded    Architectures and Compilers, ser. HiPEAC â€™11. New York, NY, USA:    ACM, 2011, pp. 167â€“176.[5] Q. Zeng, D. Wu, and P. Liu, â€œCruiser: Concurrent heap buffer overflow    monitoring using lock-free data structures,â€ in Proceedings of the 32Nd    ACM SIGPLAN Conference on Programming Language Design and    Implementation, ser. PLDI â€™11. New York, NY, USA: ACM, 2011, pp.    367â€“377.[6] D. G. Feitelson and L. Rudolph, â€œDistributed hierarchical control for    parallel processing,â€ Computer, vol. 23, no. 5, pp. 65â€“77, May 1990.[7] J. Ousterhout, â€œScheduling techniques for concurrent systems,â€ in    Proceedings of the 3rd International Conference on Distributed Computing    Systems (ICDCS â€™82). Los Alamitos, CA, USA: IEEE Computer Society,    Oct. 1982, pp. 22â€“30.",Non-technical
,
"How can you set a shared variable with no synchronization ?A bool is particularly dangerous here, at least on some arches.",Non-technical
,
"If rtnl_trylock() can not grab RTNL,there is no way the current thread can set the  variable without a race, if the word including rtnl_needed is shared by other fields in the structure.Your patch adds a subtle possibility of future bugs, even if it runs fine today.Do not pave the way for future bugs, make your code robust, please.",Non-technical
,
"It would be very helpful if you cc all involved people on the cover letterinstead of just cc'ing your own pile of email addresses. CC'ed now.This is really not helpful. The cover letter and the change logs shouldcontain a summary of that discussion and a proper justification of theproposed change. Just saying 'sysadmins might want to allow' is not usefulat all, it's yet another 'I want a pony' thing.I read through the previous thread and there was a clear request to involvesecurity people into this. Especially those who are deeply involved withhardware side channels. I don't see anyone Cc'ed on the whole series.For the record, I'm not buying the handwavy 'more noise' argument atall. It wants a proper analysis and we need to come up with criteria whichPMUs can be exposed at all.All of this want's a proper documentation clearly explaining the risks andscope of these knobs per PMU. Just throwing magic knobs at sysadmins andthen saying 'its their problem to figure it out' is not acceptable.Thanks,	tglx",Non-technical
,
"Hi,I accept it was by bad to miss adding Cc's on the cover letter, but myown email addresses hopefully should not bother you. It is simply aquestion of what I have in .gitconfig vs what I forgot to do manually.Okay, for the next round I will expand the cover letter with at leastone concrete example on how it is usable and summarize the discussion a bit.Who would you recommend I add? Because I really don't know..Presumably you see adding fine grained control as diminishing theoverall security rather than raising it? Could you explain why? Becauseincompetent sysadmin will turn it off for some PMU, while without havingthe fine-grained control they wouldn't turn it off globally?This feature was requested by the exact opposite concern, that in orderto access the i915 PMU, one has to compromise the security of the entiresystem by allowing access to *all* PMU's.Making this ability fine-grained sounds like a logical solution forsolving this weakening of security controls.Concrete example was that on video transcoding farms users want tomonitor the utilization of GPU engines (like CPU cores) and they can dothat via the i915 PMU. But for that to work today they have to dial downthe global perf_event_paranoid setting. Obvious improvement was to allowthem to only dial down the i915.perf_event_paranoid setting. As such,for this specific use case at least, the security is increased.Regards,Tvrtko",Non-technical
,
"Tvrtko,The keyword in the above sentence is 'just'. You can add as many of yoursas you want as long as everybody else is cc'ed.Sure, and because you don't know you didn't bother to ask around andignored the review request.I already added Kees and Jann. Please look for the SECCOMP folks inMAINTAINERS.I did not say at all that this might be diminishing security. And theargumentation with 'incompetent sysadmins' is just the wrong attitude.What I was asking for is proper documentation and this proper documentationis meant for _competent_ sysadmins.That documentation has to clearly describe what kind of information isaccessible and what potential side effects security wise this mighthave. You cannot expect that even competent sysadmins know offhand whatwhich PMU might expose. And telling them 'Use Google' is just not the rightthing to do.If you can't explain and document it, then providing the knob is justfulfilling somebodys 'I want a pony' request.Sure, and this wants to be documented in the cover letter and thechangelogs.But this does also require a proper analysis and documentation why it isnot a security risk to expose the i915 PMU or what potential securityissues this can create, so that the competent sysadmin can make ajudgement.And the same is required for all other PMUs which can be enabled in thesame way for unprivileged access. And we might as well come to theconclusion via analysis that for some PMUs unpriviledged access is just nota good idea and exclude them. I surely know a few which qualify forexclusion, so the right approach is to provide this knob only when the riskis analyzed and documented and the PMU has been flagged as candidate forunpriviledged exposure. I.e. opt in and not opt out.Thanks,	tglx",Non-technical
,
"Sure, but you also used the word ""pile"" and I would argue that made therest of your sentence, after and including ""instead"", sound like it notonly bothers you I forgot to Cc people on the cover letter, but it alsobothers you I included a ""pile"" of my own addresses. If that wasn't yourintention in the slightest then I apologise for misreading it.No, not because of that. You are assuming my actions and motivations andconstructing a story.""did not bother"" = negative connotations""ignored"" = negative connotationsNote instead the time lapse between this and previous posting of theseries, and if you want to assume something, assume things can getmissed and forgotten without intent or malice.Thanks!Wrong attitude what? I was trying to guess your reasoning (cues in""presumably"" and a lot of question marks) since it wasn't clear to mewhy is your position what it is.I did not mention Google.Well it's not a pony, it is mechanism to avoid having to turn off allsecurity. We can hopefully discuss it without ponies.I am happy to work on the mechanics of achieving this once the securityguys and all PMU owners get involved. Even though I am not convinced thebar to allow fine-grained control should be evaluating all possiblePMUs*, but if the security folks agree that is the case it is fine by me.Regards,Tvrtko*) The part of my reply you did not quote explains how the fine-grainedcontrol improves security in existing deployments. The documentation Iadded refers to the existing perf_event_paranoid documentation forexplanation of security concerns involved. Which is not much in itself.But essentially we both have a PMU and a knob already. I don't see whyadding the same knob per-PMU needs much more stringent criteria to beaccepted. But as said, that's for security people to decide.",Non-technical
,
"Tvrtko,Guessing my reasonings has nothing to do with you mentioning incompententsysadmins.I did not say that you mentioned google. But what is a sysadmin supposed todo when there is no documentation aside of using google? And not havingdocumentation is basically the same thing as telling them to use google.If you want to make a pettifogger contest out of this discussion, then wecan stop right here. I explained it technically why just adding a knobwithout further explanation and analysis is not acceptable.Making the knob opt in per PMU does not need all PMU owners to beinvolved. It allows to add the opt in flag on a case by case basis.The fact, that the existing knob is poorly documented does make an excusefor adding more knobs without documentation. Quite the contrary, if wenotice that the existing knob lacks proper documentation, then we shouldfix that first.Thanks,	tglx",Non-technical
,
"Sorry for being dense. What tree is this against? I can't find mentionof amdcz in Linus's tree nor linux-next.Where does serial8250_skip_old_ports get used where CONFIG_SERIAL_8250isn't defined? (i.e. why is the #ifdef needed here?)Otherwise, sure, sounds good. :)-Kees--Kees CookPixel Security",Non-technical
,
"Ah only if google could simply answer all our questions!It's not like there is or isn't a security risk and that youcan say that it is or it isn't in a global way.Essentially these are channels of information. The channels always existin form of timing variances for any shared resource (like shared cachesor shared memory/IO/interconnect bandwidth) that can be measured.Perfmon counters make the channels generally less noisy, but they do not causethem.To really close them completely you would need to avoid sharinganything, or not allowing to measure time, neither of which is practicalshort of an air gap.There are reasonable assesments you can make either way and the answerswill be different based on your requirements. There isn't a singleanswer that works for everyone.There are cases where it isn't a problem at all.If you don't have multiple users on the system your toleranceshould be extremely high.For users who have multiple users there can be different tradeoffs.So there isn't a single answer, and that is why it is importantthat this if configurable.-Andi",Non-technical
,
"I said clearly that I'm not opposed against making it configurable. Butbecause there is no single answer, it's even more important to have properdocumentation. And that's all I'm asking for aside of making it opt-ininstead of a wholesale expose everything approach.Thanks,	tglx",Non-technical
,
"From: YueHaibing <yuehaibing@huawei.com>Date: Wed, 26 Sep 2018 17:27:05 +0800Even though the return type of ndo_start_xmit is netdev_tx_t, negative error codes arestill allowed I believe.Look, reviewing these are pretty stressful for me, because you aren't documenting yourchanges and in many cases the transformations look incorrect.I'm tossing the rest of your changes in this area for now, sorry.Please double check your work and resubmit this at some time in the not-too-nearfuture.Thank you.",Non-technical
,
"The way I see it, it is pretty well marked up as is. So, this paragraphis not describing the change.What is not ""proper"" about the existing comment? Yes yes, I *know* thatGCC is not very intelligent about it and requires hand-holding, butblaming the existing comment for not *properly* marking an intentionalfall through is ... rich.Adding some more context here.		case IIO_VAL_INT:			/*			 * Convert integer scale to fractional scale by			 * setting the denominator (val2) to one...Considering the above added context, I have to say that this mindlesschange is not an improvement, as you have just destroyed the continuedsentence from the previous comment. You must have noticed that thiswas the end of a continued sentence, as you even quoted it in the commitmessage. The big question is why you did not stop to think and considerthe context?Yes, I'm annoyed by mindless changes. Especially mindless changes aimedat improving readability while in fact making things less readable.TL;DR, if you are desperate to fix ""the problem"" with this fall throughcomment, please do so in a way that preserves overall readability. Andit would be nice to not blame the existing code for brain damage in GCCand various other static analyzers.Cheers,Peter",Non-technical
,
"I still object. It would have been so damn easy and it does not take a wholelot of imagination to quiet down GCC while keeping the comments readable. Justmove the ""and"" to the previous comment, like this.		case IIO_VAL_INT:			/*			 * Convert integer scale to fractional scale by			 * setting the denominator (val2) to one, and...			 */			*val2 = 1;			ret = IIO_VAL_FRACTIONAL;			/* fall through */		case IIO_VAL_FRACTIONAL:Or add a sentence, like this (which is a bit more fun IMO)		case IIO_VAL_INT:			/*			 * Convert integer scale to fractional scale by			 * setting the denominator (val2) to one...			 */			*val2 = 1;			ret = IIO_VAL_FRACTIONAL;			/* ...and fall through. Say it again for GCC. */			/* fall through */		case IIO_VAL_FRACTIONAL:Cheers,Peter",Non-technical
,
"Which CPU architecture?  Most important architectures appear to define__HAVE_ARCH_MEMCMP.What the heck does __visible do?This is going to do bad things if the incoming addresses aren'tsuitably aligned.Certainly, byte-at-a-time is a pretty lame implementation when theaddresses are suitably aligned.  A fallback to the lame version whenthere is misalignment will be simple to do.  And presumably there willbe decent benefits to whoever is actually using this code.  But I'mwondering who is actually using this code!",Non-technical
,
Can you possibly send the entire series again and CC all patches to linux-acpiand fix the kbuild warnings if the are relevant for that matter?Thanks!,Non-technical
,
"Hi YannickCan you add a commit message explaining why you add a specific defconfigfor this board. FYI, previously, the same defconfig was used for allSTM32F7 boards (ie /stm32f746-disco_defconfig).You will also need to resync with the last master branch regardingdefconfig content.ThanksPatrice",Non-technical
,
"This is indeed guaranteed. For FTRACE use case. If it's being called from FTRACE inrun time, this would mean there were long calls in this module section, which inturn means, get_module_plt() was called at least once for this module and thissection.This doesn't hold in general, though.In any case, if you insist, I can try to rework the whole stuff implementing module_finalize().--Best regards,Alexander Sverdlin.",Non-technical
,
"So make it fit by returning an unsigned int.--Regards/Gruss,    Boris.Good mailing practices for 400: avoid top-posting and trim the reply.",Non-technical
,
"Thank you so much for many style, formatting and other issues fixes and also forintegration of 'check_at_most_once' patch, it saved me several review iterations.Regarding free of sg in two error paths, you were correct.I fixed it by placing several error labels to differentiate each handling.I also noted that reqdata_arr[b].req was not released properly, this is also fixed.following is a diff of my fix based on your modifications.(I can send it in a patch format, but it doesn't include a fix for Eric Biggers comments)@@ -573,10 +573,9 @@ static void verity_verify_io(struct dm_verity_io *io)                        verity_bv_skip_block(v, io, &io->iter);                        continue;                }-                reqdata_arr[b].req = ahash_request_alloc(v->tfm, GFP_NOIO);                if (unlikely(reqdata_arr[b].req == NULL))-                       goto err_memfree;+                       goto err_mem_req;                ahash_request_set_tfm(reqdata_arr[b].req, v->tfm);                /* +1 for the salt buffer */@@ -586,7 +585,7 @@ static void verity_verify_io(struct dm_verity_io *io)                                   GFP_NOIO);                if (!sg) {                        DMERR_LIMIT(""%s: kmalloc_array failed"", __func__);-                       goto err_memfree;+                       goto err_mem_sg;                }                sg_init_table(sg, num_of_buffs);                // FIXME: if we 'err_memfree' (or continue;) below how does this sg get kfree()'d?@@ -595,7 +594,7 @@ static void verity_verify_io(struct dm_verity_io *io)                                          reqdata_arr[b].want_digest,                                          &reqdata_arr[b].fec_io, &is_zero);                if (unlikely(r < 0))-                       goto err_memfree;+                       goto err_mem;                if (is_zero) {                        /*@@ -605,7 +604,7 @@ static void verity_verify_io(struct dm_verity_io *io)                        r = verity_for_bv_block(v, io, &io->iter,                                                verity_bv_zero);                        if (unlikely(r < 0))-                               goto err_memfree;+                               goto err_mem;                        verity_cb_complete(iodata, r);                        continue;                }@@ -644,7 +643,11 @@ static void verity_verify_io(struct dm_verity_io *io)        }        return;-err_memfree:+err_mem:+       kfree(sg);+err_mem_sg:+       ahash_request_free(reqdata_arr[b].req);+err_mem_req:        /*         * reduce expected requests by the number of unsent         * requests, -1 accounting for the current block        atomic_sub(blocks - b - 1, &iodata->expected_reqs);        verity_cb_complete(iodata, -EIO);I took your modifications and working upon it.",Non-technical
,
"The driver is looking good!It looks like you've done some kind of review that we weren't allowedto see, which is a double edged sword - I might be asking about thingsthat you've already spoken about with someone else.I'm only just learning about PECI, but I do have some general comments below.I think just saying ASPEED PECI support is enough. That way if thenext ASPEED SoC happens to have PECI we don't need to update all ofthe help text :)Nit: we use ASPEED instead of AST in the upstream kernel to distingushfrom the aspeed sdk drivers. If you feel strongly about this then Iwon't insist you change.I know these come from the ASPEED sdk driver. Do we need them all?Could the above use regmap_read_poll_timeout instead?That looks like an endian swap. Can we do something like this? regmap_write(map, reg, cpu_to_be32p((void *)msg->tx_buff))Having #defines is frowned upon. I think print_hex_dump_debug will dowhat you want here.I find this hard to read. Use a few more lines to make it clear whatyour code is doing.Actually, the entire for loop is cryptic. I understand what it's doingnow. Can you rework it to make it more readable? You follow a similarpattern above in the write case.Given the regmap_read is always going to be a memory read on theaspeed, I can't think of a situation where the read will fail.On that note, is there a reason you are using regmap and not justaccessing the hardware directly? regmap imposes a number of pointerlookups and tests each time you do a read or write.Again, a memory mapped read won't fail. How about we check that theregmap is working once in your _probe() function, and assume it willcontinue working from there (or remove the regmap abstraction alltogether).All of this code is for debugging only. Do you want to put it behindsome kind of conditional?We have a framework for doing clocks in the kernel. Would it makesense to write a driver for this clock and add it todrivers/clk/clk-aspeed.c?The property is optional so I suggest we don't print a message if it'snot present. We certainly don't want to print a message saying""invalid"".The same comment applies to the other optional properties below.Can we probe in parallel? If not, putting a sleep in the _probe willhold up the rest of drivers from being able to do anything, and holdup boot.If you decide that you do need to probe here, please add a comment.(This is the wait for the clock to be stable?)This interrupt is only for the peci device. Why is it marked as shared?",Non-technical
,
"According to my comment on the other thread, this stands true in casethe child is managed by runtime PM as well.Otherwise this looks good to me.How about adding an additional patch on top taking into account theignore_children flag and folding that into the series, kind of as youalso suggested?My point is, we might as well take the opportunity to fix this rightaway, don't you think?[...]Kind regardsUffe",Non-technical
,
"I'm really sorry for this.could you please illustrate me what the kconfig & warning is?I didn'tget such warnings from 0-day.thanks,rui",Non-technical
,
"I'm not the one that added this switch statement (it has been there since2011) and I would be happy to remove it.  However could we please deferthis to v4.17 and merge the current set of Exynos thermal fixes/cleanups(they simplify the driver a lot and make ground for future changes)?Best regards,--Bartlomiej ZolnierkiewiczSamsung R&D Institute PolandSamsung Electronics",Non-technical
,
"Hello, Arvind.Thanks for your reply :)I admit I am not familiar with this driver.I did not know this driver is only loaded during system boot-up time,I thought this driver can be loaded as a kernel module (like manydrivers) after system booting.After knowing this, I admit my patch is not proper, sorry...Best wishes,Jia-Ju Bai",Non-technical
,
"Dear Takashi,Well, I am not sure. Could you please give me hints, how to debug thisfurther? Is there some debug flag?I am only aware of the Ftrace framework, but in my experience it alsoskews the timings quite a bit, so might not be the best choice.Kind regards,Paul",Non-technical
,
I see I've missed some obvious things that you've pointed out here. I'llmark these warnings as False Positives and take your points into accountfor the analysis of the rest of the Spectre issues reported by Smatch.Sorry for the noise and thanks for the feedback.Thanks--Gustavo,Non-technical
,
"Hi,Please, drop this series. Further analysis is required as it seems allthese are False Positives.Sorry for the noise.Thanks--Gustavo",Non-technical
,
"Em Tue, 24 Apr 2018 12:36:09 +0200Peter Zijlstra <peterz@infradead.org> escreveu:Peter,Thanks for a comprehensive explanation about that. It now makes moresense to me.Yeah, better to apply a fix to avoid the issue with VIDIOC_ENUM_FMT.Btw, on almost all media drivers, the implementation for enumeratingthe supported formats are the same (and we have a few other VIDOC_ENUM_fooioctls that usually do similar stuff): the V4L2 core calls a driver,with looks into an array, returning the results to the core.So, a fix like that should likely go to almost all media drivers(there are a lot of them!), and, for every new one, to take careto avoid introducing it again during patch review process.So, I'm wondering if are there any way to mitigate it inside thecore itself, instead of doing it on every driver, e. g. changingv4l_enum_fmt() implementation at v4l2-ioctl.Ok, a ""poor man"" approach would be to pass the array directly tothe core and let the implementation there to implement the arrayfetch logic, calling array_index_nospec() there, but I wonder ifare there any other way that won't require too much code churn.Thanks,Mauro",Non-technical
,
"Luc please don't submit such a huge number of patches all at one time.Also, please fix the indentation of the functions whose argumentsspan multiple lines as has been pointed out to you in patch feedback.Finally, make this a true patch series.  It is so much easier formaintainers to work with a set of changes all doing the same thing ifyou make them a proper patch series with an appropriate ""[PATCH 0/N] ...""header posting.Thank you.",Non-technical
,
"One of the basic questions/concerns I have is accounting for surplus hugepages in the default memory resource controller.  The existing huegtlbresource controller already takes hugetlbfs huge pages into account,including surplus pages.  This series would allow surplus pages to beaccounted for in the default  memory controller, or the hugetlb controlleror both.I understand that current mechanisms do not meet the needs of the aboveuse case.  The question is whether this is an appropriate way to approachthe issue.  My cgroup experience and knowledge is extremely limited, butit does not appear that any other resource can be controlled by multiplecontrollers.  Therefore, I am concerned that this may be going againstbasic cgroup design philosophy.It would be good to get comments from people more cgroup knowledgeable,and especially from those involved in the decision to do separate hugetlbcontrol.--Mike Kravetz",Non-technical
,
"I am sorry that I didn't join the discussion for the previous versionbut time just didn't allow that. So sorry if I am repeating somethingalready sorted out.There was a deliberate decision to keep hugetlb and ""normal"" memorycgroup controllers separate. Mostly because hugetlb memory is anartificial memory subsystem on its own and it doesn't fit into the restof memcg accounted memory very well. I believe we want to keep thatstatus quo.Well such a usecase requires an explicit configuration already. Eitherby using special wrappers or modifying the code. So I would argue thatyou have quite a good knowlege of the setup. If you need a greaterflexibility then just do not use hugetlb at all and rely on THP.[...]I do not really think this is a good idea. We really do not want to makethe current hugetlb code more complex than it is already. The currenthugetlb cgroup controller is simple and works at least somehow. I wouldnot add more on top unless there is a _really_ strong usecase behind.Please make sure to describe such a usecase in details before we evenstart considering the code.Well, then I would argue that you shouldn't use 64kB pages for yoursetup or allow THP for smaller sizes. Really hugetlb pages are by nomeans a substitute here.--Michal HockoSUSE Labs",Non-technical
,
"No problem, at the beginning, I only wanted to enable the strict. Doingthis involves that I have to remove pinctrl nodes for the pins which aregoing to be request through the gpiolib to avoid conflicts. These pinswere configured with bias-pull-up. That's why I try to add the biassupport.Thanks for the detailed answer about what you have in mind.Well, yes and not! As a consequence of enabling strict mode, I have tofind another way to configure the pins.Yes, I have noticed this issue.Right, I have spotted some drivers to fix.I will try to handle the ones related to the platforms I am using.RegardsLudovic",Non-technical
,
"I apologize for having confused.The hugetlb pages obtained from the pool do not waste the buddy pool. Onthe other hand, surplus hugetlb pages waste the buddy pool. Due to thisdifference in property, I thought it could be distinguished.Although my memcg knowledge is extremely limited, memcg is accounting forvarious kinds of pages obtained from the buddy pool by the task belongingto it. I would like to argue that surplus hugepage has specificity interms of obtaining from the buddy pool, and that it is specially permittedcharge requirements for memcg.It seems very strange that charge hugetlb page to memcg, but essentiallyit only charges the usage of the compound page obtained from the buddy pool,and even if that page is used as hugetlb page after that, memcg is notinterested in that.I will completely apologize if my way of thinking is wrong. It would begreatly appreciated if you could mention why we can not charge surplushugepages to memcg.I could not understand the intention of this question, sorry. When resizethe pool, I think that the number of surplus hugepages in use does notchange. Could you explain what you were concerned about?--Thanks,Tsukada",Non-technical
,
"On 2018/05/24 22:24, Michal Hocko wrote[...]> I do not see anything like that. adjust_pool_surplus is simply andAs you said, my patch did not consider handling when manipulating thepool. And even if that handling is done well, it will not be a validreason to charge surplus hugepage to memcg.[...]I understood the concept of memcg.[...]As you said, it must be an alien. Thanks to the interaction up to here,I understood that my solution is inappropriate. I will look for anotherway.Thank you for your kind explanation.--Thanks,Tsukada",Non-technical
,
"I'm not sure I understand what you intend here. If __sync_blockdevfails, then the error should have already been marked in sb->s_wb_err(via patch #6). We wouldn't want to record that again at syncfs time.Note that __sync_blockdev will return errors based on the legacyAS_EIO/AS_ENOSPC flags.We really do need to record it in the superblock as soon as possibleafter an error occurs. If we want to allow userland to eventually beable to scrape this value out of the kernel (as we discussed at LSF/MM)then we can't assume that it'll be doing any sort of syncfs callbeforehand.The main reason to push this down into the filesystems is to allow themcontrol over whether to report errors at syncfs time via the superblockerrseq_t or not. If we don't really care about allowing this to be anopt-in thing, then we could just take the patch that I sent on April17th:    [PATCH] fs: track per-sb writeback errors and report them to syncfsWe'd also want patch #6 from this series, I think, but that's more orless enough to implement this over all filesystems, assuming they usemapping_set_error to record writeback errors. I'm fine with eitherapproach.",Non-technical
,
"Hi AlexanderPlease don't top post. And wrap your lines at around 75 charactersLook closely at the two implementations. Look at whatmmd_phy_indirect() does. I _think_ these are identical. So don't addyour own helper, please use the core code.     Andrew",Non-technical
,
"Oops, sorry, I double posted patch 5. Please disregard the second one.Logan",Non-technical
,
"Well, clients not checking the error code made this harder to debug forsure, but removing the error code is a side effect and not what ishappening here (in fact someone should probably still go back and adderror checking because these functions can still return errors butthat's not really something I have time to do). After the next couplepatches, the clients will use this change to detect that there are noport numbers and handle things similarly to the way they did before theywere broken by the multiport changes.This is the opposite of what I've ever heard before. Having a commitmessage that explains what led up to this commit is a good thing andallows people debugging in the future to better understand the decisionsmade. People debugging commits will never find the 0/X cover letterwhich is just intended to introduce the series to reviewers and describechanges if the series is posted multiple times.No this is not a feature request. This is fixing a regression that brokepreviously working code in the only sensible way I can come up with. Ifyou have a better way to fix this, I'd be glad to hear it. But thisshould *not* be treated as a feature request.Logan",Non-technical
,
"The commit description is not quite correct.  What the NO_HIDE_STALEflag does is allow a discard request for those block devices which donot have the DISCARD_ZEROES_DATA flag.I will note that the FALLOC_FL_NO_HIDE_STALE flag is a bitcontroversial in linux-fsdevel.  I have a similar patch in the VFS inGoogle's internal data center kernel, as well as an internal patchwhich implements support for this flag in ext4.  However, the patchesare out of tree, because pretty much all of the file system developerswho work for enterpise distributions were against this functionality.I know of one other major cloud provider (in China) using thefunctionality as an out-of-tree patch, but with no one else speakingin favor of it, and everyone else NAK'ing the patch and enterprisedistro's saying they would revert the patch in their distro kernels,the compromise we came to was that the code point for NO_HIDE_STALE_FLwould be reserved so that users of the out-of-tree patches wouldn'tcollide with future fallocate flags; and I would stop trying to pushthe patches upstream.I have no idea how Darrick was able to get commit 25f4c41415e5upstream, but I guess it was less controversial for block devices thanfor file systems.So I'm certainly in favor of this patch landing in mainline, but youshould be aware that there may be some opposition to it.Cheers,					- Ted",Non-technical
,
I can't take patches without any changelog text at all :(,Non-technical
,
"As far as I can tell, the above is the whole reason for the patchset,yes?  To avoid confusing users.Is that sufficient?  Can we instead simplify their lives by providingbetter documentation or informative printks or better Kconfig text,etc?And who *are* the people who are performing this configuration?  Randomsystem administrators?  Linux distro engineers?  If the latter thenthey presumably aren't easily confused!In other words, I'm trying to understand how much benefit this patchsetwill provide to our users as a whole.",Non-technical
,
"Hopefully I'm not missing anything here, but this doesn't really make anysense. I'm not sure I explained myself as well as I thought I did. To behonest, I had to double check this about literally 20 times to make sure I wasactually understanding this issue correctly. Turns out I was missing a coupleof parts, so I'm going to try again at explaining this using a diagram thatshows the various threads running concurrentlySTART: Driver load       |       |       |           Thread 1        ----- output_poll_execute()                       |           drm_helper_hpd_irq_event()                       |                       |  Schedules â†’            Thread 2                       ----------------- nouveau_display_hpd_work()                    Finish                          |                                           pm_runtime_get_sync() <--- keeps GPU alive                                                    |                                                   ...                                                    |                       ------------------------------                <still Thread 2>             drm_helper_hpd_irq_event()                       |                       |         Schedules â†’                       ------------------------------                       |                         Thread 3Drop last RPM ref -v   |                   output_poll_execute()             pm_runtime_put_sync()                  |                       |             drm_dp_mst_topology_mgr_set_mst()                    Finish                          |                                                    |                               â† Schedules          |                       -----------------------------|                       |                            |                    Thread 4                        |                       |                            |          drm_dp_mst_link_probe_work()  drm_dp_mst_wait_tx_reply() <-- these wait on eachother                       |                            |                     this is normal                       |    Sideband transactions   |                       |    happen here, this is    |                       |    where timeouts happen   |                       |                            |                       |      5 seconds later...    | autosuspend delay kicks in                       |            ...             |                        |                       |                            |                     Thread 5                       |  Communication + timeouts  |                 pm_runtime_work                       |  are still happening here  |                        |                       |                            |           nouveau_pmops_runtime_suspend()                       |                            |                        |                       |  Success! We can enable    |                        |                       |        displays now!       |            drm_kms_helper_poll_disable()                       |                            |                        |                       |                 *Atomic commit begins*              |                       |                            |     <-------------     |                       | More sideband transactions |       Waiting on       |                       |          ......            |  output_poll_execute() |                       |                            |     <-------------     |                       |                  pm_runtime_get_sync()              |                       |                            |                        |                       |   -------------------->    |     ------------->     |                       |        Waiting on          |       Waiting on       |                       |     output_poll_exec()     |    suspend requests    |                       |   -------------------->    |     ------------->     |                       |                            |                        |                       ----------------------------------------------------->|                                                                         DEADLOCKphew. that took a LONG time to come up with.Anyway-that's why your explanation doesn't make sense: the deadlock ishappening because we're calling pm_runtime_get_sync(). If we were to make thatcall conditional (e.g. drm_kms_helper_is_poll_worker()), all that would meanis that we wouldn't grab any runtime power reference and the GPU wouldimmediately suspend once the atomic commit finished, as the suspend request inThread 5 would finally get unblocked and thus----suspend.Hopefully I explained that better this time, I'll definitely make sure toactually include that diagram in the patch. As for whether or not this patchis even the right solution, I will need to confirm that tommorrow (if youdon't think it is still, please feel free to say so!) because it's gettinglate here.Cheers!	Lyude--Cheers,	Lyude Paul",Non-technical
,
"Thanks a lot for all this work! It was long overdue and it is nice tosee the project finally getting to an end, after passing into so many hands!I am not sure I understand the purpose of this level here. As far as Iunderstand, you only have per-engine control whether you want to enableCG or not. What you call BLCG and SLCG levels just mean ""don't use theboot values, but rather use our values (taken from nvidia)"".Now, here comes the nasty part: NVIDIA only ever validated the bootvalues (I guess they are extremely safe ones), and the optimised values(the ones coming from your patch 2, 3, and 4 along with the level 3.I think introducing a single parameter that controls both CG, PG, andautomatic reclocking would be safer. For CG and PG, it would be aall-or-nothing (either boot values, or everything like nvidia).This message is a bit odd, whether we keep the notion of levels or not.Can you get rid of the mention of powergating given that this is notpart of this patchset?If you agree with having a single enable bit for CG, then a simple:""Clockgating status: (boot|optimized)"" would work perfectly.All this time, I thought these parameters were for power gating... Ialso did not expect that clock gating had to be disabled before we couldprogram them.Great find!Why introduce gk104_therm_new_? I can't find references to it in thispatch (outside of the function below) or in the following patches.As you even export this function, it looks like you used to use thisfunction in an earlier revision of this series.Aside from all these nitpicks, the approach is quite self contained andI like the following patches. Well done!Once we settle on the configuration parameter, I can give you my R-b :)Martin",Non-technical
,
"First of all, I was mistaken when I wrote above that a check for!drm_kms_helper_is_poll_worker() would solve the problem.  Sorry!It doesn't because the call to pm_runtime_get_sync() is not happeningin output_poll_execute() but in drm_dp_mst_link_probe_work().Looking once more at the three stack traces you've provided, we've got:- output_poll_execute() stuck waiting for fb_helper->lock  which is held by drm_dp_mst_link_probe_work()- rpm_suspend() stuck waiting for output_poll_execute() to finish- drm_dp_mst_link_probe_work() stuck waiting in rpm_resume()For the moment we can ignore the first task, i.e. output_poll_execute(),and focus on the latter two.As said I'm unfamiliar with MST but browsing through drm_dp_mst_topology.cI notice that drm_dp_mst_link_probe_work() is the ->work element indrm_dp_mst_topology_mgr() and is queued on HPD.  I further notice thatthe work item is flushed on ->runtime_suspend:nouveau_pmops_runtime_suspend()  nouveau_do_suspend()    nouveau_display_suspend()      nouveau_display_fini()        disp->fini() == nv50_display_fini()	  nv50_mstm_fini()	    drm_dp_mst_topology_mgr_suspend()	      flush_work(&mgr->work);And before the work item is flushed, the HPD source is quiesced.So it looks like drm_dp_mst_link_probe_work() can only ever runwhile the GPU is runtime resumed, it never runs while the GPU isruntime suspended.  This means that you don't have to acquire anyruntime PM references in or below drm_dp_mst_link_probe_work().Au contraire, you must not acquire any because it will deadlock whilethe GPU is runtime suspending.  If there are functions which arecalled from drm_dp_mst_link_probe_work() as well as from other contexts,and those other contexts need a runtime PM ref to be acquired,you need to acquire the runtime PM ref conditionally on not beingdrm_dp_mst_link_probe_work() (using the current_work() technique).Alternatively, move acquisition of the runtime PM ref further up inthe call chain to those other contexts.Right, that seems to be a bug nouveau_pmops_runtime_suspend():If a display is plugged in while the GPU is about to runtime suspend,the display may be lit up by output_poll_execute() but the GPU willthen nevertheless be powered off.I guess after calling drm_kms_helper_poll_disable() we should re-checkif a crtc has been activated.  This should have bumped the runtime PMrefcount and have_disp_power_ref should be true.  In that case, thenouveau_pmops_runtime_suspend() should return -EBUSY to abort theruntime_suspend.The same check seems necessary after flushing drm_dp_mst_link_probe_work():If the work item lit up a new display, all previous suspend steps needto be unwound and -EBUSY needs to be returned to the PM core.Communication with an MST hub exceeding the autosuspend timeout isjust one scenario where this bug manifests itself.BTW, drm_kms_helper_poll_disable() seems to be called twice in theruntime_suspend code path, once in nouveau_pmops_runtime_suspend()and a second time in nouveau_display_fini().A stupid question, I notice that nv50_display_fini() calls nv50_mstm_fini()only if encoder_type != DRM_MODE_ENCODER_DPMST.  Why isn't that == ?Thanks,Lukas",Non-technical
,
"Hi Dan,Just a blind shot, without going into details - could you please checkif led-sources property documented in the common LED bindings couldn'thelp here?--Best regards,Jacek Anaszewski",Non-technical
,
"Hi!This is better than my proposal. Thanks!								Pavel--(english) http://www.livejournal.com/~pavelmachek(cesky, pictures) http://atrey.karlin.mff.cuni.cz/~pavel/picture/horses/blog.html",Non-technical
,
"I welcome this feature, been wanting it for some time now. There issimply not enough support in /proc/PID/maps or smaps to get thisinformation. This is important to improve code and data layouts.I would like to see the following changes to your proposal:   - call it PERF_SAMPLE_DATA_PAGE_SIZEThat would allow two things:   1 - not tied to PERF_SAMPLE_ADDR   2 - Allow PERF_SAMPLE_CODE_PAGE_SIZE to be addedIn some measurements, you may just care about the distribution of accessesacross page sizes. No need to use double the buffer space to save the addressyou will not use.Layout is important for code as well, in fact, that's what most peoplewant first.Having a CODE_PAGE_SIZE is therefore useful. I am happy adding it on top on yourproposal. Note that PERF_SAMPLE_CODE_PAGE_SIZE would not have to be tiedto PEBS unlike DATA_PAGE_SIZE.Thanks.",Non-technical
,
"Lui Song,Am Montag, 20. August 2018, 08:09:05 CEST schrieb Liu Song:Please use your real name. 1st Signed-off-by and patch author should match.Good find! I'll queue this for the next fixes-pull-request.Thanks,//richard",Non-technical
,
"Interesting - I don't see the grant head reservation code in any ofmy performance benchmark profiling, even when running at over amillion transactions/s on a 2-socket 32-core 64-thread skylakesystem. I see other places in the transaction subsystem that arehot (e.g the CIL context lock), but not the space reservations.My initial suspect is that you have a tiny log on your testfilesystem, so it's permanently out of space and so always hittingthe slow path. Can you tell us what the storage is and it'sconfiguration? At minimum, I need to see the output of the xfs_infocommand on your test filesystem. Fixing this may simply be using alarger log on your benchmark systems.FWIW, can you post the actual profile you are seeing in the commitmessage? That helps us identify similar problems in the future, andit lets us know what paths are leading to the transactionreservation contention. i.e. this may not even be a problem with thetransaction reservation code itself.How does this impact on the strict FIFO queue behaviour the grantqueues currently have? The current code only wakes up enough waitersto consume the newly available space and it queues new waiters tothe tail of the queue. If there ever is a spurious wakeup then thewaiter that was woken from the head remains there until the nextwakeup comes in. This is intentional - spurious wakeups are rareenough we can ignore them because a) this is the slow path, and b)correctness is far more important that performance in this path.The fast path is already lockless, and we've already given uppeformance if we reach this slow path. hence we only care aboutcorrectness in this path, not performance optimisation.AFAICT the patch changes the spurious wakeup behaviour - it requeuestasks to the tail of the queue if there wasn't space available whenthey are woken, rather than leaving them as them at the head.  Theynow have to wait for all the other reservations to make progress.This breaks the guarantees of ordered forward progress the grantqueue provides permanent transaction reservations and hence opens usup to log space deadlocks because those transactions can't movetheir objects forward in the log to free up space in the log...Also, I note that wake_q_add() assumes that the wake queue is alocal stack object and so not subject to concurrency - it explicitlystates this in the code. That's not the case here - the wake queueis part of the grant head, and so is subject to extreme concurrencythat is tempered by a spin lock.  Does the wake_q code workcorrectly (e.g. have all the necessary memory barriers, etc) whenit's not a local stack object and instead protected from concurrencyby a spin lock? At minimum, the wake_q infrastructure comments anddocumentation need updating to accommodate this new use case thatwake queues are being used for.This doesn't generally doesn't happen because the space accountingtends to prevent multiple wakeups. i.e. we only wake the tasks wehave reservation space for, and log space being made available tendsto arrive in discrete chunks (because IO is slow!) such that thatpending wakeups have already been processed before the next chunk ofavailable space comes in....Yes, but they are very rare and we don't really care about this inthe slow path. If you see lots of them, it's typically a sign of aninappropriately configured filesystem for the workload being run. Ona correctly configured system, we should almost never use this slowpath....I'm betting that you'll get that and a whole lot more simply byincreasing the log size and not running the slow path at all.Where's the hunk context in your headers? You must be using anon-standard git option here.Linux kernel specific includes go in fs/xfs/xfs_linux.h, notindividual files.Why do you need to delete the ticket from the queue here? This leadsto landmines and incorrect non-FIFO behaviour....... here. This is a potential list corruption landmine because thisfunction now has unbalanced list add and removal contexts. IOWs, wecan't restart this loop without first having guaranteed the ticketis not already on the ticket queue. You need to document constraintslike this in comments and explain what code needs to guarantee thoseconstraints are met. [Because, as I noted at the end, you got thiswrong for xlog_grant_head_wake_all()]To maintian FIFO behaviour, the ticket needs to be left at the headof the grant head wait queue until it has space available to makeprogress, not get removed and requeued to the tail. Spurious wakeups are irrelevant here - forwards progress (i.e. correctness)requires FIFO ticket ordering behaviour be maintained.This push is needed to make the necessary space we are waiting onavailable in the log. Hence leaving it out of the loop you putbelow will cause the journal to get stuck in the spurious wakeuploop below and be unable to make progress. This will lead tofilesystem hangs.That's a new nested loop. Please implement it as a loop.This is buggy  - i will lead to hangs if the filesystem is shutdown and there is a spurious wakeup that triggers this to go back tosleep.The shutdown check needs to break the sleep loop.That's racy. You can't drop the spin lock betweenxlog_grant_head_wake() and xlog_grant_head_wait(), becausefree_bytes is only valid while while the spinlock is held.  Same forthe ""wake_all"" variable you added. i..e. while waking up thewaiters, we could have run out of space again and had more tasksqueued, or had the AIL tail move and now have space available.Either way, we can do the wrong thing because we dropped the lockand free_bytes and wake_all are now stale and potentially incorrect.That's another landmine. Just define the wakeq in the context whereit is used rather than use a function wide variable that requiresreinitialisation.Ok, what about xlog_grant_head_wake_all()? You didn't convert thatto use wake queues, and so that won't remove tickets for the granthead waiter list, and so those tasks will never get out of the newinner loop you added to xlog_grant_head_wait(). That meansfilesystem shutdowns will just hang the filesystem and leave itunmountable. Did you run this through fstests?Cheers,Dave--Dave Chinnerdavid@fromorbit.com",Non-technical
,
"Denis Du <dudenis2000@yahoo.ca> writes:Sorry about being late, just returned home and am trying to get all thebacklogs under control.I remember the PPP standard is a bit cloudy about the possible issue,but the latter indeed exists (the PPP state machine was written directlyto STD-51). There is related (more visible in practice, though we aren'taffected) issue of ""active"" vs ""passive"" mode (hdlc_ppp.c is ""active"",and two ""passives"" wouldn't negotiate at all).Anyway the problem is real (though not very visible in practice,especially on relatively modern links rather than 300 or 1200 bps dialupconnections) and should be fixed. Looking at the patch, my firstimpression is it makes the code differ from STD-51 a little bit.On the other hand, perhaps applying it as is and forgetting about theissue is the way to go.Ideally, I think the negotiation failure should end up (optionally, inaddition to the current behavior) in some configurable sleep, thenthe negotiation should restart. If it's worth the effort at this point,I don't know.Perhaps I could look at this later, but no promises (this requirespulling on and setting up some legacy hardware).Anyway, since the patch is safe and can solve an existing problem:Acked-by: Krzysztof Halasa <khc@pm.waw.pl>--Krzysztof Halasa",Non-technical
,
"I mean the level of a resource in IOMEM tree (the one that's printedfrom /proc/iomem). 1-st level means its parent is root and so on.If it's not a problem anymore IIUC, can we revert the change as it stillbreaks ""hotplug_unpopulated=1"" for the reasons I described above?Nothing prevents - true, but that's plainly wrong from OS point of viewto grab physical ranges for something without knowing what's actuallybehind on that platform. I think we shouldn't consider this as a validthing to do and don't try to workaround initially incorrect code.",Non-technical
,
"How do you plan to handle the external references? For example, thefollowing LWN articles has a link this file:	https://lwn.net/Articles/718628/And changing the name and/or location will break that link, AFAIK.Regards,Boqun[...]",Non-technical
,
"IMO symlinks are mostly ending in a mess, URLs are never stable.There is a https://www.kernel.org/doc/html/latest/objects.invto handle such requirements. Take a look at *intersphinx* : http://www.sphinx-doc.org/en/stable/ext/intersphinx.htmlto see how it works:  Each Sphinx HTML build creates a file named objects.inv thatcontains a mapping from object names to URIs relative to the HTML setâ€™s root.This means articles from external (like lwn articles) has to be recompiled.Not perfect, but a first solution.I really like them, factually valuable comments .. pleaseexpress your concern so that we have a chance to move on.I think that's a pity.-- Markus --",Non-technical
,
"So I hate this rst crap with a passion, so NAK from me.",Non-technical
,
"Hi, David:HowÂ  do you think my patch?As you see, KrzysztofÂ  think my patch is ok to be accepted.But if you have a better idea to fix it,I am glad to see it. Anyway, this issue have to be fixed.Denis DUDenis Du <dudenis2000@yahoo.ca> writes:Sorry about being late, just returned home and am trying to get all thebacklogs under control.I remember the PPP standard is a bit cloudy about the possible issue,but the latter indeed exists (the PPP state machine was written directlyto STD-51). There is related (more visible in practice, though we aren'taffected) issue of ""active"" vs ""passive"" mode (hdlc_ppp.c is ""active"",and two ""passives"" wouldn't negotiate at all).Anyway the problem is real (though not very visible in practice,especially on relatively modern links rather than 300 or 1200 bps dialupconnections) and should be fixed. Looking at the patch, my firstimpression is it makes the code differ from STD-51 a little bit.On the other hand, perhaps applying it as is and forgetting about theissue is the way to go.Ideally, I think the negotiation failure should end up (optionally, inaddition to the current behavior) in some configurable sleep, thenthe negotiation should restart. If it's worth the effort at this point,I don't know.Perhaps I could look at this later, but no promises (this requirespulling on and setting up some legacy hardware).Anyway, since the patch is safe and can solve an existing problem:Acked-by: Krzysztof Halasa <khc@pm.waw.pl>--Krzysztof Halasa",Non-technical
,
"Hi Dongjiu Geng,A version of this patch has been queued by Catalin.Now that the cpufeature bits are queued, I think this can be split up into twoseparate series for v4.16-rc1, one to tackle NOTIFY_SEI and the associatedplumbing. The second for the KVM 'make SError pending' API.I didn't sign-off this patch. If you pick some bits from another version andwant to credit someone else you can 'CC:' them or just mention it in thecommit-message.Irrelevant-Nit: sys-regs usually have a 'SYS_' prefix, and are in instructionencoding order lower down the file.(These PSTATE PAN things are a bit odd as they were used to generate andinstruction before the fancy {read,write}_sysreg() helpers were added).Bits of this are spread between patches 5 and 6. If you put them in the otherorder this wouldn't happen.(but after a rebase most of this patch should disappear)So this writes an impdef ESR, because its the existing code-path in KVM.And then you overwrite it. Which is a bit odd as there is a helper to do both inone go:How come you don't use this in kvm_arm_set_sei_esr()?Thanks,James",Non-technical
,
"For 2500Base-X, do you report a speed of 2500Mbps through ethtool, orare you reporting 1000Mbps?  I don't see any code in this patch thatdeals with that.--RMK's Patch system: http://www.armlinux.org.uk/developer/patches/FTTC broadband for 0.8mile line in suburbia: sync at 8.8Mbps down 630kbps upAccording to speedtest.net: 8.21Mbps down 510kbps up",Non-technical
,
"Can you please use a consistent name space? retpoline_ ... or such?I really don't like fiddling with that variable. That's just hackery. Thevariable reflects the actual enabled mitigation state of the kernel proper.That'll break once we get other mitigation variants.These newlines are there to separate stuff for readability sake.This really can be done in a cleaner way.in linux/module.h#ifdef RETPOLINEextern bool retpoline_module_ok(bool has_retpoline);#elsestatic inline bool retpoline_module_ok(bool has_retpoline){	return true;}#endifstatic void check_modinfo_retpoline(mod, info){	if (retpoline_module_ok(get_modinfo(info, ""retpoline"")))		return;	pr_warn(""%s: loading module not compiled with retpoline compiler.\n"",		mod->name);}That only needs one function and that one can take care of setting avariable in the spectre code which then influences the sysfs output.And that output should not be ""Vulnerable"" like you force with the hackabove. It actually should tell WHY it is vulnerable despite having hadprotection in place before the module was loaded.Thanks,	tglx",Non-technical
,
I didn't get any response to a comment I've written about the pointabove during the previous patch iteration:> The old code set this bit in any mode other than AC'97 (where theMaciej,Non-technical
,
"This does not make sense vs. the documentation:This should say:And I really have to ask whether this should be named _GLOBAL_ instead of_SHARED_.Hmm?Thanks,	tglx",Non-technical
,
"Again, 'boutside' protection ...Other than that:Reviewed-by: Hannes Reinecke <hare@suse.com>Cheers,Hannes--Dr. Hannes Reinecke		   Teamlead Storage & Networkinghare@suse.de			               +49 911 74053 688SUSE LINUX GmbH, Maxfeldstr. 5, 90409 NÃ¼rnbergGF: F. ImendÃ¶rffer, J. Smithard, J. Guild, D. Upmanyu, G. NortonHRB 21284 (AG NÃ¼rnberg)",Non-technical
,
"From: Denis Du <dudenis2000@yahoo.ca>Date: Tue, 16 Jan 2018 16:58:25 +0000 (UTC)The timer is supposed to restart the protocol again, that's how thiswhole thing is designed to work.I think you are making changes to the symptom rather than the truecause of the problems you are seeing.Sorry, I will not apply this until the exact issue is betterunderstood.Thank you.",Non-technical
,
"From: Denis Du <dudenis2000@yahoo.ca>Date: Wed, 21 Feb 2018 03:35:31 +0000 (UTC)I cannot apply a patch which has been corrupted by your email client likethis.Please send it properly again, plain ASCII text, and no trasnformationsby your email client.You should send the patch to yourself and try to apply the patch youreceive, do not send to the list until you can pass the test properly.Do not use attachments to fix this problem, the patch must be inlineafter your commit message and signoffs.Please read Documentation/process/submitting-patches.rst andDocumentation/process/email-clients.rsDt for more information.Thank you.",Non-technical
,
"Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented.In drivers/net/wan/hdlc.c#L108Â Â Â Â Â Â Â Â if (hdlc->carrier == on)Â Â Â Â Â Â Â Â goto carrier_exit; /* no change in DCD line level */Â Â Â Â hdlc->carrier = on;Â Â Â Â if (!hdlc->open)Â Â Â Â Â Â Â Â goto carrier_exit;Â Â Â Â if (hdlc->carrier) {Â Â Â Â Â Â Â Â netdev_info(dev, ""Carrier detected\n"");Â Â Â Â Â Â Â Â hdlc_proto_start(dev);Â Â Â Â } else {Â Â Â Â Â Â Â Â netdev_info(dev, ""Carrier lost\n"");Â Â Â Â Â Â Â Â hdlc_proto_stop(dev);Â Â Â Â }carrier_exit:Â Â Â Â spin_unlock_irqrestore(&hdlc->state_lock, flags);Â Â Â Â return NOTIFY_DONE;If carrier keep no change by if (hdlc->carrier == on)Â Â Â Â Â Â Â Â goto carrier_exit; /* no change in DCD line level */It will do nothing, not start any new protocol and thus the timer.My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem.From: Denis Du <dudenis2000@yahoo.ca>Date: Tue, 16 Jan 2018 16:58:25 +0000 (UTC)The timer is supposed to restart the protocol again, that's how thiswhole thing is designed to work.I think you are making changes to the symptom rather than the truecause of the problems you are seeing.Sorry, I will not apply this until the exact issue is betterunderstood.Thank you.",Non-technical
,
"On Tue, 30 Jan 2018 17:14:45 +0200Igor Stoppa <igor.stoppa@huawei.com> wrote:Please don't put plain-text files into core-api - that's a directory fullof RST documents.  Your document is 99.9% RST already, better to justfinish the job and tie it into the rest of the kernel docs.We might as well put the SPDX tag here, it's a new file.This is all good information, but I'd suggest it belongs more in the 0/npatch posting than here.  The introduction of *this* document should saywhat it actually covers.This seems like a relevant and important aspect of the API that shouldn'tbe buried in the middle of a section talking about random things.So one gets this far, but has no actual idea of how to do these things.Which leads me to wonder: what is this document for?  Who are you expectingto read it?You could improve things a lot by (once again) going to RST and usingdirectives to bring in the kerneldoc comments from the source (which, Inote, do exist).  But I'd suggest rethinking this document and itsaudience.  Most of the people reading it are likely wanting to learn how to*use* this API; I think it would be best to not leave them frustrated.Thanks,jon",Non-technical
,
"Thanks for the review and apologies for the delay.Replies inlined below.[...]okok, this is all new stuff to me ... I suppose I should do it also forall the other new files I createBut what is the license for the documentation? It's not code, so GPLseems wrong. Creative commons?I just noticed a patch for checkpatch.pl about SPDX and asked the samequestion there.https://lkml.org/lkml/2018/2/2/365[...]ok[...]I'll move it to the Use section.[...]I will add a reference to the selftest file.In practice it can also work as example.ok, the example route should be more explicative.--thanks again for the review, igor",Non-technical
,
"Relatively significant?I do not object to your comment, but in practice i see that:- vmalloc is used relatively little- allocations do not seem to be huge- there seem to be way larger overheads in the handling of virtual pages  (see my proposal for the LFS/m summit, about collapsing struct   vm_struct and struct vmap_area)Can you please point me to this function/macro? I don't seem to be ableto find it, at least not in 4.15During hardened user copy permission check, I need to confirm if thememory range that would be exposed to userspace is a legitimatesub-range of a pmalloc allocation.So, I start with the pair (address, size) and I must end up to somethingI can compare it against.The idea here is to pass through struct_page and then the relatedvm_struct/vmap_area, which already has the information about thespecific chunk of virtual memory.I cannot comment on your proposal because I do not know where to findthe reference you made, or maybe I do not understand what you mean :-(--igor",Non-technical
,
"On Sat, 20 Jan 2018 21:14:48 +0530Shreeya Patel <shreeya.patel23498@gmail.com> wrote:You can't do it this simply as it will cause deadlock due to nestedlocking of the buf_lock.To share the lock you will need to provide unlocked versions ofthe read and write functions and use those if the lock has already beentaken.Jonathan_______________________________________________devel mailing listdevel@linuxdriverproject.orghttp://driverdev.linuxdriverproject.org/mailman/listinfo/driverdev-devel",Non-technical
,
Ok. I've looked at your patch for way too long now and still don't see howyou've shown it to be correct. Shouldn't there be a at least a commentto explain why zero is an appropriate initialization value in that case?      Arnd,Non-technical
,
"Are you moving checks from the core subsystem to drivers ? This looksreally nonsensical and the commit message doesn't explain the rationalefor that at all.--Best regards,Marek Vasut",Non-technical
,
"This makes no sense, cfr my comment on 5/5Seems like if the driver doesn't implement those, the core can easilydetect that and perform the necessary action. Moving the checks out ofcore seems like the wrong thing to do, rather you should enhance thechecks in core if they're insufficient in my opinion.--Best regards,Marek Vasut",Non-technical
,
"The core can very well check if these functions are not populated andreturn ENOSYSSo you remove all NULL pointer checks ? Esp. in security-sensitive code?What is the impact of this non-critical path code on performance?Come on ...You can very well impose that in the core, except you don't duplicatethe code.--Best regards,Marek Vasut",Non-technical
,
"Why you want checks for something that not exist ?Those without them will not work and will do Oops in crypto testmgr,so such drivers should not be used nor accepted in drivers/cryptoAsk yourself why crypto do not check for NULL in ahash digest or otherrequired ahash functions.Now size of crypto core is reduced.--Best regards,Kamil KoniecznySamsung R&D Institute Poland",Non-technical
,
"Are you suggesting that the kernel code should NOT perform NULL pointerchecks ?Are you suggesting each driver should implement every single callbackavailable and if it is not implemented, return -ENOSYS ? This looks likea MASSIVE code duplication.You implemented the same code thrice, it surely is not reduced.--Best regards,Marek Vasut",Non-technical
,
"You can compile kernel with generic config and at that point you haveall the duplicated code stored on your machine. But this discussion ismoving away from the point I was concerned about -- that this patchset_increases_ code duplication and I find this wrong.It does NOT reduce the binary size, just try compiling all the driversin and it will make the kernel bigger.--Best regards,Marek Vasut",Non-technical
,
"It is source code duplication. One do not load all crypto drivers at once,simple because one board has only one crypto HW (or few closely related),and if one even try, almost none of them will initialize on givenhardware. E.g. on Exynos board only exynos drivers will load, on board withomap crypto only omap crypto will load.As I said above, it reduces binary size at cost of more source code in few drivers.--Best regards,Kamil KoniecznySamsung R&D Institute Poland",Non-technical
,
"Michal Hocko wrote:Then, I am wondering why we are holding mmap_sem when callingmigrate_pages() in existing code.http://elixir.free-electrons.com/linux/latest/source/mm/migrate.c#L1576Sorry, I missed that. If mmap_sem is not needed for migrate_pages(),please ignore this patch.--Best Regards,Yan Zi",Non-technical
,
[][]Use normal patch styles.Fix your tools before you send any more patches.,Non-technical
,
"Hi Markus,While we do not mind cleanup patches, the way you post them (one fix per file) is reallyannoying and takes us too much time to review.I'll take the ""Fix a possible null pointer"" patch since it is an actual bug fix, butwill reject the others, not just this driver but all of them that are currently pendingin our patchwork (https://patchwork.linuxtv.org).Feel free to repost, but only if you organize the patch as either fixing the same type ofissue for a whole subdirectory (media/usb, media/pci, etc) or fixing all issues for asingle driver.Actual bug fixes (like the null pointer patch in this series) can still be posted asseparate patches, but cleanups shouldn't.So in this particular case I would expect two omap_vout patches: one for the bug fix,one for the cleanups.Just so you know, I'll reject any future patch series that do not follow these rules.Just use common sense when posting these things in the future.I would also suggest that your time might be spent more productively if you wouldwork on some more useful projects. There is more than enough to do. However, that'sup to you.Regards,	Hans",Non-technical
,
"Would you like to answer my still remaining questions in any moreconstructive ways?Regards,Markus",Non-technical
,
"??? I did that: either one patch per directory with the same type of change,or one patch per driver combining all the changes for that driver.Yes, and you were told not to do it like that again.Regards,	Hans",Non-technical
,
"Are you going to answer any of my remaining questions in a more constructive way?Regards,Markus",Non-technical
,
"Do any contributors get into the mood to take another look at software updatesfrom my selection of change possibilities in a more constructive way?Do you need any additional development resources?Regards,Markus",Non-technical
,
"One last time: either post per-driver patches with all the cleanups for a driverin a single patch, or a per-directory patch (drivers/media/pci, usb, etc) doingthe same cleanup for all drivers in that directory.I prefer the first approach, but it's up to you.We don't have the time to wade through dozens of one-liner cleanup patches.I don't understand what is so difficult about this.Regards,	Hans",Non-technical
,
"I preferred to offer source code adjustments according to specific transformationpatterns mostly for each software module separately (also in small patch series).I am curious if bigger patch packages would be easier to get accepted.Or would you get frightened still by any other change combination?We have got different preferences for a safe patch granularity.I imagine that there are more development factors involved.It is usual that integration of update suggestions will take some time.How would the situation change if I would dare to regroup possible update steps?There are communication difficulties to consider since your terse informationfrom your conference meeting.If you would insist on patch squashing, would you dare to use a development toollike â€œquilt foldâ€ also on your own once more?Regards,Markus",Non-technical
,
"I find such a change combination unsafe.Would you dare to apply any (of my) scripts for the semantic patch languagedirectly on the whole directory for multi-media software?Can you handle bigger patches really better than similar patch series?Are there any further possibilities to consider around consequencesfrom a general change resistance?Will any development (or management) tools like â€œquilt foldâ€ make the regroupingof possible update steps more convenient and safer?Regards,Markus",Non-technical
,
"Interesting â€¦Would you like to share any more information from this meeting?I would appreciate further indications for a corresponding change acceptance.I found a feedback by Mauro Carvalho Chehab more constructive.[GIT,PULL,FOR,v4.15] Cleanup fixeshttps://patchwork.linuxtv.org/patch/43957/â€œâ€¦This time, I was nice and I took some time doing:	$ quilt fold < `quilt next` && quilt delete `quilt next`â€¦â€Regards,Markus",Non-technical
,
Thanks for testing this and letting me know.greg k-h,Non-technical
,
"I find it very surprising that you rejected 146 useful update suggestionsso easily.What does this software area make it so special in comparison toother Linux subsystems?* Have you taken any other solution approaches into account than  a quick â€œrejectionâ€?* Could your reaction have been different if the remarkable number of  change possibilities were sent by different authors (and not only me)?* How should possibly remaining disagreements about affected implementation  details be resolved now?* Are you looking for further improvements around development tools  like â€œpatchworkâ€ and â€œquiltâ€?* Will you accept increasing risks because of bigger patch sizes?* Can such an information lead to differences in the preferred patch granularity?* How do you think about this detail?How would you ever like to clean up stuff in affected source fileswhich was accumulated (or preserved somehow) over years?I guess that this handling will trigger more communication challenges.Our â€œcommon senseâ€ seems to be occasionally different in significant ways.I distribute my software development capacity over several areas.Does your wording indicate a questionable signal for further contributions?Regards,Markus",Non-technical
,
"Wait, what?  Why would it do that, because it thinks dereferencing NULLis undefined behaviour and it can just do whatever it wants to?That feels crazy, as for these calls we ""know"" it will never be NULLbecause the previous call to debugfs_file_get() will always ensure itwill be correct.So this is a case of the compiler trying to be smarter than it reallyis, and getting things totally wrong :(Has anyone reported this to the clang developers?Papering over compiler foolishness is not something I like to do inkernel code if at all possible...thanks,greg k-h",Non-technical
,
"A: Because it messes up the order in which people normally read text.Q: Why is top-posting such a bad thing?A: Top-posting.Q: What is the most annoying thing in e-mail?A: No.Q: Should I include quotations after my reply?http://daringfireball.net/2007/07/on_topThen fix the tool, the C code is correct :)Then tell clang not to do that, like we tell gcc not to do that as thatis a foolish thing for a compiler to do when building the kernel.thanks,greg k-h",Non-technical
,
"Wait, clang does not have that?  That's crazy, how has this not been hityet when building the kernel?confused,greg k-h",Non-technical
,
"On Thu, Mar 1, 2018 at 1:02 PM, Bartlomiej Zolnierkiewicz<b.zolnierkie@samsung.com> wrote:Choose one of those two.Better to keep in order.Ditto.return !!(ch & GAYLE_IRQ_IDE);?What's wrong with dev_info() ?Hmm... Can't you use devm_ioremap_resources() to get the virtualaddress for I/O ?When you use explicit casting in printf() you are doing in 99.9% casessomething wrong.Noise.--With Best Regards,Andy Shevchenko",Non-technical
,
"How many times are we going to allow copy-and-pasting the same driver?Last time we wanted to modify the Rockchip driver, we were told""consolidate"", because ST had already forked our driver. This nearlyhalted all progress. I'm going to be real disappointed if we see anotherfork get merged.(IOW, I would say ""over my dead body,"" but I have no power here.)And why can't you use DRM?Brian",Non-technical
,
"...wait a second...this looks like it's a u-boot driver. There's asurprising amount of similarity between U-boot and Linux drivers (nocoincidence I'm sure), including <linux/...> headers.Since when do U-Boot patches go to LKML and dri-devel?Anyway, I'll try my best to ignore this series.Brian",Non-technical
,
"meta comment (i.e., not about the merits of the patch itself):You'll need to send the patch to someone if you want it to be merged.Maintainers don't mine mailing lists for patches to apply.--~Randy",Non-technical
,
"On Tue, Mar 27 2018 at  4:55am -0400,yael.chemla@foss.arm.com <yael.chemla@foss.arm.com> wrote:They've been dropped.  BUT please do note that the patches I pushed tolinux-dm.git were rebased ontop of the 'check_at_most_once' patch.I never did get an answer about how the sg array is free'd in certainerror paths (see ""FIXME:"" in the 2nd patch).Also, I fixed some issues I saw in error paths, and lots of formatting.I'll be pretty frustrated if you submit v2 that is blind to the kinds ofchanges I made.I'll send you a private copy of the patches just so you have them foryour reference.Thanks,Mike",Non-technical
,
"Is this include needed ?Please use bool.I am quite completely missing how the two functions above are different.There is a lot of duplication in those functions. Would it be possibleto find common code and use functions for it instead of duplicatingeverything several times ?What if nothing is found ?FWIW, it might be better to pass channel - DEFAULT_CHANNEL_NUMSas parameter.What if find_core_index() returns priv->gen_info->core_max, ieif it didn't find a core ?This attribute should not exist.lcrit is tcontrol - tjmax, and crit_hyst above istjmax - tcontrol ? How does this make sense ?Am I missing something, or is the same temperature reported several times ?tjmax is also reported as temp_crit cputemp_read_die(), for example.There is again a lot of duplication in those functions.Can this be made less magic with some defines ?Does this mean there will be an error message for each non-supported CPU ?Why ?-ENODEV is not an error, and should not result in an error message.Besides, the error can also be propagated from peci core code,and may well be something else.Then what ? Shouldn't this result in probe deferral or something more usefulinstead of just being ignored ?FWIW, this should be two separate patches.Needed ?It might make sense to provide the duplicate functions in a core file.This again looks like duplicate code.Please handle error cases first.More duplicate code.One set of ( ) is unnecessary on each side of the expression.Why is this ""invalid"", and why does it warrant an error message ?Is priv->addr guaranteed to be >= PECI_BASE_ADDR ?Or the peci command failed.cancel_delayed_work_sync() ?",Non-technical
,
"Cool. I would say this is done right.How about writing an i2c bus driver which sits directly on top ofanother i2c bus? Basically a one port i2c mux.The current mux code does not seem to directly allow it, since itcalls i2c_transfer() directly on the parent, where as you want it tocall your own i2c_transfer function. But maybe you could expended thecore mux code to allow the i2c_mux_core structure to contain a transferfunction?      Andrew",Non-technical
